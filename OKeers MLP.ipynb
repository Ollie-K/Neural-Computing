{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "with open('data_full.json') as file:\n",
    "    oos = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['oos_val', 'val', 'train', 'oos_test', 'test', 'oos_train'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#listing files\n",
    "oos.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assembling files into pandas dataframes\n",
    "temp = oos['oos_val']\n",
    "oos_val = pd.DataFrame(temp).rename(columns={0:\"query\", 1:\"domain\"})\n",
    "temp = oos['val']\n",
    "val = pd.DataFrame(temp).rename(columns={0:\"query\", 1:\"domain\"})\n",
    "temp = oos['train']\n",
    "train = pd.DataFrame(temp).rename(columns={0:\"query\", 1:\"domain\"})\n",
    "temp = oos['oos_test']\n",
    "oos_test = pd.DataFrame(temp).rename(columns={0:\"query\", 1:\"domain\"})\n",
    "temp = oos['test']\n",
    "test = pd.DataFrame(temp).rename(columns={0:\"query\", 1:\"domain\"})\n",
    "temp = oos['oos_train']\n",
    "oos_train = pd.DataFrame(temp).rename(columns={0:\"query\", 1:\"domain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               query domain\n",
      "0  set a warning for when my bank account starts ...    oos\n",
      "1                                 a show on broadway    oos\n",
      "2                 who has the best record in the nfl    oos\n",
      "3                 how do i find the area of a circle    oos\n",
      "4                  how many onions do i have on hand    oos\n",
      "                                       query     domain\n",
      "0   in spanish, meet me tomorrow is said how  translate\n",
      "1     in french, how do i say, see you later  translate\n",
      "2           how do you say hello in japanese  translate\n",
      "3  how do i ask about the weather in chinese  translate\n",
      "4  how can i say \"cancel my order\" in french  translate\n",
      "                                               query     domain\n",
      "0  what expression would i use to say i love you ...  translate\n",
      "1  can you tell me how to say 'i do not speak muc...  translate\n",
      "2  what is the equivalent of, 'life is good' in f...  translate\n",
      "3  tell me how to say, 'it is a beautiful morning...  translate\n",
      "4  if i were mongolian, how would i say that i am...  translate\n",
      "                                               query domain\n",
      "0                 how much has the dow changed today    oos\n",
      "1  how many prime numbers are there between 0 and...    oos\n",
      "2  can you tell me how to solve simple algebraic ...    oos\n",
      "3            can you dim the brightness of my screen    oos\n",
      "4  what is the account number to the internet ser...    oos\n",
      "                                 query     domain\n",
      "0     how would you say fly in italian  translate\n",
      "1    what's the spanish word for pasta  translate\n",
      "2  how would they say butter in zambia  translate\n",
      "3       how do you say fast in spanish  translate\n",
      "4  what's the word for trees in norway  translate\n",
      "                                               query domain\n",
      "0              how much is an overdraft fee for bank    oos\n",
      "1  why are exponents preformed before multiplicat...    oos\n",
      "2                what size wipers does this car take    oos\n",
      "3                              where is the dipstick    oos\n",
      "4                        how much is 1 share of aapl    oos\n"
     ]
    }
   ],
   "source": [
    "#inspecting dataframes\n",
    "print(oos_val.head())\n",
    "print(val.head())\n",
    "print(train.head())\n",
    "print(oos_test.head())\n",
    "print(test.head())\n",
    "print(oos_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our training protocol will use the 'out of scope' training data to train for this class, so appending the data to one dataframe\n",
    "train = train.append(oos_train, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the vectorizer that will be used for this dataset\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the TFIDF vectorizer to the training data queries and transforming it\n",
    "X = vectorizer.fit_transform(train['query']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15100, 5146)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the size of the array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '005', '00am', '00pm', '01', '02', '03', '05', '098098', '10', '100', '1000', '10000', '100000', '10294', '104', '10500', '10am', '10kg']\n",
      "['zales', 'zander', 'zazie', 'zealand', 'zebras', 'zen', 'zenith', 'zepher', 'zephers', 'zeppelin', 'zesty', 'zeus', 'zion', 'zippy', 'zippys', 'ziti', 'zombie', 'zone', 'zoo', 'zulu']\n"
     ]
    }
   ],
   "source": [
    "#inspecting vectorizer features.\n",
    "print(vectorizer.get_feature_names()[:20])\n",
    "print(vectorizer.get_feature_names()[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These aren't all words, but this reflects the fact that inputs will not always be words. Equally some are variations (zippy/zippys) but these will be preserved to minimise the work done in preprocessing input data during deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe of X\n",
    "X_df = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15100, 5146)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of X dataframe\n",
    "X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15100, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of initial training dataframe\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining training dataframe to vectorized words\n",
    "train_vec = train.join(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15100, 5148)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding shape of joined dataframe\n",
    "train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>domain</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>5136</th>\n",
       "      <th>5137</th>\n",
       "      <th>5138</th>\n",
       "      <th>5139</th>\n",
       "      <th>5140</th>\n",
       "      <th>5141</th>\n",
       "      <th>5142</th>\n",
       "      <th>5143</th>\n",
       "      <th>5144</th>\n",
       "      <th>5145</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what expression would i use to say i love you ...</td>\n",
       "      <td>translate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>can you tell me how to say 'i do not speak muc...</td>\n",
       "      <td>translate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the equivalent of, 'life is good' in f...</td>\n",
       "      <td>translate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tell me how to say, 'it is a beautiful morning...</td>\n",
       "      <td>translate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if i were mongolian, how would i say that i am...</td>\n",
       "      <td>translate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query     domain    0    1  \\\n",
       "0  what expression would i use to say i love you ...  translate  0.0  0.0   \n",
       "1  can you tell me how to say 'i do not speak muc...  translate  0.0  0.0   \n",
       "2  what is the equivalent of, 'life is good' in f...  translate  0.0  0.0   \n",
       "3  tell me how to say, 'it is a beautiful morning...  translate  0.0  0.0   \n",
       "4  if i were mongolian, how would i say that i am...  translate  0.0  0.0   \n",
       "\n",
       "     2    3    4    5    6    7  ...  5136  5137  5138  5139  5140  5141  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   5142  5143  5144  5145  \n",
       "0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 5148 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspecting first few rows of dataframe\n",
    "train_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the text queries\n",
    "train_vec = train_vec.drop('query', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000    15095\n",
       "0.744097        1\n",
       "0.731775        1\n",
       "0.694293        1\n",
       "0.577886        1\n",
       "0.698728        1\n",
       "Name: 5136, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting values of a randomly chosen column to check that not all entries are 0.0\n",
    "train_vec[5136].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['translate', 'transfer', 'timer', 'definition', 'meaning_of_life',\n",
       "       'insurance_change', 'find_phone', 'travel_alert', 'pto_request',\n",
       "       'improve_credit_score', 'fun_fact', 'change_language', 'payday',\n",
       "       'replacement_card_duration', 'time', 'application_status',\n",
       "       'flight_status', 'flip_coin', 'change_user_name',\n",
       "       'where_are_you_from', 'shopping_list_update', 'what_can_i_ask_you',\n",
       "       'maybe', 'oil_change_how', 'restaurant_reservation', 'balance',\n",
       "       'confirm_reservation', 'freeze_account', 'rollover_401k',\n",
       "       'who_made_you', 'distance', 'user_name', 'timezone', 'next_song',\n",
       "       'transactions', 'restaurant_suggestion', 'rewards_balance',\n",
       "       'pay_bill', 'spending_history', 'pto_request_status',\n",
       "       'credit_score', 'new_card', 'lost_luggage', 'repeat', 'mpg',\n",
       "       'oil_change_when', 'yes', 'travel_suggestion', 'insurance',\n",
       "       'todo_list_update', 'reminder', 'change_speed', 'tire_pressure',\n",
       "       'no', 'apr', 'nutrition_info', 'calendar', 'uber', 'calculator',\n",
       "       'date', 'carry_on', 'pto_used', 'schedule_maintenance',\n",
       "       'travel_notification', 'sync_device', 'thank_you', 'roll_dice',\n",
       "       'food_last', 'cook_time', 'reminder_update', 'report_lost_card',\n",
       "       'ingredient_substitution', 'make_call', 'alarm', 'todo_list',\n",
       "       'change_accent', 'w2', 'bill_due', 'calories', 'damaged_card',\n",
       "       'restaurant_reviews', 'routing', 'do_you_have_pets',\n",
       "       'schedule_meeting', 'gas_type', 'plug_type', 'tire_change',\n",
       "       'exchange_rate', 'next_holiday', 'change_volume',\n",
       "       'who_do_you_work_for', 'credit_limit', 'how_busy',\n",
       "       'accept_reservations', 'order_status', 'pin_change', 'goodbye',\n",
       "       'account_blocked', 'what_song', 'international_fees',\n",
       "       'last_maintenance', 'meeting_schedule', 'ingredients_list',\n",
       "       'report_fraud', 'measurement_conversion', 'smart_home',\n",
       "       'book_hotel', 'current_location', 'weather', 'taxes',\n",
       "       'min_payment', 'whisper_mode', 'cancel', 'international_visa',\n",
       "       'vaccines', 'pto_balance', 'directions', 'spelling', 'greeting',\n",
       "       'reset_settings', 'what_is_your_name', 'direct_deposit',\n",
       "       'interest_rate', 'credit_limit_change', 'what_are_your_hobbies',\n",
       "       'book_flight', 'shopping_list', 'text', 'bill_balance',\n",
       "       'share_location', 'redeem_rewards', 'play_music',\n",
       "       'calendar_update', 'are_you_a_bot', 'gas', 'expiration_date',\n",
       "       'update_playlist', 'cancel_reservation', 'tell_joke',\n",
       "       'change_ai_name', 'how_old_are_you', 'car_rental', 'jump_start',\n",
       "       'meal_suggestion', 'recipe', 'income', 'order', 'traffic',\n",
       "       'order_checks', 'card_declined', 'oos'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting unique domains\n",
    "train_vec['domain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constructing a mapping dictionary for domains to tranform them into nubmers\n",
    "y_dic = {}\n",
    "domain = 0\n",
    "for item in train_vec['domain'].unique():\n",
    "    y_dic[item] = domain\n",
    "    domain += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>5136</th>\n",
       "      <th>5137</th>\n",
       "      <th>5138</th>\n",
       "      <th>5139</th>\n",
       "      <th>5140</th>\n",
       "      <th>5141</th>\n",
       "      <th>5142</th>\n",
       "      <th>5143</th>\n",
       "      <th>5144</th>\n",
       "      <th>5145</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8218</th>\n",
       "      <td>do_you_have_pets</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8136</th>\n",
       "      <td>routing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>insurance_change</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7446</th>\n",
       "      <td>todo_list</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>pto_request_status</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  domain    0    1    2    3    4    5    6    7    8  ...  \\\n",
       "8218    do_you_have_pets  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "8136             routing  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "577     insurance_change  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "7446           todo_list  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3978  pto_request_status  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "      5136  5137  5138  5139  5140  5141  5142  5143  5144  5145  \n",
       "8218   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "8136   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "577    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "7446   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3978   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 5147 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffling training data\n",
    "train_vec = shuffle(train_vec, random_state=0)\n",
    "train_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a column of target values\n",
    "train_vec['y'] = train_vec['domain'].replace(y_dic)\n",
    "#removing the text domains\n",
    "train_vec = train_vec.iloc[:, 1:]\n",
    "#defining x and y data\n",
    "train_x = train_vec.iloc[:,:-1]\n",
    "train_y = train_vec.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming queries from other datasets to vectors\n",
    "Xv = vectorizer.transform(val['query']).toarray()\n",
    "Xvo = vectorizer.transform(oos_val['query']).toarray()\n",
    "Xtest = vectorizer.transform(test['query']).toarray()\n",
    "Xto = vectorizer.transform(oos_test['query']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning arrays to dataframes\n",
    "Xv_df = pd.DataFrame(Xv)\n",
    "Xvo_df = pd.DataFrame(Xvo)\n",
    "Xtest_df = pd.DataFrame(Xtest)\n",
    "Xto_df = pd.DataFrame(Xto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating vector datasets for validation set (excluding out of scope values)\n",
    "val_vec = pd.concat([val, Xv_df], axis=1)\n",
    "val_vec = val_vec.drop('query', axis=1)\n",
    "val_vec = shuffle(val_vec, random_state=0)\n",
    "val_vec['y'] = val_vec['domain'].replace(y_dic)\n",
    "val = val_vec.iloc[:, 1:]\n",
    "val_x = val.iloc[:,:-1]\n",
    "val_y = val.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating vector datasets for out of scope validation set\n",
    "val_oos_vec = pd.concat([oos_val, Xvo_df], axis=1)\n",
    "val_oos_vec = val_oos_vec.drop('query', axis=1)\n",
    "val_oos_vec = shuffle(val_oos_vec, random_state=0)\n",
    "val_oos_vec['y'] = val_oos_vec['domain'].replace(y_dic)\n",
    "val_oos = val_oos_vec.iloc[:, 1:]\n",
    "val_oos_x = val_oos.iloc[:,:-1]\n",
    "val_oos_y = val_oos.iloc[:,-1]\n",
    "val_full = val.append(val_oos, ignore_index=True)\n",
    "val_full_x = val_full.iloc[:,:-1]\n",
    "val_full_y = val_full.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating vector datasets for testing set (excluding out of scope values)\n",
    "test_vec = pd.concat([test, Xtest_df], axis=1)\n",
    "test_vec = test_vec.drop('query', axis=1)\n",
    "test_vec = shuffle(test_vec, random_state=0)\n",
    "test_vec['y']= test_vec['domain'].replace(y_dic)\n",
    "test = test_vec.iloc[:, 1:]\n",
    "test_x = test.iloc[:,:-1]\n",
    "test_y = test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating vector datasets for out of scope testing set\n",
    "test_oos_vec = pd.concat([oos_test, Xto_df], axis=1)\n",
    "test_oos_vec = test_oos_vec.drop('query', axis=1)\n",
    "test_oos_vec = shuffle(test_oos_vec, random_state=0)\n",
    "test_oos_vec['y'] = test_oos_vec['domain'].replace(y_dic)\n",
    "test_oos = test_oos_vec.iloc[:, 1:]\n",
    "test_oos_x = test.iloc[:,:-1]\n",
    "test_oos_y = test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing torch packages\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial MLP using parameters from reference paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining perceptron dimensions\n",
    "vocab_dim = 5146 #number of words in the vocabulary\n",
    "hidden_dim = 400 #number of neurons in hidden layer\n",
    "output_dim = 151 #number of classes (150 in scope plus Out of Scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assembling training arrays.\n",
    "train_y = np.array(train_y)\n",
    "train_x = np.array(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining multilayer perceptron\n",
    "class CLINCModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim=vocab_dim, #setting input dimensions\n",
    "            hidden_dim=hidden_dim, #setting hidden layer dimensions\n",
    "            output_dim=output_dim, #setting output dimensions\n",
    "            dropout=0 #setting a dropout rate\n",
    "    ):\n",
    "        super(CLINCModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout) #defining the dropout function\n",
    "\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim) #defining the hidden layer function\n",
    "        self.output = nn.Linear(hidden_dim, output_dim) #defining the output layer function\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = torch.tanh(self.hidden(X)) #applying a tanh activation function to outputs from the hidden layer\n",
    "        X = self.dropout(X) #applying the dropout function\n",
    "        X = F.softmax(self.output(X), dim=-1) #applying the softmax function to the outputs\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing skorch modules\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import EarlyStopping\n",
    "from skorch.dataset import Dataset\n",
    "from skorch.helper import predefined_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming data to tensors\n",
    "train_x = torch.tensor(train_x).float()\n",
    "val_full_x = torch.tensor(np.array(val_full_x)).float()\n",
    "val_x = torch.tensor(np.array(val_x)).float()\n",
    "val_oos_x = torch.tensor(np.array(val_oos_x)).float()\n",
    "test_x = torch.tensor(np.array(test_x)).float()\n",
    "test_oos_x = torch.tensor(np.array(test_oos_x)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming targets to arrays\n",
    "val_full_y = np.array(val_full_y)\n",
    "val_y = np.array(val_y)\n",
    "val_oos_y = np.array(val_oos_y)\n",
    "test_y = np.array(test_y)\n",
    "test_oos_y = np.array(test_oos_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising the classifier\n",
    "net = NeuralNetClassifier( #a neural network classifier\n",
    "    module=CLINCModule, #use the MLP defined previously\n",
    "    criterion=torch.nn.CrossEntropyLoss, #using Cross Entropy Loss as the loss function, due to being a multiclass classification problem\n",
    "    max_epochs=1000, #defining the maximum number of epochs\n",
    "    optimizer=torch.optim.SGD, #using stochastic gradient descent for optimization\n",
    "    callbacks=[EarlyStopping(patience=5)], #implementing early stopping with a patience of 5 epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0046\u001b[0m        \u001b[35m5.0173\u001b[0m  2.8404\n",
      "      2        \u001b[36m5.0173\u001b[0m       0.0046        \u001b[35m5.0173\u001b[0m  2.5806\n",
      "      3        \u001b[36m5.0173\u001b[0m       0.0046        5.0173  2.5644\n",
      "      4        \u001b[36m5.0173\u001b[0m       0.0046        \u001b[35m5.0173\u001b[0m  2.5759\n",
      "      5        \u001b[36m5.0173\u001b[0m       0.0046        5.0173  2.6285\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=CLINCModule(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (hidden): Linear(in_features=5146, out_features=400, bias=True)\n",
       "    (output): Linear(in_features=400, out_features=151, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the classifier to the training data\n",
    "net.fit(train_x, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy\n",
      "0.005298013245033113\n",
      "Val accuracy\n",
      "0.003\n",
      "pred time\n",
      "0.3200225830078125\n",
      "OOS Val Accuracy\n",
      "0.23\n",
      "OOS pred time\n",
      "0.01287078857421875\n"
     ]
    }
   ],
   "source": [
    "tlabels = net.predict(train_x) #using the trained model to predict from training data\n",
    "tacc = accuracy_score(tlabels, train_y) #comparing predicted domains to actual classes using classification accuracy\n",
    "print('training accuracy')\n",
    "print(tacc) #printing the training accuracy\n",
    "time0 = time.time() # timer\n",
    "labels = net.predict(val_x) #predicting validation set\n",
    "acc = accuracy_score(labels, val_y) #calculating accuracy score for validation predictions\n",
    "time1 = time.time() # timer\n",
    "print('Val accuracy')\n",
    "print(acc) #printing validation accuracy\n",
    "print('pred time')\n",
    "print(time1-time0) #printing validation prediction time\n",
    "time2 = time.time() # timer\n",
    "olabels = net.predict(val_oos_x) # predicting for Out of Scope Validation set\n",
    "oos_acc = accuracy_score(olabels, val_oos_y) #calculating accuracy score for OOS validation predictions\n",
    "time3 = time.time() # timer\n",
    "print('OOS Val Accuracy')\n",
    "print(oos_acc) #printing OOS validation accuracy\n",
    "print('OOS pred time')\n",
    "print(time3-time2) #printing OOS validation prediction time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converged too quickly, likely not in global minimum. Will reattempt using different dropouts, learning rates, momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0033\u001b[0m        \u001b[35m5.0173\u001b[0m  2.7095\n",
      "      2        \u001b[36m5.0173\u001b[0m       0.0033        5.0173  2.5825\n",
      "      3        \u001b[36m5.0173\u001b[0m       0.0033        5.0173  2.5890\n",
      "      4        5.0173       0.0033        5.0173  2.5863\n",
      "      5        \u001b[36m5.0173\u001b[0m       0.0033        \u001b[35m5.0173\u001b[0m  2.5609\n",
      "      6        5.0173       0.0033        5.0173  2.5750\n",
      "      7        \u001b[36m5.0173\u001b[0m       0.0033        5.0173  2.5444\n",
      "      8        \u001b[36m5.0173\u001b[0m       0.0033        5.0173  2.5716\n",
      "      9        5.0173       0.0033        5.0173  2.5837\n",
      "     10        \u001b[36m5.0173\u001b[0m       0.0033        5.0173  2.6356\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{1: 0.0035099337748344373}\n",
      "Val accuracy\n",
      "{1: 0.006333333333333333}\n",
      "pred time\n",
      "{1: 0.2524840831756592}\n",
      "OOS Val Accuracy\n",
      "{1: 0.0}\n",
      "OOS pred time\n",
      "{1: 0.008231878280639648}\n",
      "0.5\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0060\u001b[0m        \u001b[35m5.0173\u001b[0m  2.7288\n",
      "      2        \u001b[36m5.0173\u001b[0m       0.0060        5.0173  2.8022\n",
      "      3        \u001b[36m5.0173\u001b[0m       0.0060        \u001b[35m5.0173\u001b[0m  2.8299\n",
      "      4        \u001b[36m5.0173\u001b[0m       0.0060        5.0173  2.7363\n",
      "      5        5.0173       0.0060        \u001b[35m5.0173\u001b[0m  2.6902\n",
      "      6        5.0173       0.0060        5.0173  2.6544\n",
      "      7        5.0173       0.0060        5.0173  2.6593\n",
      "      8        5.0173       0.0060        \u001b[35m5.0173\u001b[0m  2.6746\n",
      "      9        5.0173       0.0060        \u001b[35m5.0173\u001b[0m  2.6849\n",
      "     10        5.0173       0.0060        \u001b[35m5.0173\u001b[0m  2.6407\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{1: 0.0035099337748344373, 0.5: 0.004437086092715232}\n",
      "Val accuracy\n",
      "{1: 0.006333333333333333, 0.5: 0.006333333333333333}\n",
      "pred time\n",
      "{1: 0.2524840831756592, 0.5: 0.25479769706726074}\n",
      "OOS Val Accuracy\n",
      "{1: 0.0, 0.5: 0.0}\n",
      "OOS pred time\n",
      "{1: 0.008231878280639648, 0.5: 0.011022090911865234}\n",
      "0.1\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0079\u001b[0m        \u001b[35m5.0173\u001b[0m  2.6367\n",
      "      2        \u001b[36m5.0173\u001b[0m       0.0079        5.0173  2.6428\n",
      "      3        5.0173       0.0079        5.0173  2.6591\n",
      "      4        \u001b[36m5.0173\u001b[0m       0.0079        5.0173  2.6621\n",
      "      5        \u001b[36m5.0173\u001b[0m       0.0079        \u001b[35m5.0173\u001b[0m  2.6492\n",
      "      6        5.0173       0.0079        \u001b[35m5.0173\u001b[0m  2.6101\n",
      "      7        5.0173       0.0079        \u001b[35m5.0173\u001b[0m  2.6387\n",
      "      8        \u001b[36m5.0173\u001b[0m       0.0079        5.0173  2.6502\n",
      "      9        5.0173       0.0079        \u001b[35m5.0173\u001b[0m  2.6682\n",
      "     10        \u001b[36m5.0173\u001b[0m       0.0079        \u001b[35m5.0173\u001b[0m  2.6442\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{1: 0.0035099337748344373, 0.5: 0.004437086092715232, 0.1: 0.008543046357615894}\n",
      "Val accuracy\n",
      "{1: 0.006333333333333333, 0.5: 0.006333333333333333, 0.1: 0.010333333333333333}\n",
      "pred time\n",
      "{1: 0.2524840831756592, 0.5: 0.25479769706726074, 0.1: 0.24672174453735352}\n",
      "OOS Val Accuracy\n",
      "{1: 0.0, 0.5: 0.0, 0.1: 0.0}\n",
      "OOS pred time\n",
      "{1: 0.008231878280639648, 0.5: 0.011022090911865234, 0.1: 0.00803995132446289}\n"
     ]
    }
   ],
   "source": [
    "dropouts = [1, 0.5, 0.1] #defining potential dropout values\n",
    "tacc={} #initialising training accuracy results dictionary\n",
    "vacc = {} #initialising validation accuracy results dictionary\n",
    "vtime = {} #initialising validation time dictionary\n",
    "oacc = {} #initialising OOS Validation accuracy results dictionary\n",
    "otime = {} #initialising OOS validation time dictionary\n",
    "for d in dropouts:    #looping over dropout values\n",
    "    print(d) #print the dropout rate\n",
    "    class CLINCModule(nn.Module): #define the module, as per above\n",
    "        def __init__(\n",
    "                self,\n",
    "                input_dim=vocab_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim,\n",
    "                dropout=d #looping through this value\n",
    "        ):\n",
    "            super(CLINCModule, self).__init__()\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "            self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = torch.tanh(self.hidden(X))\n",
    "            X = self.dropout(X)\n",
    "            X = F.softmax(self.output(X), dim=-1)\n",
    "            return X\n",
    "   #initialising the model as above\n",
    "    net = NeuralNetClassifier(\n",
    "    module=CLINCModule,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    max_epochs=1000,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    callbacks=[EarlyStopping(patience=10)], #Bigger early stopping patience of 10 epochs\n",
    "    )\n",
    "    \n",
    "    #fitting model and calculating results\n",
    "    net.fit(train_x, train_y) #fitting to training data\n",
    "    tlabels = net.predict(train_x) #predicting from training data\n",
    "    tacc[d] = accuracy_score(tlabels, train_y) #calculating training accuracy and storing it in dict\n",
    "    print('training accuracy')\n",
    "    print(tacc) #printing full training accuracy dict\n",
    "    time0 = time.time() #timer\n",
    "    labels = net.predict(val_x) #predicting validation data\n",
    "    vacc[d] = accuracy_score(labels, val_y) #calculating validation accuracy and storing it in dict\n",
    "    time1 = time.time() # timer\n",
    "    vtime[d] = time1-time0 #calculating validation prediction time & storing in dict \n",
    "    print('Val accuracy')\n",
    "    print(vacc) #printing full validation accuracy dict\n",
    "    print('pred time')\n",
    "    print(vtime) #printing full validation prediction time dict\n",
    "    time2 = time.time() #timer\n",
    "    olabels = net.predict(val_oos_x) #predicting OOS validation data\n",
    "    oacc[d] = accuracy_score(olabels, val_oos_y) #calculating OOS validation accuracy and storing in dict\n",
    "    time3 = time.time() #timer\n",
    "    otime[d]=time3-time2 #calculating OOS validation prediction time & storing in dict\n",
    "    print('OOS Val Accuracy')\n",
    "    print(oacc)# printing full OOS validation accuracy dict\n",
    "    print('OOS pred time')\n",
    "    print(otime) #printing full OOS validation prediction time dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0169\u001b[0m        \u001b[35m5.0173\u001b[0m  2.7157\n",
      "      2        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0348\u001b[0m        \u001b[35m5.0172\u001b[0m  2.6195\n",
      "      3        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0540\u001b[0m        \u001b[35m5.0172\u001b[0m  2.6411\n",
      "      4        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0728\u001b[0m        \u001b[35m5.0172\u001b[0m  2.6060\n",
      "      5        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0954\u001b[0m        \u001b[35m5.0172\u001b[0m  2.5968\n",
      "      6        \u001b[36m5.0172\u001b[0m       \u001b[32m0.1185\u001b[0m        \u001b[35m5.0172\u001b[0m  2.5800\n",
      "      7        \u001b[36m5.0171\u001b[0m       \u001b[32m0.1348\u001b[0m        \u001b[35m5.0171\u001b[0m  2.5846\n",
      "      8        \u001b[36m5.0171\u001b[0m       \u001b[32m0.1513\u001b[0m        \u001b[35m5.0171\u001b[0m  2.6166\n",
      "      9        \u001b[36m5.0171\u001b[0m       \u001b[32m0.1705\u001b[0m        \u001b[35m5.0171\u001b[0m  2.6094\n",
      "     10        \u001b[36m5.0171\u001b[0m       \u001b[32m0.1911\u001b[0m        \u001b[35m5.0171\u001b[0m  2.6303\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.21410596026490067}\n",
      "Val accuracy\n",
      "{10: 0.19633333333333333}\n",
      "pred time\n",
      "{0.1: 0.24280714988708496}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.008342981338500977}\n",
      "5\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0126\u001b[0m        \u001b[35m5.0173\u001b[0m  2.5908\n",
      "      2        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0152\u001b[0m        \u001b[35m5.0173\u001b[0m  2.6018\n",
      "      3        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0205\u001b[0m        \u001b[35m5.0172\u001b[0m  2.5847\n",
      "      4        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0268\u001b[0m        \u001b[35m5.0172\u001b[0m  2.6483\n",
      "      5        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0334\u001b[0m        \u001b[35m5.0172\u001b[0m  2.6130\n",
      "      6        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0470\u001b[0m        \u001b[35m5.0172\u001b[0m  2.5997\n",
      "      7        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0606\u001b[0m        \u001b[35m5.0172\u001b[0m  2.5779\n",
      "      8        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0642\u001b[0m        \u001b[35m5.0172\u001b[0m  2.5844\n",
      "      9        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0725\u001b[0m        \u001b[35m5.0172\u001b[0m  2.5956\n",
      "     10        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0778\u001b[0m        \u001b[35m5.0172\u001b[0m  2.5866\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.21410596026490067, 5: 0.08827814569536424}\n",
      "Val accuracy\n",
      "{10: 0.19633333333333333, 5: 0.084}\n",
      "pred time\n",
      "{0.1: 0.24246692657470703}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.008342981338500977, 5: 0.00878000259399414}\n",
      "1\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0043\u001b[0m        \u001b[35m5.0173\u001b[0m  2.6032\n",
      "      2        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0053\u001b[0m        \u001b[35m5.0173\u001b[0m  2.6176\n",
      "      3        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0063\u001b[0m        \u001b[35m5.0173\u001b[0m  2.5949\n",
      "      4        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0070\u001b[0m        \u001b[35m5.0173\u001b[0m  2.6284\n",
      "      5        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0093\u001b[0m        \u001b[35m5.0173\u001b[0m  2.5905\n",
      "      6        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0103\u001b[0m        \u001b[35m5.0173\u001b[0m  2.5960\n",
      "      7        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0119\u001b[0m        \u001b[35m5.0173\u001b[0m  2.5957\n",
      "      8        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0129\u001b[0m        \u001b[35m5.0173\u001b[0m  2.5940\n",
      "      9        \u001b[36m5.0173\u001b[0m       0.0129        \u001b[35m5.0173\u001b[0m  2.6258\n",
      "     10        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0149\u001b[0m        \u001b[35m5.0173\u001b[0m  2.5895\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.21410596026490067, 5: 0.08827814569536424, 1: 0.01695364238410596}\n",
      "Val accuracy\n",
      "{10: 0.19633333333333333, 5: 0.084, 1: 0.018}\n",
      "pred time\n",
      "{0.1: 0.24679803848266602}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0, 1: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.008342981338500977, 5: 0.00878000259399414, 1: 0.008368253707885742}\n",
      "0.5\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0043\u001b[0m        \u001b[35m5.0173\u001b[0m  2.6098\n",
      "      2        \u001b[36m5.0173\u001b[0m       0.0043        \u001b[35m5.0173\u001b[0m  2.5971\n",
      "      3        \u001b[36m5.0173\u001b[0m       0.0043        \u001b[35m5.0173\u001b[0m  2.6280\n",
      "      4        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0053\u001b[0m        \u001b[35m5.0173\u001b[0m  2.6083\n",
      "      5        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0063\u001b[0m        \u001b[35m5.0173\u001b[0m  2.6393\n",
      "      6        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0066\u001b[0m        \u001b[35m5.0173\u001b[0m  2.5981\n",
      "      7        \u001b[36m5.0173\u001b[0m       0.0066        \u001b[35m5.0173\u001b[0m  2.6179\n",
      "      8        \u001b[36m5.0173\u001b[0m       0.0066        \u001b[35m5.0173\u001b[0m  2.6124\n",
      "      9        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0073\u001b[0m        \u001b[35m5.0173\u001b[0m  2.6223\n",
      "     10        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0076\u001b[0m        \u001b[35m5.0173\u001b[0m  2.6902\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.21410596026490067, 5: 0.08827814569536424, 1: 0.01695364238410596, 0.5: 0.00814569536423841}\n",
      "Val accuracy\n",
      "{10: 0.19633333333333333, 5: 0.084, 1: 0.018, 0.5: 0.009666666666666667}\n",
      "pred time\n",
      "{0.1: 0.2576870918273926}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0, 1: 0.0, 0.5: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.008342981338500977, 5: 0.00878000259399414, 1: 0.008368253707885742, 0.5: 0.008599042892456055}\n",
      "0.1\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0050\u001b[0m        \u001b[35m5.0173\u001b[0m  2.6438\n",
      "      2        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0053\u001b[0m        \u001b[35m5.0173\u001b[0m  2.6157\n",
      "      3        \u001b[36m5.0173\u001b[0m       0.0053        \u001b[35m5.0173\u001b[0m  2.6610\n",
      "      4        \u001b[36m5.0173\u001b[0m       0.0053        \u001b[35m5.0173\u001b[0m  2.6537\n",
      "      5        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0056\u001b[0m        \u001b[35m5.0173\u001b[0m  2.6091\n",
      "      6        \u001b[36m5.0173\u001b[0m       0.0056        \u001b[35m5.0173\u001b[0m  2.6450\n",
      "      7        \u001b[36m5.0173\u001b[0m       0.0056        \u001b[35m5.0173\u001b[0m  2.6033\n",
      "      8        \u001b[36m5.0173\u001b[0m       0.0056        \u001b[35m5.0173\u001b[0m  2.6162\n",
      "      9        \u001b[36m5.0173\u001b[0m       0.0056        \u001b[35m5.0173\u001b[0m  2.6678\n",
      "     10        \u001b[36m5.0173\u001b[0m       0.0056        \u001b[35m5.0173\u001b[0m  2.7253\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.21410596026490067, 5: 0.08827814569536424, 1: 0.01695364238410596, 0.5: 0.00814569536423841, 0.1: 0.004172185430463576}\n",
      "Val accuracy\n",
      "{10: 0.19633333333333333, 5: 0.084, 1: 0.018, 0.5: 0.009666666666666667, 0.1: 0.0033333333333333335}\n",
      "pred time\n",
      "{0.1: 0.2735140323638916}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0, 1: 0.0, 0.5: 0.0, 0.1: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.008342981338500977, 5: 0.00878000259399414, 1: 0.008368253707885742, 0.5: 0.008599042892456055, 0.1: 0.008755922317504883}\n",
      "0.01\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0046\u001b[0m        \u001b[35m5.0173\u001b[0m  2.6361\n",
      "      2        \u001b[36m5.0173\u001b[0m       0.0046        \u001b[35m5.0173\u001b[0m  2.6519\n",
      "      3        \u001b[36m5.0173\u001b[0m       0.0046        5.0173  2.6801\n",
      "      4        \u001b[36m5.0173\u001b[0m       0.0046        \u001b[35m5.0173\u001b[0m  2.6814\n",
      "      5        \u001b[36m5.0173\u001b[0m       0.0046        5.0173  2.7029\n",
      "      6        \u001b[36m5.0173\u001b[0m       0.0046        5.0173  2.7987\n",
      "      7        \u001b[36m5.0173\u001b[0m       0.0046        5.0173  2.7517\n",
      "      8        \u001b[36m5.0173\u001b[0m       0.0046        \u001b[35m5.0173\u001b[0m  2.7425\n",
      "      9        \u001b[36m5.0173\u001b[0m       0.0046        5.0173  2.7128\n",
      "     10        \u001b[36m5.0173\u001b[0m       0.0046        \u001b[35m5.0173\u001b[0m  2.6883\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.21410596026490067, 5: 0.08827814569536424, 1: 0.01695364238410596, 0.5: 0.00814569536423841, 0.1: 0.004172185430463576, 0.01: 0.004503311258278146}\n",
      "Val accuracy\n",
      "{10: 0.19633333333333333, 5: 0.084, 1: 0.018, 0.5: 0.009666666666666667, 0.1: 0.0033333333333333335, 0.01: 0.006666666666666667}\n",
      "pred time\n",
      "{0.1: 0.2539210319519043}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0, 1: 0.0, 0.5: 0.0, 0.1: 0.0, 0.01: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.008342981338500977, 5: 0.00878000259399414, 1: 0.008368253707885742, 0.5: 0.008599042892456055, 0.1: 0.008755922317504883, 0.01: 0.008543968200683594}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0073\u001b[0m        \u001b[35m5.0173\u001b[0m  2.6826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m5.0173\u001b[0m       0.0073        5.0173  2.6848\n",
      "      3        \u001b[36m5.0173\u001b[0m       0.0073        5.0173  2.6724\n",
      "      4        5.0173       0.0073        5.0173  2.6982\n",
      "      5        \u001b[36m5.0173\u001b[0m       0.0073        5.0173  2.7871\n",
      "      6        \u001b[36m5.0173\u001b[0m       0.0073        5.0173  2.7626\n",
      "      7        \u001b[36m5.0173\u001b[0m       0.0073        5.0173  2.7045\n",
      "      8        5.0173       0.0073        5.0173  2.6944\n",
      "      9        \u001b[36m5.0173\u001b[0m       0.0073        5.0173  2.7003\n",
      "     10        5.0173       0.0073        5.0173  2.6909\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.21410596026490067, 5: 0.08827814569536424, 1: 0.01695364238410596, 0.5: 0.00814569536423841, 0.1: 0.004172185430463576, 0.01: 0.004503311258278146, 0.001: 0.008013245033112583}\n",
      "Val accuracy\n",
      "{10: 0.19633333333333333, 5: 0.084, 1: 0.018, 0.5: 0.009666666666666667, 0.1: 0.0033333333333333335, 0.01: 0.006666666666666667, 0.001: 0.007}\n",
      "pred time\n",
      "{0.1: 0.2646620273590088}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0, 1: 0.0, 0.5: 0.0, 0.1: 0.0, 0.01: 0.0, 0.001: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.008342981338500977, 5: 0.00878000259399414, 1: 0.008368253707885742, 0.5: 0.008599042892456055, 0.1: 0.008755922317504883, 0.01: 0.008543968200683594, 0.001: 0.009671926498413086}\n",
      "0.0001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0070\u001b[0m        \u001b[35m5.0173\u001b[0m  2.6774\n",
      "      2        5.0173       0.0070        5.0173  2.6852\n",
      "      3        5.0173       0.0070        5.0173  2.6919\n",
      "      4        5.0173       0.0070        5.0173  2.6956\n",
      "      5        5.0173       0.0070        5.0173  2.6374\n",
      "      6        5.0173       0.0070        5.0173  2.6732\n",
      "      7        5.0173       0.0070        5.0173  2.6785\n",
      "      8        5.0173       0.0070        5.0173  2.6550\n",
      "      9        5.0173       0.0070        5.0173  2.6755\n",
      "     10        5.0173       0.0070        5.0173  2.6597\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.21410596026490067, 5: 0.08827814569536424, 1: 0.01695364238410596, 0.5: 0.00814569536423841, 0.1: 0.004172185430463576, 0.01: 0.004503311258278146, 0.001: 0.008013245033112583, 0.0001: 0.007880794701986755}\n",
      "Val accuracy\n",
      "{10: 0.19633333333333333, 5: 0.084, 1: 0.018, 0.5: 0.009666666666666667, 0.1: 0.0033333333333333335, 0.01: 0.006666666666666667, 0.001: 0.007, 0.0001: 0.007}\n",
      "pred time\n",
      "{0.1: 0.2577648162841797}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0, 1: 0.0, 0.5: 0.0, 0.1: 0.0, 0.01: 0.0, 0.001: 0.0, 0.0001: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.008342981338500977, 5: 0.00878000259399414, 1: 0.008368253707885742, 0.5: 0.008599042892456055, 0.1: 0.008755922317504883, 0.01: 0.008543968200683594, 0.001: 0.009671926498413086, 0.0001: 0.008495807647705078}\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [10, 5, 1, 0.5, 0.1, 0.01, 0.001, 0.0001] #looking at different learning rates\n",
    "#emptying results dicts\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "for lr in learning_rates: #looping through different learning rates   \n",
    "    print(lr)\n",
    "    class CLINCModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                input_dim=vocab_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim,\n",
    "                dropout=0\n",
    "        ):\n",
    "            super(CLINCModule, self).__init__()\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "            self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = torch.tanh(self.hidden(X))\n",
    "            X = self.dropout(X)\n",
    "            X = F.softmax(self.output(X), dim=-1)\n",
    "            return X\n",
    "   \n",
    "    net = NeuralNetClassifier(\n",
    "    module=CLINCModule,\n",
    "    lr=lr, #looping through different learning rates\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    max_epochs=1000,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    callbacks=[EarlyStopping(patience=10)],\n",
    "    )\n",
    "    \n",
    "    net.fit(train_x, train_y)\n",
    "    tlabels = net.predict(train_x)\n",
    "    tacc[lr] = accuracy_score(tlabels, train_y)\n",
    "    print('training accuracy')\n",
    "    print(tacc)\n",
    "    time0 = time.time()\n",
    "    labels = net.predict(val_x)\n",
    "    vacc[lr] = accuracy_score(labels, val_y)\n",
    "    time1 = time.time()\n",
    "    vtime[d] = time1-time0\n",
    "    print('Val accuracy')\n",
    "    print(vacc)\n",
    "    print('pred time')\n",
    "    print(vtime)\n",
    "    time2 = time.time()\n",
    "    olabels = net.predict(val_oos_x)\n",
    "    oacc[lr] = accuracy_score(olabels, val_oos_y)\n",
    "    time3 = time.time()\n",
    "    otime[lr]=time3-time2\n",
    "    print('OOS Val Accuracy')\n",
    "    print(oacc)\n",
    "    print('OOS pred time')\n",
    "    print(otime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           nan       \u001b[32m0.0066\u001b[0m           nan  2.9037\n",
      "      2           nan       0.0066           nan  2.8744\n",
      "      3           nan       0.0066           nan  2.8993\n",
      "      4           nan       0.0066           nan  2.8462\n",
      "      5           nan       0.0066           nan  2.8437\n",
      "      6           nan       0.0066           nan  2.8491\n",
      "      7           nan       0.0066           nan  2.8397\n",
      "      8           nan       0.0066           nan  2.8402\n",
      "      9           nan       0.0066           nan  2.8399\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667}\n",
      "pred time\n",
      "{0.1: 0.24516987800598145}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.008492708206176758}\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           nan       \u001b[32m0.0066\u001b[0m           nan  2.8537\n",
      "      2           nan       0.0066           nan  2.9015\n",
      "      3           nan       0.0066           nan  2.8765\n",
      "      4           nan       0.0066           nan  2.9189\n",
      "      5           nan       0.0066           nan  2.8639\n",
      "      6           nan       0.0066           nan  3.0109\n",
      "      7           nan       0.0066           nan  2.9334\n",
      "      8           nan       0.0066           nan  2.9659\n",
      "      9           nan       0.0066           nan  2.9916\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391, 5: 0.006622516556291391}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667, 5: 0.006666666666666667}\n",
      "pred time\n",
      "{0.1: 0.3167991638183594}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.008492708206176758, 5: 0.01059412956237793}\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0053\u001b[0m        \u001b[35m5.0173\u001b[0m  2.8762\n",
      "      2        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0060\u001b[0m        \u001b[35m5.0173\u001b[0m  2.9137\n",
      "      3        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0066\u001b[0m        \u001b[35m5.0173\u001b[0m  2.8846\n",
      "      4        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0070\u001b[0m        \u001b[35m5.0173\u001b[0m  2.8623\n",
      "      5        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0103\u001b[0m        \u001b[35m5.0173\u001b[0m  2.8287\n",
      "      6        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0136\u001b[0m        \u001b[35m5.0172\u001b[0m  2.9050\n",
      "      7        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0185\u001b[0m        \u001b[35m5.0172\u001b[0m  2.9147\n",
      "      8        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0262\u001b[0m        \u001b[35m5.0172\u001b[0m  2.8782\n",
      "      9        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0397\u001b[0m        \u001b[35m5.0172\u001b[0m  3.0296\n",
      "     10        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0520\u001b[0m        \u001b[35m5.0172\u001b[0m  3.0927\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391, 5: 0.006622516556291391, 1: 0.07403973509933774}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667, 5: 0.006666666666666667, 1: 0.065}\n",
      "pred time\n",
      "{0.1: 0.25283098220825195}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0, 1: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.008492708206176758, 5: 0.01059412956237793, 1: 0.009158134460449219}\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0086\u001b[0m        \u001b[35m5.0173\u001b[0m  3.1422\n",
      "      2        \u001b[36m5.0173\u001b[0m       0.0086        \u001b[35m5.0173\u001b[0m  2.9592\n",
      "      3        \u001b[36m5.0173\u001b[0m       0.0086        \u001b[35m5.0173\u001b[0m  2.9679\n",
      "      4        \u001b[36m5.0173\u001b[0m       0.0086        \u001b[35m5.0173\u001b[0m  2.9312\n",
      "      5        \u001b[36m5.0173\u001b[0m       0.0086        \u001b[35m5.0173\u001b[0m  2.8664\n",
      "      6        \u001b[36m5.0173\u001b[0m       0.0086        \u001b[35m5.0173\u001b[0m  2.9355\n",
      "      7        \u001b[36m5.0173\u001b[0m       0.0086        \u001b[35m5.0173\u001b[0m  2.9545\n",
      "      8        \u001b[36m5.0173\u001b[0m       0.0086        5.0173  2.9160\n",
      "      9        \u001b[36m5.0173\u001b[0m       0.0086        \u001b[35m5.0173\u001b[0m  3.0195\n",
      "     10        \u001b[36m5.0173\u001b[0m       0.0086        \u001b[35m5.0173\u001b[0m  2.9520\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391, 5: 0.006622516556291391, 1: 0.07403973509933774, 0.5: 0.008609271523178808}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667, 5: 0.006666666666666667, 1: 0.065, 0.5: 0.009}\n",
      "pred time\n",
      "{0.1: 0.34403109550476074}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0, 1: 0.0, 0.5: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.008492708206176758, 5: 0.01059412956237793, 1: 0.009158134460449219, 0.5: 0.008433818817138672}\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0070\u001b[0m        \u001b[35m5.0173\u001b[0m  3.0323\n",
      "      2        \u001b[36m5.0173\u001b[0m       0.0070        \u001b[35m5.0173\u001b[0m  2.9533\n",
      "      3        \u001b[36m5.0173\u001b[0m       0.0070        5.0173  3.0368\n",
      "      4        \u001b[36m5.0173\u001b[0m       0.0070        \u001b[35m5.0173\u001b[0m  3.0209\n",
      "      5        \u001b[36m5.0173\u001b[0m       0.0070        5.0173  2.8391\n",
      "      6        \u001b[36m5.0173\u001b[0m       0.0070        \u001b[35m5.0173\u001b[0m  2.8888\n",
      "      7        \u001b[36m5.0173\u001b[0m       0.0070        \u001b[35m5.0173\u001b[0m  2.8525\n",
      "      8        \u001b[36m5.0173\u001b[0m       0.0070        5.0173  2.9853\n",
      "      9        \u001b[36m5.0173\u001b[0m       0.0070        5.0173  2.9735\n",
      "     10        \u001b[36m5.0173\u001b[0m       0.0070        5.0173  2.8620\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391, 5: 0.006622516556291391, 1: 0.07403973509933774, 0.5: 0.008609271523178808, 0.1: 0.00728476821192053}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667, 5: 0.006666666666666667, 1: 0.065, 0.5: 0.009, 0.1: 0.006666666666666667}\n",
      "pred time\n",
      "{0.1: 0.2576451301574707}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0, 1: 0.0, 0.5: 0.0, 0.1: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.008492708206176758, 5: 0.01059412956237793, 1: 0.009158134460449219, 0.5: 0.008433818817138672, 0.1: 0.009519815444946289}\n"
     ]
    }
   ],
   "source": [
    "momentum = [10, 5, 1, 0.5, 0.1] #changing momentum applied \n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "for p in momentum:    #looping through momentum\n",
    "    class CLINCModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                input_dim=vocab_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim,\n",
    "                dropout=0\n",
    "        ):\n",
    "            super(CLINCModule, self).__init__()\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "            self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = torch.tanh(self.hidden(X))\n",
    "            X = self.dropout(X)\n",
    "            X = F.softmax(self.output(X), dim=-1)\n",
    "            return X\n",
    "   \n",
    "    net = NeuralNetClassifier(\n",
    "    module=CLINCModule,\n",
    "    optimizer__momentum=p, #looping through momentum values\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    max_epochs=1000,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    callbacks=[EarlyStopping(patience=10)],\n",
    "    )\n",
    "    \n",
    "    net.fit(train_x, train_y)\n",
    "    tlabels = net.predict(train_x)\n",
    "    tacc[p] = accuracy_score(tlabels, train_y)\n",
    "    print('training accuracy')\n",
    "    print(tacc)\n",
    "    time0 = time.time()\n",
    "    labels = net.predict(val_x)\n",
    "    vacc[p] = accuracy_score(labels, val_y)\n",
    "    time1 = time.time()\n",
    "    vtime[d] = time1-time0\n",
    "    print('Val accuracy')\n",
    "    print(vacc)\n",
    "    print('pred time')\n",
    "    print(vtime)\n",
    "    time2 = time.time()\n",
    "    olabels = net.predict(val_oos_x)\n",
    "    oacc[p] = accuracy_score(olabels, val_oos_y)\n",
    "    time3 = time.time()\n",
    "    otime[p]=time3-time2\n",
    "    print('OOS Val Accuracy')\n",
    "    print(oacc)\n",
    "    print('OOS pred time')\n",
    "    print(otime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not converging satisfactorily with SGD. Attempt using Adam optimizer, varying dropout rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0053\u001b[0m        \u001b[35m5.0173\u001b[0m  3.7077\n",
      "      2        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0066\u001b[0m        \u001b[35m5.0173\u001b[0m  3.6635\n",
      "      3        5.0173       0.0066        \u001b[35m5.0173\u001b[0m  3.5737\n",
      "      4        \u001b[36m5.0173\u001b[0m       0.0066        5.0173  3.7169\n",
      "      5        5.0173       0.0066        5.0173  3.8467\n",
      "      6        5.0173       0.0066        \u001b[35m5.0173\u001b[0m  3.9625\n",
      "      7        5.0173       0.0066        5.0173  3.8979\n",
      "      8        5.0173       0.0066        5.0173  3.6462\n",
      "      9        5.0173       0.0066        5.0173  3.6076\n",
      "     10        5.0173       0.0066        5.0173  3.6912\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{1: 0.006622516556291391}\n",
      "Val accuracy\n",
      "{1: 0.006666666666666667}\n",
      "pred time\n",
      "{1: 0.24365901947021484}\n",
      "OOS Val Accuracy\n",
      "{1: 0.0}\n",
      "OOS pred time\n",
      "{1: 0.00878596305847168}\n",
      "0.5\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m4.6150\u001b[0m       \u001b[32m0.8427\u001b[0m        \u001b[35m4.2147\u001b[0m  3.6517\n",
      "      2        \u001b[36m4.1352\u001b[0m       \u001b[32m0.9119\u001b[0m        \u001b[35m4.1315\u001b[0m  3.6879\n",
      "      3        \u001b[36m4.0707\u001b[0m       \u001b[32m0.9215\u001b[0m        \u001b[35m4.1180\u001b[0m  3.9094\n",
      "      4        \u001b[36m4.0548\u001b[0m       0.9185        \u001b[35m4.1169\u001b[0m  3.9139\n",
      "      5        \u001b[36m4.0497\u001b[0m       \u001b[32m0.9258\u001b[0m        \u001b[35m4.1128\u001b[0m  3.7597\n",
      "      6        \u001b[36m4.0460\u001b[0m       \u001b[32m0.9268\u001b[0m        \u001b[35m4.1109\u001b[0m  3.6021\n",
      "      7        \u001b[36m4.0454\u001b[0m       0.9235        4.1128  3.6502\n",
      "      8        \u001b[36m4.0394\u001b[0m       \u001b[32m0.9288\u001b[0m        \u001b[35m4.1078\u001b[0m  3.6812\n",
      "      9        4.0394       0.9228        4.1111  3.7249\n",
      "     10        \u001b[36m4.0385\u001b[0m       0.9225        4.1094  3.7013\n",
      "     11        \u001b[36m4.0369\u001b[0m       0.9222        4.1112  3.5957\n",
      "     12        \u001b[36m4.0367\u001b[0m       0.9245        4.1084  3.7813\n",
      "     13        4.0370       0.9248        4.1088  3.6861\n",
      "     14        4.0373       0.9255        \u001b[35m4.1074\u001b[0m  3.5636\n",
      "     15        \u001b[36m4.0360\u001b[0m       0.9185        4.1139  3.5884\n",
      "     16        4.0361       0.9275        4.1085  3.7226\n",
      "     17        4.0364       0.9205        4.1129  3.8434\n",
      "     18        4.0374       0.9179        4.1123  3.8408\n",
      "     19        4.0369       0.9179        4.1126  3.7300\n",
      "     20        4.0377       0.9142        4.1177  3.5971\n",
      "     21        4.0375       0.9156        4.1164  3.8087\n",
      "     22        4.0375       0.9166        4.1142  3.6226\n",
      "     23        4.0378       0.9159        4.1134  3.6792\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{1: 0.006622516556291391, 0.5: 0.9793377483443708}\n",
      "Val accuracy\n",
      "{1: 0.006666666666666667, 0.5: 0.8776666666666667}\n",
      "pred time\n",
      "{1: 0.24365901947021484, 0.5: 0.27951478958129883}\n",
      "OOS Val Accuracy\n",
      "{1: 0.0, 0.5: 0.11}\n",
      "OOS pred time\n",
      "{1: 0.00878596305847168, 0.5: 0.009487152099609375}\n",
      "0.1\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m4.5515\u001b[0m       \u001b[32m0.8576\u001b[0m        \u001b[35m4.1912\u001b[0m  3.7122\n",
      "      2        \u001b[36m4.1095\u001b[0m       \u001b[32m0.9103\u001b[0m        \u001b[35m4.1312\u001b[0m  3.7483\n",
      "      3        \u001b[36m4.0639\u001b[0m       \u001b[32m0.9162\u001b[0m        \u001b[35m4.1224\u001b[0m  3.6029\n",
      "      4        \u001b[36m4.0515\u001b[0m       \u001b[32m0.9205\u001b[0m        \u001b[35m4.1154\u001b[0m  3.5980\n",
      "      5        \u001b[36m4.0474\u001b[0m       \u001b[32m0.9235\u001b[0m        4.1159  3.6002\n",
      "      6        \u001b[36m4.0454\u001b[0m       0.9219        \u001b[35m4.1137\u001b[0m  3.5877\n",
      "      7        4.0454       0.9232        4.1145  3.5834\n",
      "      8        \u001b[36m4.0421\u001b[0m       \u001b[32m0.9305\u001b[0m        \u001b[35m4.1081\u001b[0m  3.5733\n",
      "      9        \u001b[36m4.0408\u001b[0m       0.9215        4.1146  3.6036\n",
      "     10        \u001b[36m4.0393\u001b[0m       0.9225        4.1124  3.5936\n",
      "     11        \u001b[36m4.0381\u001b[0m       0.9169        4.1175  3.5795\n",
      "     12        \u001b[36m4.0375\u001b[0m       0.9219        4.1143  3.4690\n",
      "     13        \u001b[36m4.0366\u001b[0m       0.9225        4.1126  3.5738\n",
      "     14        4.0369       0.9228        4.1111  3.5749\n",
      "     15        \u001b[36m4.0361\u001b[0m       0.9185        4.1149  3.5786\n",
      "     16        4.0367       0.9189        4.1169  3.5805\n",
      "     17        4.0376       0.9146        4.1167  3.5852\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{1: 0.006622516556291391, 0.5: 0.9793377483443708, 0.1: 0.9733112582781457}\n",
      "Val accuracy\n",
      "{1: 0.006666666666666667, 0.5: 0.8776666666666667, 0.1: 0.8683333333333333}\n",
      "pred time\n",
      "{1: 0.24365901947021484, 0.5: 0.27951478958129883, 0.1: 0.26523923873901367}\n",
      "OOS Val Accuracy\n",
      "{1: 0.0, 0.5: 0.11, 0.1: 0.09}\n",
      "OOS pred time\n",
      "{1: 0.00878596305847168, 0.5: 0.009487152099609375, 0.1: 0.009885787963867188}\n",
      "0.01\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m4.5534\u001b[0m       \u001b[32m0.8636\u001b[0m        \u001b[35m4.1901\u001b[0m  3.5701\n",
      "      2        \u001b[36m4.1105\u001b[0m       \u001b[32m0.9132\u001b[0m        \u001b[35m4.1285\u001b[0m  3.5743\n",
      "      3        \u001b[36m4.0669\u001b[0m       \u001b[32m0.9139\u001b[0m        \u001b[35m4.1228\u001b[0m  3.5759\n",
      "      4        \u001b[36m4.0556\u001b[0m       \u001b[32m0.9219\u001b[0m        \u001b[35m4.1169\u001b[0m  3.5754\n",
      "      5        \u001b[36m4.0492\u001b[0m       0.9199        4.1181  3.5888\n",
      "      6        \u001b[36m4.0473\u001b[0m       \u001b[32m0.9245\u001b[0m        \u001b[35m4.1128\u001b[0m  3.5085\n",
      "      7        \u001b[36m4.0443\u001b[0m       0.9212        4.1155  3.4911\n",
      "      8        \u001b[36m4.0440\u001b[0m       0.9199        4.1164  3.5001\n",
      "      9        4.0443       0.9189        4.1186  3.6780\n",
      "     10        4.0444       0.9209        4.1153  3.6831\n",
      "     11        \u001b[36m4.0430\u001b[0m       0.9212        4.1141  4.0122\n",
      "     12        \u001b[36m4.0417\u001b[0m       0.9235        \u001b[35m4.1120\u001b[0m  3.8727\n",
      "     13        \u001b[36m4.0402\u001b[0m       0.9129        4.1205  3.7608\n",
      "     14        \u001b[36m4.0379\u001b[0m       0.9195        4.1135  3.6170\n",
      "     15        \u001b[36m4.0366\u001b[0m       0.9219        4.1128  3.6810\n",
      "     16        \u001b[36m4.0365\u001b[0m       0.9189        4.1128  3.6596\n",
      "     17        \u001b[36m4.0362\u001b[0m       0.9228        \u001b[35m4.1113\u001b[0m  3.6885\n",
      "     18        4.0366       0.9175        4.1160  3.6227\n",
      "     19        4.0395       0.9109        4.1222  3.6473\n",
      "     20        4.0403       0.9123        4.1211  3.5868\n",
      "     21        4.0420       0.9099        4.1246  3.6195\n",
      "     22        4.0449       0.9056        4.1262  3.6567\n",
      "     23        4.0457       0.8967        4.1365  3.7046\n",
      "     24        4.0463       0.9040        4.1265  3.8277\n",
      "     25        4.0437       0.9036        4.1262  3.9629\n",
      "     26        4.0411       0.9116        4.1205  4.2427\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{1: 0.006622516556291391, 0.5: 0.9793377483443708, 0.1: 0.9733112582781457, 0.01: 0.9740397350993377}\n",
      "Val accuracy\n",
      "{1: 0.006666666666666667, 0.5: 0.8776666666666667, 0.1: 0.8683333333333333, 0.01: 0.8613333333333333}\n",
      "pred time\n",
      "{1: 0.24365901947021484, 0.5: 0.27951478958129883, 0.1: 0.26523923873901367, 0.01: 0.2642199993133545}\n",
      "OOS Val Accuracy\n",
      "{1: 0.0, 0.5: 0.11, 0.1: 0.09, 0.01: 0.11}\n",
      "OOS pred time\n",
      "{1: 0.00878596305847168, 0.5: 0.009487152099609375, 0.1: 0.009885787963867188, 0.01: 0.010416269302368164}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m4.5496\u001b[0m       \u001b[32m0.8619\u001b[0m        \u001b[35m4.1884\u001b[0m  3.6286\n",
      "      2        \u001b[36m4.1117\u001b[0m       \u001b[32m0.9073\u001b[0m        \u001b[35m4.1302\u001b[0m  3.7874\n",
      "      3        \u001b[36m4.0686\u001b[0m       \u001b[32m0.9156\u001b[0m        \u001b[35m4.1215\u001b[0m  3.6524\n",
      "      4        \u001b[36m4.0561\u001b[0m       \u001b[32m0.9185\u001b[0m        \u001b[35m4.1164\u001b[0m  3.6148\n",
      "      5        \u001b[36m4.0485\u001b[0m       \u001b[32m0.9212\u001b[0m        \u001b[35m4.1136\u001b[0m  3.6013\n",
      "      6        \u001b[36m4.0469\u001b[0m       \u001b[32m0.9219\u001b[0m        4.1143  3.5928\n",
      "      7        \u001b[36m4.0459\u001b[0m       0.9212        \u001b[35m4.1129\u001b[0m  3.5874\n",
      "      8        \u001b[36m4.0452\u001b[0m       0.9195        4.1162  3.5951\n",
      "      9        \u001b[36m4.0445\u001b[0m       \u001b[32m0.9228\u001b[0m        \u001b[35m4.1108\u001b[0m  3.5965\n",
      "     10        \u001b[36m4.0435\u001b[0m       0.9225        4.1115  3.5904\n",
      "     11        \u001b[36m4.0432\u001b[0m       \u001b[32m0.9248\u001b[0m        \u001b[35m4.1102\u001b[0m  3.6035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12        \u001b[36m4.0427\u001b[0m       0.9225        4.1119  3.6072\n",
      "     13        \u001b[36m4.0422\u001b[0m       0.9175        4.1157  3.5930\n",
      "     14        4.0424       0.9185        4.1142  3.6085\n",
      "     15        \u001b[36m4.0398\u001b[0m       0.9248        4.1110  3.6459\n",
      "     16        4.0403       0.9099        4.1234  3.6318\n",
      "     17        4.0435       0.9083        4.1214  3.5218\n",
      "     18        4.0419       0.9083        4.1232  3.7210\n",
      "     19        4.0425       0.9046        4.1272  3.5768\n",
      "     20        4.0418       0.9083        4.1231  3.6162\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{1: 0.006622516556291391, 0.5: 0.9793377483443708, 0.1: 0.9733112582781457, 0.01: 0.9740397350993377, 0.001: 0.9733774834437086}\n",
      "Val accuracy\n",
      "{1: 0.006666666666666667, 0.5: 0.8776666666666667, 0.1: 0.8683333333333333, 0.01: 0.8613333333333333, 0.001: 0.874}\n",
      "pred time\n",
      "{1: 0.24365901947021484, 0.5: 0.27951478958129883, 0.1: 0.26523923873901367, 0.01: 0.2642199993133545, 0.001: 0.25611376762390137}\n",
      "OOS Val Accuracy\n",
      "{1: 0.0, 0.5: 0.11, 0.1: 0.09, 0.01: 0.11, 0.001: 0.09}\n",
      "OOS pred time\n",
      "{1: 0.00878596305847168, 0.5: 0.009487152099609375, 0.1: 0.009885787963867188, 0.01: 0.010416269302368164, 0.001: 0.008425235748291016}\n",
      "0\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m4.5516\u001b[0m       \u001b[32m0.8632\u001b[0m        \u001b[35m4.1890\u001b[0m  3.7023\n",
      "      2        \u001b[36m4.1115\u001b[0m       \u001b[32m0.9103\u001b[0m        \u001b[35m4.1292\u001b[0m  3.6755\n",
      "      3        \u001b[36m4.0678\u001b[0m       \u001b[32m0.9132\u001b[0m        \u001b[35m4.1242\u001b[0m  3.5838\n",
      "      4        \u001b[36m4.0566\u001b[0m       \u001b[32m0.9169\u001b[0m        \u001b[35m4.1190\u001b[0m  3.7635\n",
      "      5        \u001b[36m4.0502\u001b[0m       0.9139        4.1219  3.6488\n",
      "      6        \u001b[36m4.0469\u001b[0m       \u001b[32m0.9228\u001b[0m        \u001b[35m4.1137\u001b[0m  3.6785\n",
      "      7        \u001b[36m4.0460\u001b[0m       0.9225        4.1143  3.6509\n",
      "      8        \u001b[36m4.0449\u001b[0m       0.9222        4.1155  3.8085\n",
      "      9        \u001b[36m4.0445\u001b[0m       0.9228        \u001b[35m4.1115\u001b[0m  3.6370\n",
      "     10        \u001b[36m4.0432\u001b[0m       0.9199        4.1142  3.7065\n",
      "     11        4.0435       0.9209        4.1144  3.7277\n",
      "     12        4.0438       0.9205        4.1141  3.6086\n",
      "     13        4.0437       0.9215        4.1123  3.5342\n",
      "     14        4.0440       0.9219        4.1132  3.5205\n",
      "     15        4.0436       0.9182        4.1164  3.5133\n",
      "     16        4.0435       \u001b[32m0.9242\u001b[0m        4.1127  3.5055\n",
      "     17        4.0435       0.9222        4.1135  3.5060\n",
      "     18        4.0436       0.9159        4.1190  3.4986\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{1: 0.006622516556291391, 0.5: 0.9793377483443708, 0.1: 0.9733112582781457, 0.01: 0.9740397350993377, 0.001: 0.9733774834437086, 0: 0.9655629139072848}\n",
      "Val accuracy\n",
      "{1: 0.006666666666666667, 0.5: 0.8776666666666667, 0.1: 0.8683333333333333, 0.01: 0.8613333333333333, 0.001: 0.874, 0: 0.863}\n",
      "pred time\n",
      "{1: 0.24365901947021484, 0.5: 0.27951478958129883, 0.1: 0.26523923873901367, 0.01: 0.2642199993133545, 0.001: 0.25611376762390137, 0: 0.24973678588867188}\n",
      "OOS Val Accuracy\n",
      "{1: 0.0, 0.5: 0.11, 0.1: 0.09, 0.01: 0.11, 0.001: 0.09, 0: 0.07}\n",
      "OOS pred time\n",
      "{1: 0.00878596305847168, 0.5: 0.009487152099609375, 0.1: 0.009885787963867188, 0.01: 0.010416269302368164, 0.001: 0.008425235748291016, 0: 0.00892496109008789}\n"
     ]
    }
   ],
   "source": [
    "dropouts = [1, 0.5, 0.1, 0.01, 0.001, 0] #dropouts to try\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "for d in dropouts:    #looping through dropouts\n",
    "    print(d) #print dropout rate\n",
    "    class CLINCModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                input_dim=vocab_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim,\n",
    "                dropout=d #dropout rate set to value in loop\n",
    "        ):\n",
    "            super(CLINCModule, self).__init__()\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "            self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = torch.tanh(self.hidden(X))\n",
    "            X = self.dropout(X)\n",
    "            X = F.softmax(self.output(X), dim=-1)\n",
    "            return X\n",
    "   \n",
    "    net = NeuralNetClassifier(\n",
    "    module=CLINCModule,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    max_epochs=1000,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    callbacks=[EarlyStopping(patience=10)],\n",
    "    )\n",
    "    \n",
    "    net.fit(train_x, train_y)\n",
    "    tlabels = net.predict(train_x)\n",
    "    tacc[d] = accuracy_score(tlabels, train_y)\n",
    "    print('training accuracy')\n",
    "    print(tacc)\n",
    "    time0 = time.time()\n",
    "    labels = net.predict(val_x)\n",
    "    vacc[d] = accuracy_score(labels, val_y)\n",
    "    time1 = time.time()\n",
    "    vtime[d] = time1-time0\n",
    "    print('Val accuracy')\n",
    "    print(vacc)\n",
    "    print('pred time')\n",
    "    print(vtime)\n",
    "    time2 = time.time()\n",
    "    olabels = net.predict(val_oos_x)\n",
    "    oacc[d] = accuracy_score(olabels, val_oos_y)\n",
    "    time3 = time.time()\n",
    "    otime[d]=time3-time2\n",
    "    print('OOS Val Accuracy')\n",
    "    print(oacc)\n",
    "    print('OOS pred time')\n",
    "    print(otime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has improved, will retain Adam & dropout rate of 0.5. Now investigating Learning Rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0221\u001b[0m       \u001b[32m0.0066\u001b[0m        \u001b[35m5.0220\u001b[0m  4.3490\n",
      "      2        \u001b[36m5.0220\u001b[0m       0.0066        5.0220  4.3117\n",
      "      3        5.0220       0.0066        5.0220  4.8271\n",
      "      4        5.0220       0.0066        5.0220  3.9213\n",
      "      5        5.0220       0.0066        5.0220  4.2449\n",
      "      6        5.0220       0.0066        5.0220  4.0830\n",
      "      7        5.0220       0.0066        5.0220  4.0942\n",
      "      8        5.0220       0.0066        5.0220  4.3219\n",
      "      9        5.0220       0.0066        5.0220  4.3452\n",
      "     10        5.0220       0.0066        5.0220  4.3482\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667}\n",
      "pred time\n",
      "{0.001: 0.3723461627960205}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.01131582260131836}\n",
      "5\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0220\u001b[0m       \u001b[32m0.0066\u001b[0m        \u001b[35m5.0220\u001b[0m  4.1024\n",
      "      2        \u001b[36m5.0220\u001b[0m       0.0066        5.0220  4.1481\n",
      "      3        5.0220       0.0066        5.0220  4.1129\n",
      "      4        5.0220       0.0066        5.0220  3.8756\n",
      "      5        5.0220       0.0066        5.0220  3.9863\n",
      "      6        5.0220       0.0066        5.0220  3.9399\n",
      "      7        5.0220       0.0066        5.0220  3.9526\n",
      "      8        5.0220       0.0066        5.0220  4.0266\n",
      "      9        5.0220       0.0066        5.0220  4.0676\n",
      "     10        5.0220       0.0066        5.0220  4.0284\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391, 5: 0.006622516556291391}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667, 5: 0.006666666666666667}\n",
      "pred time\n",
      "{0.001: 0.3494570255279541}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.01131582260131836, 5: 0.008625030517578125}\n",
      "1\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0219\u001b[0m       \u001b[32m0.0066\u001b[0m        \u001b[35m5.0220\u001b[0m  3.9507\n",
      "      2        5.0220       0.0066        5.0220  3.9367\n",
      "      3        5.0220       0.0060        5.0226  3.9922\n",
      "      4        \u001b[36m5.0217\u001b[0m       0.0066        5.0220  3.8530\n",
      "      5        \u001b[36m5.0216\u001b[0m       0.0066        5.0220  3.9513\n",
      "      6        5.0220       0.0066        5.0220  4.0126\n",
      "      7        5.0220       0.0066        5.0220  4.0582\n",
      "      8        5.0220       0.0066        5.0220  4.2028\n",
      "      9        5.0220       0.0066        5.0220  4.4212\n",
      "     10        5.0220       0.0066        5.0220  4.1327\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391, 5: 0.006622516556291391, 1: 0.006622516556291391}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667, 5: 0.006666666666666667, 1: 0.006666666666666667}\n",
      "pred time\n",
      "{0.001: 0.33930492401123047}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0, 1: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.01131582260131836, 5: 0.008625030517578125, 1: 0.01005697250366211}\n",
      "0.5\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0184\u001b[0m       \u001b[32m0.0129\u001b[0m        \u001b[35m5.0157\u001b[0m  3.8735\n",
      "      2        \u001b[36m5.0162\u001b[0m       0.0096        5.0190  3.8398\n",
      "      3        5.0172       0.0119        5.0167  3.8497\n",
      "      4        \u001b[36m5.0156\u001b[0m       \u001b[32m0.0132\u001b[0m        \u001b[35m5.0153\u001b[0m  3.9722\n",
      "      5        5.0159       0.0123        5.0163  4.1124\n",
      "      6        \u001b[36m5.0154\u001b[0m       0.0132        5.0153  4.2258\n",
      "      7        5.0168       0.0113        5.0173  4.3755\n",
      "      8        5.0158       0.0123        5.0163  4.5419\n",
      "      9        5.0156       0.0126        5.0160  4.3456\n",
      "     10        5.0159       0.0129        5.0157  4.3307\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391, 5: 0.006622516556291391, 1: 0.006622516556291391, 0.5: 0.012781456953642384}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667, 5: 0.006666666666666667, 1: 0.006666666666666667, 0.5: 0.013333333333333334}\n",
      "pred time\n",
      "{0.001: 0.3363962173461914}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0, 1: 0.0, 0.5: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.01131582260131836, 5: 0.008625030517578125, 1: 0.01005697250366211, 0.5: 0.007462978363037109}\n",
      "0.1\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m4.7207\u001b[0m       \u001b[32m0.3990\u001b[0m        \u001b[35m4.6294\u001b[0m  4.7219\n",
      "      2        \u001b[36m4.6292\u001b[0m       \u001b[32m0.4195\u001b[0m        \u001b[35m4.6090\u001b[0m  5.6510\n",
      "      3        \u001b[36m4.6259\u001b[0m       0.4162        4.6124  5.1874\n",
      "      4        \u001b[36m4.6095\u001b[0m       \u001b[32m0.4205\u001b[0m        \u001b[35m4.6081\u001b[0m  4.5669\n",
      "      5        \u001b[36m4.5993\u001b[0m       \u001b[32m0.4411\u001b[0m        \u001b[35m4.5879\u001b[0m  4.3130\n",
      "      6        4.6014       0.4331        4.5953  4.3515\n",
      "      7        \u001b[36m4.5895\u001b[0m       0.4348        4.5934  4.1449\n",
      "      8        4.5918       \u001b[32m0.4421\u001b[0m        \u001b[35m4.5863\u001b[0m  4.4604\n",
      "      9        \u001b[36m4.5853\u001b[0m       0.4417        4.5868  4.2952\n",
      "     10        4.5870       \u001b[32m0.4447\u001b[0m        \u001b[35m4.5845\u001b[0m  4.4824\n",
      "     11        \u001b[36m4.5832\u001b[0m       0.4397        4.5892  4.4574\n",
      "     12        4.5907       0.4354        4.5931  4.4823\n",
      "     13        4.5873       0.4397        4.5887  4.3070\n",
      "     14        \u001b[36m4.5824\u001b[0m       0.4394        4.5889  4.4071\n",
      "     15        4.5827       0.4440        4.5845  4.3113\n",
      "     16        4.5839       0.4397        4.5891  4.5698\n",
      "     17        4.5852       0.4417        4.5870  4.5678\n",
      "     18        \u001b[36m4.5802\u001b[0m       0.4407        4.5875  4.3580\n",
      "     19        \u001b[36m4.5743\u001b[0m       \u001b[32m0.4526\u001b[0m        \u001b[35m4.5756\u001b[0m  4.3750\n",
      "     20        \u001b[36m4.5734\u001b[0m       \u001b[32m0.4546\u001b[0m        \u001b[35m4.5740\u001b[0m  4.4813\n",
      "     21        4.5773       0.4421        4.5866  4.5092\n",
      "     22        4.5741       0.4510        4.5776  4.4482\n",
      "     23        \u001b[36m4.5709\u001b[0m       0.4513        4.5777  4.3603\n",
      "     24        4.5769       0.4500        4.5786  4.3494\n",
      "     25        4.5751       0.4510        4.5776  4.4008\n",
      "     26        \u001b[36m4.5700\u001b[0m       \u001b[32m0.4560\u001b[0m        \u001b[35m4.5726\u001b[0m  4.3659\n",
      "     27        \u001b[36m4.5699\u001b[0m       0.4490        4.5793  4.2146\n",
      "     28        4.5739       0.4540        4.5746  4.3198\n",
      "     29        \u001b[36m4.5668\u001b[0m       \u001b[32m0.4589\u001b[0m        \u001b[35m4.5696\u001b[0m  4.3422\n",
      "     30        \u001b[36m4.5664\u001b[0m       0.4500        4.5788  4.2286\n",
      "     31        \u001b[36m4.5648\u001b[0m       0.4550        4.5737  4.4358\n",
      "     32        4.5649       0.4553        4.5733  4.3303\n",
      "     33        4.5666       0.4550        4.5733  4.3466\n",
      "     34        4.5651       0.4556        4.5730  4.4666\n",
      "     35        4.5655       0.4579        4.5707  4.5031\n",
      "     36        \u001b[36m4.5638\u001b[0m       0.4570        4.5717  4.6320\n",
      "     37        4.5641       0.4576        4.5711  4.5744\n",
      "     38        4.5646       0.4566        4.5720  4.5720\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391, 5: 0.006622516556291391, 1: 0.006622516556291391, 0.5: 0.012781456953642384, 0.1: 0.47258278145695365}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667, 5: 0.006666666666666667, 1: 0.006666666666666667, 0.5: 0.013333333333333334, 0.1: 0.44733333333333336}\n",
      "pred time\n",
      "{0.001: 0.36118221282958984}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0, 1: 0.0, 0.5: 0.0, 0.1: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.01131582260131836, 5: 0.008625030517578125, 1: 0.01005697250366211, 0.5: 0.007462978363037109, 0.1: 0.010442256927490234}\n",
      "0.01\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m4.6082\u001b[0m       \u001b[32m0.8490\u001b[0m        \u001b[35m4.2088\u001b[0m  4.2023\n",
      "      2        \u001b[36m4.1312\u001b[0m       \u001b[32m0.9212\u001b[0m        \u001b[35m4.1253\u001b[0m  4.0042\n",
      "      3        \u001b[36m4.0696\u001b[0m       \u001b[32m0.9222\u001b[0m        \u001b[35m4.1185\u001b[0m  3.9350\n",
      "      4        \u001b[36m4.0547\u001b[0m       \u001b[32m0.9245\u001b[0m        \u001b[35m4.1144\u001b[0m  3.8841\n",
      "      5        \u001b[36m4.0509\u001b[0m       \u001b[32m0.9272\u001b[0m        \u001b[35m4.1104\u001b[0m  3.9466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6        \u001b[36m4.0473\u001b[0m       0.9219        4.1131  3.9236\n",
      "      7        \u001b[36m4.0455\u001b[0m       0.9262        \u001b[35m4.1096\u001b[0m  3.8869\n",
      "      8        \u001b[36m4.0406\u001b[0m       \u001b[32m0.9301\u001b[0m        \u001b[35m4.1069\u001b[0m  3.9216\n",
      "      9        \u001b[36m4.0389\u001b[0m       0.9291        \u001b[35m4.1062\u001b[0m  3.9415\n",
      "     10        \u001b[36m4.0375\u001b[0m       0.9275        4.1071  4.1294\n",
      "     11        4.0379       0.9268        4.1085  4.0735\n",
      "     12        4.0379       0.9285        4.1062  4.0020\n",
      "     13        \u001b[36m4.0370\u001b[0m       0.9195        4.1130  3.8344\n",
      "     14        4.0378       0.9252        4.1087  3.6418\n",
      "     15        4.0371       0.9248        4.1071  3.7036\n",
      "     16        \u001b[36m4.0368\u001b[0m       0.9245        4.1077  3.7419\n",
      "     17        4.0368       0.9215        4.1112  3.9115\n",
      "     18        4.0370       0.9255        \u001b[35m4.1061\u001b[0m  3.9666\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391, 5: 0.006622516556291391, 1: 0.006622516556291391, 0.5: 0.012781456953642384, 0.1: 0.47258278145695365, 0.01: 0.9788741721854305}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667, 5: 0.006666666666666667, 1: 0.006666666666666667, 0.5: 0.013333333333333334, 0.1: 0.44733333333333336, 0.01: 0.874}\n",
      "pred time\n",
      "{0.001: 0.2640388011932373}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0, 1: 0.0, 0.5: 0.0, 0.1: 0.0, 0.01: 0.07}\n",
      "OOS pred time\n",
      "{10: 0.01131582260131836, 5: 0.008625030517578125, 1: 0.01005697250366211, 0.5: 0.007462978363037109, 0.1: 0.010442256927490234, 0.01: 0.009956121444702148}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0147\u001b[0m       \u001b[32m0.7358\u001b[0m        \u001b[35m5.0046\u001b[0m  3.6535\n",
      "      2        \u001b[36m4.8435\u001b[0m       0.6662        \u001b[35m4.6123\u001b[0m  3.9754\n",
      "      3        \u001b[36m4.4287\u001b[0m       \u001b[32m0.8483\u001b[0m        \u001b[35m4.3367\u001b[0m  3.8633\n",
      "      4        \u001b[36m4.2450\u001b[0m       \u001b[32m0.8950\u001b[0m        \u001b[35m4.2398\u001b[0m  3.6118\n",
      "      5        \u001b[36m4.1686\u001b[0m       \u001b[32m0.9129\u001b[0m        \u001b[35m4.1947\u001b[0m  3.7318\n",
      "      6        \u001b[36m4.1290\u001b[0m       \u001b[32m0.9225\u001b[0m        \u001b[35m4.1706\u001b[0m  4.0712\n",
      "      7        \u001b[36m4.1053\u001b[0m       \u001b[32m0.9278\u001b[0m        \u001b[35m4.1563\u001b[0m  4.1294\n",
      "      8        \u001b[36m4.0869\u001b[0m       \u001b[32m0.9334\u001b[0m        \u001b[35m4.1462\u001b[0m  4.0460\n",
      "      9        \u001b[36m4.0739\u001b[0m       \u001b[32m0.9361\u001b[0m        \u001b[35m4.1382\u001b[0m  3.9577\n",
      "     10        \u001b[36m4.0641\u001b[0m       \u001b[32m0.9374\u001b[0m        \u001b[35m4.1327\u001b[0m  4.0754\n",
      "     11        \u001b[36m4.0579\u001b[0m       \u001b[32m0.9387\u001b[0m        \u001b[35m4.1284\u001b[0m  4.0565\n",
      "     12        \u001b[36m4.0537\u001b[0m       \u001b[32m0.9394\u001b[0m        \u001b[35m4.1248\u001b[0m  3.9836\n",
      "     13        \u001b[36m4.0501\u001b[0m       0.9394        \u001b[35m4.1224\u001b[0m  4.0134\n",
      "     14        \u001b[36m4.0472\u001b[0m       0.9384        \u001b[35m4.1206\u001b[0m  3.9548\n",
      "     15        \u001b[36m4.0448\u001b[0m       \u001b[32m0.9401\u001b[0m        \u001b[35m4.1185\u001b[0m  3.9190\n",
      "     16        \u001b[36m4.0434\u001b[0m       0.9377        \u001b[35m4.1170\u001b[0m  3.9943\n",
      "     17        \u001b[36m4.0419\u001b[0m       0.9394        \u001b[35m4.1154\u001b[0m  4.0733\n",
      "     18        \u001b[36m4.0408\u001b[0m       0.9397        \u001b[35m4.1143\u001b[0m  3.8622\n",
      "     19        \u001b[36m4.0398\u001b[0m       \u001b[32m0.9411\u001b[0m        \u001b[35m4.1128\u001b[0m  3.9690\n",
      "     20        \u001b[36m4.0387\u001b[0m       0.9407        \u001b[35m4.1111\u001b[0m  4.0807\n",
      "     21        \u001b[36m4.0381\u001b[0m       0.9407        \u001b[35m4.1104\u001b[0m  3.9188\n",
      "     22        \u001b[36m4.0374\u001b[0m       0.9407        \u001b[35m4.1097\u001b[0m  3.8851\n",
      "     23        \u001b[36m4.0365\u001b[0m       0.9404        \u001b[35m4.1087\u001b[0m  4.0571\n",
      "     24        \u001b[36m4.0362\u001b[0m       \u001b[32m0.9414\u001b[0m        \u001b[35m4.1081\u001b[0m  3.6313\n",
      "     25        \u001b[36m4.0357\u001b[0m       0.9401        \u001b[35m4.1080\u001b[0m  3.6375\n",
      "     26        \u001b[36m4.0353\u001b[0m       0.9401        \u001b[35m4.1075\u001b[0m  3.6358\n",
      "     27        \u001b[36m4.0349\u001b[0m       0.9394        \u001b[35m4.1070\u001b[0m  3.5638\n",
      "     28        \u001b[36m4.0347\u001b[0m       0.9407        \u001b[35m4.1065\u001b[0m  3.5787\n",
      "     29        \u001b[36m4.0343\u001b[0m       0.9414        \u001b[35m4.1064\u001b[0m  3.5605\n",
      "     30        \u001b[36m4.0340\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m4.1058\u001b[0m  3.5489\n",
      "     31        \u001b[36m4.0339\u001b[0m       0.9424        \u001b[35m4.1050\u001b[0m  3.5981\n",
      "     32        \u001b[36m4.0336\u001b[0m       0.9417        \u001b[35m4.1049\u001b[0m  3.5665\n",
      "     33        4.0336       \u001b[32m0.9427\u001b[0m        \u001b[35m4.1047\u001b[0m  3.5546\n",
      "     34        \u001b[36m4.0334\u001b[0m       0.9404        \u001b[35m4.1043\u001b[0m  3.6713\n",
      "     35        \u001b[36m4.0332\u001b[0m       0.9411        \u001b[35m4.1041\u001b[0m  3.6361\n",
      "     36        \u001b[36m4.0332\u001b[0m       0.9401        \u001b[35m4.1039\u001b[0m  3.6079\n",
      "     37        \u001b[36m4.0330\u001b[0m       0.9407        \u001b[35m4.1034\u001b[0m  3.8625\n",
      "     38        \u001b[36m4.0329\u001b[0m       0.9407        \u001b[35m4.1031\u001b[0m  3.7287\n",
      "     39        \u001b[36m4.0328\u001b[0m       0.9417        \u001b[35m4.1026\u001b[0m  3.5736\n",
      "     40        \u001b[36m4.0327\u001b[0m       0.9407        4.1027  3.6961\n",
      "     41        \u001b[36m4.0326\u001b[0m       0.9414        \u001b[35m4.1024\u001b[0m  4.1445\n",
      "     42        \u001b[36m4.0326\u001b[0m       0.9414        \u001b[35m4.1020\u001b[0m  4.2434\n",
      "     43        \u001b[36m4.0324\u001b[0m       0.9411        \u001b[35m4.1015\u001b[0m  4.2171\n",
      "     44        4.0325       0.9407        \u001b[35m4.1014\u001b[0m  4.2489\n",
      "     45        \u001b[36m4.0322\u001b[0m       0.9411        4.1015  4.3585\n",
      "     46        4.0322       0.9407        \u001b[35m4.1012\u001b[0m  4.3155\n",
      "     47        \u001b[36m4.0322\u001b[0m       0.9411        \u001b[35m4.1011\u001b[0m  4.3605\n",
      "     48        \u001b[36m4.0320\u001b[0m       0.9397        4.1012  4.3659\n",
      "     49        4.0321       0.9411        4.1012  4.3970\n",
      "     50        \u001b[36m4.0320\u001b[0m       0.9401        \u001b[35m4.1009\u001b[0m  4.3903\n",
      "     51        \u001b[36m4.0319\u001b[0m       0.9397        \u001b[35m4.1007\u001b[0m  4.3467\n",
      "     52        \u001b[36m4.0319\u001b[0m       0.9411        \u001b[35m4.1001\u001b[0m  4.3801\n",
      "     53        \u001b[36m4.0318\u001b[0m       0.9404        4.1004  4.3459\n",
      "     54        \u001b[36m4.0317\u001b[0m       0.9404        \u001b[35m4.0998\u001b[0m  4.3681\n",
      "     55        4.0318       0.9404        \u001b[35m4.0998\u001b[0m  4.3737\n",
      "     56        \u001b[36m4.0316\u001b[0m       0.9407        \u001b[35m4.0997\u001b[0m  4.4504\n",
      "     57        4.0317       0.9411        \u001b[35m4.0991\u001b[0m  4.2093\n",
      "     58        \u001b[36m4.0315\u001b[0m       0.9411        4.0993  4.2754\n",
      "     59        \u001b[36m4.0315\u001b[0m       0.9411        4.0994  4.4197\n",
      "     60        4.0315       0.9414        \u001b[35m4.0989\u001b[0m  4.3703\n",
      "     61        \u001b[36m4.0314\u001b[0m       0.9427        \u001b[35m4.0988\u001b[0m  4.4018\n",
      "     62        \u001b[36m4.0314\u001b[0m       0.9407        \u001b[35m4.0986\u001b[0m  4.3919\n",
      "     63        \u001b[36m4.0314\u001b[0m       0.9401        \u001b[35m4.0983\u001b[0m  4.4296\n",
      "     64        4.0315       0.9424        4.0986  4.4301\n",
      "     65        4.0314       0.9417        4.0983  4.3656\n",
      "     66        \u001b[36m4.0313\u001b[0m       0.9414        4.0986  4.4254\n",
      "     67        \u001b[36m4.0313\u001b[0m       0.9421        \u001b[35m4.0982\u001b[0m  4.4308\n",
      "     68        \u001b[36m4.0313\u001b[0m       0.9411        4.0983  4.4300\n",
      "     69        \u001b[36m4.0312\u001b[0m       0.9407        4.0985  4.3863\n",
      "     70        4.0313       0.9414        \u001b[35m4.0982\u001b[0m  4.3750\n",
      "     71        \u001b[36m4.0311\u001b[0m       0.9411        4.0982  4.3586\n",
      "     72        4.0312       0.9401        \u001b[35m4.0981\u001b[0m  4.2867\n",
      "     73        4.0312       0.9414        \u001b[35m4.0981\u001b[0m  4.3470\n",
      "     74        4.0312       0.9404        \u001b[35m4.0977\u001b[0m  4.3592\n",
      "     75        4.0312       0.9394        4.0981  4.3684\n",
      "     76        \u001b[36m4.0311\u001b[0m       0.9401        \u001b[35m4.0972\u001b[0m  4.3671\n",
      "     77        4.0312       0.9397        4.0974  4.3678\n",
      "     78        \u001b[36m4.0311\u001b[0m       0.9407        4.0972  4.4125\n",
      "     79        \u001b[36m4.0311\u001b[0m       0.9397        \u001b[35m4.0971\u001b[0m  4.3526\n",
      "     80        \u001b[36m4.0311\u001b[0m       0.9387        4.0973  4.3806\n",
      "     81        4.0311       0.9391        4.0973  4.3890\n",
      "     82        4.0311       0.9397        4.0973  4.4099\n",
      "     83        4.0311       0.9374        4.0974  4.3920\n",
      "     84        \u001b[36m4.0310\u001b[0m       0.9387        4.0972  4.3182\n",
      "     85        \u001b[36m4.0310\u001b[0m       0.9391        \u001b[35m4.0970\u001b[0m  4.2750\n",
      "     86        4.0311       0.9384        \u001b[35m4.0967\u001b[0m  4.3166\n",
      "     87        \u001b[36m4.0310\u001b[0m       0.9394        \u001b[35m4.0965\u001b[0m  4.4099\n",
      "     88        \u001b[36m4.0310\u001b[0m       0.9374        4.0970  4.4371\n",
      "     89        \u001b[36m4.0309\u001b[0m       0.9384        4.0969  4.4547\n",
      "     90        4.0310       0.9387        4.0969  4.4416\n",
      "     91        4.0309       0.9384        \u001b[35m4.0964\u001b[0m  4.4074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     92        \u001b[36m4.0309\u001b[0m       0.9377        4.0965  4.4242\n",
      "     93        \u001b[36m4.0309\u001b[0m       0.9377        4.0966  4.4377\n",
      "     94        \u001b[36m4.0309\u001b[0m       0.9384        \u001b[35m4.0962\u001b[0m  4.3801\n",
      "     95        \u001b[36m4.0308\u001b[0m       0.9371        4.0965  4.4224\n",
      "     96        4.0308       0.9384        4.0966  4.4281\n",
      "     97        \u001b[36m4.0308\u001b[0m       0.9381        4.0966  4.3827\n",
      "     98        \u001b[36m4.0308\u001b[0m       0.9391        4.0964  4.4118\n",
      "     99        4.0308       0.9387        4.0965  4.4504\n",
      "    100        \u001b[36m4.0308\u001b[0m       0.9394        4.0964  4.3556\n",
      "    101        \u001b[36m4.0308\u001b[0m       0.9374        4.0966  4.3739\n",
      "    102        4.0308       0.9387        4.0967  4.5497\n",
      "    103        \u001b[36m4.0308\u001b[0m       0.9387        4.0966  4.3953\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391, 5: 0.006622516556291391, 1: 0.006622516556291391, 0.5: 0.012781456953642384, 0.1: 0.47258278145695365, 0.01: 0.9788741721854305, 0.001: 0.9859602649006622}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667, 5: 0.006666666666666667, 1: 0.006666666666666667, 0.5: 0.013333333333333334, 0.1: 0.44733333333333336, 0.01: 0.874, 0.001: 0.8963333333333333}\n",
      "pred time\n",
      "{0.001: 0.382688045501709}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0, 1: 0.0, 0.5: 0.0, 0.1: 0.0, 0.01: 0.07, 0.001: 0.11}\n",
      "OOS pred time\n",
      "{10: 0.01131582260131836, 5: 0.008625030517578125, 1: 0.01005697250366211, 0.5: 0.007462978363037109, 0.1: 0.010442256927490234, 0.01: 0.009956121444702148, 0.001: 0.012646913528442383}\n",
      "0.0001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0172\u001b[0m       \u001b[32m0.2046\u001b[0m        \u001b[35m5.0171\u001b[0m  4.3873\n",
      "      2        \u001b[36m5.0170\u001b[0m       \u001b[32m0.4493\u001b[0m        \u001b[35m5.0168\u001b[0m  4.4072\n",
      "      3        \u001b[36m5.0166\u001b[0m       \u001b[32m0.6715\u001b[0m        \u001b[35m5.0165\u001b[0m  4.3878\n",
      "      4        \u001b[36m5.0161\u001b[0m       \u001b[32m0.7407\u001b[0m        \u001b[35m5.0159\u001b[0m  4.3988\n",
      "      5        \u001b[36m5.0153\u001b[0m       \u001b[32m0.7811\u001b[0m        \u001b[35m5.0150\u001b[0m  4.8006\n",
      "      6        \u001b[36m5.0140\u001b[0m       0.7808        \u001b[35m5.0133\u001b[0m  4.4014\n",
      "      7        \u001b[36m5.0116\u001b[0m       0.7467        \u001b[35m5.0102\u001b[0m  4.3884\n",
      "      8        \u001b[36m5.0062\u001b[0m       0.5765        \u001b[35m5.0025\u001b[0m  4.3708\n",
      "      9        \u001b[36m4.9928\u001b[0m       0.3924        \u001b[35m4.9844\u001b[0m  4.4034\n",
      "     10        \u001b[36m4.9661\u001b[0m       0.3825        \u001b[35m4.9536\u001b[0m  4.3372\n",
      "     11        \u001b[36m4.9266\u001b[0m       0.4026        \u001b[35m4.9125\u001b[0m  4.3826\n",
      "     12        \u001b[36m4.8801\u001b[0m       0.4275        \u001b[35m4.8673\u001b[0m  4.3803\n",
      "     13        \u001b[36m4.8317\u001b[0m       0.4642        \u001b[35m4.8237\u001b[0m  4.4144\n",
      "     14        \u001b[36m4.7864\u001b[0m       0.5099        \u001b[35m4.7821\u001b[0m  4.3715\n",
      "     15        \u001b[36m4.7424\u001b[0m       0.5440        \u001b[35m4.7425\u001b[0m  4.3934\n",
      "     16        \u001b[36m4.7007\u001b[0m       0.5818        \u001b[35m4.7044\u001b[0m  4.4111\n",
      "     17        \u001b[36m4.6601\u001b[0m       0.6175        \u001b[35m4.6676\u001b[0m  4.3876\n",
      "     18        \u001b[36m4.6198\u001b[0m       0.6460        \u001b[35m4.6321\u001b[0m  4.3986\n",
      "     19        \u001b[36m4.5821\u001b[0m       0.6758        \u001b[35m4.5981\u001b[0m  4.3823\n",
      "     20        \u001b[36m4.5461\u001b[0m       0.7007        \u001b[35m4.5661\u001b[0m  4.4179\n",
      "     21        \u001b[36m4.5121\u001b[0m       0.7212        \u001b[35m4.5367\u001b[0m  4.3909\n",
      "     22        \u001b[36m4.4817\u001b[0m       0.7447        \u001b[35m4.5095\u001b[0m  4.3749\n",
      "     23        \u001b[36m4.4538\u001b[0m       0.7632        \u001b[35m4.4846\u001b[0m  4.4025\n",
      "     24        \u001b[36m4.4284\u001b[0m       0.7778        \u001b[35m4.4617\u001b[0m  4.5192\n",
      "     25        \u001b[36m4.4048\u001b[0m       \u001b[32m0.7934\u001b[0m        \u001b[35m4.4404\u001b[0m  4.4605\n",
      "     26        \u001b[36m4.3831\u001b[0m       \u001b[32m0.8046\u001b[0m        \u001b[35m4.4206\u001b[0m  4.4282\n",
      "     27        \u001b[36m4.3634\u001b[0m       \u001b[32m0.8159\u001b[0m        \u001b[35m4.4023\u001b[0m  4.4307\n",
      "     28        \u001b[36m4.3442\u001b[0m       \u001b[32m0.8288\u001b[0m        \u001b[35m4.3856\u001b[0m  4.2002\n",
      "     29        \u001b[36m4.3278\u001b[0m       \u001b[32m0.8368\u001b[0m        \u001b[35m4.3702\u001b[0m  4.0716\n",
      "     30        \u001b[36m4.3116\u001b[0m       \u001b[32m0.8457\u001b[0m        \u001b[35m4.3561\u001b[0m  4.3548\n",
      "     31        \u001b[36m4.2973\u001b[0m       \u001b[32m0.8500\u001b[0m        \u001b[35m4.3432\u001b[0m  4.3695\n",
      "     32        \u001b[36m4.2846\u001b[0m       \u001b[32m0.8553\u001b[0m        \u001b[35m4.3313\u001b[0m  4.4004\n",
      "     33        \u001b[36m4.2714\u001b[0m       \u001b[32m0.8606\u001b[0m        \u001b[35m4.3205\u001b[0m  4.4133\n",
      "     34        \u001b[36m4.2611\u001b[0m       \u001b[32m0.8619\u001b[0m        \u001b[35m4.3104\u001b[0m  4.3841\n",
      "     35        \u001b[36m4.2506\u001b[0m       \u001b[32m0.8662\u001b[0m        \u001b[35m4.3012\u001b[0m  4.4366\n",
      "     36        \u001b[36m4.2409\u001b[0m       \u001b[32m0.8705\u001b[0m        \u001b[35m4.2927\u001b[0m  4.3938\n",
      "     37        \u001b[36m4.2319\u001b[0m       \u001b[32m0.8758\u001b[0m        \u001b[35m4.2846\u001b[0m  4.3442\n",
      "     38        \u001b[36m4.2236\u001b[0m       \u001b[32m0.8808\u001b[0m        \u001b[35m4.2771\u001b[0m  4.3522\n",
      "     39        \u001b[36m4.2155\u001b[0m       \u001b[32m0.8844\u001b[0m        \u001b[35m4.2700\u001b[0m  4.3521\n",
      "     40        \u001b[36m4.2077\u001b[0m       \u001b[32m0.8894\u001b[0m        \u001b[35m4.2633\u001b[0m  4.3551\n",
      "     41        \u001b[36m4.2009\u001b[0m       \u001b[32m0.8930\u001b[0m        \u001b[35m4.2570\u001b[0m  4.3572\n",
      "     42        \u001b[36m4.1940\u001b[0m       \u001b[32m0.8947\u001b[0m        \u001b[35m4.2510\u001b[0m  4.3617\n",
      "     43        \u001b[36m4.1877\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m4.2453\u001b[0m  4.3730\n",
      "     44        \u001b[36m4.1815\u001b[0m       \u001b[32m0.9030\u001b[0m        \u001b[35m4.2398\u001b[0m  4.3223\n",
      "     45        \u001b[36m4.1752\u001b[0m       \u001b[32m0.9053\u001b[0m        \u001b[35m4.2345\u001b[0m  4.3594\n",
      "     46        \u001b[36m4.1704\u001b[0m       \u001b[32m0.9070\u001b[0m        \u001b[35m4.2295\u001b[0m  4.3682\n",
      "     47        \u001b[36m4.1647\u001b[0m       \u001b[32m0.9083\u001b[0m        \u001b[35m4.2247\u001b[0m  4.3790\n",
      "     48        \u001b[36m4.1596\u001b[0m       \u001b[32m0.9089\u001b[0m        \u001b[35m4.2201\u001b[0m  4.3588\n",
      "     49        \u001b[36m4.1552\u001b[0m       \u001b[32m0.9109\u001b[0m        \u001b[35m4.2159\u001b[0m  4.3673\n",
      "     50        \u001b[36m4.1507\u001b[0m       \u001b[32m0.9123\u001b[0m        \u001b[35m4.2118\u001b[0m  4.3985\n",
      "     51        \u001b[36m4.1461\u001b[0m       0.9123        \u001b[35m4.2080\u001b[0m  4.4060\n",
      "     52        \u001b[36m4.1428\u001b[0m       \u001b[32m0.9136\u001b[0m        \u001b[35m4.2045\u001b[0m  4.3391\n",
      "     53        \u001b[36m4.1387\u001b[0m       \u001b[32m0.9159\u001b[0m        \u001b[35m4.2010\u001b[0m  4.4059\n",
      "     54        \u001b[36m4.1353\u001b[0m       \u001b[32m0.9166\u001b[0m        \u001b[35m4.1978\u001b[0m  4.3929\n",
      "     55        \u001b[36m4.1318\u001b[0m       \u001b[32m0.9189\u001b[0m        \u001b[35m4.1948\u001b[0m  4.3318\n",
      "     56        \u001b[36m4.1295\u001b[0m       0.9189        \u001b[35m4.1919\u001b[0m  4.3307\n",
      "     57        \u001b[36m4.1260\u001b[0m       \u001b[32m0.9202\u001b[0m        \u001b[35m4.1892\u001b[0m  4.3069\n",
      "     58        \u001b[36m4.1231\u001b[0m       \u001b[32m0.9205\u001b[0m        \u001b[35m4.1866\u001b[0m  4.3508\n",
      "     59        \u001b[36m4.1206\u001b[0m       \u001b[32m0.9212\u001b[0m        \u001b[35m4.1841\u001b[0m  4.3441\n",
      "     60        \u001b[36m4.1173\u001b[0m       \u001b[32m0.9225\u001b[0m        \u001b[35m4.1817\u001b[0m  4.3789\n",
      "     61        \u001b[36m4.1152\u001b[0m       \u001b[32m0.9228\u001b[0m        \u001b[35m4.1795\u001b[0m  4.3932\n",
      "     62        \u001b[36m4.1123\u001b[0m       \u001b[32m0.9238\u001b[0m        \u001b[35m4.1774\u001b[0m  4.3882\n",
      "     63        \u001b[36m4.1097\u001b[0m       \u001b[32m0.9242\u001b[0m        \u001b[35m4.1753\u001b[0m  4.3830\n",
      "     64        \u001b[36m4.1076\u001b[0m       \u001b[32m0.9255\u001b[0m        \u001b[35m4.1733\u001b[0m  4.2836\n",
      "     65        \u001b[36m4.1057\u001b[0m       0.9255        \u001b[35m4.1715\u001b[0m  4.2468\n",
      "     66        \u001b[36m4.1034\u001b[0m       0.9255        \u001b[35m4.1697\u001b[0m  4.2335\n",
      "     67        \u001b[36m4.1006\u001b[0m       \u001b[32m0.9258\u001b[0m        \u001b[35m4.1680\u001b[0m  4.0359\n",
      "     68        \u001b[36m4.0984\u001b[0m       0.9258        \u001b[35m4.1662\u001b[0m  4.1368\n",
      "     69        \u001b[36m4.0966\u001b[0m       \u001b[32m0.9268\u001b[0m        \u001b[35m4.1647\u001b[0m  4.2182\n",
      "     70        \u001b[36m4.0952\u001b[0m       \u001b[32m0.9278\u001b[0m        \u001b[35m4.1632\u001b[0m  4.1739\n",
      "     71        \u001b[36m4.0926\u001b[0m       \u001b[32m0.9281\u001b[0m        \u001b[35m4.1618\u001b[0m  4.1875\n",
      "     72        \u001b[36m4.0918\u001b[0m       0.9281        \u001b[35m4.1603\u001b[0m  4.2320\n",
      "     73        \u001b[36m4.0897\u001b[0m       0.9281        \u001b[35m4.1590\u001b[0m  4.3339\n",
      "     74        \u001b[36m4.0885\u001b[0m       \u001b[32m0.9291\u001b[0m        \u001b[35m4.1577\u001b[0m  4.3086\n",
      "     75        \u001b[36m4.0865\u001b[0m       0.9291        \u001b[35m4.1564\u001b[0m  4.3342\n",
      "     76        \u001b[36m4.0850\u001b[0m       \u001b[32m0.9305\u001b[0m        \u001b[35m4.1552\u001b[0m  4.3302\n",
      "     77        \u001b[36m4.0837\u001b[0m       0.9295        \u001b[35m4.1540\u001b[0m  4.0621\n",
      "     78        \u001b[36m4.0824\u001b[0m       0.9298        \u001b[35m4.1528\u001b[0m  3.7403\n",
      "     79        \u001b[36m4.0806\u001b[0m       \u001b[32m0.9311\u001b[0m        \u001b[35m4.1517\u001b[0m  3.6061\n",
      "     80        \u001b[36m4.0796\u001b[0m       \u001b[32m0.9318\u001b[0m        \u001b[35m4.1507\u001b[0m  3.5641\n",
      "     81        \u001b[36m4.0784\u001b[0m       \u001b[32m0.9328\u001b[0m        \u001b[35m4.1496\u001b[0m  3.5752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     82        \u001b[36m4.0771\u001b[0m       0.9328        \u001b[35m4.1486\u001b[0m  3.6110\n",
      "     83        \u001b[36m4.0759\u001b[0m       0.9325        \u001b[35m4.1477\u001b[0m  3.6947\n",
      "     84        \u001b[36m4.0747\u001b[0m       0.9328        \u001b[35m4.1468\u001b[0m  3.6522\n",
      "     85        \u001b[36m4.0740\u001b[0m       0.9325        \u001b[35m4.1458\u001b[0m  3.6171\n",
      "     86        \u001b[36m4.0729\u001b[0m       \u001b[32m0.9331\u001b[0m        \u001b[35m4.1449\u001b[0m  3.6124\n",
      "     87        \u001b[36m4.0721\u001b[0m       0.9328        \u001b[35m4.1440\u001b[0m  3.5807\n",
      "     88        \u001b[36m4.0705\u001b[0m       0.9328        \u001b[35m4.1431\u001b[0m  3.5693\n",
      "     89        \u001b[36m4.0693\u001b[0m       0.9331        \u001b[35m4.1422\u001b[0m  3.5716\n",
      "     90        \u001b[36m4.0690\u001b[0m       \u001b[32m0.9341\u001b[0m        \u001b[35m4.1413\u001b[0m  3.5493\n",
      "     91        \u001b[36m4.0675\u001b[0m       0.9341        \u001b[35m4.1404\u001b[0m  3.5730\n",
      "     92        \u001b[36m4.0665\u001b[0m       \u001b[32m0.9344\u001b[0m        \u001b[35m4.1396\u001b[0m  3.5952\n",
      "     93        \u001b[36m4.0659\u001b[0m       0.9344        \u001b[35m4.1387\u001b[0m  3.6197\n",
      "     94        \u001b[36m4.0647\u001b[0m       \u001b[32m0.9348\u001b[0m        \u001b[35m4.1379\u001b[0m  3.6179\n",
      "     95        \u001b[36m4.0636\u001b[0m       0.9344        \u001b[35m4.1371\u001b[0m  4.1802\n",
      "     96        \u001b[36m4.0626\u001b[0m       \u001b[32m0.9351\u001b[0m        \u001b[35m4.1363\u001b[0m  4.6260\n",
      "     97        \u001b[36m4.0622\u001b[0m       0.9351        \u001b[35m4.1356\u001b[0m  4.4660\n",
      "     98        \u001b[36m4.0610\u001b[0m       \u001b[32m0.9354\u001b[0m        \u001b[35m4.1348\u001b[0m  4.3168\n",
      "     99        \u001b[36m4.0599\u001b[0m       0.9354        \u001b[35m4.1341\u001b[0m  4.2896\n",
      "    100        \u001b[36m4.0594\u001b[0m       \u001b[32m0.9358\u001b[0m        \u001b[35m4.1334\u001b[0m  4.3215\n",
      "    101        \u001b[36m4.0583\u001b[0m       \u001b[32m0.9361\u001b[0m        \u001b[35m4.1327\u001b[0m  4.3231\n",
      "    102        \u001b[36m4.0577\u001b[0m       \u001b[32m0.9364\u001b[0m        \u001b[35m4.1321\u001b[0m  3.7994\n",
      "    103        \u001b[36m4.0568\u001b[0m       \u001b[32m0.9368\u001b[0m        \u001b[35m4.1314\u001b[0m  3.6541\n",
      "    104        \u001b[36m4.0568\u001b[0m       \u001b[32m0.9371\u001b[0m        \u001b[35m4.1308\u001b[0m  3.6938\n",
      "    105        \u001b[36m4.0558\u001b[0m       \u001b[32m0.9374\u001b[0m        \u001b[35m4.1301\u001b[0m  3.6773\n",
      "    106        \u001b[36m4.0547\u001b[0m       0.9371        \u001b[35m4.1295\u001b[0m  3.6963\n",
      "    107        4.0547       \u001b[32m0.9381\u001b[0m        \u001b[35m4.1290\u001b[0m  3.6393\n",
      "    108        \u001b[36m4.0538\u001b[0m       0.9377        \u001b[35m4.1285\u001b[0m  3.5570\n",
      "    109        \u001b[36m4.0527\u001b[0m       0.9377        \u001b[35m4.1279\u001b[0m  3.5531\n",
      "    110        \u001b[36m4.0527\u001b[0m       0.9377        \u001b[35m4.1273\u001b[0m  3.5530\n",
      "    111        \u001b[36m4.0521\u001b[0m       0.9374        \u001b[35m4.1268\u001b[0m  3.5391\n",
      "    112        \u001b[36m4.0514\u001b[0m       0.9374        \u001b[35m4.1262\u001b[0m  3.5654\n",
      "    113        \u001b[36m4.0513\u001b[0m       0.9374        \u001b[35m4.1257\u001b[0m  3.6106\n",
      "    114        \u001b[36m4.0507\u001b[0m       0.9377        \u001b[35m4.1252\u001b[0m  3.7571\n",
      "    115        \u001b[36m4.0504\u001b[0m       0.9381        \u001b[35m4.1247\u001b[0m  3.7653\n",
      "    116        \u001b[36m4.0498\u001b[0m       0.9381        \u001b[35m4.1242\u001b[0m  3.7149\n",
      "    117        \u001b[36m4.0493\u001b[0m       \u001b[32m0.9387\u001b[0m        \u001b[35m4.1238\u001b[0m  3.6007\n",
      "    118        \u001b[36m4.0490\u001b[0m       \u001b[32m0.9391\u001b[0m        \u001b[35m4.1233\u001b[0m  3.6771\n",
      "    119        \u001b[36m4.0484\u001b[0m       \u001b[32m0.9397\u001b[0m        \u001b[35m4.1229\u001b[0m  3.8060\n",
      "    120        \u001b[36m4.0478\u001b[0m       0.9394        \u001b[35m4.1225\u001b[0m  3.6782\n",
      "    121        \u001b[36m4.0473\u001b[0m       0.9394        \u001b[35m4.1220\u001b[0m  3.6129\n",
      "    122        \u001b[36m4.0471\u001b[0m       0.9394        \u001b[35m4.1216\u001b[0m  3.6593\n",
      "    123        \u001b[36m4.0469\u001b[0m       0.9394        \u001b[35m4.1211\u001b[0m  3.7156\n",
      "    124        \u001b[36m4.0462\u001b[0m       0.9394        \u001b[35m4.1207\u001b[0m  3.6289\n",
      "    125        \u001b[36m4.0459\u001b[0m       \u001b[32m0.9401\u001b[0m        \u001b[35m4.1203\u001b[0m  3.6685\n",
      "    126        \u001b[36m4.0458\u001b[0m       \u001b[32m0.9411\u001b[0m        \u001b[35m4.1199\u001b[0m  3.5609\n",
      "    127        \u001b[36m4.0452\u001b[0m       0.9407        \u001b[35m4.1196\u001b[0m  3.6525\n",
      "    128        4.0454       0.9411        \u001b[35m4.1192\u001b[0m  3.6560\n",
      "    129        \u001b[36m4.0446\u001b[0m       0.9411        \u001b[35m4.1188\u001b[0m  3.6311\n",
      "    130        \u001b[36m4.0444\u001b[0m       0.9404        \u001b[35m4.1185\u001b[0m  3.6655\n",
      "    131        \u001b[36m4.0439\u001b[0m       0.9411        \u001b[35m4.1181\u001b[0m  3.6902\n",
      "    132        \u001b[36m4.0437\u001b[0m       \u001b[32m0.9414\u001b[0m        \u001b[35m4.1178\u001b[0m  3.5423\n",
      "    133        \u001b[36m4.0436\u001b[0m       0.9414        \u001b[35m4.1173\u001b[0m  3.5666\n",
      "    134        \u001b[36m4.0434\u001b[0m       0.9411        \u001b[35m4.1170\u001b[0m  3.5720\n",
      "    135        \u001b[36m4.0431\u001b[0m       0.9411        \u001b[35m4.1166\u001b[0m  3.6040\n",
      "    136        \u001b[36m4.0426\u001b[0m       0.9414        \u001b[35m4.1163\u001b[0m  3.5905\n",
      "    137        \u001b[36m4.0422\u001b[0m       0.9411        \u001b[35m4.1160\u001b[0m  3.6081\n",
      "    138        \u001b[36m4.0420\u001b[0m       0.9411        \u001b[35m4.1156\u001b[0m  3.5508\n",
      "    139        \u001b[36m4.0419\u001b[0m       \u001b[32m0.9417\u001b[0m        \u001b[35m4.1153\u001b[0m  3.8050\n",
      "    140        \u001b[36m4.0413\u001b[0m       0.9417        \u001b[35m4.1150\u001b[0m  3.5889\n",
      "    141        4.0413       0.9414        \u001b[35m4.1147\u001b[0m  3.5889\n",
      "    142        \u001b[36m4.0412\u001b[0m       0.9411        \u001b[35m4.1145\u001b[0m  3.5631\n",
      "    143        \u001b[36m4.0407\u001b[0m       0.9417        \u001b[35m4.1142\u001b[0m  3.7164\n",
      "    144        4.0408       0.9417        \u001b[35m4.1139\u001b[0m  3.6792\n",
      "    145        \u001b[36m4.0405\u001b[0m       0.9414        \u001b[35m4.1136\u001b[0m  3.5522\n",
      "    146        \u001b[36m4.0402\u001b[0m       0.9411        \u001b[35m4.1134\u001b[0m  3.7453\n",
      "    147        \u001b[36m4.0399\u001b[0m       0.9414        \u001b[35m4.1131\u001b[0m  3.5421\n",
      "    148        \u001b[36m4.0398\u001b[0m       0.9417        \u001b[35m4.1129\u001b[0m  3.5426\n",
      "    149        \u001b[36m4.0397\u001b[0m       0.9414        \u001b[35m4.1127\u001b[0m  3.5363\n",
      "    150        \u001b[36m4.0394\u001b[0m       0.9414        \u001b[35m4.1125\u001b[0m  3.6199\n",
      "    151        4.0394       \u001b[32m0.9421\u001b[0m        \u001b[35m4.1123\u001b[0m  3.5769\n",
      "    152        \u001b[36m4.0393\u001b[0m       0.9421        \u001b[35m4.1121\u001b[0m  3.5635\n",
      "    153        \u001b[36m4.0389\u001b[0m       0.9421        \u001b[35m4.1119\u001b[0m  3.5407\n",
      "    154        \u001b[36m4.0387\u001b[0m       0.9421        \u001b[35m4.1116\u001b[0m  3.5848\n",
      "    155        \u001b[36m4.0387\u001b[0m       0.9417        \u001b[35m4.1114\u001b[0m  3.5762\n",
      "    156        \u001b[36m4.0385\u001b[0m       0.9421        \u001b[35m4.1112\u001b[0m  3.7154\n",
      "    157        \u001b[36m4.0381\u001b[0m       0.9417        \u001b[35m4.1110\u001b[0m  3.7166\n",
      "    158        4.0383       0.9417        \u001b[35m4.1108\u001b[0m  3.8527\n",
      "    159        \u001b[36m4.0379\u001b[0m       0.9417        \u001b[35m4.1106\u001b[0m  3.8943\n",
      "    160        \u001b[36m4.0377\u001b[0m       0.9417        \u001b[35m4.1104\u001b[0m  3.5596\n",
      "    161        4.0377       0.9417        \u001b[35m4.1102\u001b[0m  3.5217\n",
      "    162        \u001b[36m4.0376\u001b[0m       0.9417        \u001b[35m4.1101\u001b[0m  3.6178\n",
      "    163        \u001b[36m4.0373\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m4.1099\u001b[0m  4.0099\n",
      "    164        4.0375       0.9414        \u001b[35m4.1097\u001b[0m  3.7259\n",
      "    165        4.0373       0.9417        \u001b[35m4.1095\u001b[0m  3.8498\n",
      "    166        \u001b[36m4.0370\u001b[0m       0.9414        \u001b[35m4.1093\u001b[0m  3.8163\n",
      "    167        4.0371       0.9414        \u001b[35m4.1092\u001b[0m  4.0390\n",
      "    168        \u001b[36m4.0370\u001b[0m       0.9421        \u001b[35m4.1090\u001b[0m  4.1386\n",
      "    169        \u001b[36m4.0367\u001b[0m       0.9417        \u001b[35m4.1089\u001b[0m  4.1288\n",
      "    170        4.0368       0.9421        \u001b[35m4.1087\u001b[0m  3.9802\n",
      "    171        \u001b[36m4.0366\u001b[0m       0.9421        \u001b[35m4.1086\u001b[0m  4.1601\n",
      "    172        \u001b[36m4.0364\u001b[0m       0.9421        \u001b[35m4.1084\u001b[0m  3.9465\n",
      "    173        4.0364       0.9417        \u001b[35m4.1083\u001b[0m  3.8815\n",
      "    174        \u001b[36m4.0362\u001b[0m       0.9421        \u001b[35m4.1082\u001b[0m  3.7731\n",
      "    175        \u001b[36m4.0362\u001b[0m       0.9421        \u001b[35m4.1081\u001b[0m  3.8696\n",
      "    176        \u001b[36m4.0361\u001b[0m       0.9424        \u001b[35m4.1079\u001b[0m  3.7779\n",
      "    177        \u001b[36m4.0360\u001b[0m       0.9424        \u001b[35m4.1077\u001b[0m  3.9048\n",
      "    178        \u001b[36m4.0359\u001b[0m       \u001b[32m0.9427\u001b[0m        \u001b[35m4.1076\u001b[0m  3.9612\n",
      "    179        \u001b[36m4.0358\u001b[0m       0.9421        \u001b[35m4.1074\u001b[0m  4.0993\n",
      "    180        \u001b[36m4.0355\u001b[0m       0.9421        \u001b[35m4.1074\u001b[0m  3.9791\n",
      "    181        4.0358       0.9417        \u001b[35m4.1072\u001b[0m  3.8860\n",
      "    182        \u001b[36m4.0353\u001b[0m       0.9421        \u001b[35m4.1071\u001b[0m  3.6701\n",
      "    183        4.0355       0.9417        \u001b[35m4.1070\u001b[0m  3.6401\n",
      "    184        \u001b[36m4.0353\u001b[0m       0.9417        \u001b[35m4.1069\u001b[0m  3.5319\n",
      "    185        \u001b[36m4.0352\u001b[0m       0.9417        \u001b[35m4.1067\u001b[0m  3.5260\n",
      "    186        \u001b[36m4.0350\u001b[0m       0.9421        \u001b[35m4.1066\u001b[0m  3.5282\n",
      "    187        4.0352       0.9417        \u001b[35m4.1065\u001b[0m  4.0014\n",
      "    188        \u001b[36m4.0350\u001b[0m       0.9417        \u001b[35m4.1065\u001b[0m  4.1508\n",
      "    189        4.0350       0.9417        \u001b[35m4.1063\u001b[0m  3.7394\n",
      "    190        4.0350       0.9421        \u001b[35m4.1063\u001b[0m  3.5549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    191        \u001b[36m4.0349\u001b[0m       0.9424        \u001b[35m4.1061\u001b[0m  3.9134\n",
      "    192        \u001b[36m4.0347\u001b[0m       0.9424        \u001b[35m4.1060\u001b[0m  4.0978\n",
      "    193        \u001b[36m4.0346\u001b[0m       0.9421        \u001b[35m4.1059\u001b[0m  3.8796\n",
      "    194        4.0347       0.9421        \u001b[35m4.1059\u001b[0m  3.5725\n",
      "    195        \u001b[36m4.0345\u001b[0m       0.9421        \u001b[35m4.1058\u001b[0m  3.7760\n",
      "    196        4.0347       0.9427        \u001b[35m4.1057\u001b[0m  4.0846\n",
      "    197        \u001b[36m4.0345\u001b[0m       0.9424        \u001b[35m4.1056\u001b[0m  3.9865\n",
      "    198        \u001b[36m4.0345\u001b[0m       0.9414        \u001b[35m4.1055\u001b[0m  3.7321\n",
      "    199        \u001b[36m4.0343\u001b[0m       0.9414        \u001b[35m4.1055\u001b[0m  3.9641\n",
      "    200        4.0343       0.9417        \u001b[35m4.1054\u001b[0m  3.7564\n",
      "    201        \u001b[36m4.0342\u001b[0m       0.9417        \u001b[35m4.1054\u001b[0m  3.8173\n",
      "    202        4.0342       0.9421        \u001b[35m4.1052\u001b[0m  3.8850\n",
      "    203        \u001b[36m4.0342\u001b[0m       0.9414        \u001b[35m4.1051\u001b[0m  3.6633\n",
      "    204        \u001b[36m4.0341\u001b[0m       0.9414        \u001b[35m4.1049\u001b[0m  3.7514\n",
      "    205        \u001b[36m4.0340\u001b[0m       0.9417        \u001b[35m4.1048\u001b[0m  3.9749\n",
      "    206        \u001b[36m4.0339\u001b[0m       0.9424        \u001b[35m4.1047\u001b[0m  4.0767\n",
      "    207        \u001b[36m4.0339\u001b[0m       0.9417        \u001b[35m4.1047\u001b[0m  4.1772\n",
      "    208        \u001b[36m4.0339\u001b[0m       0.9417        \u001b[35m4.1046\u001b[0m  4.1754\n",
      "    209        \u001b[36m4.0339\u001b[0m       0.9414        \u001b[35m4.1045\u001b[0m  4.1811\n",
      "    210        \u001b[36m4.0339\u001b[0m       0.9411        \u001b[35m4.1044\u001b[0m  4.2171\n",
      "    211        \u001b[36m4.0336\u001b[0m       0.9411        \u001b[35m4.1044\u001b[0m  4.2824\n",
      "    212        4.0337       0.9411        \u001b[35m4.1043\u001b[0m  4.3598\n",
      "    213        4.0337       0.9411        \u001b[35m4.1043\u001b[0m  4.4317\n",
      "    214        4.0337       0.9411        \u001b[35m4.1042\u001b[0m  4.3787\n",
      "    215        4.0336       0.9407        \u001b[35m4.1042\u001b[0m  4.4108\n",
      "    216        \u001b[36m4.0335\u001b[0m       0.9414        \u001b[35m4.1041\u001b[0m  4.4117\n",
      "    217        \u001b[36m4.0334\u001b[0m       0.9411        \u001b[35m4.1040\u001b[0m  4.4648\n",
      "    218        4.0335       0.9411        \u001b[35m4.1039\u001b[0m  4.3784\n",
      "    219        \u001b[36m4.0334\u001b[0m       0.9411        4.1039  4.3630\n",
      "    220        4.0334       0.9407        \u001b[35m4.1039\u001b[0m  4.3596\n",
      "    221        4.0334       0.9411        \u001b[35m4.1038\u001b[0m  4.3709\n",
      "    222        \u001b[36m4.0333\u001b[0m       0.9407        \u001b[35m4.1038\u001b[0m  4.3688\n",
      "    223        \u001b[36m4.0332\u001b[0m       0.9414        \u001b[35m4.1036\u001b[0m  4.3800\n",
      "    224        4.0332       0.9417        \u001b[35m4.1036\u001b[0m  4.3137\n",
      "    225        4.0333       0.9411        \u001b[35m4.1035\u001b[0m  4.3994\n",
      "    226        4.0332       0.9411        4.1035  4.3856\n",
      "    227        \u001b[36m4.0331\u001b[0m       0.9407        \u001b[35m4.1035\u001b[0m  4.3746\n",
      "    228        \u001b[36m4.0330\u001b[0m       0.9414        \u001b[35m4.1034\u001b[0m  4.3916\n",
      "    229        4.0331       0.9414        \u001b[35m4.1033\u001b[0m  4.3718\n",
      "    230        4.0331       0.9411        \u001b[35m4.1032\u001b[0m  4.3693\n",
      "    231        \u001b[36m4.0329\u001b[0m       0.9407        \u001b[35m4.1031\u001b[0m  4.3733\n",
      "    232        4.0329       0.9404        \u001b[35m4.1030\u001b[0m  4.2577\n",
      "    233        \u001b[36m4.0329\u001b[0m       0.9401        \u001b[35m4.1029\u001b[0m  4.3630\n",
      "    234        \u001b[36m4.0328\u001b[0m       0.9407        \u001b[35m4.1028\u001b[0m  4.3887\n",
      "    235        \u001b[36m4.0328\u001b[0m       0.9411        \u001b[35m4.1028\u001b[0m  4.3645\n",
      "    236        \u001b[36m4.0328\u001b[0m       0.9411        \u001b[35m4.1027\u001b[0m  4.4270\n",
      "    237        4.0329       0.9411        \u001b[35m4.1026\u001b[0m  4.4245\n",
      "    238        \u001b[36m4.0326\u001b[0m       0.9404        \u001b[35m4.1026\u001b[0m  4.3959\n",
      "    239        \u001b[36m4.0326\u001b[0m       0.9411        \u001b[35m4.1026\u001b[0m  4.3781\n",
      "    240        \u001b[36m4.0326\u001b[0m       0.9407        \u001b[35m4.1025\u001b[0m  4.2143\n",
      "    241        \u001b[36m4.0326\u001b[0m       0.9407        \u001b[35m4.1025\u001b[0m  4.4006\n",
      "    242        4.0326       0.9407        4.1026  4.2796\n",
      "    243        \u001b[36m4.0325\u001b[0m       0.9404        4.1025  4.3982\n",
      "    244        \u001b[36m4.0325\u001b[0m       0.9404        \u001b[35m4.1025\u001b[0m  4.3684\n",
      "    245        4.0326       0.9401        4.1025  4.3853\n",
      "    246        4.0326       0.9401        4.1025  4.3883\n",
      "    247        \u001b[36m4.0324\u001b[0m       0.9404        \u001b[35m4.1024\u001b[0m  4.3501\n",
      "    248        4.0324       0.9401        \u001b[35m4.1024\u001b[0m  4.3956\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391, 5: 0.006622516556291391, 1: 0.006622516556291391, 0.5: 0.012781456953642384, 0.1: 0.47258278145695365, 0.01: 0.9788741721854305, 0.001: 0.9859602649006622, 0.0001: 0.9858278145695364}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667, 5: 0.006666666666666667, 1: 0.006666666666666667, 0.5: 0.013333333333333334, 0.1: 0.44733333333333336, 0.01: 0.874, 0.001: 0.8963333333333333, 0.0001: 0.8983333333333333}\n",
      "pred time\n",
      "{0.001: 1.4420032501220703}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0, 1: 0.0, 0.5: 0.0, 0.1: 0.0, 0.01: 0.07, 0.001: 0.11, 0.0001: 0.14}\n",
      "OOS pred time\n",
      "{10: 0.01131582260131836, 5: 0.008625030517578125, 1: 0.01005697250366211, 0.5: 0.007462978363037109, 0.1: 0.010442256927490234, 0.01: 0.009956121444702148, 0.001: 0.012646913528442383, 0.0001: 0.18695378303527832}\n",
      "1e-05\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0109\u001b[0m        \u001b[35m5.0173\u001b[0m  4.3251\n",
      "      2        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0192\u001b[0m        \u001b[35m5.0172\u001b[0m  4.6625\n",
      "      3        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0328\u001b[0m        \u001b[35m5.0172\u001b[0m  4.3687\n",
      "      4        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0460\u001b[0m        \u001b[35m5.0172\u001b[0m  4.3441\n",
      "      5        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0649\u001b[0m        \u001b[35m5.0172\u001b[0m  4.3680\n",
      "      6        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0937\u001b[0m        \u001b[35m5.0172\u001b[0m  3.8357\n",
      "      7        \u001b[36m5.0171\u001b[0m       \u001b[32m0.1189\u001b[0m        \u001b[35m5.0171\u001b[0m  3.5310\n",
      "      8        \u001b[36m5.0171\u001b[0m       \u001b[32m0.1430\u001b[0m        \u001b[35m5.0171\u001b[0m  3.5376\n",
      "      9        \u001b[36m5.0171\u001b[0m       \u001b[32m0.1629\u001b[0m        \u001b[35m5.0171\u001b[0m  3.5892\n",
      "     10        \u001b[36m5.0171\u001b[0m       \u001b[32m0.1851\u001b[0m        \u001b[35m5.0171\u001b[0m  3.5405\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391, 5: 0.006622516556291391, 1: 0.006622516556291391, 0.5: 0.012781456953642384, 0.1: 0.47258278145695365, 0.01: 0.9788741721854305, 0.001: 0.9859602649006622, 0.0001: 0.9858278145695364, 1e-05: 0.24072847682119206}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667, 5: 0.006666666666666667, 1: 0.006666666666666667, 0.5: 0.013333333333333334, 0.1: 0.44733333333333336, 0.01: 0.874, 0.001: 0.8963333333333333, 0.0001: 0.8983333333333333, 1e-05: 0.211}\n",
      "pred time\n",
      "{0.001: 0.25922203063964844}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0, 1: 0.0, 0.5: 0.0, 0.1: 0.0, 0.01: 0.07, 0.001: 0.11, 0.0001: 0.14, 1e-05: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.01131582260131836, 5: 0.008625030517578125, 1: 0.01005697250366211, 0.5: 0.007462978363037109, 0.1: 0.010442256927490234, 0.01: 0.009956121444702148, 0.001: 0.012646913528442383, 0.0001: 0.18695378303527832, 1e-05: 0.008339881896972656}\n",
      "1e-06\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0099\u001b[0m        \u001b[35m5.0173\u001b[0m  3.5549\n",
      "      2        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0103\u001b[0m        \u001b[35m5.0173\u001b[0m  3.5695\n",
      "      3        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0109\u001b[0m        \u001b[35m5.0173\u001b[0m  3.5574\n",
      "      4        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0119\u001b[0m        \u001b[35m5.0173\u001b[0m  3.5538\n",
      "      5        \u001b[36m5.0173\u001b[0m       0.0119        \u001b[35m5.0173\u001b[0m  3.5653\n",
      "      6        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0136\u001b[0m        \u001b[35m5.0173\u001b[0m  3.5805\n",
      "      7        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0149\u001b[0m        \u001b[35m5.0173\u001b[0m  3.5684\n",
      "      8        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0159\u001b[0m        \u001b[35m5.0173\u001b[0m  3.5159\n",
      "      9        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0166\u001b[0m        \u001b[35m5.0173\u001b[0m  3.4974\n",
      "     10        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0182\u001b[0m        \u001b[35m5.0173\u001b[0m  3.5101\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391, 5: 0.006622516556291391, 1: 0.006622516556291391, 0.5: 0.012781456953642384, 0.1: 0.47258278145695365, 0.01: 0.9788741721854305, 0.001: 0.9859602649006622, 0.0001: 0.9858278145695364, 1e-05: 0.24072847682119206, 1e-06: 0.015364238410596026}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy\n",
      "{10: 0.006666666666666667, 5: 0.006666666666666667, 1: 0.006666666666666667, 0.5: 0.013333333333333334, 0.1: 0.44733333333333336, 0.01: 0.874, 0.001: 0.8963333333333333, 0.0001: 0.8983333333333333, 1e-05: 0.211, 1e-06: 0.016}\n",
      "pred time\n",
      "{0.001: 0.2431046962738037}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 5: 0.0, 1: 0.0, 0.5: 0.0, 0.1: 0.0, 0.01: 0.07, 0.001: 0.11, 0.0001: 0.14, 1e-05: 0.0, 1e-06: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.01131582260131836, 5: 0.008625030517578125, 1: 0.01005697250366211, 0.5: 0.007462978363037109, 0.1: 0.010442256927490234, 0.01: 0.009956121444702148, 0.001: 0.012646913528442383, 0.0001: 0.18695378303527832, 1e-05: 0.008339881896972656, 1e-06: 0.008316993713378906}\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [10, 5, 1, 0.5, 0.1, 0.01, 0.001, 1e-4, 1e-5 ,1e-6]\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "for lr in learning_rates:    \n",
    "    print(lr)\n",
    "    class CLINCModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                input_dim=vocab_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim,\n",
    "                dropout=0.5\n",
    "        ):\n",
    "            super(CLINCModule, self).__init__()\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "            self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = torch.tanh(self.hidden(X))\n",
    "            X = self.dropout(X)\n",
    "            X = F.softmax(self.output(X), dim=-1)\n",
    "            return X\n",
    "   \n",
    "    net = NeuralNetClassifier(\n",
    "    module=CLINCModule,\n",
    "    lr=lr,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    max_epochs=1000,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    callbacks=[EarlyStopping(patience=10)],\n",
    "    )\n",
    "    \n",
    "    net.fit(train_x, train_y)\n",
    "    tlabels = net.predict(train_x)\n",
    "    tacc[lr] = accuracy_score(tlabels, train_y)\n",
    "    print('training accuracy')\n",
    "    print(tacc)\n",
    "    time0 = time.time()\n",
    "    labels = net.predict(val_x)\n",
    "    vacc[lr] = accuracy_score(labels, val_y)\n",
    "    time1 = time.time()\n",
    "    vtime[d] = time1-time0\n",
    "    print('Val accuracy')\n",
    "    print(vacc)\n",
    "    print('pred time')\n",
    "    print(vtime)\n",
    "    time2 = time.time()\n",
    "    olabels = net.predict(val_oos_x)\n",
    "    oacc[lr] = accuracy_score(olabels, val_oos_y)\n",
    "    time3 = time.time()\n",
    "    otime[lr]=time3-time2\n",
    "    print('OOS Val Accuracy')\n",
    "    print(oacc)\n",
    "    print('OOS pred time')\n",
    "    print(otime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy very similar for learning rates of 0.001 and 0.0001. Former chosen due to faster training time. Investigating effect of number of neurons in hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0166\u001b[0m       \u001b[32m0.6139\u001b[0m        \u001b[35m5.0153\u001b[0m  1.4640\n",
      "      2        \u001b[36m5.0072\u001b[0m       0.5146        \u001b[35m4.9842\u001b[0m  1.4421\n",
      "      3        \u001b[36m4.8927\u001b[0m       0.5685        \u001b[35m4.7778\u001b[0m  1.5117\n",
      "      4        \u001b[36m4.6625\u001b[0m       \u001b[32m0.7056\u001b[0m        \u001b[35m4.5625\u001b[0m  1.4323\n",
      "      5        \u001b[36m4.4843\u001b[0m       \u001b[32m0.7795\u001b[0m        \u001b[35m4.4313\u001b[0m  1.6715\n",
      "      6        \u001b[36m4.3751\u001b[0m       \u001b[32m0.8275\u001b[0m        \u001b[35m4.3504\u001b[0m  1.6004\n",
      "      7        \u001b[36m4.3020\u001b[0m       \u001b[32m0.8589\u001b[0m        \u001b[35m4.2952\u001b[0m  1.5017\n",
      "      8        \u001b[36m4.2513\u001b[0m       \u001b[32m0.8818\u001b[0m        \u001b[35m4.2584\u001b[0m  1.4168\n",
      "      9        \u001b[36m4.2166\u001b[0m       \u001b[32m0.8964\u001b[0m        \u001b[35m4.2296\u001b[0m  1.4802\n",
      "     10        \u001b[36m4.1852\u001b[0m       \u001b[32m0.9046\u001b[0m        \u001b[35m4.2073\u001b[0m  1.4061\n",
      "     11        \u001b[36m4.1655\u001b[0m       \u001b[32m0.9103\u001b[0m        \u001b[35m4.1918\u001b[0m  1.4697\n",
      "     12        \u001b[36m4.1482\u001b[0m       \u001b[32m0.9129\u001b[0m        \u001b[35m4.1804\u001b[0m  1.4371\n",
      "     13        \u001b[36m4.1346\u001b[0m       \u001b[32m0.9179\u001b[0m        \u001b[35m4.1715\u001b[0m  1.4536\n",
      "     14        \u001b[36m4.1245\u001b[0m       \u001b[32m0.9195\u001b[0m        \u001b[35m4.1644\u001b[0m  1.3987\n",
      "     15        \u001b[36m4.1164\u001b[0m       \u001b[32m0.9212\u001b[0m        \u001b[35m4.1583\u001b[0m  1.4139\n",
      "     16        \u001b[36m4.1083\u001b[0m       \u001b[32m0.9219\u001b[0m        \u001b[35m4.1538\u001b[0m  1.3966\n",
      "     17        \u001b[36m4.1008\u001b[0m       \u001b[32m0.9242\u001b[0m        \u001b[35m4.1496\u001b[0m  1.3935\n",
      "     18        \u001b[36m4.0959\u001b[0m       \u001b[32m0.9255\u001b[0m        \u001b[35m4.1458\u001b[0m  1.4054\n",
      "     19        \u001b[36m4.0897\u001b[0m       0.9255        \u001b[35m4.1426\u001b[0m  1.4123\n",
      "     20        \u001b[36m4.0840\u001b[0m       \u001b[32m0.9272\u001b[0m        \u001b[35m4.1401\u001b[0m  1.3944\n",
      "     21        \u001b[36m4.0809\u001b[0m       \u001b[32m0.9275\u001b[0m        \u001b[35m4.1377\u001b[0m  1.3941\n",
      "     22        \u001b[36m4.0783\u001b[0m       \u001b[32m0.9298\u001b[0m        \u001b[35m4.1359\u001b[0m  1.4800\n",
      "     23        \u001b[36m4.0753\u001b[0m       0.9298        \u001b[35m4.1339\u001b[0m  1.6593\n",
      "     24        \u001b[36m4.0722\u001b[0m       \u001b[32m0.9305\u001b[0m        \u001b[35m4.1318\u001b[0m  1.4499\n",
      "     25        \u001b[36m4.0692\u001b[0m       \u001b[32m0.9321\u001b[0m        \u001b[35m4.1299\u001b[0m  1.4564\n",
      "     26        \u001b[36m4.0662\u001b[0m       0.9305        \u001b[35m4.1277\u001b[0m  1.3983\n",
      "     27        \u001b[36m4.0633\u001b[0m       \u001b[32m0.9338\u001b[0m        \u001b[35m4.1258\u001b[0m  1.4450\n",
      "     28        \u001b[36m4.0613\u001b[0m       0.9338        \u001b[35m4.1244\u001b[0m  1.4097\n",
      "     29        \u001b[36m4.0599\u001b[0m       0.9325        \u001b[35m4.1235\u001b[0m  1.4891\n",
      "     30        \u001b[36m4.0569\u001b[0m       0.9325        \u001b[35m4.1222\u001b[0m  1.4354\n",
      "     31        \u001b[36m4.0558\u001b[0m       0.9331        \u001b[35m4.1212\u001b[0m  1.3971\n",
      "     32        \u001b[36m4.0546\u001b[0m       0.9331        \u001b[35m4.1201\u001b[0m  1.4711\n",
      "     33        \u001b[36m4.0532\u001b[0m       0.9325        \u001b[35m4.1192\u001b[0m  1.4577\n",
      "     34        \u001b[36m4.0525\u001b[0m       0.9338        \u001b[35m4.1179\u001b[0m  1.3984\n",
      "     35        \u001b[36m4.0509\u001b[0m       \u001b[32m0.9341\u001b[0m        \u001b[35m4.1172\u001b[0m  1.4282\n",
      "     36        \u001b[36m4.0497\u001b[0m       0.9334        \u001b[35m4.1166\u001b[0m  1.4860\n",
      "     37        \u001b[36m4.0491\u001b[0m       0.9321        \u001b[35m4.1159\u001b[0m  1.5890\n",
      "     38        \u001b[36m4.0486\u001b[0m       0.9334        \u001b[35m4.1154\u001b[0m  1.4084\n",
      "     39        \u001b[36m4.0471\u001b[0m       0.9328        \u001b[35m4.1150\u001b[0m  1.4152\n",
      "     40        4.0475       0.9334        \u001b[35m4.1144\u001b[0m  1.4264\n",
      "     41        \u001b[36m4.0460\u001b[0m       0.9338        \u001b[35m4.1143\u001b[0m  1.4143\n",
      "     42        \u001b[36m4.0455\u001b[0m       0.9334        \u001b[35m4.1142\u001b[0m  1.4069\n",
      "     43        \u001b[36m4.0448\u001b[0m       0.9334        \u001b[35m4.1134\u001b[0m  1.4073\n",
      "     44        \u001b[36m4.0441\u001b[0m       \u001b[32m0.9348\u001b[0m        \u001b[35m4.1130\u001b[0m  1.4087\n",
      "     45        \u001b[36m4.0436\u001b[0m       \u001b[32m0.9354\u001b[0m        \u001b[35m4.1123\u001b[0m  1.4243\n",
      "     46        \u001b[36m4.0432\u001b[0m       0.9344        4.1128  1.4090\n",
      "     47        \u001b[36m4.0426\u001b[0m       0.9351        \u001b[35m4.1121\u001b[0m  1.4006\n",
      "     48        \u001b[36m4.0423\u001b[0m       0.9344        \u001b[35m4.1115\u001b[0m  1.4020\n",
      "     49        \u001b[36m4.0422\u001b[0m       0.9348        \u001b[35m4.1113\u001b[0m  1.4121\n",
      "     50        \u001b[36m4.0419\u001b[0m       0.9341        \u001b[35m4.1109\u001b[0m  1.4297\n",
      "     51        \u001b[36m4.0412\u001b[0m       0.9338        \u001b[35m4.1108\u001b[0m  1.4117\n",
      "     52        \u001b[36m4.0410\u001b[0m       0.9344        \u001b[35m4.1104\u001b[0m  1.3998\n",
      "     53        \u001b[36m4.0403\u001b[0m       0.9328        \u001b[35m4.1099\u001b[0m  1.4105\n",
      "     54        \u001b[36m4.0398\u001b[0m       0.9328        \u001b[35m4.1098\u001b[0m  1.4009\n",
      "     55        4.0400       0.9331        4.1098  1.3979\n",
      "     56        4.0399       0.9341        \u001b[35m4.1096\u001b[0m  1.4054\n",
      "     57        \u001b[36m4.0392\u001b[0m       \u001b[32m0.9361\u001b[0m        \u001b[35m4.1091\u001b[0m  1.3993\n",
      "     58        4.0392       0.9354        \u001b[35m4.1084\u001b[0m  1.3900\n",
      "     59        \u001b[36m4.0388\u001b[0m       0.9358        4.1084  1.3973\n",
      "     60        \u001b[36m4.0386\u001b[0m       0.9344        \u001b[35m4.1083\u001b[0m  1.4180\n",
      "     61        \u001b[36m4.0380\u001b[0m       0.9351        \u001b[35m4.1082\u001b[0m  1.3974\n",
      "     62        \u001b[36m4.0376\u001b[0m       0.9344        \u001b[35m4.1080\u001b[0m  1.4105\n",
      "     63        \u001b[36m4.0374\u001b[0m       0.9334        \u001b[35m4.1077\u001b[0m  1.4095\n",
      "     64        4.0374       0.9344        \u001b[35m4.1076\u001b[0m  1.3925\n",
      "     65        \u001b[36m4.0367\u001b[0m       0.9351        \u001b[35m4.1071\u001b[0m  1.3943\n",
      "     66        4.0370       0.9341        \u001b[35m4.1068\u001b[0m  1.3960\n",
      "     67        4.0368       0.9351        \u001b[35m4.1065\u001b[0m  1.4043\n",
      "     68        \u001b[36m4.0363\u001b[0m       0.9348        \u001b[35m4.1065\u001b[0m  1.3894\n",
      "     69        \u001b[36m4.0362\u001b[0m       0.9348        \u001b[35m4.1064\u001b[0m  1.3990\n",
      "     70        4.0363       0.9354        \u001b[35m4.1064\u001b[0m  1.4030\n",
      "     71        4.0363       0.9354        4.1065  1.4184\n",
      "     72        4.0364       0.9358        \u001b[35m4.1062\u001b[0m  1.4018\n",
      "     73        \u001b[36m4.0354\u001b[0m       0.9361        4.1063  1.4007\n",
      "     74        4.0354       0.9348        \u001b[35m4.1060\u001b[0m  1.4019\n",
      "     75        \u001b[36m4.0352\u001b[0m       0.9354        \u001b[35m4.1059\u001b[0m  1.4078\n",
      "     76        \u001b[36m4.0350\u001b[0m       0.9344        \u001b[35m4.1059\u001b[0m  1.4332\n",
      "     77        4.0352       0.9341        4.1061  1.4075\n",
      "     78        4.0352       0.9358        \u001b[35m4.1057\u001b[0m  1.3955\n",
      "     79        \u001b[36m4.0349\u001b[0m       0.9341        \u001b[35m4.1057\u001b[0m  1.4262\n",
      "     80        4.0350       0.9348        \u001b[35m4.1053\u001b[0m  1.4219\n",
      "     81        \u001b[36m4.0347\u001b[0m       0.9341        \u001b[35m4.1049\u001b[0m  1.4169\n",
      "     82        4.0352       0.9348        \u001b[35m4.1048\u001b[0m  1.4006\n",
      "     83        \u001b[36m4.0347\u001b[0m       0.9338        \u001b[35m4.1045\u001b[0m  1.3895\n",
      "     84        \u001b[36m4.0343\u001b[0m       0.9348        \u001b[35m4.1043\u001b[0m  1.4011\n",
      "     85        \u001b[36m4.0343\u001b[0m       0.9344        \u001b[35m4.1040\u001b[0m  1.3903\n",
      "     86        4.0344       0.9358        4.1042  1.3918\n",
      "     87        \u001b[36m4.0343\u001b[0m       0.9358        4.1042  1.4222\n",
      "     88        \u001b[36m4.0341\u001b[0m       0.9354        4.1041  1.4093\n",
      "     89        \u001b[36m4.0339\u001b[0m       0.9338        4.1046  1.4878\n",
      "     90        4.0340       0.9354        4.1043  1.5214\n",
      "     91        4.0340       0.9344        4.1040  1.4815\n",
      "     92        \u001b[36m4.0339\u001b[0m       0.9348        \u001b[35m4.1038\u001b[0m  1.4228\n",
      "     93        4.0340       0.9361        4.1038  1.5621\n",
      "     94        \u001b[36m4.0338\u001b[0m       0.9354        \u001b[35m4.1035\u001b[0m  1.5653\n",
      "     95        \u001b[36m4.0335\u001b[0m       0.9348        4.1036  1.4680\n",
      "     96        4.0336       0.9354        \u001b[35m4.1034\u001b[0m  1.4571\n",
      "     97        \u001b[36m4.0335\u001b[0m       0.9344        4.1037  1.4555\n",
      "     98        \u001b[36m4.0334\u001b[0m       0.9338        4.1038  1.7093\n",
      "     99        \u001b[36m4.0334\u001b[0m       0.9351        4.1039  1.6280\n",
      "    100        \u001b[36m4.0332\u001b[0m       0.9351        4.1039  1.4940\n",
      "    101        4.0334       0.9331        4.1040  1.6735\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{100: 0.9843708609271523}\n",
      "Val accuracy\n",
      "{100: 0.896}\n",
      "pred time\n",
      "{100: 0.21036410331726074}\n",
      "OOS Val Accuracy\n",
      "{100: 0.09}\n",
      "OOS pred time\n",
      "{100: 0.005872011184692383}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0161\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m5.0130\u001b[0m  2.4918\n",
      "      2        \u001b[36m4.9678\u001b[0m       0.5159        \u001b[35m4.8504\u001b[0m  2.1707\n",
      "      3        \u001b[36m4.6733\u001b[0m       0.7325        \u001b[35m4.5248\u001b[0m  2.1588\n",
      "      4        \u001b[36m4.4092\u001b[0m       \u001b[32m0.8331\u001b[0m        \u001b[35m4.3554\u001b[0m  2.1886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5        \u001b[36m4.2802\u001b[0m       \u001b[32m0.8811\u001b[0m        \u001b[35m4.2753\u001b[0m  2.1377\n",
      "      6        \u001b[36m4.2122\u001b[0m       \u001b[32m0.8967\u001b[0m        \u001b[35m4.2296\u001b[0m  2.2624\n",
      "      7        \u001b[36m4.1692\u001b[0m       \u001b[32m0.9119\u001b[0m        \u001b[35m4.1997\u001b[0m  2.1465\n",
      "      8        \u001b[36m4.1415\u001b[0m       \u001b[32m0.9205\u001b[0m        \u001b[35m4.1801\u001b[0m  2.1145\n",
      "      9        \u001b[36m4.1214\u001b[0m       \u001b[32m0.9232\u001b[0m        \u001b[35m4.1670\u001b[0m  2.0629\n",
      "     10        \u001b[36m4.1077\u001b[0m       \u001b[32m0.9235\u001b[0m        \u001b[35m4.1579\u001b[0m  2.1666\n",
      "     11        \u001b[36m4.0958\u001b[0m       \u001b[32m0.9285\u001b[0m        \u001b[35m4.1506\u001b[0m  2.2052\n",
      "     12        \u001b[36m4.0858\u001b[0m       \u001b[32m0.9305\u001b[0m        \u001b[35m4.1451\u001b[0m  2.0893\n",
      "     13        \u001b[36m4.0781\u001b[0m       \u001b[32m0.9331\u001b[0m        \u001b[35m4.1394\u001b[0m  2.0739\n",
      "     14        \u001b[36m4.0700\u001b[0m       \u001b[32m0.9354\u001b[0m        \u001b[35m4.1346\u001b[0m  2.0583\n",
      "     15        \u001b[36m4.0650\u001b[0m       \u001b[32m0.9358\u001b[0m        \u001b[35m4.1309\u001b[0m  2.1139\n",
      "     16        \u001b[36m4.0608\u001b[0m       \u001b[32m0.9374\u001b[0m        \u001b[35m4.1279\u001b[0m  2.0858\n",
      "     17        \u001b[36m4.0576\u001b[0m       \u001b[32m0.9391\u001b[0m        \u001b[35m4.1254\u001b[0m  2.0596\n",
      "     18        \u001b[36m4.0545\u001b[0m       \u001b[32m0.9394\u001b[0m        \u001b[35m4.1234\u001b[0m  2.1064\n",
      "     19        \u001b[36m4.0521\u001b[0m       \u001b[32m0.9404\u001b[0m        \u001b[35m4.1216\u001b[0m  2.1020\n",
      "     20        \u001b[36m4.0503\u001b[0m       0.9401        \u001b[35m4.1201\u001b[0m  2.2215\n",
      "     21        \u001b[36m4.0485\u001b[0m       \u001b[32m0.9407\u001b[0m        \u001b[35m4.1189\u001b[0m  2.0695\n",
      "     22        \u001b[36m4.0470\u001b[0m       0.9404        \u001b[35m4.1175\u001b[0m  2.0412\n",
      "     23        \u001b[36m4.0461\u001b[0m       0.9394        \u001b[35m4.1165\u001b[0m  2.1407\n",
      "     24        \u001b[36m4.0453\u001b[0m       0.9391        \u001b[35m4.1160\u001b[0m  2.0492\n",
      "     25        \u001b[36m4.0441\u001b[0m       0.9401        \u001b[35m4.1147\u001b[0m  2.0472\n",
      "     26        \u001b[36m4.0429\u001b[0m       0.9404        \u001b[35m4.1136\u001b[0m  2.0473\n",
      "     27        \u001b[36m4.0419\u001b[0m       0.9397        \u001b[35m4.1126\u001b[0m  2.0400\n",
      "     28        \u001b[36m4.0410\u001b[0m       0.9407        \u001b[35m4.1117\u001b[0m  2.0434\n",
      "     29        \u001b[36m4.0403\u001b[0m       \u001b[32m0.9417\u001b[0m        \u001b[35m4.1108\u001b[0m  2.0408\n",
      "     30        \u001b[36m4.0396\u001b[0m       0.9417        \u001b[35m4.1103\u001b[0m  2.0445\n",
      "     31        \u001b[36m4.0390\u001b[0m       0.9417        \u001b[35m4.1098\u001b[0m  2.0436\n",
      "     32        \u001b[36m4.0388\u001b[0m       0.9417        \u001b[35m4.1095\u001b[0m  2.0530\n",
      "     33        \u001b[36m4.0379\u001b[0m       0.9407        \u001b[35m4.1093\u001b[0m  2.1543\n",
      "     34        \u001b[36m4.0374\u001b[0m       0.9407        \u001b[35m4.1088\u001b[0m  2.0804\n",
      "     35        \u001b[36m4.0371\u001b[0m       0.9407        \u001b[35m4.1079\u001b[0m  2.1478\n",
      "     36        \u001b[36m4.0366\u001b[0m       0.9414        \u001b[35m4.1077\u001b[0m  2.3365\n",
      "     37        \u001b[36m4.0362\u001b[0m       0.9417        \u001b[35m4.1072\u001b[0m  2.2247\n",
      "     38        \u001b[36m4.0360\u001b[0m       0.9401        \u001b[35m4.1069\u001b[0m  2.1586\n",
      "     39        \u001b[36m4.0359\u001b[0m       0.9407        \u001b[35m4.1064\u001b[0m  2.0886\n",
      "     40        \u001b[36m4.0353\u001b[0m       0.9397        \u001b[35m4.1059\u001b[0m  2.0977\n",
      "     41        \u001b[36m4.0352\u001b[0m       0.9397        \u001b[35m4.1052\u001b[0m  2.1627\n",
      "     42        \u001b[36m4.0350\u001b[0m       0.9387        \u001b[35m4.1052\u001b[0m  2.0589\n",
      "     43        \u001b[36m4.0347\u001b[0m       0.9384        \u001b[35m4.1051\u001b[0m  2.0782\n",
      "     44        \u001b[36m4.0345\u001b[0m       0.9407        \u001b[35m4.1048\u001b[0m  2.0745\n",
      "     45        \u001b[36m4.0344\u001b[0m       0.9397        \u001b[35m4.1041\u001b[0m  2.0516\n",
      "     46        \u001b[36m4.0340\u001b[0m       0.9404        \u001b[35m4.1039\u001b[0m  2.0401\n",
      "     47        \u001b[36m4.0339\u001b[0m       0.9401        \u001b[35m4.1035\u001b[0m  2.0511\n",
      "     48        \u001b[36m4.0338\u001b[0m       0.9411        \u001b[35m4.1033\u001b[0m  2.0588\n",
      "     49        4.0340       0.9414        4.1033  2.0445\n",
      "     50        \u001b[36m4.0337\u001b[0m       0.9394        4.1036  2.0543\n",
      "     51        \u001b[36m4.0335\u001b[0m       0.9391        \u001b[35m4.1032\u001b[0m  2.0828\n",
      "     52        \u001b[36m4.0335\u001b[0m       0.9374        \u001b[35m4.1027\u001b[0m  2.1047\n",
      "     53        \u001b[36m4.0332\u001b[0m       0.9394        \u001b[35m4.1023\u001b[0m  2.0518\n",
      "     54        \u001b[36m4.0331\u001b[0m       0.9401        \u001b[35m4.1019\u001b[0m  2.0489\n",
      "     55        \u001b[36m4.0330\u001b[0m       0.9397        \u001b[35m4.1018\u001b[0m  2.0418\n",
      "     56        4.0331       0.9401        \u001b[35m4.1017\u001b[0m  2.0456\n",
      "     57        \u001b[36m4.0330\u001b[0m       0.9391        \u001b[35m4.1016\u001b[0m  2.0664\n",
      "     58        \u001b[36m4.0330\u001b[0m       0.9381        4.1018  2.0627\n",
      "     59        \u001b[36m4.0327\u001b[0m       0.9374        \u001b[35m4.1016\u001b[0m  2.0463\n",
      "     60        \u001b[36m4.0327\u001b[0m       0.9381        \u001b[35m4.1008\u001b[0m  2.0421\n",
      "     61        \u001b[36m4.0326\u001b[0m       0.9358        4.1014  2.0431\n",
      "     62        \u001b[36m4.0326\u001b[0m       0.9354        4.1013  2.0613\n",
      "     63        \u001b[36m4.0323\u001b[0m       0.9351        4.1013  2.0441\n",
      "     64        4.0324       0.9364        4.1010  2.0483\n",
      "     65        4.0324       0.9361        4.1010  2.0402\n",
      "     66        \u001b[36m4.0322\u001b[0m       0.9348        4.1010  2.0516\n",
      "     67        4.0324       0.9368        \u001b[35m4.1008\u001b[0m  2.0384\n",
      "     68        \u001b[36m4.0322\u001b[0m       0.9371        \u001b[35m4.1004\u001b[0m  2.0462\n",
      "     69        \u001b[36m4.0321\u001b[0m       0.9348        4.1007  2.0578\n",
      "     70        \u001b[36m4.0320\u001b[0m       0.9344        4.1006  2.0432\n",
      "     71        4.0322       0.9348        4.1005  2.0478\n",
      "     72        4.0321       0.9348        4.1011  2.0441\n",
      "     73        4.0320       0.9361        4.1011  2.0366\n",
      "     74        \u001b[36m4.0319\u001b[0m       0.9351        4.1007  2.0460\n",
      "     75        \u001b[36m4.0318\u001b[0m       0.9351        4.1008  2.0414\n",
      "     76        \u001b[36m4.0318\u001b[0m       0.9364        4.1008  2.0663\n",
      "     77        \u001b[36m4.0318\u001b[0m       0.9341        4.1009  2.0448\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{100: 0.9843708609271523, 200: 0.9852980132450331}\n",
      "Val accuracy\n",
      "{100: 0.896, 200: 0.899}\n",
      "pred time\n",
      "{100: 0.21036410331726074, 200: 0.1925978660583496}\n",
      "OOS Val Accuracy\n",
      "{100: 0.09, 200: 0.12}\n",
      "OOS pred time\n",
      "{100: 0.005872011184692383, 200: 0.0051860809326171875}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0147\u001b[0m       \u001b[32m0.7175\u001b[0m        \u001b[35m5.0046\u001b[0m  3.5521\n",
      "      2        \u001b[36m4.8433\u001b[0m       0.6632        \u001b[35m4.6133\u001b[0m  3.5140\n",
      "      3        \u001b[36m4.4300\u001b[0m       \u001b[32m0.8424\u001b[0m        \u001b[35m4.3382\u001b[0m  3.5076\n",
      "      4        \u001b[36m4.2472\u001b[0m       \u001b[32m0.8977\u001b[0m        \u001b[35m4.2415\u001b[0m  3.5042\n",
      "      5        \u001b[36m4.1709\u001b[0m       \u001b[32m0.9149\u001b[0m        \u001b[35m4.1961\u001b[0m  3.4951\n",
      "      6        \u001b[36m4.1307\u001b[0m       \u001b[32m0.9238\u001b[0m        \u001b[35m4.1715\u001b[0m  3.4984\n",
      "      7        \u001b[36m4.1052\u001b[0m       \u001b[32m0.9275\u001b[0m        \u001b[35m4.1564\u001b[0m  3.5255\n",
      "      8        \u001b[36m4.0867\u001b[0m       \u001b[32m0.9334\u001b[0m        \u001b[35m4.1462\u001b[0m  3.4903\n",
      "      9        \u001b[36m4.0735\u001b[0m       \u001b[32m0.9361\u001b[0m        \u001b[35m4.1385\u001b[0m  3.4823\n",
      "     10        \u001b[36m4.0651\u001b[0m       \u001b[32m0.9368\u001b[0m        \u001b[35m4.1330\u001b[0m  3.4855\n",
      "     11        \u001b[36m4.0584\u001b[0m       \u001b[32m0.9381\u001b[0m        \u001b[35m4.1287\u001b[0m  3.4874\n",
      "     12        \u001b[36m4.0538\u001b[0m       0.9381        \u001b[35m4.1255\u001b[0m  3.4757\n",
      "     13        \u001b[36m4.0502\u001b[0m       \u001b[32m0.9384\u001b[0m        \u001b[35m4.1229\u001b[0m  3.4838\n",
      "     14        \u001b[36m4.0474\u001b[0m       \u001b[32m0.9404\u001b[0m        \u001b[35m4.1208\u001b[0m  3.4970\n",
      "     15        \u001b[36m4.0455\u001b[0m       \u001b[32m0.9407\u001b[0m        \u001b[35m4.1186\u001b[0m  3.4678\n",
      "     16        \u001b[36m4.0436\u001b[0m       \u001b[32m0.9417\u001b[0m        \u001b[35m4.1167\u001b[0m  3.4760\n",
      "     17        \u001b[36m4.0421\u001b[0m       0.9414        \u001b[35m4.1150\u001b[0m  3.4485\n",
      "     18        \u001b[36m4.0410\u001b[0m       0.9401        \u001b[35m4.1137\u001b[0m  3.4964\n",
      "     19        \u001b[36m4.0398\u001b[0m       0.9411        \u001b[35m4.1126\u001b[0m  3.4787\n",
      "     20        \u001b[36m4.0389\u001b[0m       0.9404        \u001b[35m4.1116\u001b[0m  3.5404\n",
      "     21        \u001b[36m4.0380\u001b[0m       0.9401        \u001b[35m4.1107\u001b[0m  3.6025\n",
      "     22        \u001b[36m4.0374\u001b[0m       \u001b[32m0.9421\u001b[0m        \u001b[35m4.1098\u001b[0m  3.6262\n",
      "     23        \u001b[36m4.0370\u001b[0m       0.9411        \u001b[35m4.1091\u001b[0m  3.4940\n",
      "     24        \u001b[36m4.0364\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m4.1077\u001b[0m  3.5377\n",
      "     25        \u001b[36m4.0360\u001b[0m       \u001b[32m0.9430\u001b[0m        \u001b[35m4.1075\u001b[0m  3.6033\n",
      "     26        \u001b[36m4.0353\u001b[0m       0.9414        \u001b[35m4.1071\u001b[0m  3.5499\n",
      "     27        \u001b[36m4.0348\u001b[0m       0.9421        \u001b[35m4.1066\u001b[0m  3.4861\n",
      "     28        \u001b[36m4.0347\u001b[0m       0.9421        \u001b[35m4.1058\u001b[0m  3.4804\n",
      "     29        \u001b[36m4.0343\u001b[0m       0.9417        \u001b[35m4.1052\u001b[0m  3.4800\n",
      "     30        4.0343       0.9421        \u001b[35m4.1047\u001b[0m  3.4804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     31        \u001b[36m4.0340\u001b[0m       0.9417        \u001b[35m4.1044\u001b[0m  3.4775\n",
      "     32        \u001b[36m4.0338\u001b[0m       0.9421        \u001b[35m4.1041\u001b[0m  3.4732\n",
      "     33        \u001b[36m4.0335\u001b[0m       0.9411        \u001b[35m4.1035\u001b[0m  3.4961\n",
      "     34        \u001b[36m4.0332\u001b[0m       0.9411        \u001b[35m4.1032\u001b[0m  3.4818\n",
      "     35        \u001b[36m4.0331\u001b[0m       0.9424        \u001b[35m4.1026\u001b[0m  3.4845\n",
      "     36        \u001b[36m4.0329\u001b[0m       0.9427        \u001b[35m4.1022\u001b[0m  3.4852\n",
      "     37        \u001b[36m4.0329\u001b[0m       0.9427        \u001b[35m4.1022\u001b[0m  3.4870\n",
      "     38        \u001b[36m4.0329\u001b[0m       0.9417        \u001b[35m4.1015\u001b[0m  3.4766\n",
      "     39        \u001b[36m4.0328\u001b[0m       0.9414        \u001b[35m4.1014\u001b[0m  3.4807\n",
      "     40        \u001b[36m4.0326\u001b[0m       0.9414        \u001b[35m4.1011\u001b[0m  3.4810\n",
      "     41        \u001b[36m4.0326\u001b[0m       0.9414        \u001b[35m4.1009\u001b[0m  3.5063\n",
      "     42        \u001b[36m4.0325\u001b[0m       0.9421        4.1010  3.4088\n",
      "     43        \u001b[36m4.0324\u001b[0m       0.9417        \u001b[35m4.1007\u001b[0m  3.4946\n",
      "     44        \u001b[36m4.0323\u001b[0m       0.9414        \u001b[35m4.1003\u001b[0m  3.4977\n",
      "     45        \u001b[36m4.0322\u001b[0m       0.9411        \u001b[35m4.1002\u001b[0m  3.4775\n",
      "     46        \u001b[36m4.0322\u001b[0m       0.9407        \u001b[35m4.0999\u001b[0m  3.5845\n",
      "     47        4.0322       0.9421        \u001b[35m4.0992\u001b[0m  3.5168\n",
      "     48        \u001b[36m4.0321\u001b[0m       0.9407        \u001b[35m4.0991\u001b[0m  3.5275\n",
      "     49        \u001b[36m4.0321\u001b[0m       0.9417        \u001b[35m4.0990\u001b[0m  3.4715\n",
      "     50        \u001b[36m4.0319\u001b[0m       0.9394        4.0994  3.4984\n",
      "     51        4.0320       0.9404        \u001b[35m4.0989\u001b[0m  3.4785\n",
      "     52        \u001b[36m4.0318\u001b[0m       0.9407        \u001b[35m4.0989\u001b[0m  3.4775\n",
      "     53        \u001b[36m4.0317\u001b[0m       0.9391        \u001b[35m4.0989\u001b[0m  3.4756\n",
      "     54        \u001b[36m4.0317\u001b[0m       0.9401        \u001b[35m4.0986\u001b[0m  3.4775\n",
      "     55        4.0317       0.9404        4.0986  3.4141\n",
      "     56        \u001b[36m4.0316\u001b[0m       0.9404        \u001b[35m4.0983\u001b[0m  3.4781\n",
      "     57        4.0317       0.9394        \u001b[35m4.0980\u001b[0m  3.4724\n",
      "     58        4.0316       0.9391        4.0981  3.4480\n",
      "     59        \u001b[36m4.0316\u001b[0m       0.9401        \u001b[35m4.0979\u001b[0m  3.4514\n",
      "     60        \u001b[36m4.0315\u001b[0m       0.9404        \u001b[35m4.0977\u001b[0m  3.4604\n",
      "     61        \u001b[36m4.0315\u001b[0m       0.9407        \u001b[35m4.0974\u001b[0m  3.5716\n",
      "     62        \u001b[36m4.0314\u001b[0m       0.9397        4.0975  3.4962\n",
      "     63        \u001b[36m4.0314\u001b[0m       0.9407        \u001b[35m4.0971\u001b[0m  3.4435\n",
      "     64        \u001b[36m4.0314\u001b[0m       0.9407        4.0972  3.4512\n",
      "     65        4.0314       0.9384        4.0972  3.4451\n",
      "     66        \u001b[36m4.0313\u001b[0m       0.9404        \u001b[35m4.0968\u001b[0m  3.4411\n",
      "     67        \u001b[36m4.0313\u001b[0m       0.9414        4.0969  3.4533\n",
      "     68        \u001b[36m4.0312\u001b[0m       0.9414        4.0968  3.4398\n",
      "     69        \u001b[36m4.0311\u001b[0m       0.9414        4.0968  3.3469\n",
      "     70        \u001b[36m4.0310\u001b[0m       0.9421        4.0969  3.4414\n",
      "     71        \u001b[36m4.0310\u001b[0m       0.9407        \u001b[35m4.0966\u001b[0m  3.4407\n",
      "     72        \u001b[36m4.0310\u001b[0m       0.9414        \u001b[35m4.0966\u001b[0m  3.4388\n",
      "     73        \u001b[36m4.0310\u001b[0m       0.9401        4.0967  3.4409\n",
      "     74        \u001b[36m4.0309\u001b[0m       0.9391        \u001b[35m4.0965\u001b[0m  3.4409\n",
      "     75        4.0310       0.9414        \u001b[35m4.0961\u001b[0m  3.4493\n",
      "     76        4.0309       0.9407        4.0965  3.4606\n",
      "     77        \u001b[36m4.0309\u001b[0m       0.9404        4.0962  3.4482\n",
      "     78        \u001b[36m4.0309\u001b[0m       0.9407        \u001b[35m4.0959\u001b[0m  3.4644\n",
      "     79        \u001b[36m4.0309\u001b[0m       0.9404        4.0960  3.4391\n",
      "     80        4.0309       0.9397        4.0961  3.4593\n",
      "     81        4.0309       0.9384        4.0962  3.4405\n",
      "     82        4.0309       0.9404        \u001b[35m4.0958\u001b[0m  3.4497\n",
      "     83        \u001b[36m4.0308\u001b[0m       0.9407        4.0958  3.4841\n",
      "     84        \u001b[36m4.0308\u001b[0m       0.9404        4.0958  3.4550\n",
      "     85        4.0309       0.9404        \u001b[35m4.0957\u001b[0m  3.4439\n",
      "     86        4.0308       0.9401        4.0959  3.4390\n",
      "     87        \u001b[36m4.0308\u001b[0m       0.9394        4.0961  3.4357\n",
      "     88        \u001b[36m4.0308\u001b[0m       0.9401        4.0960  3.4540\n",
      "     89        \u001b[36m4.0307\u001b[0m       0.9404        \u001b[35m4.0954\u001b[0m  3.4375\n",
      "     90        \u001b[36m4.0307\u001b[0m       0.9404        \u001b[35m4.0952\u001b[0m  3.4574\n",
      "     91        4.0308       0.9404        4.0957  3.5504\n",
      "     92        4.0308       0.9407        4.0957  3.7153\n",
      "     93        4.0308       0.9407        4.0956  3.5483\n",
      "     94        4.0308       0.9417        \u001b[35m4.0951\u001b[0m  3.4755\n",
      "     95        \u001b[36m4.0307\u001b[0m       0.9414        4.0954  3.6797\n",
      "     96        4.0308       0.9407        4.0953  3.5405\n",
      "     97        4.0307       0.9404        4.0955  3.5880\n",
      "     98        4.0308       0.9414        4.0952  3.4566\n",
      "     99        4.0307       0.9407        4.0952  3.4569\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{100: 0.9843708609271523, 200: 0.9852980132450331, 400: 0.9864238410596027}\n",
      "Val accuracy\n",
      "{100: 0.896, 200: 0.899, 400: 0.9}\n",
      "pred time\n",
      "{100: 0.21036410331726074, 200: 0.1925978660583496, 400: 0.31163692474365234}\n",
      "OOS Val Accuracy\n",
      "{100: 0.09, 200: 0.12, 400: 0.12}\n",
      "OOS pred time\n",
      "{100: 0.005872011184692383, 200: 0.0051860809326171875, 400: 0.01047205924987793}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0090\u001b[0m       \u001b[32m0.5397\u001b[0m        \u001b[35m4.9532\u001b[0m  6.4162\n",
      "      2        \u001b[36m4.6486\u001b[0m       \u001b[32m0.8070\u001b[0m        \u001b[35m4.3985\u001b[0m  6.3476\n",
      "      3        \u001b[36m4.2666\u001b[0m       \u001b[32m0.8980\u001b[0m        \u001b[35m4.2324\u001b[0m  6.2986\n",
      "      4        \u001b[36m4.1565\u001b[0m       \u001b[32m0.9199\u001b[0m        \u001b[35m4.1794\u001b[0m  6.4058\n",
      "      5        \u001b[36m4.1108\u001b[0m       \u001b[32m0.9275\u001b[0m        \u001b[35m4.1551\u001b[0m  6.3110\n",
      "      6        \u001b[36m4.0845\u001b[0m       \u001b[32m0.9328\u001b[0m        \u001b[35m4.1414\u001b[0m  6.5669\n",
      "      7        \u001b[36m4.0670\u001b[0m       \u001b[32m0.9377\u001b[0m        \u001b[35m4.1330\u001b[0m  6.4193\n",
      "      8        \u001b[36m4.0576\u001b[0m       \u001b[32m0.9401\u001b[0m        \u001b[35m4.1271\u001b[0m  6.3572\n",
      "      9        \u001b[36m4.0510\u001b[0m       \u001b[32m0.9407\u001b[0m        \u001b[35m4.1231\u001b[0m  6.3503\n",
      "     10        \u001b[36m4.0467\u001b[0m       0.9401        \u001b[35m4.1202\u001b[0m  6.5679\n",
      "     11        \u001b[36m4.0437\u001b[0m       0.9401        \u001b[35m4.1177\u001b[0m  6.2727\n",
      "     12        \u001b[36m4.0418\u001b[0m       \u001b[32m0.9414\u001b[0m        \u001b[35m4.1157\u001b[0m  6.2916\n",
      "     13        \u001b[36m4.0401\u001b[0m       0.9407        \u001b[35m4.1137\u001b[0m  6.2880\n",
      "     14        \u001b[36m4.0387\u001b[0m       0.9414        \u001b[35m4.1120\u001b[0m  6.2789\n",
      "     15        \u001b[36m4.0374\u001b[0m       0.9411        \u001b[35m4.1108\u001b[0m  6.3367\n",
      "     16        \u001b[36m4.0367\u001b[0m       \u001b[32m0.9417\u001b[0m        \u001b[35m4.1098\u001b[0m  6.3004\n",
      "     17        \u001b[36m4.0359\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m4.1091\u001b[0m  6.3149\n",
      "     18        \u001b[36m4.0353\u001b[0m       0.9411        \u001b[35m4.1083\u001b[0m  6.2776\n",
      "     19        \u001b[36m4.0348\u001b[0m       0.9401        \u001b[35m4.1074\u001b[0m  6.3163\n",
      "     20        \u001b[36m4.0346\u001b[0m       0.9421        \u001b[35m4.1066\u001b[0m  6.7712\n",
      "     21        \u001b[36m4.0344\u001b[0m       0.9417        \u001b[35m4.1061\u001b[0m  6.8309\n",
      "     22        \u001b[36m4.0340\u001b[0m       0.9417        \u001b[35m4.1053\u001b[0m  6.3527\n",
      "     23        \u001b[36m4.0337\u001b[0m       0.9414        \u001b[35m4.1047\u001b[0m  6.4662\n",
      "     24        \u001b[36m4.0336\u001b[0m       0.9417        \u001b[35m4.1041\u001b[0m  6.6418\n",
      "     25        \u001b[36m4.0335\u001b[0m       0.9417        \u001b[35m4.1034\u001b[0m  6.3825\n",
      "     26        \u001b[36m4.0332\u001b[0m       0.9417        \u001b[35m4.1030\u001b[0m  6.2416\n",
      "     27        \u001b[36m4.0331\u001b[0m       0.9417        \u001b[35m4.1024\u001b[0m  6.2775\n",
      "     28        \u001b[36m4.0329\u001b[0m       0.9411        \u001b[35m4.1020\u001b[0m  6.3487\n",
      "     29        \u001b[36m4.0327\u001b[0m       0.9424        \u001b[35m4.1018\u001b[0m  6.3315\n",
      "     30        \u001b[36m4.0325\u001b[0m       \u001b[32m0.9430\u001b[0m        4.1018  6.2348\n",
      "     31        \u001b[36m4.0324\u001b[0m       0.9424        \u001b[35m4.1017\u001b[0m  6.2034\n",
      "     32        \u001b[36m4.0322\u001b[0m       0.9401        \u001b[35m4.1013\u001b[0m  6.2495\n",
      "     33        \u001b[36m4.0322\u001b[0m       0.9407        \u001b[35m4.1011\u001b[0m  6.2179\n",
      "     34        \u001b[36m4.0320\u001b[0m       0.9407        \u001b[35m4.1010\u001b[0m  6.2049\n",
      "     35        \u001b[36m4.0318\u001b[0m       0.9407        \u001b[35m4.1008\u001b[0m  6.2255\n",
      "     36        \u001b[36m4.0318\u001b[0m       0.9414        \u001b[35m4.1002\u001b[0m  6.2231\n",
      "     37        \u001b[36m4.0318\u001b[0m       0.9404        \u001b[35m4.1001\u001b[0m  6.2277\n",
      "     38        \u001b[36m4.0317\u001b[0m       0.9404        \u001b[35m4.0999\u001b[0m  6.2408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     39        \u001b[36m4.0317\u001b[0m       0.9414        \u001b[35m4.0995\u001b[0m  6.2374\n",
      "     40        \u001b[36m4.0316\u001b[0m       0.9401        \u001b[35m4.0993\u001b[0m  6.2264\n",
      "     41        \u001b[36m4.0316\u001b[0m       0.9411        \u001b[35m4.0989\u001b[0m  6.2515\n",
      "     42        4.0316       0.9401        \u001b[35m4.0989\u001b[0m  6.2312\n",
      "     43        \u001b[36m4.0315\u001b[0m       0.9407        \u001b[35m4.0988\u001b[0m  6.2284\n",
      "     44        4.0315       0.9407        \u001b[35m4.0988\u001b[0m  6.2701\n",
      "     45        \u001b[36m4.0315\u001b[0m       0.9411        \u001b[35m4.0983\u001b[0m  6.2650\n",
      "     46        4.0315       0.9421        4.0983  6.2162\n",
      "     47        \u001b[36m4.0314\u001b[0m       0.9421        \u001b[35m4.0982\u001b[0m  6.1493\n",
      "     48        \u001b[36m4.0314\u001b[0m       0.9417        4.0983  6.1465\n",
      "     49        \u001b[36m4.0314\u001b[0m       0.9411        \u001b[35m4.0980\u001b[0m  6.2331\n",
      "     50        \u001b[36m4.0312\u001b[0m       0.9417        \u001b[35m4.0978\u001b[0m  6.2109\n",
      "     51        \u001b[36m4.0312\u001b[0m       0.9424        \u001b[35m4.0976\u001b[0m  6.2606\n",
      "     52        4.0313       0.9424        \u001b[35m4.0974\u001b[0m  6.2269\n",
      "     53        4.0312       0.9427        \u001b[35m4.0973\u001b[0m  6.2587\n",
      "     54        \u001b[36m4.0312\u001b[0m       0.9417        \u001b[35m4.0970\u001b[0m  6.2244\n",
      "     55        4.0312       0.9417        \u001b[35m4.0968\u001b[0m  6.3281\n",
      "     56        4.0312       0.9417        4.0970  6.3155\n",
      "     57        \u001b[36m4.0311\u001b[0m       0.9417        \u001b[35m4.0965\u001b[0m  6.2382\n",
      "     58        4.0312       0.9407        4.0969  6.2189\n",
      "     59        \u001b[36m4.0311\u001b[0m       0.9414        4.0965  6.2339\n",
      "     60        4.0311       0.9411        \u001b[35m4.0960\u001b[0m  6.2161\n",
      "     61        \u001b[36m4.0310\u001b[0m       0.9417        4.0962  6.2096\n",
      "     62        4.0310       0.9424        4.0963  6.2298\n",
      "     63        \u001b[36m4.0309\u001b[0m       0.9417        4.0961  6.2424\n",
      "     64        \u001b[36m4.0308\u001b[0m       0.9407        4.0968  6.2254\n",
      "     65        \u001b[36m4.0307\u001b[0m       0.9414        4.0963  6.2128\n",
      "     66        \u001b[36m4.0306\u001b[0m       0.9407        4.0965  6.2990\n",
      "     67        4.0307       0.9424        4.0963  6.3150\n",
      "     68        \u001b[36m4.0306\u001b[0m       0.9414        4.0961  6.3142\n",
      "     69        \u001b[36m4.0306\u001b[0m       0.9407        \u001b[35m4.0960\u001b[0m  6.4534\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{100: 0.9843708609271523, 200: 0.9852980132450331, 400: 0.9864238410596027, 800: 0.9868211920529801}\n",
      "Val accuracy\n",
      "{100: 0.896, 200: 0.899, 400: 0.9, 800: 0.901}\n",
      "pred time\n",
      "{100: 0.21036410331726074, 200: 0.1925978660583496, 400: 0.31163692474365234, 800: 0.362407922744751}\n",
      "OOS Val Accuracy\n",
      "{100: 0.09, 200: 0.12, 400: 0.12, 800: 0.12}\n",
      "OOS pred time\n",
      "{100: 0.005872011184692383, 200: 0.0051860809326171875, 400: 0.01047205924987793, 800: 0.011768817901611328}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m4.9826\u001b[0m       \u001b[32m0.5579\u001b[0m        \u001b[35m4.7820\u001b[0m  11.3379\n",
      "      2        \u001b[36m4.4357\u001b[0m       \u001b[32m0.8748\u001b[0m        \u001b[35m4.2623\u001b[0m  11.6021\n",
      "      3        \u001b[36m4.1720\u001b[0m       \u001b[32m0.9225\u001b[0m        \u001b[35m4.1758\u001b[0m  11.7920\n",
      "      4        \u001b[36m4.1065\u001b[0m       \u001b[32m0.9325\u001b[0m        \u001b[35m4.1477\u001b[0m  11.5075\n",
      "      5        \u001b[36m4.0748\u001b[0m       \u001b[32m0.9368\u001b[0m        \u001b[35m4.1340\u001b[0m  11.4787\n",
      "      6        \u001b[36m4.0578\u001b[0m       \u001b[32m0.9404\u001b[0m        \u001b[35m4.1257\u001b[0m  11.4030\n",
      "      7        \u001b[36m4.0489\u001b[0m       \u001b[32m0.9421\u001b[0m        \u001b[35m4.1206\u001b[0m  11.3488\n",
      "      8        \u001b[36m4.0440\u001b[0m       \u001b[32m0.9427\u001b[0m        \u001b[35m4.1171\u001b[0m  11.3853\n",
      "      9        \u001b[36m4.0409\u001b[0m       \u001b[32m0.9434\u001b[0m        \u001b[35m4.1141\u001b[0m  11.6265\n",
      "     10        \u001b[36m4.0390\u001b[0m       0.9430        \u001b[35m4.1118\u001b[0m  11.6312\n",
      "     11        \u001b[36m4.0377\u001b[0m       0.9430        \u001b[35m4.1102\u001b[0m  11.5201\n",
      "     12        \u001b[36m4.0364\u001b[0m       0.9434        \u001b[35m4.1086\u001b[0m  11.4574\n",
      "     13        \u001b[36m4.0355\u001b[0m       \u001b[32m0.9444\u001b[0m        \u001b[35m4.1074\u001b[0m  11.4264\n",
      "     14        \u001b[36m4.0350\u001b[0m       0.9437        \u001b[35m4.1070\u001b[0m  11.4326\n",
      "     15        \u001b[36m4.0342\u001b[0m       0.9444        \u001b[35m4.1064\u001b[0m  11.4256\n",
      "     16        \u001b[36m4.0337\u001b[0m       0.9444        \u001b[35m4.1050\u001b[0m  11.4993\n",
      "     17        \u001b[36m4.0334\u001b[0m       0.9444        \u001b[35m4.1045\u001b[0m  11.4941\n",
      "     18        \u001b[36m4.0332\u001b[0m       0.9437        \u001b[35m4.1038\u001b[0m  11.4740\n",
      "     19        \u001b[36m4.0329\u001b[0m       0.9437        \u001b[35m4.1031\u001b[0m  11.4449\n",
      "     20        \u001b[36m4.0328\u001b[0m       0.9437        \u001b[35m4.1028\u001b[0m  11.4202\n",
      "     21        \u001b[36m4.0326\u001b[0m       0.9444        \u001b[35m4.1024\u001b[0m  11.4349\n",
      "     22        \u001b[36m4.0324\u001b[0m       0.9444        \u001b[35m4.1020\u001b[0m  11.6808\n",
      "     23        \u001b[36m4.0322\u001b[0m       0.9430        4.1021  11.6897\n",
      "     24        \u001b[36m4.0320\u001b[0m       0.9434        \u001b[35m4.1013\u001b[0m  11.4895\n",
      "     25        4.0320       0.9437        \u001b[35m4.1010\u001b[0m  10.9961\n",
      "     26        \u001b[36m4.0319\u001b[0m       0.9430        \u001b[35m4.1008\u001b[0m  11.0970\n",
      "     27        \u001b[36m4.0317\u001b[0m       0.9434        \u001b[35m4.1006\u001b[0m  11.1887\n",
      "     28        \u001b[36m4.0316\u001b[0m       0.9440        \u001b[35m4.1001\u001b[0m  10.9359\n",
      "     29        4.0317       0.9424        4.1002  10.9167\n",
      "     30        \u001b[36m4.0316\u001b[0m       0.9434        \u001b[35m4.0993\u001b[0m  11.0406\n",
      "     31        \u001b[36m4.0315\u001b[0m       0.9421        4.0994  11.2420\n",
      "     32        \u001b[36m4.0315\u001b[0m       0.9417        4.0995  10.9983\n",
      "     33        \u001b[36m4.0315\u001b[0m       0.9417        \u001b[35m4.0991\u001b[0m  10.9363\n",
      "     34        \u001b[36m4.0314\u001b[0m       0.9421        \u001b[35m4.0990\u001b[0m  10.9501\n",
      "     35        \u001b[36m4.0314\u001b[0m       0.9421        \u001b[35m4.0987\u001b[0m  10.9804\n",
      "     36        \u001b[36m4.0313\u001b[0m       0.9414        \u001b[35m4.0986\u001b[0m  10.9334\n",
      "     37        \u001b[36m4.0312\u001b[0m       0.9414        4.0987  10.9212\n",
      "     38        \u001b[36m4.0311\u001b[0m       0.9414        \u001b[35m4.0985\u001b[0m  11.0176\n",
      "     39        4.0311       0.9414        \u001b[35m4.0981\u001b[0m  10.9088\n",
      "     40        \u001b[36m4.0310\u001b[0m       0.9404        \u001b[35m4.0980\u001b[0m  10.9674\n",
      "     41        4.0310       0.9404        \u001b[35m4.0979\u001b[0m  10.8747\n",
      "     42        \u001b[36m4.0310\u001b[0m       0.9407        \u001b[35m4.0977\u001b[0m  11.0290\n",
      "     43        \u001b[36m4.0310\u001b[0m       0.9414        4.0978  10.9619\n",
      "     44        \u001b[36m4.0309\u001b[0m       0.9421        \u001b[35m4.0974\u001b[0m  10.9361\n",
      "     45        4.0309       0.9411        4.0974  11.1516\n",
      "     46        \u001b[36m4.0308\u001b[0m       0.9414        \u001b[35m4.0973\u001b[0m  11.0088\n",
      "     47        \u001b[36m4.0308\u001b[0m       0.9404        \u001b[35m4.0972\u001b[0m  10.9464\n",
      "     48        \u001b[36m4.0307\u001b[0m       0.9414        4.0973  10.8988\n",
      "     49        4.0308       0.9417        \u001b[35m4.0969\u001b[0m  10.9374\n",
      "     50        \u001b[36m4.0307\u001b[0m       0.9407        \u001b[35m4.0967\u001b[0m  10.9170\n",
      "     51        \u001b[36m4.0307\u001b[0m       0.9397        \u001b[35m4.0967\u001b[0m  10.9260\n",
      "     52        \u001b[36m4.0307\u001b[0m       0.9397        \u001b[35m4.0966\u001b[0m  11.1788\n",
      "     53        \u001b[36m4.0307\u001b[0m       0.9404        \u001b[35m4.0963\u001b[0m  11.2347\n",
      "     54        \u001b[36m4.0306\u001b[0m       0.9401        4.0965  11.1396\n",
      "     55        \u001b[36m4.0306\u001b[0m       0.9404        \u001b[35m4.0963\u001b[0m  11.2580\n",
      "     56        \u001b[36m4.0306\u001b[0m       0.9401        4.0964  11.1638\n",
      "     57        4.0306       0.9411        \u001b[35m4.0962\u001b[0m  11.2170\n",
      "     58        \u001b[36m4.0306\u001b[0m       0.9407        \u001b[35m4.0962\u001b[0m  11.5900\n",
      "     59        4.0306       0.9411        \u001b[35m4.0958\u001b[0m  11.5837\n",
      "     60        \u001b[36m4.0306\u001b[0m       0.9411        4.0959  11.4786\n",
      "     61        4.0306       0.9407        4.0960  11.4261\n",
      "     62        4.0306       0.9397        4.0959  11.4981\n",
      "     63        \u001b[36m4.0306\u001b[0m       0.9407        4.0961  11.5943\n",
      "     64        \u001b[36m4.0305\u001b[0m       0.9407        4.0958  11.0756\n",
      "     65        \u001b[36m4.0305\u001b[0m       0.9401        \u001b[35m4.0957\u001b[0m  10.9530\n",
      "     66        \u001b[36m4.0305\u001b[0m       0.9411        \u001b[35m4.0955\u001b[0m  10.9617\n",
      "     67        \u001b[36m4.0305\u001b[0m       0.9404        \u001b[35m4.0952\u001b[0m  10.9683\n",
      "     68        \u001b[36m4.0305\u001b[0m       0.9401        4.0953  10.9144\n",
      "     69        4.0305       0.9411        \u001b[35m4.0952\u001b[0m  11.0105\n",
      "     70        4.0305       0.9407        \u001b[35m4.0952\u001b[0m  10.9303\n",
      "     71        \u001b[36m4.0305\u001b[0m       0.9407        4.0952  10.9110\n",
      "     72        4.0306       0.9411        \u001b[35m4.0951\u001b[0m  11.0522\n",
      "     73        4.0306       0.9424        4.0953  11.0241\n",
      "     74        \u001b[36m4.0305\u001b[0m       0.9414        4.0957  11.0231\n",
      "     75        4.0306       0.9397        \u001b[35m4.0950\u001b[0m  10.9304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     76        \u001b[36m4.0305\u001b[0m       0.9404        4.0957  11.0205\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{100: 0.9843708609271523, 200: 0.9852980132450331, 400: 0.9864238410596027, 800: 0.9868211920529801, 1600: 0.9867549668874173}\n",
      "Val accuracy\n",
      "{100: 0.896, 200: 0.899, 400: 0.9, 800: 0.901, 1600: 0.9003333333333333}\n",
      "pred time\n",
      "{100: 0.21036410331726074, 200: 0.1925978660583496, 400: 0.31163692474365234, 800: 0.362407922744751, 1600: 0.5692059993743896}\n",
      "OOS Val Accuracy\n",
      "{100: 0.09, 200: 0.12, 400: 0.12, 800: 0.12, 1600: 0.12}\n",
      "OOS pred time\n",
      "{100: 0.005872011184692383, 200: 0.0051860809326171875, 400: 0.01047205924987793, 800: 0.011768817901611328, 1600: 0.018018007278442383}\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001 #using best learning rate from earlier\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "hidden_list = [100, 200, 400, 800, 1600] #hidden layer sizes\n",
    "for hidden_dim in hidden_list:    #looping through hidden layer sizes\n",
    "    print(lr)\n",
    "    class CLINCModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                input_dim=vocab_dim,\n",
    "                hidden_dim=hidden_dim, #setting hidden layer size\n",
    "                output_dim=output_dim,\n",
    "                dropout=0.5\n",
    "        ):\n",
    "            super(CLINCModule, self).__init__()\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "            self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = torch.tanh(self.hidden(X))\n",
    "            X = self.dropout(X)\n",
    "            X = F.softmax(self.output(X), dim=-1)\n",
    "            return X\n",
    "   \n",
    "    net = NeuralNetClassifier(\n",
    "    module=CLINCModule,\n",
    "    lr=lr,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    max_epochs=1000,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    callbacks=[EarlyStopping(patience=10)],\n",
    "    )\n",
    "    \n",
    "    net.fit(train_x, train_y)\n",
    "    tlabels = net.predict(train_x)\n",
    "    tacc[hidden_dim] = accuracy_score(tlabels, train_y)\n",
    "    print('training accuracy')\n",
    "    print(tacc)\n",
    "    time0 = time.time()\n",
    "    labels = net.predict(val_x)\n",
    "    vacc[hidden_dim] = accuracy_score(labels, val_y)\n",
    "    time1 = time.time()\n",
    "    vtime[hidden_dim] = time1-time0\n",
    "    print('Val accuracy')\n",
    "    print(vacc)\n",
    "    print('pred time')\n",
    "    print(vtime)\n",
    "    time2 = time.time()\n",
    "    olabels = net.predict(val_oos_x)\n",
    "    oacc[hidden_dim] = accuracy_score(olabels, val_oos_y)\n",
    "    time3 = time.time()\n",
    "    otime[hidden_dim]=time3-time2\n",
    "    print('OOS Val Accuracy')\n",
    "    print(oacc)\n",
    "    print('OOS pred time')\n",
    "    print(otime)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very small increase in validation accuracy with increasing hidden layer size up to 800 (around 0.5% from 89.6% for 100 neurons), but significantly increasing time (near double). Will investigate effect of additional hidden layer, using same layer size for both layers to limit computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0170\u001b[0m       \u001b[32m0.2563\u001b[0m        \u001b[35m5.0161\u001b[0m  1.5456\n",
      "      2        \u001b[36m4.9989\u001b[0m       \u001b[32m0.2695\u001b[0m        \u001b[35m4.9425\u001b[0m  1.4847\n",
      "      3        \u001b[36m4.8555\u001b[0m       \u001b[32m0.4331\u001b[0m        \u001b[35m4.7242\u001b[0m  1.4527\n",
      "      4        \u001b[36m4.6858\u001b[0m       \u001b[32m0.5921\u001b[0m        \u001b[35m4.5562\u001b[0m  1.5185\n",
      "      5        \u001b[36m4.5525\u001b[0m       \u001b[32m0.6838\u001b[0m        \u001b[35m4.4358\u001b[0m  1.4512\n",
      "      6        \u001b[36m4.4529\u001b[0m       \u001b[32m0.7308\u001b[0m        \u001b[35m4.3619\u001b[0m  1.4932\n",
      "      7        \u001b[36m4.3932\u001b[0m       \u001b[32m0.7579\u001b[0m        \u001b[35m4.3205\u001b[0m  1.4904\n",
      "      8        \u001b[36m4.3447\u001b[0m       \u001b[32m0.7801\u001b[0m        \u001b[35m4.2895\u001b[0m  1.4620\n",
      "      9        \u001b[36m4.3109\u001b[0m       \u001b[32m0.7917\u001b[0m        \u001b[35m4.2715\u001b[0m  1.4609\n",
      "     10        \u001b[36m4.2875\u001b[0m       \u001b[32m0.7967\u001b[0m        \u001b[35m4.2599\u001b[0m  1.4564\n",
      "     11        \u001b[36m4.2694\u001b[0m       \u001b[32m0.8063\u001b[0m        \u001b[35m4.2488\u001b[0m  1.4581\n",
      "     12        \u001b[36m4.2509\u001b[0m       \u001b[32m0.8182\u001b[0m        \u001b[35m4.2360\u001b[0m  1.4457\n",
      "     13        \u001b[36m4.2346\u001b[0m       \u001b[32m0.8308\u001b[0m        \u001b[35m4.2220\u001b[0m  1.4493\n",
      "     14        \u001b[36m4.2185\u001b[0m       \u001b[32m0.8401\u001b[0m        \u001b[35m4.2119\u001b[0m  1.4799\n",
      "     15        \u001b[36m4.2047\u001b[0m       \u001b[32m0.8500\u001b[0m        \u001b[35m4.2030\u001b[0m  1.4940\n",
      "     16        \u001b[36m4.1852\u001b[0m       \u001b[32m0.8652\u001b[0m        \u001b[35m4.1880\u001b[0m  1.4622\n",
      "     17        \u001b[36m4.1721\u001b[0m       \u001b[32m0.8742\u001b[0m        \u001b[35m4.1769\u001b[0m  1.4582\n",
      "     18        \u001b[36m4.1592\u001b[0m       \u001b[32m0.8781\u001b[0m        \u001b[35m4.1713\u001b[0m  1.4692\n",
      "     19        \u001b[36m4.1509\u001b[0m       \u001b[32m0.8785\u001b[0m        \u001b[35m4.1656\u001b[0m  1.4514\n",
      "     20        \u001b[36m4.1440\u001b[0m       \u001b[32m0.8821\u001b[0m        \u001b[35m4.1621\u001b[0m  1.4548\n",
      "     21        \u001b[36m4.1378\u001b[0m       \u001b[32m0.8848\u001b[0m        \u001b[35m4.1601\u001b[0m  1.4610\n",
      "     22        \u001b[36m4.1339\u001b[0m       \u001b[32m0.8851\u001b[0m        \u001b[35m4.1590\u001b[0m  1.4821\n",
      "     23        \u001b[36m4.1295\u001b[0m       0.8841        \u001b[35m4.1581\u001b[0m  1.4494\n",
      "     24        \u001b[36m4.1269\u001b[0m       \u001b[32m0.8874\u001b[0m        \u001b[35m4.1561\u001b[0m  1.4575\n",
      "     25        \u001b[36m4.1227\u001b[0m       0.8874        \u001b[35m4.1559\u001b[0m  1.4569\n",
      "     26        \u001b[36m4.1202\u001b[0m       0.8874        \u001b[35m4.1546\u001b[0m  1.4485\n",
      "     27        \u001b[36m4.1153\u001b[0m       \u001b[32m0.8930\u001b[0m        \u001b[35m4.1490\u001b[0m  1.4477\n",
      "     28        \u001b[36m4.1119\u001b[0m       0.8930        \u001b[35m4.1476\u001b[0m  1.4476\n",
      "     29        \u001b[36m4.1105\u001b[0m       \u001b[32m0.8947\u001b[0m        \u001b[35m4.1468\u001b[0m  1.4693\n",
      "     30        \u001b[36m4.1062\u001b[0m       0.8944        \u001b[35m4.1460\u001b[0m  1.4518\n",
      "     31        \u001b[36m4.1043\u001b[0m       \u001b[32m0.8983\u001b[0m        \u001b[35m4.1445\u001b[0m  1.4665\n",
      "     32        \u001b[36m4.1011\u001b[0m       \u001b[32m0.9007\u001b[0m        \u001b[35m4.1434\u001b[0m  1.4462\n",
      "     33        \u001b[36m4.0989\u001b[0m       0.8970        4.1435  1.4570\n",
      "     34        \u001b[36m4.0961\u001b[0m       0.8987        \u001b[35m4.1415\u001b[0m  1.4561\n",
      "     35        4.0977       0.8970        4.1422  1.4463\n",
      "     36        \u001b[36m4.0944\u001b[0m       0.8974        \u001b[35m4.1413\u001b[0m  1.4421\n",
      "     37        \u001b[36m4.0933\u001b[0m       0.9003        \u001b[35m4.1400\u001b[0m  1.4416\n",
      "     38        \u001b[36m4.0915\u001b[0m       \u001b[32m0.9010\u001b[0m        \u001b[35m4.1388\u001b[0m  1.4540\n",
      "     39        \u001b[36m4.0896\u001b[0m       0.9007        4.1389  1.4557\n",
      "     40        \u001b[36m4.0890\u001b[0m       \u001b[32m0.9036\u001b[0m        \u001b[35m4.1371\u001b[0m  1.4457\n",
      "     41        \u001b[36m4.0865\u001b[0m       0.9030        \u001b[35m4.1366\u001b[0m  1.4569\n",
      "     42        \u001b[36m4.0821\u001b[0m       0.9030        \u001b[35m4.1355\u001b[0m  1.4798\n",
      "     43        4.0829       \u001b[32m0.9043\u001b[0m        \u001b[35m4.1348\u001b[0m  1.4741\n",
      "     44        \u001b[36m4.0804\u001b[0m       0.9033        \u001b[35m4.1344\u001b[0m  1.4444\n",
      "     45        \u001b[36m4.0794\u001b[0m       0.9043        \u001b[35m4.1328\u001b[0m  1.4806\n",
      "     46        \u001b[36m4.0783\u001b[0m       0.9043        4.1340  1.5440\n",
      "     47        4.0789       \u001b[32m0.9056\u001b[0m        4.1331  1.4565\n",
      "     48        \u001b[36m4.0778\u001b[0m       0.9053        \u001b[35m4.1323\u001b[0m  1.4488\n",
      "     49        \u001b[36m4.0754\u001b[0m       0.9056        4.1324  1.4514\n",
      "     50        4.0755       0.9043        \u001b[35m4.1318\u001b[0m  1.4448\n",
      "     51        \u001b[36m4.0731\u001b[0m       0.9046        4.1322  1.4580\n",
      "     52        4.0741       0.9033        \u001b[35m4.1317\u001b[0m  1.4449\n",
      "     53        \u001b[36m4.0727\u001b[0m       \u001b[32m0.9066\u001b[0m        \u001b[35m4.1309\u001b[0m  1.4459\n",
      "     54        \u001b[36m4.0716\u001b[0m       0.9060        \u001b[35m4.1303\u001b[0m  1.4507\n",
      "     55        4.0717       0.9060        4.1313  1.4850\n",
      "     56        \u001b[36m4.0705\u001b[0m       0.9040        4.1313  1.4860\n",
      "     57        \u001b[36m4.0697\u001b[0m       0.9066        \u001b[35m4.1302\u001b[0m  1.4509\n",
      "     58        \u001b[36m4.0696\u001b[0m       \u001b[32m0.9073\u001b[0m        \u001b[35m4.1295\u001b[0m  1.4635\n",
      "     59        \u001b[36m4.0695\u001b[0m       0.9046        4.1306  1.4479\n",
      "     60        \u001b[36m4.0691\u001b[0m       0.9053        \u001b[35m4.1294\u001b[0m  1.4442\n",
      "     61        4.0694       0.9050        4.1301  1.4455\n",
      "     62        \u001b[36m4.0682\u001b[0m       0.9050        4.1299  1.4928\n",
      "     63        \u001b[36m4.0674\u001b[0m       0.9036        4.1309  1.4627\n",
      "     64        \u001b[36m4.0671\u001b[0m       0.9033        4.1312  1.4535\n",
      "     65        \u001b[36m4.0659\u001b[0m       0.9056        4.1297  1.4835\n",
      "     66        4.0674       0.9056        4.1297  1.4555\n",
      "     67        4.0662       0.9046        4.1296  1.4445\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{100: 0.9678145695364239}\n",
      "Val accuracy\n",
      "{100: 0.873}\n",
      "pred time\n",
      "{100: 0.16866612434387207}\n",
      "OOS Val Accuracy\n",
      "{100: 0.07}\n",
      "OOS pred time\n",
      "{100: 0.004477977752685547}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0165\u001b[0m       \u001b[32m0.4341\u001b[0m        \u001b[35m5.0122\u001b[0m  2.1825\n",
      "      2        \u001b[36m4.8992\u001b[0m       \u001b[32m0.4954\u001b[0m        \u001b[35m4.6959\u001b[0m  2.1926\n",
      "      3        \u001b[36m4.5527\u001b[0m       \u001b[32m0.7477\u001b[0m        \u001b[35m4.3876\u001b[0m  2.2030\n",
      "      4        \u001b[36m4.3417\u001b[0m       \u001b[32m0.8305\u001b[0m        \u001b[35m4.2699\u001b[0m  2.1964\n",
      "      5        \u001b[36m4.2404\u001b[0m       \u001b[32m0.8735\u001b[0m        \u001b[35m4.2079\u001b[0m  2.1793\n",
      "      6        \u001b[36m4.1808\u001b[0m       \u001b[32m0.8858\u001b[0m        \u001b[35m4.1809\u001b[0m  2.1839\n",
      "      7        \u001b[36m4.1530\u001b[0m       \u001b[32m0.8970\u001b[0m        \u001b[35m4.1646\u001b[0m  2.1838\n",
      "      8        \u001b[36m4.1275\u001b[0m       \u001b[32m0.9053\u001b[0m        \u001b[35m4.1496\u001b[0m  2.1824\n",
      "      9        \u001b[36m4.1069\u001b[0m       \u001b[32m0.9136\u001b[0m        \u001b[35m4.1403\u001b[0m  2.1839\n",
      "     10        \u001b[36m4.0931\u001b[0m       \u001b[32m0.9159\u001b[0m        \u001b[35m4.1343\u001b[0m  2.1823\n",
      "     11        \u001b[36m4.0835\u001b[0m       \u001b[32m0.9179\u001b[0m        \u001b[35m4.1312\u001b[0m  2.1889\n",
      "     12        \u001b[36m4.0773\u001b[0m       \u001b[32m0.9195\u001b[0m        \u001b[35m4.1287\u001b[0m  2.1858\n",
      "     13        \u001b[36m4.0697\u001b[0m       0.9179        \u001b[35m4.1267\u001b[0m  2.1913\n",
      "     14        \u001b[36m4.0665\u001b[0m       \u001b[32m0.9228\u001b[0m        \u001b[35m4.1235\u001b[0m  2.1831\n",
      "     15        \u001b[36m4.0630\u001b[0m       0.9195        \u001b[35m4.1230\u001b[0m  2.1863\n",
      "     16        \u001b[36m4.0593\u001b[0m       0.9195        4.1230  2.1844\n",
      "     17        \u001b[36m4.0576\u001b[0m       0.9175        \u001b[35m4.1225\u001b[0m  2.1808\n",
      "     18        \u001b[36m4.0552\u001b[0m       0.9179        \u001b[35m4.1221\u001b[0m  2.1883\n",
      "     19        \u001b[36m4.0544\u001b[0m       0.9185        4.1222  2.1824\n",
      "     20        \u001b[36m4.0533\u001b[0m       0.9166        \u001b[35m4.1216\u001b[0m  2.1893\n",
      "     21        \u001b[36m4.0514\u001b[0m       0.9175        \u001b[35m4.1205\u001b[0m  2.1804\n",
      "     22        \u001b[36m4.0504\u001b[0m       0.9205        \u001b[35m4.1192\u001b[0m  2.1877\n",
      "     23        \u001b[36m4.0492\u001b[0m       0.9202        \u001b[35m4.1183\u001b[0m  2.1835\n",
      "     24        \u001b[36m4.0483\u001b[0m       0.9215        \u001b[35m4.1171\u001b[0m  2.1820\n",
      "     25        \u001b[36m4.0477\u001b[0m       0.9222        4.1174  2.2396\n",
      "     26        \u001b[36m4.0468\u001b[0m       0.9212        4.1179  2.2637\n",
      "     27        4.0470       0.9189        4.1186  2.2058\n",
      "     28        \u001b[36m4.0449\u001b[0m       0.9172        4.1189  2.1864\n",
      "     29        4.0457       0.9182        4.1178  2.1888\n",
      "     30        \u001b[36m4.0444\u001b[0m       0.9209        \u001b[35m4.1163\u001b[0m  2.1832\n",
      "     31        \u001b[36m4.0439\u001b[0m       0.9175        4.1169  2.1881\n",
      "     32        4.0439       0.9189        4.1174  2.2201\n",
      "     33        \u001b[36m4.0426\u001b[0m       0.9179        4.1175  2.2206\n",
      "     34        4.0431       0.9202        4.1170  2.2017\n",
      "     35        \u001b[36m4.0426\u001b[0m       0.9202        4.1168  2.2033\n",
      "     36        \u001b[36m4.0419\u001b[0m       0.9192        4.1167  2.2027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     37        \u001b[36m4.0410\u001b[0m       0.9179        4.1172  2.2781\n",
      "     38        4.0411       0.9175        4.1171  2.2547\n",
      "     39        \u001b[36m4.0410\u001b[0m       0.9169        4.1169  2.2403\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{100: 0.9678145695364239, 200: 0.9784768211920529}\n",
      "Val accuracy\n",
      "{100: 0.873, 200: 0.885}\n",
      "pred time\n",
      "{100: 0.16866612434387207, 200: 0.21779298782348633}\n",
      "OOS Val Accuracy\n",
      "{100: 0.07, 200: 0.08}\n",
      "OOS pred time\n",
      "{100: 0.004477977752685547, 200: 0.006827116012573242}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0109\u001b[0m       \u001b[32m0.1705\u001b[0m        \u001b[35m4.9560\u001b[0m  4.1834\n",
      "      2        \u001b[36m4.6944\u001b[0m       \u001b[32m0.7275\u001b[0m        \u001b[35m4.4184\u001b[0m  4.0486\n",
      "      3        \u001b[36m4.3032\u001b[0m       \u001b[32m0.8589\u001b[0m        \u001b[35m4.2301\u001b[0m  4.2061\n",
      "      4        \u001b[36m4.1745\u001b[0m       \u001b[32m0.9017\u001b[0m        \u001b[35m4.1690\u001b[0m  4.0524\n",
      "      5        \u001b[36m4.1204\u001b[0m       \u001b[32m0.9156\u001b[0m        \u001b[35m4.1438\u001b[0m  4.1345\n",
      "      6        \u001b[36m4.0896\u001b[0m       \u001b[32m0.9219\u001b[0m        \u001b[35m4.1345\u001b[0m  4.1656\n",
      "      7        \u001b[36m4.0745\u001b[0m       \u001b[32m0.9225\u001b[0m        \u001b[35m4.1296\u001b[0m  4.2349\n",
      "      8        \u001b[36m4.0649\u001b[0m       \u001b[32m0.9248\u001b[0m        \u001b[35m4.1235\u001b[0m  4.1786\n",
      "      9        \u001b[36m4.0570\u001b[0m       \u001b[32m0.9295\u001b[0m        \u001b[35m4.1194\u001b[0m  4.0482\n",
      "     10        \u001b[36m4.0525\u001b[0m       0.9272        \u001b[35m4.1189\u001b[0m  4.1464\n",
      "     11        \u001b[36m4.0490\u001b[0m       0.9258        \u001b[35m4.1165\u001b[0m  4.1046\n",
      "     12        \u001b[36m4.0469\u001b[0m       0.9258        \u001b[35m4.1161\u001b[0m  4.0677\n",
      "     13        \u001b[36m4.0450\u001b[0m       0.9272        \u001b[35m4.1146\u001b[0m  4.1824\n",
      "     14        \u001b[36m4.0435\u001b[0m       0.9291        \u001b[35m4.1131\u001b[0m  4.1418\n",
      "     15        \u001b[36m4.0431\u001b[0m       0.9272        4.1146  4.0295\n",
      "     16        \u001b[36m4.0421\u001b[0m       0.9262        4.1137  4.0099\n",
      "     17        \u001b[36m4.0411\u001b[0m       0.9252        4.1133  4.0163\n",
      "     18        \u001b[36m4.0402\u001b[0m       0.9258        4.1136  4.0129\n",
      "     19        4.0403       0.9238        \u001b[35m4.1128\u001b[0m  4.0043\n",
      "     20        \u001b[36m4.0395\u001b[0m       0.9228        4.1133  4.0015\n",
      "     21        \u001b[36m4.0392\u001b[0m       0.9238        4.1132  4.0220\n",
      "     22        \u001b[36m4.0385\u001b[0m       0.9281        \u001b[35m4.1115\u001b[0m  4.0181\n",
      "     23        \u001b[36m4.0379\u001b[0m       0.9268        \u001b[35m4.1115\u001b[0m  4.0124\n",
      "     24        4.0379       0.9268        4.1126  4.0094\n",
      "     25        \u001b[36m4.0378\u001b[0m       0.9245        4.1121  4.0037\n",
      "     26        \u001b[36m4.0371\u001b[0m       0.9242        4.1128  4.0083\n",
      "     27        4.0377       0.9262        \u001b[35m4.1112\u001b[0m  4.0268\n",
      "     28        \u001b[36m4.0367\u001b[0m       0.9248        4.1118  4.0561\n",
      "     29        \u001b[36m4.0362\u001b[0m       0.9255        \u001b[35m4.1111\u001b[0m  4.1614\n",
      "     30        4.0365       0.9238        4.1122  4.0947\n",
      "     31        \u001b[36m4.0361\u001b[0m       0.9281        \u001b[35m4.1095\u001b[0m  4.0558\n",
      "     32        \u001b[36m4.0358\u001b[0m       0.9272        4.1111  4.3539\n",
      "     33        4.0358       0.9255        4.1098  4.7534\n",
      "     34        4.0359       0.9235        4.1112  4.2298\n",
      "     35        4.0361       0.9225        4.1118  4.2544\n",
      "     36        \u001b[36m4.0357\u001b[0m       0.9242        4.1117  4.2870\n",
      "     37        \u001b[36m4.0353\u001b[0m       0.9248        4.1112  4.1512\n",
      "     38        \u001b[36m4.0353\u001b[0m       0.9255        \u001b[35m4.1094\u001b[0m  4.1577\n",
      "     39        4.0357       0.9245        4.1117  4.2039\n",
      "     40        4.0355       0.9225        4.1106  4.2100\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{100: 0.9678145695364239, 200: 0.9784768211920529, 400: 0.9813245033112583}\n",
      "Val accuracy\n",
      "{100: 0.873, 200: 0.885, 400: 0.883}\n",
      "pred time\n",
      "{100: 0.16866612434387207, 200: 0.21779298782348633, 400: 0.31244707107543945}\n",
      "OOS Val Accuracy\n",
      "{100: 0.07, 200: 0.08, 400: 0.09}\n",
      "OOS pred time\n",
      "{100: 0.004477977752685547, 200: 0.006827116012573242, 400: 0.008316993713378906}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m4.9812\u001b[0m       \u001b[32m0.3589\u001b[0m        \u001b[35m4.7882\u001b[0m  7.3326\n",
      "      2        \u001b[36m4.4699\u001b[0m       \u001b[32m0.8291\u001b[0m        \u001b[35m4.2599\u001b[0m  7.5729\n",
      "      3        \u001b[36m4.1839\u001b[0m       \u001b[32m0.8937\u001b[0m        \u001b[35m4.1669\u001b[0m  7.6138\n",
      "      4        \u001b[36m4.1059\u001b[0m       \u001b[32m0.9156\u001b[0m        \u001b[35m4.1387\u001b[0m  7.7153\n",
      "      5        \u001b[36m4.0743\u001b[0m       \u001b[32m0.9172\u001b[0m        \u001b[35m4.1290\u001b[0m  7.7586\n",
      "      6        \u001b[36m4.0596\u001b[0m       \u001b[32m0.9225\u001b[0m        \u001b[35m4.1236\u001b[0m  7.8459\n",
      "      7        \u001b[36m4.0507\u001b[0m       \u001b[32m0.9258\u001b[0m        \u001b[35m4.1195\u001b[0m  7.5897\n",
      "      8        \u001b[36m4.0457\u001b[0m       \u001b[32m0.9275\u001b[0m        \u001b[35m4.1166\u001b[0m  7.6501\n",
      "      9        \u001b[36m4.0443\u001b[0m       0.9255        4.1171  7.6600\n",
      "     10        \u001b[36m4.0418\u001b[0m       0.9255        \u001b[35m4.1159\u001b[0m  7.6326\n",
      "     11        \u001b[36m4.0397\u001b[0m       0.9248        4.1163  7.7966\n",
      "     12        \u001b[36m4.0392\u001b[0m       0.9258        4.1165  7.5785\n",
      "     13        \u001b[36m4.0383\u001b[0m       0.9275        \u001b[35m4.1138\u001b[0m  8.3040\n",
      "     14        \u001b[36m4.0381\u001b[0m       0.9258        4.1150  7.8108\n",
      "     15        \u001b[36m4.0378\u001b[0m       0.9209        4.1154  7.6736\n",
      "     16        \u001b[36m4.0370\u001b[0m       0.9228        4.1151  7.7214\n",
      "     17        \u001b[36m4.0368\u001b[0m       0.9242        4.1140  7.7007\n",
      "     18        \u001b[36m4.0362\u001b[0m       0.9225        4.1145  7.6969\n",
      "     19        4.0362       0.9252        4.1145  7.6426\n",
      "     20        \u001b[36m4.0361\u001b[0m       0.9222        4.1152  7.5766\n",
      "     21        \u001b[36m4.0353\u001b[0m       0.9222        4.1144  7.8767\n",
      "     22        4.0355       0.9245        4.1141  7.8261\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{100: 0.9678145695364239, 200: 0.9784768211920529, 400: 0.9813245033112583, 800: 0.98}\n",
      "Val accuracy\n",
      "{100: 0.873, 200: 0.885, 400: 0.883, 800: 0.8873333333333333}\n",
      "pred time\n",
      "{100: 0.16866612434387207, 200: 0.21779298782348633, 400: 0.31244707107543945, 800: 0.44314098358154297}\n",
      "OOS Val Accuracy\n",
      "{100: 0.07, 200: 0.08, 400: 0.09, 800: 0.11}\n",
      "OOS pred time\n",
      "{100: 0.004477977752685547, 200: 0.006827116012573242, 400: 0.008316993713378906, 800: 0.014445066452026367}\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "hidden_list = [100, 200, 400, 800] #hidden layer sizes\n",
    "for hidden_dim in hidden_list:    #looping through hidden layer size\n",
    "    print(lr)\n",
    "    class CLINCModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                input_dim=vocab_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim,\n",
    "                dropout=0.5\n",
    "        ):\n",
    "            super(CLINCModule, self).__init__()\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "            self.hidden2 = nn.Linear(hidden_dim, hidden_dim) #additional hiden layer\n",
    "            self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = torch.tanh(self.hidden(X))\n",
    "            X = self.dropout(X)\n",
    "            X = torch.tanh(self.hidden2(X)) #additional layer\n",
    "            X = self.dropout(X) #additional dropout layer\n",
    "            X = F.softmax(self.output(X), dim=-1)\n",
    "            return X\n",
    "   \n",
    "    net = NeuralNetClassifier(\n",
    "    module=CLINCModule,\n",
    "    lr=lr,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    max_epochs=1000,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    callbacks=[EarlyStopping(patience=10)],\n",
    "    )\n",
    "    \n",
    "    net.fit(train_x, train_y)\n",
    "    tlabels = net.predict(train_x)\n",
    "    tacc[hidden_dim] = accuracy_score(tlabels, train_y)\n",
    "    print('training accuracy')\n",
    "    print(tacc)\n",
    "    time0 = time.time()\n",
    "    labels = net.predict(val_x)\n",
    "    vacc[hidden_dim] = accuracy_score(labels, val_y)\n",
    "    time1 = time.time()\n",
    "    vtime[hidden_dim] = time1-time0\n",
    "    print('Val accuracy')\n",
    "    print(vacc)\n",
    "    print('pred time')\n",
    "    print(vtime)\n",
    "    time2 = time.time()\n",
    "    olabels = net.predict(val_oos_x)\n",
    "    oacc[hidden_dim] = accuracy_score(olabels, val_oos_y)\n",
    "    time3 = time.time()\n",
    "    otime[hidden_dim]=time3-time2\n",
    "    print('OOS Val Accuracy')\n",
    "    print(oacc)\n",
    "    print('OOS pred time')\n",
    "    print(otime)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse accuracy than for one layer for all layer sizes, so will use a single layers. As 100 neurons in a single layer performed quite similarly to larger layers, will investigate effect of smaller hidden layer to increase speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0170\u001b[0m       \u001b[32m0.1593\u001b[0m        \u001b[35m5.0167\u001b[0m  1.2534\n",
      "      2        \u001b[36m5.0157\u001b[0m       \u001b[32m0.3493\u001b[0m        \u001b[35m5.0145\u001b[0m  1.0968\n",
      "      3        \u001b[36m5.0111\u001b[0m       \u001b[32m0.3834\u001b[0m        \u001b[35m5.0061\u001b[0m  1.1054\n",
      "      4        \u001b[36m4.9911\u001b[0m       0.3073        \u001b[35m4.9709\u001b[0m  1.0619\n",
      "      5        \u001b[36m4.9445\u001b[0m       \u001b[32m0.3970\u001b[0m        \u001b[35m4.9091\u001b[0m  1.0228\n",
      "      6        \u001b[36m4.8859\u001b[0m       \u001b[32m0.4404\u001b[0m        \u001b[35m4.8360\u001b[0m  1.0695\n",
      "      7        \u001b[36m4.8279\u001b[0m       \u001b[32m0.4745\u001b[0m        \u001b[35m4.7697\u001b[0m  1.0470\n",
      "      8        \u001b[36m4.7768\u001b[0m       \u001b[32m0.5109\u001b[0m        \u001b[35m4.7119\u001b[0m  1.0754\n",
      "      9        \u001b[36m4.7325\u001b[0m       \u001b[32m0.5315\u001b[0m        \u001b[35m4.6623\u001b[0m  1.1561\n",
      "     10        \u001b[36m4.6959\u001b[0m       \u001b[32m0.5487\u001b[0m        \u001b[35m4.6220\u001b[0m  1.0389\n",
      "     11        \u001b[36m4.6648\u001b[0m       \u001b[32m0.5649\u001b[0m        \u001b[35m4.5898\u001b[0m  1.0400\n",
      "     12        \u001b[36m4.6389\u001b[0m       \u001b[32m0.5791\u001b[0m        \u001b[35m4.5638\u001b[0m  1.0533\n",
      "     13        \u001b[36m4.6186\u001b[0m       \u001b[32m0.5911\u001b[0m        \u001b[35m4.5418\u001b[0m  1.1238\n",
      "     14        \u001b[36m4.5977\u001b[0m       \u001b[32m0.5993\u001b[0m        \u001b[35m4.5221\u001b[0m  1.0451\n",
      "     15        \u001b[36m4.5792\u001b[0m       \u001b[32m0.6123\u001b[0m        \u001b[35m4.5039\u001b[0m  1.1313\n",
      "     16        \u001b[36m4.5650\u001b[0m       \u001b[32m0.6245\u001b[0m        \u001b[35m4.4863\u001b[0m  1.2064\n",
      "     17        \u001b[36m4.5473\u001b[0m       \u001b[32m0.6411\u001b[0m        \u001b[35m4.4690\u001b[0m  1.1666\n",
      "     18        \u001b[36m4.5308\u001b[0m       \u001b[32m0.6517\u001b[0m        \u001b[35m4.4529\u001b[0m  1.2112\n",
      "     19        \u001b[36m4.5154\u001b[0m       \u001b[32m0.6609\u001b[0m        \u001b[35m4.4386\u001b[0m  1.2745\n",
      "     20        \u001b[36m4.5069\u001b[0m       \u001b[32m0.6748\u001b[0m        \u001b[35m4.4254\u001b[0m  1.2494\n",
      "     21        \u001b[36m4.4931\u001b[0m       \u001b[32m0.6861\u001b[0m        \u001b[35m4.4118\u001b[0m  1.2584\n",
      "     22        \u001b[36m4.4762\u001b[0m       \u001b[32m0.7050\u001b[0m        \u001b[35m4.3976\u001b[0m  1.0530\n",
      "     23        \u001b[36m4.4650\u001b[0m       \u001b[32m0.7189\u001b[0m        \u001b[35m4.3842\u001b[0m  1.2416\n",
      "     24        \u001b[36m4.4506\u001b[0m       \u001b[32m0.7285\u001b[0m        \u001b[35m4.3713\u001b[0m  1.0824\n",
      "     25        \u001b[36m4.4393\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m4.3595\u001b[0m  1.0442\n",
      "     26        \u001b[36m4.4287\u001b[0m       \u001b[32m0.7450\u001b[0m        \u001b[35m4.3488\u001b[0m  1.0440\n",
      "     27        \u001b[36m4.4152\u001b[0m       \u001b[32m0.7556\u001b[0m        \u001b[35m4.3387\u001b[0m  1.0459\n",
      "     28        \u001b[36m4.4071\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m4.3293\u001b[0m  1.0418\n",
      "     29        \u001b[36m4.3975\u001b[0m       \u001b[32m0.7705\u001b[0m        \u001b[35m4.3213\u001b[0m  1.0694\n",
      "     30        \u001b[36m4.3901\u001b[0m       \u001b[32m0.7762\u001b[0m        \u001b[35m4.3141\u001b[0m  1.0403\n",
      "     31        \u001b[36m4.3816\u001b[0m       \u001b[32m0.7778\u001b[0m        \u001b[35m4.3076\u001b[0m  1.0355\n",
      "     32        \u001b[36m4.3758\u001b[0m       \u001b[32m0.7815\u001b[0m        \u001b[35m4.3015\u001b[0m  1.0364\n",
      "     33        \u001b[36m4.3687\u001b[0m       \u001b[32m0.7858\u001b[0m        \u001b[35m4.2957\u001b[0m  1.0419\n",
      "     34        \u001b[36m4.3634\u001b[0m       \u001b[32m0.7894\u001b[0m        \u001b[35m4.2898\u001b[0m  1.0399\n",
      "     35        \u001b[36m4.3552\u001b[0m       \u001b[32m0.7987\u001b[0m        \u001b[35m4.2814\u001b[0m  1.0404\n",
      "     36        \u001b[36m4.3460\u001b[0m       \u001b[32m0.8116\u001b[0m        \u001b[35m4.2715\u001b[0m  1.0382\n",
      "     37        \u001b[36m4.3416\u001b[0m       \u001b[32m0.8219\u001b[0m        \u001b[35m4.2632\u001b[0m  1.0412\n",
      "     38        \u001b[36m4.3269\u001b[0m       \u001b[32m0.8272\u001b[0m        \u001b[35m4.2561\u001b[0m  1.0431\n",
      "     39        \u001b[36m4.3254\u001b[0m       \u001b[32m0.8325\u001b[0m        \u001b[35m4.2505\u001b[0m  1.0369\n",
      "     40        \u001b[36m4.3170\u001b[0m       \u001b[32m0.8354\u001b[0m        \u001b[35m4.2449\u001b[0m  1.0346\n",
      "     41        \u001b[36m4.3103\u001b[0m       \u001b[32m0.8387\u001b[0m        \u001b[35m4.2398\u001b[0m  1.0373\n",
      "     42        \u001b[36m4.3047\u001b[0m       \u001b[32m0.8421\u001b[0m        \u001b[35m4.2345\u001b[0m  1.0467\n",
      "     43        \u001b[36m4.3001\u001b[0m       \u001b[32m0.8480\u001b[0m        \u001b[35m4.2294\u001b[0m  1.0401\n",
      "     44        \u001b[36m4.2909\u001b[0m       \u001b[32m0.8546\u001b[0m        \u001b[35m4.2241\u001b[0m  1.0402\n",
      "     45        \u001b[36m4.2900\u001b[0m       \u001b[32m0.8583\u001b[0m        \u001b[35m4.2192\u001b[0m  1.0407\n",
      "     46        \u001b[36m4.2839\u001b[0m       \u001b[32m0.8616\u001b[0m        \u001b[35m4.2145\u001b[0m  1.0409\n",
      "     47        \u001b[36m4.2752\u001b[0m       \u001b[32m0.8639\u001b[0m        \u001b[35m4.2107\u001b[0m  1.0356\n",
      "     48        \u001b[36m4.2740\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m4.2070\u001b[0m  1.0402\n",
      "     49        \u001b[36m4.2686\u001b[0m       \u001b[32m0.8662\u001b[0m        \u001b[35m4.2035\u001b[0m  1.0418\n",
      "     50        \u001b[36m4.2663\u001b[0m       \u001b[32m0.8689\u001b[0m        \u001b[35m4.2008\u001b[0m  1.0392\n",
      "     51        \u001b[36m4.2616\u001b[0m       \u001b[32m0.8709\u001b[0m        \u001b[35m4.1982\u001b[0m  1.0376\n",
      "     52        \u001b[36m4.2544\u001b[0m       \u001b[32m0.8725\u001b[0m        \u001b[35m4.1953\u001b[0m  1.0443\n",
      "     53        \u001b[36m4.2516\u001b[0m       \u001b[32m0.8745\u001b[0m        \u001b[35m4.1927\u001b[0m  1.0343\n",
      "     54        \u001b[36m4.2489\u001b[0m       \u001b[32m0.8755\u001b[0m        \u001b[35m4.1903\u001b[0m  1.0379\n",
      "     55        \u001b[36m4.2460\u001b[0m       \u001b[32m0.8762\u001b[0m        \u001b[35m4.1884\u001b[0m  1.0361\n",
      "     56        \u001b[36m4.2387\u001b[0m       \u001b[32m0.8765\u001b[0m        \u001b[35m4.1864\u001b[0m  1.0348\n",
      "     57        4.2393       \u001b[32m0.8772\u001b[0m        \u001b[35m4.1847\u001b[0m  1.0613\n",
      "     58        \u001b[36m4.2357\u001b[0m       \u001b[32m0.8775\u001b[0m        \u001b[35m4.1830\u001b[0m  1.0405\n",
      "     59        4.2394       \u001b[32m0.8778\u001b[0m        \u001b[35m4.1819\u001b[0m  1.0345\n",
      "     60        \u001b[36m4.2347\u001b[0m       \u001b[32m0.8795\u001b[0m        \u001b[35m4.1805\u001b[0m  1.0385\n",
      "     61        \u001b[36m4.2262\u001b[0m       0.8778        \u001b[35m4.1790\u001b[0m  1.0357\n",
      "     62        4.2285       \u001b[32m0.8798\u001b[0m        \u001b[35m4.1778\u001b[0m  1.0396\n",
      "     63        \u001b[36m4.2225\u001b[0m       \u001b[32m0.8801\u001b[0m        \u001b[35m4.1765\u001b[0m  1.0400\n",
      "     64        \u001b[36m4.2177\u001b[0m       0.8798        \u001b[35m4.1753\u001b[0m  1.0359\n",
      "     65        \u001b[36m4.2140\u001b[0m       \u001b[32m0.8805\u001b[0m        \u001b[35m4.1739\u001b[0m  1.0407\n",
      "     66        4.2174       \u001b[32m0.8815\u001b[0m        \u001b[35m4.1730\u001b[0m  1.0375\n",
      "     67        4.2149       0.8808        \u001b[35m4.1721\u001b[0m  1.0480\n",
      "     68        \u001b[36m4.2128\u001b[0m       0.8815        \u001b[35m4.1712\u001b[0m  1.0488\n",
      "     69        4.2134       \u001b[32m0.8821\u001b[0m        \u001b[35m4.1704\u001b[0m  1.0658\n",
      "     70        \u001b[36m4.2104\u001b[0m       \u001b[32m0.8828\u001b[0m        \u001b[35m4.1695\u001b[0m  1.0469\n",
      "     71        \u001b[36m4.2054\u001b[0m       \u001b[32m0.8848\u001b[0m        \u001b[35m4.1683\u001b[0m  1.0573\n",
      "     72        \u001b[36m4.2022\u001b[0m       \u001b[32m0.8854\u001b[0m        \u001b[35m4.1674\u001b[0m  1.0394\n",
      "     73        \u001b[36m4.2011\u001b[0m       \u001b[32m0.8864\u001b[0m        \u001b[35m4.1662\u001b[0m  1.0419\n",
      "     74        \u001b[36m4.2005\u001b[0m       0.8864        \u001b[35m4.1652\u001b[0m  1.0516\n",
      "     75        \u001b[36m4.1994\u001b[0m       \u001b[32m0.8871\u001b[0m        \u001b[35m4.1642\u001b[0m  1.0469\n",
      "     76        \u001b[36m4.1980\u001b[0m       \u001b[32m0.8881\u001b[0m        \u001b[35m4.1624\u001b[0m  1.0425\n",
      "     77        4.1992       \u001b[32m0.8891\u001b[0m        \u001b[35m4.1613\u001b[0m  1.0433\n",
      "     78        \u001b[36m4.1962\u001b[0m       \u001b[32m0.8917\u001b[0m        \u001b[35m4.1604\u001b[0m  1.0431\n",
      "     79        \u001b[36m4.1938\u001b[0m       0.8907        \u001b[35m4.1595\u001b[0m  1.0393\n",
      "     80        \u001b[36m4.1921\u001b[0m       0.8901        \u001b[35m4.1590\u001b[0m  1.0405\n",
      "     81        \u001b[36m4.1909\u001b[0m       0.8917        \u001b[35m4.1583\u001b[0m  1.0444\n",
      "     82        4.1912       \u001b[32m0.8927\u001b[0m        \u001b[35m4.1575\u001b[0m  1.0407\n",
      "     83        \u001b[36m4.1832\u001b[0m       0.8927        \u001b[35m4.1570\u001b[0m  1.0434\n",
      "     84        4.1891       0.8927        \u001b[35m4.1564\u001b[0m  1.0406\n",
      "     85        4.1850       \u001b[32m0.8937\u001b[0m        \u001b[35m4.1559\u001b[0m  1.0612\n",
      "     86        4.1837       0.8934        \u001b[35m4.1554\u001b[0m  1.0412\n",
      "     87        \u001b[36m4.1831\u001b[0m       \u001b[32m0.8944\u001b[0m        \u001b[35m4.1549\u001b[0m  1.0355\n",
      "     88        \u001b[36m4.1768\u001b[0m       \u001b[32m0.8947\u001b[0m        \u001b[35m4.1542\u001b[0m  1.0430\n",
      "     89        4.1784       0.8944        \u001b[35m4.1537\u001b[0m  1.0404\n",
      "     90        4.1797       0.8944        \u001b[35m4.1533\u001b[0m  1.0471\n",
      "     91        \u001b[36m4.1758\u001b[0m       0.8944        \u001b[35m4.1531\u001b[0m  1.0418\n",
      "     92        4.1784       0.8947        \u001b[35m4.1527\u001b[0m  1.0383\n",
      "     93        \u001b[36m4.1757\u001b[0m       0.8947        \u001b[35m4.1522\u001b[0m  1.0395\n",
      "     94        \u001b[36m4.1735\u001b[0m       \u001b[32m0.8967\u001b[0m        \u001b[35m4.1515\u001b[0m  1.0624\n",
      "     95        4.1740       0.8960        \u001b[35m4.1512\u001b[0m  1.0447\n",
      "     96        \u001b[36m4.1700\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m4.1507\u001b[0m  1.0407\n",
      "     97        \u001b[36m4.1685\u001b[0m       0.8974        \u001b[35m4.1501\u001b[0m  1.0382\n",
      "     98        4.1692       \u001b[32m0.8977\u001b[0m        \u001b[35m4.1494\u001b[0m  1.0407\n",
      "     99        4.1698       \u001b[32m0.8980\u001b[0m        \u001b[35m4.1488\u001b[0m  1.0453\n",
      "    100        4.1687       \u001b[32m0.8990\u001b[0m        \u001b[35m4.1484\u001b[0m  1.0421\n",
      "    101        \u001b[36m4.1663\u001b[0m       0.8983        \u001b[35m4.1478\u001b[0m  1.0381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    102        \u001b[36m4.1657\u001b[0m       \u001b[32m0.8997\u001b[0m        \u001b[35m4.1473\u001b[0m  1.0417\n",
      "    103        \u001b[36m4.1646\u001b[0m       0.8997        \u001b[35m4.1466\u001b[0m  1.0497\n",
      "    104        \u001b[36m4.1627\u001b[0m       \u001b[32m0.9007\u001b[0m        \u001b[35m4.1463\u001b[0m  1.0408\n",
      "    105        \u001b[36m4.1615\u001b[0m       0.8993        \u001b[35m4.1460\u001b[0m  1.0436\n",
      "    106        4.1628       0.8990        \u001b[35m4.1457\u001b[0m  1.0390\n",
      "    107        \u001b[36m4.1581\u001b[0m       0.9003        \u001b[35m4.1453\u001b[0m  1.0346\n",
      "    108        \u001b[36m4.1578\u001b[0m       0.8987        \u001b[35m4.1450\u001b[0m  1.0380\n",
      "    109        \u001b[36m4.1574\u001b[0m       0.9003        \u001b[35m4.1445\u001b[0m  1.0430\n",
      "    110        4.1603       0.9000        \u001b[35m4.1443\u001b[0m  1.0448\n",
      "    111        \u001b[36m4.1567\u001b[0m       0.8997        \u001b[35m4.1441\u001b[0m  1.0347\n",
      "    112        \u001b[36m4.1556\u001b[0m       0.9007        \u001b[35m4.1436\u001b[0m  1.2328\n",
      "    113        \u001b[36m4.1544\u001b[0m       0.9007        \u001b[35m4.1433\u001b[0m  1.0396\n",
      "    114        4.1554       \u001b[32m0.9010\u001b[0m        \u001b[35m4.1430\u001b[0m  1.0346\n",
      "    115        4.1554       0.8997        \u001b[35m4.1428\u001b[0m  1.0308\n",
      "    116        \u001b[36m4.1521\u001b[0m       0.9010        \u001b[35m4.1426\u001b[0m  1.0315\n",
      "    117        \u001b[36m4.1521\u001b[0m       0.9007        \u001b[35m4.1423\u001b[0m  1.0341\n",
      "    118        \u001b[36m4.1519\u001b[0m       0.8990        4.1423  1.0279\n",
      "    119        \u001b[36m4.1486\u001b[0m       0.8997        \u001b[35m4.1420\u001b[0m  1.0352\n",
      "    120        4.1515       0.9007        \u001b[35m4.1415\u001b[0m  1.0335\n",
      "    121        \u001b[36m4.1479\u001b[0m       0.9000        4.1415  1.0352\n",
      "    122        4.1522       0.9000        \u001b[35m4.1412\u001b[0m  1.0314\n",
      "    123        4.1482       0.9003        \u001b[35m4.1410\u001b[0m  1.0353\n",
      "    124        4.1489       0.9003        \u001b[35m4.1409\u001b[0m  1.0275\n",
      "    125        \u001b[36m4.1463\u001b[0m       0.9010        \u001b[35m4.1406\u001b[0m  1.0677\n",
      "    126        4.1477       \u001b[32m0.9017\u001b[0m        \u001b[35m4.1404\u001b[0m  1.0271\n",
      "    127        \u001b[36m4.1453\u001b[0m       0.9007        \u001b[35m4.1402\u001b[0m  1.0593\n",
      "    128        4.1475       \u001b[32m0.9030\u001b[0m        \u001b[35m4.1398\u001b[0m  1.0319\n",
      "    129        4.1454       0.9023        \u001b[35m4.1398\u001b[0m  1.0285\n",
      "    130        \u001b[36m4.1446\u001b[0m       0.9020        \u001b[35m4.1394\u001b[0m  1.0340\n",
      "    131        \u001b[36m4.1429\u001b[0m       0.9026        \u001b[35m4.1393\u001b[0m  1.0351\n",
      "    132        \u001b[36m4.1427\u001b[0m       0.9020        \u001b[35m4.1391\u001b[0m  1.0243\n",
      "    133        \u001b[36m4.1426\u001b[0m       0.9017        \u001b[35m4.1390\u001b[0m  1.0310\n",
      "    134        \u001b[36m4.1412\u001b[0m       0.9017        \u001b[35m4.1388\u001b[0m  1.0317\n",
      "    135        \u001b[36m4.1382\u001b[0m       0.9017        \u001b[35m4.1388\u001b[0m  1.0354\n",
      "    136        4.1387       0.9030        \u001b[35m4.1383\u001b[0m  1.0383\n",
      "    137        4.1386       0.9020        \u001b[35m4.1380\u001b[0m  1.0288\n",
      "    138        4.1382       0.9023        \u001b[35m4.1378\u001b[0m  1.0354\n",
      "    139        4.1391       0.9030        \u001b[35m4.1375\u001b[0m  1.0574\n",
      "    140        4.1388       \u001b[32m0.9033\u001b[0m        \u001b[35m4.1370\u001b[0m  1.0366\n",
      "    141        4.1391       0.9033        \u001b[35m4.1365\u001b[0m  1.0283\n",
      "    142        \u001b[36m4.1379\u001b[0m       \u001b[32m0.9050\u001b[0m        \u001b[35m4.1360\u001b[0m  1.0314\n",
      "    143        4.1381       0.9043        \u001b[35m4.1358\u001b[0m  1.0406\n",
      "    144        \u001b[36m4.1321\u001b[0m       0.9046        \u001b[35m4.1353\u001b[0m  1.0398\n",
      "    145        4.1337       0.9046        \u001b[35m4.1352\u001b[0m  1.0327\n",
      "    146        4.1353       0.9040        4.1354  1.0403\n",
      "    147        4.1350       0.9040        4.1354  1.0403\n",
      "    148        4.1329       0.9046        \u001b[35m4.1351\u001b[0m  1.0230\n",
      "    149        4.1327       0.9046        \u001b[35m4.1348\u001b[0m  1.0343\n",
      "    150        4.1323       \u001b[32m0.9060\u001b[0m        \u001b[35m4.1345\u001b[0m  1.0428\n",
      "    151        \u001b[36m4.1311\u001b[0m       \u001b[32m0.9063\u001b[0m        \u001b[35m4.1344\u001b[0m  1.0361\n",
      "    152        4.1318       0.9063        \u001b[35m4.1343\u001b[0m  1.0306\n",
      "    153        4.1316       0.9050        \u001b[35m4.1343\u001b[0m  1.0215\n",
      "    154        4.1320       0.9063        \u001b[35m4.1340\u001b[0m  1.0369\n",
      "    155        \u001b[36m4.1310\u001b[0m       0.9053        4.1340  1.0355\n",
      "    156        4.1317       0.9060        \u001b[35m4.1337\u001b[0m  1.0347\n",
      "    157        \u001b[36m4.1306\u001b[0m       \u001b[32m0.9070\u001b[0m        \u001b[35m4.1334\u001b[0m  1.0331\n",
      "    158        \u001b[36m4.1288\u001b[0m       0.9066        4.1336  1.0416\n",
      "    159        4.1306       0.9070        \u001b[35m4.1334\u001b[0m  1.0364\n",
      "    160        \u001b[36m4.1286\u001b[0m       0.9070        \u001b[35m4.1332\u001b[0m  1.0477\n",
      "    161        4.1289       \u001b[32m0.9073\u001b[0m        \u001b[35m4.1330\u001b[0m  1.0657\n",
      "    162        \u001b[36m4.1267\u001b[0m       0.9063        \u001b[35m4.1330\u001b[0m  1.0438\n",
      "    163        4.1289       \u001b[32m0.9083\u001b[0m        \u001b[35m4.1330\u001b[0m  1.0484\n",
      "    164        4.1288       0.9076        \u001b[35m4.1328\u001b[0m  1.0442\n",
      "    165        \u001b[36m4.1222\u001b[0m       0.9073        4.1328  1.0567\n",
      "    166        4.1265       0.9060        \u001b[35m4.1328\u001b[0m  1.0445\n",
      "    167        4.1246       0.9063        4.1330  1.0251\n",
      "    168        4.1231       0.9070        4.1329  1.0435\n",
      "    169        4.1251       0.9076        \u001b[35m4.1328\u001b[0m  1.0439\n",
      "    170        4.1241       0.9070        \u001b[35m4.1327\u001b[0m  1.0393\n",
      "    171        4.1255       0.9073        4.1327  1.0390\n",
      "    172        4.1240       0.9063        \u001b[35m4.1324\u001b[0m  1.0290\n",
      "    173        4.1258       0.9066        \u001b[35m4.1324\u001b[0m  1.0329\n",
      "    174        \u001b[36m4.1213\u001b[0m       0.9070        4.1324  1.0325\n",
      "    175        4.1218       0.9063        4.1325  1.0361\n",
      "    176        4.1217       0.9066        4.1324  1.0332\n",
      "    177        4.1225       0.9066        \u001b[35m4.1324\u001b[0m  1.0338\n",
      "    178        4.1239       0.9063        \u001b[35m4.1322\u001b[0m  1.0372\n",
      "    179        4.1234       0.9056        4.1323  1.0351\n",
      "    180        4.1219       0.9060        \u001b[35m4.1321\u001b[0m  1.0240\n",
      "    181        \u001b[36m4.1210\u001b[0m       0.9046        4.1323  1.0391\n",
      "    182        \u001b[36m4.1200\u001b[0m       0.9053        \u001b[35m4.1312\u001b[0m  1.0316\n",
      "    183        \u001b[36m4.1185\u001b[0m       \u001b[32m0.9089\u001b[0m        \u001b[35m4.1287\u001b[0m  1.0364\n",
      "    184        \u001b[36m4.1137\u001b[0m       \u001b[32m0.9093\u001b[0m        \u001b[35m4.1281\u001b[0m  1.0385\n",
      "    185        4.1177       \u001b[32m0.9103\u001b[0m        4.1282  1.0310\n",
      "    186        \u001b[36m4.1132\u001b[0m       \u001b[32m0.9109\u001b[0m        \u001b[35m4.1281\u001b[0m  1.0340\n",
      "    187        4.1176       0.9109        \u001b[35m4.1280\u001b[0m  1.0374\n",
      "    188        4.1152       0.9096        \u001b[35m4.1279\u001b[0m  1.0418\n",
      "    189        4.1154       0.9099        \u001b[35m4.1279\u001b[0m  1.0340\n",
      "    190        \u001b[36m4.1126\u001b[0m       0.9093        4.1279  1.0284\n",
      "    191        4.1139       0.9079        4.1279  1.0352\n",
      "    192        4.1138       0.9093        4.1279  1.0304\n",
      "    193        4.1133       0.9089        4.1280  1.0411\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{25: 0.9689403973509934}\n",
      "Val accuracy\n",
      "{25: 0.8746666666666667}\n",
      "pred time\n",
      "{25: 0.1365070343017578}\n",
      "OOS Val Accuracy\n",
      "{25: 0.13}\n",
      "OOS pred time\n",
      "{25: 0.0035619735717773438}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0169\u001b[0m       \u001b[32m0.2911\u001b[0m        \u001b[35m5.0162\u001b[0m  1.1615\n",
      "      2        \u001b[36m5.0141\u001b[0m       \u001b[32m0.6179\u001b[0m        \u001b[35m5.0105\u001b[0m  1.1571\n",
      "      3        \u001b[36m4.9923\u001b[0m       0.4407        \u001b[35m4.9583\u001b[0m  1.1629\n",
      "      4        \u001b[36m4.8947\u001b[0m       0.5050        \u001b[35m4.8197\u001b[0m  1.1775\n",
      "      5        \u001b[36m4.7594\u001b[0m       0.5927        \u001b[35m4.6829\u001b[0m  1.1491\n",
      "      6        \u001b[36m4.6397\u001b[0m       \u001b[32m0.6596\u001b[0m        \u001b[35m4.5748\u001b[0m  1.1493\n",
      "      7        \u001b[36m4.5501\u001b[0m       \u001b[32m0.7129\u001b[0m        \u001b[35m4.4954\u001b[0m  1.1497\n",
      "      8        \u001b[36m4.4784\u001b[0m       \u001b[32m0.7507\u001b[0m        \u001b[35m4.4349\u001b[0m  1.1498\n",
      "      9        \u001b[36m4.4268\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m4.3879\u001b[0m  1.1531\n",
      "     10        \u001b[36m4.3813\u001b[0m       \u001b[32m0.8010\u001b[0m        \u001b[35m4.3474\u001b[0m  1.1612\n",
      "     11        \u001b[36m4.3416\u001b[0m       \u001b[32m0.8242\u001b[0m        \u001b[35m4.3140\u001b[0m  1.1544\n",
      "     12        \u001b[36m4.3115\u001b[0m       \u001b[32m0.8407\u001b[0m        \u001b[35m4.2884\u001b[0m  1.1471\n",
      "     13        \u001b[36m4.2851\u001b[0m       \u001b[32m0.8500\u001b[0m        \u001b[35m4.2675\u001b[0m  1.1512\n",
      "     14        \u001b[36m4.2623\u001b[0m       \u001b[32m0.8566\u001b[0m        \u001b[35m4.2519\u001b[0m  1.1511\n",
      "     15        \u001b[36m4.2476\u001b[0m       \u001b[32m0.8652\u001b[0m        \u001b[35m4.2395\u001b[0m  1.1520\n",
      "     16        \u001b[36m4.2333\u001b[0m       \u001b[32m0.8715\u001b[0m        \u001b[35m4.2284\u001b[0m  1.1559\n",
      "     17        \u001b[36m4.2172\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m4.2186\u001b[0m  1.1851\n",
      "     18        \u001b[36m4.2060\u001b[0m       \u001b[32m0.8765\u001b[0m        \u001b[35m4.2107\u001b[0m  1.1554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     19        \u001b[36m4.1946\u001b[0m       \u001b[32m0.8811\u001b[0m        \u001b[35m4.2033\u001b[0m  1.1530\n",
      "     20        \u001b[36m4.1885\u001b[0m       \u001b[32m0.8834\u001b[0m        \u001b[35m4.1971\u001b[0m  1.1529\n",
      "     21        \u001b[36m4.1798\u001b[0m       \u001b[32m0.8848\u001b[0m        \u001b[35m4.1925\u001b[0m  1.1491\n",
      "     22        \u001b[36m4.1739\u001b[0m       \u001b[32m0.8854\u001b[0m        \u001b[35m4.1883\u001b[0m  1.1520\n",
      "     23        \u001b[36m4.1681\u001b[0m       \u001b[32m0.8861\u001b[0m        \u001b[35m4.1843\u001b[0m  1.1820\n",
      "     24        \u001b[36m4.1629\u001b[0m       0.8848        \u001b[35m4.1808\u001b[0m  1.1494\n",
      "     25        \u001b[36m4.1569\u001b[0m       \u001b[32m0.8877\u001b[0m        \u001b[35m4.1769\u001b[0m  1.1473\n",
      "     26        \u001b[36m4.1522\u001b[0m       \u001b[32m0.8930\u001b[0m        \u001b[35m4.1724\u001b[0m  1.1567\n",
      "     27        \u001b[36m4.1456\u001b[0m       \u001b[32m0.8967\u001b[0m        \u001b[35m4.1675\u001b[0m  1.1580\n",
      "     28        \u001b[36m4.1410\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m4.1642\u001b[0m  1.1575\n",
      "     29        \u001b[36m4.1365\u001b[0m       \u001b[32m0.8997\u001b[0m        \u001b[35m4.1614\u001b[0m  1.1503\n",
      "     30        \u001b[36m4.1325\u001b[0m       \u001b[32m0.9023\u001b[0m        \u001b[35m4.1588\u001b[0m  1.1540\n",
      "     31        \u001b[36m4.1274\u001b[0m       \u001b[32m0.9033\u001b[0m        \u001b[35m4.1566\u001b[0m  1.1560\n",
      "     32        \u001b[36m4.1239\u001b[0m       0.9030        \u001b[35m4.1550\u001b[0m  1.1564\n",
      "     33        \u001b[36m4.1205\u001b[0m       \u001b[32m0.9036\u001b[0m        \u001b[35m4.1535\u001b[0m  1.2002\n",
      "     34        \u001b[36m4.1185\u001b[0m       \u001b[32m0.9043\u001b[0m        \u001b[35m4.1520\u001b[0m  1.1707\n",
      "     35        \u001b[36m4.1157\u001b[0m       \u001b[32m0.9046\u001b[0m        \u001b[35m4.1509\u001b[0m  1.2413\n",
      "     36        \u001b[36m4.1126\u001b[0m       \u001b[32m0.9053\u001b[0m        \u001b[35m4.1496\u001b[0m  1.1699\n",
      "     37        \u001b[36m4.1115\u001b[0m       0.9046        \u001b[35m4.1486\u001b[0m  1.2162\n",
      "     38        \u001b[36m4.1096\u001b[0m       0.9050        \u001b[35m4.1473\u001b[0m  1.1672\n",
      "     39        \u001b[36m4.1073\u001b[0m       \u001b[32m0.9063\u001b[0m        \u001b[35m4.1459\u001b[0m  1.1582\n",
      "     40        \u001b[36m4.1039\u001b[0m       \u001b[32m0.9086\u001b[0m        \u001b[35m4.1441\u001b[0m  1.1524\n",
      "     41        \u001b[36m4.1008\u001b[0m       \u001b[32m0.9106\u001b[0m        \u001b[35m4.1424\u001b[0m  1.1539\n",
      "     42        \u001b[36m4.0994\u001b[0m       0.9106        \u001b[35m4.1412\u001b[0m  1.1483\n",
      "     43        \u001b[36m4.0964\u001b[0m       \u001b[32m0.9136\u001b[0m        \u001b[35m4.1394\u001b[0m  1.1562\n",
      "     44        \u001b[36m4.0945\u001b[0m       \u001b[32m0.9139\u001b[0m        \u001b[35m4.1381\u001b[0m  1.1484\n",
      "     45        \u001b[36m4.0917\u001b[0m       \u001b[32m0.9152\u001b[0m        \u001b[35m4.1368\u001b[0m  1.1565\n",
      "     46        \u001b[36m4.0901\u001b[0m       \u001b[32m0.9159\u001b[0m        \u001b[35m4.1357\u001b[0m  1.1491\n",
      "     47        \u001b[36m4.0894\u001b[0m       0.9159        \u001b[35m4.1346\u001b[0m  1.1488\n",
      "     48        \u001b[36m4.0871\u001b[0m       0.9156        \u001b[35m4.1337\u001b[0m  1.1496\n",
      "     49        \u001b[36m4.0864\u001b[0m       \u001b[32m0.9172\u001b[0m        \u001b[35m4.1327\u001b[0m  1.2039\n",
      "     50        \u001b[36m4.0852\u001b[0m       0.9169        \u001b[35m4.1319\u001b[0m  1.2996\n",
      "     51        \u001b[36m4.0820\u001b[0m       \u001b[32m0.9179\u001b[0m        \u001b[35m4.1305\u001b[0m  1.2285\n",
      "     52        \u001b[36m4.0813\u001b[0m       \u001b[32m0.9189\u001b[0m        \u001b[35m4.1293\u001b[0m  1.2041\n",
      "     53        \u001b[36m4.0787\u001b[0m       \u001b[32m0.9209\u001b[0m        \u001b[35m4.1284\u001b[0m  1.2489\n",
      "     54        \u001b[36m4.0775\u001b[0m       \u001b[32m0.9215\u001b[0m        \u001b[35m4.1269\u001b[0m  1.2284\n",
      "     55        \u001b[36m4.0742\u001b[0m       \u001b[32m0.9248\u001b[0m        \u001b[35m4.1255\u001b[0m  1.1629\n",
      "     56        \u001b[36m4.0726\u001b[0m       0.9242        \u001b[35m4.1246\u001b[0m  1.2030\n",
      "     57        \u001b[36m4.0700\u001b[0m       0.9245        \u001b[35m4.1236\u001b[0m  1.1716\n",
      "     58        4.0708       \u001b[32m0.9255\u001b[0m        \u001b[35m4.1228\u001b[0m  1.1590\n",
      "     59        \u001b[36m4.0691\u001b[0m       0.9255        \u001b[35m4.1220\u001b[0m  1.1599\n",
      "     60        \u001b[36m4.0675\u001b[0m       0.9252        \u001b[35m4.1219\u001b[0m  1.1600\n",
      "     61        \u001b[36m4.0670\u001b[0m       \u001b[32m0.9258\u001b[0m        \u001b[35m4.1218\u001b[0m  1.1666\n",
      "     62        \u001b[36m4.0666\u001b[0m       0.9258        \u001b[35m4.1211\u001b[0m  1.1582\n",
      "     63        \u001b[36m4.0650\u001b[0m       \u001b[32m0.9281\u001b[0m        \u001b[35m4.1206\u001b[0m  1.1574\n",
      "     64        \u001b[36m4.0647\u001b[0m       0.9252        \u001b[35m4.1204\u001b[0m  1.1620\n",
      "     65        \u001b[36m4.0632\u001b[0m       0.9252        \u001b[35m4.1201\u001b[0m  1.1563\n",
      "     66        \u001b[36m4.0628\u001b[0m       0.9258        \u001b[35m4.1198\u001b[0m  1.1470\n",
      "     67        \u001b[36m4.0611\u001b[0m       0.9252        \u001b[35m4.1196\u001b[0m  1.1501\n",
      "     68        \u001b[36m4.0604\u001b[0m       0.9255        \u001b[35m4.1193\u001b[0m  1.1483\n",
      "     69        \u001b[36m4.0599\u001b[0m       0.9258        \u001b[35m4.1189\u001b[0m  1.1488\n",
      "     70        4.0599       0.9262        \u001b[35m4.1186\u001b[0m  1.1796\n",
      "     71        \u001b[36m4.0588\u001b[0m       0.9272        \u001b[35m4.1184\u001b[0m  1.1465\n",
      "     72        \u001b[36m4.0586\u001b[0m       0.9278        \u001b[35m4.1180\u001b[0m  1.1525\n",
      "     73        \u001b[36m4.0574\u001b[0m       0.9268        4.1180  1.1880\n",
      "     74        4.0575       0.9268        \u001b[35m4.1179\u001b[0m  1.1695\n",
      "     75        4.0576       0.9275        \u001b[35m4.1173\u001b[0m  1.1525\n",
      "     76        \u001b[36m4.0567\u001b[0m       0.9278        4.1174  1.1590\n",
      "     77        \u001b[36m4.0565\u001b[0m       0.9268        \u001b[35m4.1172\u001b[0m  1.1536\n",
      "     78        \u001b[36m4.0561\u001b[0m       0.9272        \u001b[35m4.1170\u001b[0m  1.1824\n",
      "     79        \u001b[36m4.0553\u001b[0m       0.9268        \u001b[35m4.1166\u001b[0m  1.2240\n",
      "     80        \u001b[36m4.0552\u001b[0m       0.9268        \u001b[35m4.1164\u001b[0m  1.1518\n",
      "     81        \u001b[36m4.0533\u001b[0m       0.9265        \u001b[35m4.1164\u001b[0m  1.1830\n",
      "     82        4.0545       0.9278        \u001b[35m4.1160\u001b[0m  1.1781\n",
      "     83        4.0538       0.9268        \u001b[35m4.1159\u001b[0m  1.1584\n",
      "     84        \u001b[36m4.0530\u001b[0m       0.9265        4.1159  1.1615\n",
      "     85        4.0532       0.9278        \u001b[35m4.1159\u001b[0m  1.1523\n",
      "     86        4.0537       0.9265        \u001b[35m4.1156\u001b[0m  1.2137\n",
      "     87        \u001b[36m4.0521\u001b[0m       0.9265        \u001b[35m4.1154\u001b[0m  1.1827\n",
      "     88        \u001b[36m4.0515\u001b[0m       0.9268        \u001b[35m4.1149\u001b[0m  1.1565\n",
      "     89        \u001b[36m4.0511\u001b[0m       0.9268        \u001b[35m4.1148\u001b[0m  1.2036\n",
      "     90        4.0512       0.9252        4.1149  1.1913\n",
      "     91        \u001b[36m4.0507\u001b[0m       0.9262        4.1150  1.2023\n",
      "     92        \u001b[36m4.0503\u001b[0m       0.9262        4.1149  1.1973\n",
      "     93        \u001b[36m4.0501\u001b[0m       0.9255        4.1151  1.1966\n",
      "     94        \u001b[36m4.0496\u001b[0m       0.9258        4.1150  1.1873\n",
      "     95        \u001b[36m4.0493\u001b[0m       0.9258        4.1150  1.1659\n",
      "     96        4.0506       0.9258        4.1149  1.1696\n",
      "     97        4.0494       0.9255        \u001b[35m4.1148\u001b[0m  1.2006\n",
      "     98        4.0498       0.9255        \u001b[35m4.1144\u001b[0m  1.1790\n",
      "     99        \u001b[36m4.0482\u001b[0m       0.9252        4.1144  1.1511\n",
      "    100        4.0483       0.9262        4.1145  1.1498\n",
      "    101        4.0484       0.9275        \u001b[35m4.1143\u001b[0m  1.1586\n",
      "    102        \u001b[36m4.0481\u001b[0m       0.9268        \u001b[35m4.1143\u001b[0m  1.1486\n",
      "    103        4.0486       0.9265        \u001b[35m4.1141\u001b[0m  1.1544\n",
      "    104        \u001b[36m4.0466\u001b[0m       0.9268        4.1142  1.1487\n",
      "    105        4.0467       0.9275        \u001b[35m4.1139\u001b[0m  1.1513\n",
      "    106        4.0468       0.9268        \u001b[35m4.1138\u001b[0m  1.1538\n",
      "    107        4.0473       0.9262        \u001b[35m4.1137\u001b[0m  1.1504\n",
      "    108        4.0467       0.9265        4.1138  1.1437\n",
      "    109        \u001b[36m4.0463\u001b[0m       0.9272        4.1137  1.1481\n",
      "    110        \u001b[36m4.0461\u001b[0m       0.9262        \u001b[35m4.1136\u001b[0m  1.1558\n",
      "    111        4.0466       0.9255        4.1137  1.1497\n",
      "    112        \u001b[36m4.0459\u001b[0m       0.9252        4.1137  1.1472\n",
      "    113        \u001b[36m4.0455\u001b[0m       0.9248        4.1138  1.1527\n",
      "    114        4.0459       0.9248        4.1139  1.1511\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{25: 0.9689403973509934, 50: 0.9792052980132451}\n",
      "Val accuracy\n",
      "{25: 0.8746666666666667, 50: 0.888}\n",
      "pred time\n",
      "{25: 0.1365070343017578, 50: 0.1475369930267334}\n",
      "OOS Val Accuracy\n",
      "{25: 0.13, 50: 0.12}\n",
      "OOS pred time\n",
      "{25: 0.0035619735717773438, 50: 0.003982067108154297}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0168\u001b[0m       \u001b[32m0.4401\u001b[0m        \u001b[35m5.0158\u001b[0m  1.3226\n",
      "      2        \u001b[36m5.0114\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m5.0012\u001b[0m  1.3022\n",
      "      3        \u001b[36m4.9485\u001b[0m       0.4904        \u001b[35m4.8680\u001b[0m  1.3066\n",
      "      4        \u001b[36m4.7696\u001b[0m       \u001b[32m0.6341\u001b[0m        \u001b[35m4.6723\u001b[0m  1.2964\n",
      "      5        \u001b[36m4.5943\u001b[0m       \u001b[32m0.7086\u001b[0m        \u001b[35m4.5231\u001b[0m  1.2992\n",
      "      6        \u001b[36m4.4706\u001b[0m       \u001b[32m0.7669\u001b[0m        \u001b[35m4.4308\u001b[0m  1.3173\n",
      "      7        \u001b[36m4.3935\u001b[0m       \u001b[32m0.8023\u001b[0m        \u001b[35m4.3682\u001b[0m  1.3064\n",
      "      8        \u001b[36m4.3349\u001b[0m       \u001b[32m0.8331\u001b[0m        \u001b[35m4.3191\u001b[0m  1.3395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9        \u001b[36m4.2895\u001b[0m       \u001b[32m0.8483\u001b[0m        \u001b[35m4.2847\u001b[0m  1.3191\n",
      "     10        \u001b[36m4.2563\u001b[0m       \u001b[32m0.8639\u001b[0m        \u001b[35m4.2581\u001b[0m  1.3010\n",
      "     11        \u001b[36m4.2287\u001b[0m       \u001b[32m0.8715\u001b[0m        \u001b[35m4.2385\u001b[0m  1.3066\n",
      "     12        \u001b[36m4.2075\u001b[0m       \u001b[32m0.8791\u001b[0m        \u001b[35m4.2229\u001b[0m  1.2926\n",
      "     13        \u001b[36m4.1916\u001b[0m       \u001b[32m0.8897\u001b[0m        \u001b[35m4.2095\u001b[0m  1.3463\n",
      "     14        \u001b[36m4.1756\u001b[0m       \u001b[32m0.8944\u001b[0m        \u001b[35m4.1974\u001b[0m  1.3234\n",
      "     15        \u001b[36m4.1623\u001b[0m       \u001b[32m0.9013\u001b[0m        \u001b[35m4.1871\u001b[0m  1.3014\n",
      "     16        \u001b[36m4.1498\u001b[0m       \u001b[32m0.9060\u001b[0m        \u001b[35m4.1779\u001b[0m  1.3060\n",
      "     17        \u001b[36m4.1394\u001b[0m       \u001b[32m0.9116\u001b[0m        \u001b[35m4.1710\u001b[0m  1.3210\n",
      "     18        \u001b[36m4.1311\u001b[0m       \u001b[32m0.9136\u001b[0m        \u001b[35m4.1646\u001b[0m  1.3380\n",
      "     19        \u001b[36m4.1220\u001b[0m       \u001b[32m0.9185\u001b[0m        \u001b[35m4.1586\u001b[0m  1.3046\n",
      "     20        \u001b[36m4.1159\u001b[0m       \u001b[32m0.9199\u001b[0m        \u001b[35m4.1537\u001b[0m  1.3277\n",
      "     21        \u001b[36m4.1089\u001b[0m       \u001b[32m0.9222\u001b[0m        \u001b[35m4.1501\u001b[0m  1.3110\n",
      "     22        \u001b[36m4.1021\u001b[0m       \u001b[32m0.9242\u001b[0m        \u001b[35m4.1472\u001b[0m  1.2969\n",
      "     23        \u001b[36m4.0968\u001b[0m       \u001b[32m0.9255\u001b[0m        \u001b[35m4.1443\u001b[0m  1.3022\n",
      "     24        \u001b[36m4.0930\u001b[0m       0.9255        \u001b[35m4.1419\u001b[0m  1.3230\n",
      "     25        \u001b[36m4.0891\u001b[0m       0.9252        \u001b[35m4.1398\u001b[0m  1.2921\n",
      "     26        \u001b[36m4.0848\u001b[0m       \u001b[32m0.9265\u001b[0m        \u001b[35m4.1378\u001b[0m  1.2985\n",
      "     27        \u001b[36m4.0833\u001b[0m       \u001b[32m0.9272\u001b[0m        \u001b[35m4.1359\u001b[0m  1.2992\n",
      "     28        \u001b[36m4.0802\u001b[0m       0.9272        \u001b[35m4.1346\u001b[0m  1.3168\n",
      "     29        \u001b[36m4.0774\u001b[0m       0.9272        \u001b[35m4.1331\u001b[0m  1.3240\n",
      "     30        \u001b[36m4.0753\u001b[0m       0.9272        \u001b[35m4.1318\u001b[0m  1.3240\n",
      "     31        \u001b[36m4.0730\u001b[0m       \u001b[32m0.9285\u001b[0m        \u001b[35m4.1306\u001b[0m  1.3056\n",
      "     32        \u001b[36m4.0711\u001b[0m       0.9275        \u001b[35m4.1292\u001b[0m  1.3163\n",
      "     33        \u001b[36m4.0701\u001b[0m       \u001b[32m0.9288\u001b[0m        \u001b[35m4.1279\u001b[0m  1.3098\n",
      "     34        \u001b[36m4.0675\u001b[0m       0.9288        \u001b[35m4.1267\u001b[0m  1.3033\n",
      "     35        \u001b[36m4.0645\u001b[0m       \u001b[32m0.9308\u001b[0m        \u001b[35m4.1255\u001b[0m  1.3152\n",
      "     36        \u001b[36m4.0645\u001b[0m       \u001b[32m0.9315\u001b[0m        \u001b[35m4.1246\u001b[0m  1.3019\n",
      "     37        \u001b[36m4.0621\u001b[0m       \u001b[32m0.9318\u001b[0m        \u001b[35m4.1235\u001b[0m  1.3010\n",
      "     38        \u001b[36m4.0603\u001b[0m       0.9315        \u001b[35m4.1224\u001b[0m  1.3004\n",
      "     39        \u001b[36m4.0597\u001b[0m       0.9315        \u001b[35m4.1215\u001b[0m  1.3074\n",
      "     40        \u001b[36m4.0575\u001b[0m       0.9301        \u001b[35m4.1208\u001b[0m  1.3234\n",
      "     41        \u001b[36m4.0567\u001b[0m       0.9315        \u001b[35m4.1200\u001b[0m  1.3202\n",
      "     42        \u001b[36m4.0556\u001b[0m       \u001b[32m0.9321\u001b[0m        \u001b[35m4.1193\u001b[0m  1.3026\n",
      "     43        \u001b[36m4.0547\u001b[0m       \u001b[32m0.9331\u001b[0m        \u001b[35m4.1185\u001b[0m  1.2988\n",
      "     44        \u001b[36m4.0543\u001b[0m       0.9325        \u001b[35m4.1177\u001b[0m  1.3384\n",
      "     45        \u001b[36m4.0527\u001b[0m       0.9308        \u001b[35m4.1169\u001b[0m  1.3049\n",
      "     46        \u001b[36m4.0520\u001b[0m       0.9308        \u001b[35m4.1167\u001b[0m  1.3032\n",
      "     47        \u001b[36m4.0518\u001b[0m       \u001b[32m0.9341\u001b[0m        \u001b[35m4.1158\u001b[0m  1.3196\n",
      "     48        \u001b[36m4.0512\u001b[0m       0.9341        \u001b[35m4.1152\u001b[0m  1.3128\n",
      "     49        \u001b[36m4.0502\u001b[0m       0.9334        \u001b[35m4.1149\u001b[0m  1.2997\n",
      "     50        4.0502       0.9338        \u001b[35m4.1146\u001b[0m  1.2978\n",
      "     51        \u001b[36m4.0499\u001b[0m       0.9334        \u001b[35m4.1142\u001b[0m  1.3545\n",
      "     52        \u001b[36m4.0486\u001b[0m       0.9334        \u001b[35m4.1136\u001b[0m  1.3178\n",
      "     53        \u001b[36m4.0477\u001b[0m       0.9331        \u001b[35m4.1133\u001b[0m  1.2981\n",
      "     54        \u001b[36m4.0473\u001b[0m       0.9331        \u001b[35m4.1128\u001b[0m  1.3092\n",
      "     55        4.0476       0.9341        \u001b[35m4.1125\u001b[0m  1.3647\n",
      "     56        \u001b[36m4.0461\u001b[0m       0.9318        \u001b[35m4.1124\u001b[0m  1.2926\n",
      "     57        4.0462       0.9338        \u001b[35m4.1123\u001b[0m  1.3067\n",
      "     58        \u001b[36m4.0459\u001b[0m       0.9328        \u001b[35m4.1118\u001b[0m  1.3048\n",
      "     59        \u001b[36m4.0445\u001b[0m       0.9334        \u001b[35m4.1113\u001b[0m  1.3140\n",
      "     60        \u001b[36m4.0445\u001b[0m       0.9334        \u001b[35m4.1110\u001b[0m  1.3040\n",
      "     61        \u001b[36m4.0444\u001b[0m       0.9341        4.1111  1.3178\n",
      "     62        \u001b[36m4.0435\u001b[0m       0.9334        \u001b[35m4.1109\u001b[0m  1.3017\n",
      "     63        \u001b[36m4.0433\u001b[0m       0.9334        4.1109  1.3383\n",
      "     64        4.0440       0.9331        \u001b[35m4.1107\u001b[0m  1.3028\n",
      "     65        \u001b[36m4.0424\u001b[0m       0.9331        \u001b[35m4.1105\u001b[0m  1.3010\n",
      "     66        \u001b[36m4.0421\u001b[0m       \u001b[32m0.9348\u001b[0m        \u001b[35m4.1101\u001b[0m  1.3206\n",
      "     67        \u001b[36m4.0419\u001b[0m       0.9334        \u001b[35m4.1098\u001b[0m  1.2967\n",
      "     68        \u001b[36m4.0412\u001b[0m       0.9331        \u001b[35m4.1097\u001b[0m  1.3012\n",
      "     69        4.0419       \u001b[32m0.9351\u001b[0m        \u001b[35m4.1094\u001b[0m  1.3003\n",
      "     70        \u001b[36m4.0412\u001b[0m       0.9351        \u001b[35m4.1091\u001b[0m  1.3149\n",
      "     71        4.0414       0.9344        \u001b[35m4.1086\u001b[0m  1.3026\n",
      "     72        \u001b[36m4.0400\u001b[0m       0.9351        4.1087  1.3045\n",
      "     73        4.0404       \u001b[32m0.9354\u001b[0m        \u001b[35m4.1084\u001b[0m  1.3230\n",
      "     74        4.0403       0.9348        \u001b[35m4.1082\u001b[0m  1.3130\n",
      "     75        \u001b[36m4.0398\u001b[0m       0.9338        \u001b[35m4.1080\u001b[0m  1.2950\n",
      "     76        4.0398       0.9344        4.1081  1.2973\n",
      "     77        \u001b[36m4.0395\u001b[0m       0.9341        \u001b[35m4.1078\u001b[0m  1.3020\n",
      "     78        4.0396       0.9348        4.1078  1.3477\n",
      "     79        \u001b[36m4.0392\u001b[0m       0.9338        \u001b[35m4.1078\u001b[0m  1.2977\n",
      "     80        \u001b[36m4.0383\u001b[0m       0.9338        \u001b[35m4.1077\u001b[0m  1.3072\n",
      "     81        4.0391       0.9351        \u001b[35m4.1076\u001b[0m  1.3075\n",
      "     82        4.0388       0.9348        4.1078  1.2948\n",
      "     83        4.0387       0.9338        4.1079  1.2978\n",
      "     84        \u001b[36m4.0383\u001b[0m       0.9331        4.1078  1.2973\n",
      "     85        4.0387       0.9351        \u001b[35m4.1073\u001b[0m  1.3435\n",
      "     86        4.0383       0.9341        4.1074  1.3097\n",
      "     87        \u001b[36m4.0380\u001b[0m       0.9328        \u001b[35m4.1073\u001b[0m  1.2972\n",
      "     88        \u001b[36m4.0377\u001b[0m       0.9328        \u001b[35m4.1072\u001b[0m  1.3015\n",
      "     89        \u001b[36m4.0375\u001b[0m       0.9321        4.1073  1.3027\n",
      "     90        \u001b[36m4.0374\u001b[0m       0.9318        4.1073  1.2963\n",
      "     91        \u001b[36m4.0369\u001b[0m       0.9328        4.1073  1.3045\n",
      "     92        4.0372       0.9334        \u001b[35m4.1068\u001b[0m  1.2948\n",
      "     93        4.0371       0.9331        \u001b[35m4.1066\u001b[0m  1.3316\n",
      "     94        \u001b[36m4.0366\u001b[0m       0.9331        \u001b[35m4.1066\u001b[0m  1.2993\n",
      "     95        4.0369       0.9334        \u001b[35m4.1061\u001b[0m  1.3286\n",
      "     96        4.0367       0.9338        \u001b[35m4.1061\u001b[0m  1.3110\n",
      "     97        \u001b[36m4.0363\u001b[0m       0.9334        4.1063  1.3913\n",
      "     98        \u001b[36m4.0362\u001b[0m       0.9334        4.1066  1.3312\n",
      "     99        4.0367       0.9311        4.1066  1.2883\n",
      "    100        4.0363       0.9321        4.1064  1.3033\n",
      "    101        \u001b[36m4.0361\u001b[0m       0.9311        4.1065  1.2940\n",
      "    102        \u001b[36m4.0361\u001b[0m       0.9311        4.1063  1.3110\n",
      "    103        \u001b[36m4.0358\u001b[0m       0.9311        4.1061  1.3048\n",
      "    104        4.0358       0.9318        4.1061  1.3018\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{25: 0.9689403973509934, 50: 0.9792052980132451, 75: 0.9833112582781457}\n",
      "Val accuracy\n",
      "{25: 0.8746666666666667, 50: 0.888, 75: 0.896}\n",
      "pred time\n",
      "{25: 0.1365070343017578, 50: 0.1475369930267334, 75: 0.16062092781066895}\n",
      "OOS Val Accuracy\n",
      "{25: 0.13, 50: 0.12, 75: 0.11}\n",
      "OOS pred time\n",
      "{25: 0.0035619735717773438, 50: 0.003982067108154297, 75: 0.004182100296020508}\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "hidden_list = [25, 50, 75] #hidden layer size\n",
    "for hidden_dim in hidden_list:    #looping for hidden layer size\n",
    "    print(lr)\n",
    "    class CLINCModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                input_dim=vocab_dim,\n",
    "                hidden_dim=hidden_dim,#setting hidden layer size\n",
    "                output_dim=output_dim,\n",
    "                dropout=0.5\n",
    "        ):\n",
    "            super(CLINCModule, self).__init__()\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "            self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = torch.tanh(self.hidden(X))\n",
    "            X = self.dropout(X)\n",
    "            X = F.softmax(self.output(X), dim=-1)\n",
    "            return X\n",
    "   \n",
    "    net = NeuralNetClassifier(\n",
    "    module=CLINCModule,\n",
    "    lr=lr,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    max_epochs=1000,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    callbacks=[EarlyStopping(patience=10)],\n",
    "    )\n",
    "    \n",
    "    net.fit(train_x, train_y)\n",
    "    tlabels = net.predict(train_x)\n",
    "    tacc[hidden_dim] = accuracy_score(tlabels, train_y)\n",
    "    print('training accuracy')\n",
    "    print(tacc)\n",
    "    time0 = time.time()\n",
    "    labels = net.predict(val_x)\n",
    "    vacc[hidden_dim] = accuracy_score(labels, val_y)\n",
    "    time1 = time.time()\n",
    "    vtime[hidden_dim] = time1-time0\n",
    "    print('Val accuracy')\n",
    "    print(vacc)\n",
    "    print('pred time')\n",
    "    print(vtime)\n",
    "    time2 = time.time()\n",
    "    olabels = net.predict(val_oos_x)\n",
    "    oacc[hidden_dim] = accuracy_score(olabels, val_oos_y)\n",
    "    time3 = time.time()\n",
    "    otime[hidden_dim]=time3-time2\n",
    "    print('OOS Val Accuracy')\n",
    "    print(oacc)\n",
    "    print('OOS pred time')\n",
    "    print(otime)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitely worse than 100 neurons. Would 151 hidden neurons be beneficial, given output size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0164\u001b[0m       \u001b[32m0.6871\u001b[0m        \u001b[35m5.0142\u001b[0m  1.8697\n",
      "      2        \u001b[36m4.9909\u001b[0m       0.4632        \u001b[35m4.9248\u001b[0m  1.8631\n",
      "      3        \u001b[36m4.7729\u001b[0m       0.6576        \u001b[35m4.6273\u001b[0m  1.8291\n",
      "      4        \u001b[36m4.5074\u001b[0m       \u001b[32m0.7858\u001b[0m        \u001b[35m4.4366\u001b[0m  1.8232\n",
      "      5        \u001b[36m4.3543\u001b[0m       \u001b[32m0.8497\u001b[0m        \u001b[35m4.3283\u001b[0m  1.8285\n",
      "      6        \u001b[36m4.2655\u001b[0m       \u001b[32m0.8811\u001b[0m        \u001b[35m4.2671\u001b[0m  1.8184\n",
      "      7        \u001b[36m4.2122\u001b[0m       \u001b[32m0.8934\u001b[0m        \u001b[35m4.2314\u001b[0m  1.8413\n",
      "      8        \u001b[36m4.1786\u001b[0m       \u001b[32m0.9030\u001b[0m        \u001b[35m4.2078\u001b[0m  1.8570\n",
      "      9        \u001b[36m4.1546\u001b[0m       \u001b[32m0.9139\u001b[0m        \u001b[35m4.1886\u001b[0m  1.8207\n",
      "     10        \u001b[36m4.1356\u001b[0m       \u001b[32m0.9189\u001b[0m        \u001b[35m4.1739\u001b[0m  1.8298\n",
      "     11        \u001b[36m4.1188\u001b[0m       \u001b[32m0.9225\u001b[0m        \u001b[35m4.1636\u001b[0m  1.8285\n",
      "     12        \u001b[36m4.1071\u001b[0m       \u001b[32m0.9248\u001b[0m        \u001b[35m4.1558\u001b[0m  1.8272\n",
      "     13        \u001b[36m4.0970\u001b[0m       \u001b[32m0.9252\u001b[0m        \u001b[35m4.1501\u001b[0m  1.8286\n",
      "     14        \u001b[36m4.0882\u001b[0m       \u001b[32m0.9295\u001b[0m        \u001b[35m4.1453\u001b[0m  1.8223\n",
      "     15        \u001b[36m4.0819\u001b[0m       \u001b[32m0.9308\u001b[0m        \u001b[35m4.1413\u001b[0m  1.8230\n",
      "     16        \u001b[36m4.0773\u001b[0m       0.9308        \u001b[35m4.1377\u001b[0m  1.8167\n",
      "     17        \u001b[36m4.0713\u001b[0m       \u001b[32m0.9341\u001b[0m        \u001b[35m4.1343\u001b[0m  1.8249\n",
      "     18        \u001b[36m4.0669\u001b[0m       \u001b[32m0.9348\u001b[0m        \u001b[35m4.1314\u001b[0m  1.8241\n",
      "     19        \u001b[36m4.0621\u001b[0m       \u001b[32m0.9361\u001b[0m        \u001b[35m4.1286\u001b[0m  1.8352\n",
      "     20        \u001b[36m4.0601\u001b[0m       \u001b[32m0.9368\u001b[0m        \u001b[35m4.1262\u001b[0m  1.8223\n",
      "     21        \u001b[36m4.0575\u001b[0m       \u001b[32m0.9381\u001b[0m        \u001b[35m4.1243\u001b[0m  1.8283\n",
      "     22        \u001b[36m4.0548\u001b[0m       0.9371        \u001b[35m4.1226\u001b[0m  1.8204\n",
      "     23        \u001b[36m4.0523\u001b[0m       0.9377        \u001b[35m4.1212\u001b[0m  1.8197\n",
      "     24        \u001b[36m4.0510\u001b[0m       0.9374        \u001b[35m4.1199\u001b[0m  1.8052\n",
      "     25        \u001b[36m4.0487\u001b[0m       0.9371        \u001b[35m4.1186\u001b[0m  1.8152\n",
      "     26        \u001b[36m4.0476\u001b[0m       \u001b[32m0.9387\u001b[0m        \u001b[35m4.1176\u001b[0m  1.8115\n",
      "     27        \u001b[36m4.0469\u001b[0m       0.9374        \u001b[35m4.1169\u001b[0m  1.8163\n",
      "     28        \u001b[36m4.0461\u001b[0m       0.9381        \u001b[35m4.1158\u001b[0m  1.8062\n",
      "     29        \u001b[36m4.0449\u001b[0m       0.9381        \u001b[35m4.1149\u001b[0m  1.8218\n",
      "     30        \u001b[36m4.0436\u001b[0m       0.9371        \u001b[35m4.1143\u001b[0m  1.8126\n",
      "     31        \u001b[36m4.0433\u001b[0m       0.9387        \u001b[35m4.1134\u001b[0m  1.7997\n",
      "     32        \u001b[36m4.0422\u001b[0m       0.9387        \u001b[35m4.1123\u001b[0m  1.8148\n",
      "     33        \u001b[36m4.0415\u001b[0m       0.9374        \u001b[35m4.1118\u001b[0m  1.8001\n",
      "     34        \u001b[36m4.0413\u001b[0m       0.9381        \u001b[35m4.1109\u001b[0m  1.8019\n",
      "     35        \u001b[36m4.0408\u001b[0m       0.9384        \u001b[35m4.1103\u001b[0m  1.7975\n",
      "     36        \u001b[36m4.0399\u001b[0m       0.9377        \u001b[35m4.1100\u001b[0m  1.8263\n",
      "     37        \u001b[36m4.0396\u001b[0m       0.9381        \u001b[35m4.1096\u001b[0m  1.8223\n",
      "     38        \u001b[36m4.0389\u001b[0m       0.9381        \u001b[35m4.1093\u001b[0m  1.8163\n",
      "     39        \u001b[36m4.0385\u001b[0m       0.9377        \u001b[35m4.1090\u001b[0m  1.8016\n",
      "     40        \u001b[36m4.0384\u001b[0m       0.9371        \u001b[35m4.1087\u001b[0m  1.7968\n",
      "     41        \u001b[36m4.0379\u001b[0m       0.9377        \u001b[35m4.1083\u001b[0m  1.8135\n",
      "     42        \u001b[36m4.0373\u001b[0m       0.9374        4.1084  1.8023\n",
      "     43        \u001b[36m4.0372\u001b[0m       0.9364        4.1084  1.7934\n",
      "     44        \u001b[36m4.0368\u001b[0m       0.9364        \u001b[35m4.1080\u001b[0m  1.8113\n",
      "     45        \u001b[36m4.0367\u001b[0m       0.9364        \u001b[35m4.1075\u001b[0m  1.8288\n",
      "     46        \u001b[36m4.0362\u001b[0m       0.9371        \u001b[35m4.1071\u001b[0m  1.8495\n",
      "     47        4.0363       0.9368        \u001b[35m4.1066\u001b[0m  1.9096\n",
      "     48        \u001b[36m4.0360\u001b[0m       0.9361        \u001b[35m4.1063\u001b[0m  1.9403\n",
      "     49        \u001b[36m4.0357\u001b[0m       0.9364        \u001b[35m4.1063\u001b[0m  1.8958\n",
      "     50        \u001b[36m4.0356\u001b[0m       0.9374        \u001b[35m4.1057\u001b[0m  1.8790\n",
      "     51        \u001b[36m4.0354\u001b[0m       0.9387        \u001b[35m4.1053\u001b[0m  1.8761\n",
      "     52        \u001b[36m4.0350\u001b[0m       0.9371        \u001b[35m4.1051\u001b[0m  1.8573\n",
      "     53        4.0352       \u001b[32m0.9391\u001b[0m        \u001b[35m4.1049\u001b[0m  2.0963\n",
      "     54        \u001b[36m4.0350\u001b[0m       0.9387        \u001b[35m4.1048\u001b[0m  1.8888\n",
      "     55        \u001b[36m4.0347\u001b[0m       0.9377        \u001b[35m4.1045\u001b[0m  1.8067\n",
      "     56        \u001b[36m4.0345\u001b[0m       0.9368        4.1047  1.8229\n",
      "     57        \u001b[36m4.0343\u001b[0m       0.9364        4.1046  1.8154\n",
      "     58        4.0345       0.9377        \u001b[35m4.1042\u001b[0m  1.8130\n",
      "     59        \u001b[36m4.0341\u001b[0m       0.9377        \u001b[35m4.1039\u001b[0m  1.8145\n",
      "     60        \u001b[36m4.0339\u001b[0m       0.9377        \u001b[35m4.1036\u001b[0m  1.8035\n",
      "     61        \u001b[36m4.0339\u001b[0m       0.9377        4.1037  1.8256\n",
      "     62        \u001b[36m4.0336\u001b[0m       0.9384        \u001b[35m4.1034\u001b[0m  1.9207\n",
      "     63        4.0337       0.9384        \u001b[35m4.1032\u001b[0m  6.9032\n",
      "     64        4.0336       0.9381        4.1033  1.9023\n",
      "     65        \u001b[36m4.0333\u001b[0m       0.9384        \u001b[35m4.1029\u001b[0m  1.8319\n",
      "     66        \u001b[36m4.0332\u001b[0m       0.9391        \u001b[35m4.1024\u001b[0m  1.8131\n",
      "     67        \u001b[36m4.0330\u001b[0m       0.9387        \u001b[35m4.1023\u001b[0m  1.8161\n",
      "     68        4.0331       0.9374        4.1025  3.7185\n",
      "     69        4.0331       0.9381        4.1026  250.7708\n",
      "     70        \u001b[36m4.0328\u001b[0m       0.9374        4.1023  2.0427\n",
      "     71        4.0328       0.9374        4.1023  2.2110\n",
      "     72        \u001b[36m4.0328\u001b[0m       0.9377        \u001b[35m4.1021\u001b[0m  1.9160\n",
      "     73        \u001b[36m4.0326\u001b[0m       0.9364        4.1023  1.6951\n",
      "     74        4.0326       0.9364        4.1023  7.6521\n",
      "     75        4.0326       0.9371        4.1023  6.9720\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{151: 0.9851655629139073}\n",
      "Val accuracy\n",
      "{151: 0.9006666666666666}\n",
      "pred time\n",
      "{151: 0.8297371864318848}\n",
      "OOS Val Accuracy\n",
      "{151: 0.12}\n",
      "OOS pred time\n",
      "{151: 0.02385878562927246}\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "hidden_list = [151]\n",
    "for hidden_dim in hidden_list:    \n",
    "    print(lr)\n",
    "    class CLINCModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                input_dim=vocab_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim,\n",
    "                dropout=0.5\n",
    "        ):\n",
    "            super(CLINCModule, self).__init__()\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "            self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = torch.tanh(self.hidden(X))\n",
    "            X = self.dropout(X)\n",
    "            X = F.softmax(self.output(X), dim=-1)\n",
    "            return X\n",
    "   \n",
    "    net = NeuralNetClassifier(\n",
    "    module=CLINCModule,\n",
    "    lr=lr,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    max_epochs=1000,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    callbacks=[EarlyStopping(patience=10)],\n",
    "    )\n",
    "    \n",
    "    net.fit(train_x, train_y)\n",
    "    tlabels = net.predict(train_x)\n",
    "    tacc[hidden_dim] = accuracy_score(tlabels, train_y)\n",
    "    print('training accuracy')\n",
    "    print(tacc)\n",
    "    time0 = time.time()\n",
    "    labels = net.predict(val_x)\n",
    "    vacc[hidden_dim] = accuracy_score(labels, val_y)\n",
    "    time1 = time.time()\n",
    "    vtime[hidden_dim] = time1-time0\n",
    "    print('Val accuracy')\n",
    "    print(vacc)\n",
    "    print('pred time')\n",
    "    print(vtime)\n",
    "    time2 = time.time()\n",
    "    olabels = net.predict(val_oos_x)\n",
    "    oacc[hidden_dim] = accuracy_score(olabels, val_oos_y)\n",
    "    time3 = time.time()\n",
    "    otime[hidden_dim]=time3-time2\n",
    "    print('OOS Val Accuracy')\n",
    "    print(oacc)\n",
    "    print('OOS pred time')\n",
    "    print(otime)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No. 800 neurons has given best accuracy accuracy at the moment. Can this be improved with different activation functions for the hidden layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0130\u001b[0m       \u001b[32m0.2997\u001b[0m        \u001b[35m4.9847\u001b[0m  6.2996\n",
      "      2        \u001b[36m4.7681\u001b[0m       \u001b[32m0.6013\u001b[0m        \u001b[35m4.5543\u001b[0m  6.2730\n",
      "      3        \u001b[36m4.4382\u001b[0m       \u001b[32m0.7411\u001b[0m        \u001b[35m4.3775\u001b[0m  6.2243\n",
      "      4        \u001b[36m4.3059\u001b[0m       \u001b[32m0.8113\u001b[0m        \u001b[35m4.2919\u001b[0m  6.2451\n",
      "      5        \u001b[36m4.2359\u001b[0m       \u001b[32m0.8305\u001b[0m        \u001b[35m4.2508\u001b[0m  6.2227\n",
      "      6        \u001b[36m4.1975\u001b[0m       \u001b[32m0.8447\u001b[0m        \u001b[35m4.2265\u001b[0m  6.2319\n",
      "      7        \u001b[36m4.1729\u001b[0m       \u001b[32m0.8632\u001b[0m        \u001b[35m4.2091\u001b[0m  6.2383\n",
      "      8        \u001b[36m4.1431\u001b[0m       \u001b[32m0.8987\u001b[0m        \u001b[35m4.1805\u001b[0m  6.1958\n",
      "      9        \u001b[36m4.1115\u001b[0m       \u001b[32m0.9116\u001b[0m        \u001b[35m4.1579\u001b[0m  6.2770\n",
      "     10        \u001b[36m4.0936\u001b[0m       \u001b[32m0.9156\u001b[0m        \u001b[35m4.1471\u001b[0m  6.1687\n",
      "     11        \u001b[36m4.0848\u001b[0m       \u001b[32m0.9166\u001b[0m        \u001b[35m4.1420\u001b[0m  6.2382\n",
      "     12        \u001b[36m4.0799\u001b[0m       0.9162        \u001b[35m4.1392\u001b[0m  6.2232\n",
      "     13        \u001b[36m4.0758\u001b[0m       \u001b[32m0.9192\u001b[0m        \u001b[35m4.1377\u001b[0m  6.2241\n",
      "     14        \u001b[36m4.0685\u001b[0m       \u001b[32m0.9242\u001b[0m        \u001b[35m4.1334\u001b[0m  6.1465\n",
      "     15        \u001b[36m4.0594\u001b[0m       \u001b[32m0.9308\u001b[0m        \u001b[35m4.1262\u001b[0m  6.1324\n",
      "     16        \u001b[36m4.0530\u001b[0m       \u001b[32m0.9338\u001b[0m        \u001b[35m4.1215\u001b[0m  6.1196\n",
      "     17        \u001b[36m4.0488\u001b[0m       0.9328        \u001b[35m4.1191\u001b[0m  6.1269\n",
      "     18        \u001b[36m4.0468\u001b[0m       \u001b[32m0.9364\u001b[0m        \u001b[35m4.1158\u001b[0m  6.1024\n",
      "     19        \u001b[36m4.0453\u001b[0m       \u001b[32m0.9368\u001b[0m        \u001b[35m4.1140\u001b[0m  6.1039\n",
      "     20        \u001b[36m4.0443\u001b[0m       \u001b[32m0.9391\u001b[0m        \u001b[35m4.1126\u001b[0m  6.1608\n",
      "     21        \u001b[36m4.0431\u001b[0m       0.9384        \u001b[35m4.1118\u001b[0m  6.1463\n",
      "     22        \u001b[36m4.0426\u001b[0m       \u001b[32m0.9394\u001b[0m        \u001b[35m4.1101\u001b[0m  6.1162\n",
      "     23        \u001b[36m4.0417\u001b[0m       0.9361        \u001b[35m4.1097\u001b[0m  6.1605\n",
      "     24        \u001b[36m4.0412\u001b[0m       0.9387        \u001b[35m4.1083\u001b[0m  6.1595\n",
      "     25        \u001b[36m4.0408\u001b[0m       0.9384        \u001b[35m4.1076\u001b[0m  6.1247\n",
      "     26        \u001b[36m4.0407\u001b[0m       0.9381        \u001b[35m4.1075\u001b[0m  6.1424\n",
      "     27        \u001b[36m4.0385\u001b[0m       \u001b[32m0.9434\u001b[0m        \u001b[35m4.1059\u001b[0m  6.1339\n",
      "     28        \u001b[36m4.0364\u001b[0m       0.9411        4.1064  6.1230\n",
      "     29        \u001b[36m4.0354\u001b[0m       0.9411        \u001b[35m4.1053\u001b[0m  6.1617\n",
      "     30        \u001b[36m4.0348\u001b[0m       0.9401        4.1055  6.1321\n",
      "     31        \u001b[36m4.0343\u001b[0m       0.9411        \u001b[35m4.1039\u001b[0m  6.1454\n",
      "     32        \u001b[36m4.0338\u001b[0m       0.9401        \u001b[35m4.1034\u001b[0m  6.1303\n",
      "     33        \u001b[36m4.0336\u001b[0m       0.9424        \u001b[35m4.1021\u001b[0m  6.1182\n",
      "     34        \u001b[36m4.0332\u001b[0m       0.9417        \u001b[35m4.1018\u001b[0m  6.2036\n",
      "     35        \u001b[36m4.0330\u001b[0m       0.9411        \u001b[35m4.1016\u001b[0m  6.1689\n",
      "     36        \u001b[36m4.0328\u001b[0m       0.9411        4.1017  6.1474\n",
      "     37        \u001b[36m4.0326\u001b[0m       0.9417        \u001b[35m4.1007\u001b[0m  6.2133\n",
      "     38        \u001b[36m4.0325\u001b[0m       0.9424        \u001b[35m4.1000\u001b[0m  6.1662\n",
      "     39        \u001b[36m4.0321\u001b[0m       0.9407        4.1003  6.1380\n",
      "     40        4.0322       0.9414        \u001b[35m4.0999\u001b[0m  6.1431\n",
      "     41        \u001b[36m4.0320\u001b[0m       0.9411        \u001b[35m4.0993\u001b[0m  6.1419\n",
      "     42        4.0321       0.9414        \u001b[35m4.0991\u001b[0m  6.1208\n",
      "     43        \u001b[36m4.0319\u001b[0m       0.9434        \u001b[35m4.0988\u001b[0m  6.1206\n",
      "     44        \u001b[36m4.0318\u001b[0m       0.9427        \u001b[35m4.0977\u001b[0m  6.1330\n",
      "     45        \u001b[36m4.0317\u001b[0m       0.9414        4.0978  6.1281\n",
      "     46        \u001b[36m4.0315\u001b[0m       0.9430        4.0978  6.3312\n",
      "     47        4.0318       0.9421        4.0981  6.2142\n",
      "     48        \u001b[36m4.0315\u001b[0m       0.9417        4.0978  6.4022\n",
      "     49        \u001b[36m4.0315\u001b[0m       0.9434        \u001b[35m4.0971\u001b[0m  6.1830\n",
      "     50        \u001b[36m4.0315\u001b[0m       \u001b[32m0.9444\u001b[0m        \u001b[35m4.0958\u001b[0m  6.1584\n",
      "     51        4.0316       \u001b[32m0.9450\u001b[0m        \u001b[35m4.0958\u001b[0m  6.1691\n",
      "     52        \u001b[36m4.0314\u001b[0m       0.9417        4.0966  6.2689\n",
      "     53        4.0315       0.9437        4.0961  6.2215\n",
      "     54        \u001b[36m4.0314\u001b[0m       0.9437        4.0962  6.2179\n",
      "     55        4.0314       0.9450        \u001b[35m4.0946\u001b[0m  6.2264\n",
      "     56        \u001b[36m4.0313\u001b[0m       0.9440        4.0950  6.2887\n",
      "     57        \u001b[36m4.0313\u001b[0m       0.9440        4.0948  6.2086\n",
      "     58        \u001b[36m4.0312\u001b[0m       0.9434        4.0955  6.2469\n",
      "     59        4.0312       0.9437        4.0949  6.2535\n",
      "     60        \u001b[36m4.0311\u001b[0m       0.9434        4.0951  6.2539\n",
      "     61        \u001b[36m4.0311\u001b[0m       0.9447        \u001b[35m4.0941\u001b[0m  6.2206\n",
      "     62        4.0312       0.9414        4.0950  6.1947\n",
      "     63        4.0312       0.9437        4.0941  6.1783\n",
      "     64        4.0311       0.9437        4.0946  6.2525\n",
      "     65        \u001b[36m4.0310\u001b[0m       0.9417        4.0949  6.1987\n",
      "     66        4.0311       0.9440        \u001b[35m4.0934\u001b[0m  6.2506\n",
      "     67        \u001b[36m4.0310\u001b[0m       0.9421        4.0946  6.3936\n",
      "     68        4.0311       0.9421        4.0941  6.2799\n",
      "     69        4.0311       0.9421        4.0938  6.2575\n",
      "     70        \u001b[36m4.0310\u001b[0m       0.9437        \u001b[35m4.0931\u001b[0m  6.2304\n",
      "     71        4.0312       0.9437        \u001b[35m4.0930\u001b[0m  6.2287\n",
      "     72        \u001b[36m4.0309\u001b[0m       0.9437        4.0937  6.1479\n",
      "     73        \u001b[36m4.0309\u001b[0m       0.9430        4.0934  6.1393\n",
      "     74        4.0309       0.9411        4.0942  6.1804\n",
      "     75        \u001b[36m4.0308\u001b[0m       0.9444        \u001b[35m4.0927\u001b[0m  6.1531\n",
      "     76        \u001b[36m4.0306\u001b[0m       0.9440        4.0930  6.1535\n",
      "     77        \u001b[36m4.0306\u001b[0m       0.9434        4.0933  6.1519\n",
      "     78        4.0306       0.9421        4.0936  6.1501\n",
      "     79        4.0306       0.9417        4.0944  6.2064\n",
      "     80        4.0306       0.9421        4.0935  6.1860\n",
      "     81        \u001b[36m4.0306\u001b[0m       0.9437        4.0929  6.2740\n",
      "     82        \u001b[36m4.0306\u001b[0m       0.9434        4.0932  6.2599\n",
      "     83        \u001b[36m4.0305\u001b[0m       0.9421        4.0934  6.2305\n",
      "     84        4.0306       0.9430        4.0936  6.2670\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{800: 0.9870198675496689}\n",
      "Val accuracy\n",
      "{800: 0.9046666666666666}\n",
      "pred time\n",
      "{800: 0.3731682300567627}\n",
      "OOS Val Accuracy\n",
      "{800: 0.23}\n",
      "OOS pred time\n",
      "{800: 0.012464046478271484}\n",
      "ReLU\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "hidden_dim = 800\n",
    "class CLINCModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim=vocab_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_dim=output_dim,\n",
    "            dropout=0.5\n",
    "    ):\n",
    "        super(CLINCModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = F.relu(self.hidden(X)) #ReLU activation function for hidden layer\n",
    "        X = self.dropout(X)\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "module=CLINCModule,\n",
    "lr=lr,\n",
    "criterion=torch.nn.CrossEntropyLoss,\n",
    "max_epochs=1000,\n",
    "optimizer=torch.optim.Adam,\n",
    "callbacks=[EarlyStopping(patience=10)],\n",
    ")\n",
    "\n",
    "net.fit(train_x, train_y)\n",
    "tlabels = net.predict(train_x)\n",
    "tacc[hidden_dim] = accuracy_score(tlabels, train_y)\n",
    "print('training accuracy')\n",
    "print(tacc)\n",
    "time0 = time.time()\n",
    "labels = net.predict(val_x)\n",
    "vacc[hidden_dim] = accuracy_score(labels, val_y)\n",
    "time1 = time.time()\n",
    "vtime[hidden_dim] = time1-time0\n",
    "print('Val accuracy')\n",
    "print(vacc)\n",
    "print('pred time')\n",
    "print(vtime)\n",
    "time2 = time.time()\n",
    "olabels = net.predict(val_oos_x)\n",
    "oacc[hidden_dim] = accuracy_score(olabels, val_oos_y)\n",
    "time3 = time.time()\n",
    "otime[hidden_dim]=time3-time2\n",
    "print('OOS Val Accuracy')\n",
    "print(oacc)\n",
    "print('OOS pred time')\n",
    "print(otime)\n",
    "print('ReLU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slight improvement with ReLU (0.3%). Will attempt other functions to see whether they outperform ReLU, otherwise keep. Sigmoid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ollie/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0180\u001b[0m       \u001b[32m0.0066\u001b[0m        \u001b[35m5.0166\u001b[0m  6.3491\n",
      "      2        \u001b[36m5.0165\u001b[0m       \u001b[32m0.0232\u001b[0m        \u001b[35m5.0146\u001b[0m  6.3888\n",
      "      3        \u001b[36m5.0135\u001b[0m       \u001b[32m0.0344\u001b[0m        \u001b[35m5.0097\u001b[0m  6.4449\n",
      "      4        \u001b[36m5.0064\u001b[0m       \u001b[32m0.0576\u001b[0m        \u001b[35m4.9979\u001b[0m  6.3237\n",
      "      5        \u001b[36m4.9930\u001b[0m       \u001b[32m0.0679\u001b[0m        \u001b[35m4.9813\u001b[0m  6.2590\n",
      "      6        \u001b[36m4.9763\u001b[0m       \u001b[32m0.0772\u001b[0m        \u001b[35m4.9647\u001b[0m  6.3531\n",
      "      7        \u001b[36m4.9621\u001b[0m       0.0768        \u001b[35m4.9568\u001b[0m  6.2890\n",
      "      8        \u001b[36m4.9560\u001b[0m       \u001b[32m0.0778\u001b[0m        \u001b[35m4.9533\u001b[0m  6.2982\n",
      "      9        \u001b[36m4.9528\u001b[0m       \u001b[32m0.0808\u001b[0m        \u001b[35m4.9503\u001b[0m  6.2021\n",
      "     10        \u001b[36m4.9486\u001b[0m       \u001b[32m0.0874\u001b[0m        \u001b[35m4.9457\u001b[0m  6.3159\n",
      "     11        \u001b[36m4.9428\u001b[0m       \u001b[32m0.0954\u001b[0m        \u001b[35m4.9393\u001b[0m  6.2446\n",
      "     12        \u001b[36m4.9365\u001b[0m       \u001b[32m0.1036\u001b[0m        \u001b[35m4.9321\u001b[0m  6.2184\n",
      "     13        \u001b[36m4.9292\u001b[0m       \u001b[32m0.1175\u001b[0m        \u001b[35m4.9257\u001b[0m  6.2237\n",
      "     14        \u001b[36m4.9233\u001b[0m       \u001b[32m0.1252\u001b[0m        \u001b[35m4.9166\u001b[0m  6.2313\n",
      "     15        \u001b[36m4.9119\u001b[0m       \u001b[32m0.1358\u001b[0m        \u001b[35m4.9038\u001b[0m  6.2675\n",
      "     16        \u001b[36m4.9017\u001b[0m       \u001b[32m0.1364\u001b[0m        \u001b[35m4.8975\u001b[0m  6.1742\n",
      "     17        \u001b[36m4.8972\u001b[0m       \u001b[32m0.1368\u001b[0m        \u001b[35m4.8950\u001b[0m  6.2737\n",
      "     18        \u001b[36m4.8937\u001b[0m       \u001b[32m0.1384\u001b[0m        \u001b[35m4.8926\u001b[0m  6.2983\n",
      "     19        \u001b[36m4.8906\u001b[0m       \u001b[32m0.1430\u001b[0m        \u001b[35m4.8885\u001b[0m  6.2231\n",
      "     20        \u001b[36m4.8872\u001b[0m       \u001b[32m0.1487\u001b[0m        \u001b[35m4.8859\u001b[0m  6.2485\n",
      "     21        \u001b[36m4.8838\u001b[0m       \u001b[32m0.1490\u001b[0m        \u001b[35m4.8833\u001b[0m  6.2958\n",
      "     22        \u001b[36m4.8808\u001b[0m       \u001b[32m0.1573\u001b[0m        \u001b[35m4.8796\u001b[0m  6.3749\n",
      "     23        \u001b[36m4.8750\u001b[0m       \u001b[32m0.1623\u001b[0m        \u001b[35m4.8738\u001b[0m  6.3052\n",
      "     24        \u001b[36m4.8677\u001b[0m       \u001b[32m0.1775\u001b[0m        \u001b[35m4.8635\u001b[0m  6.3270\n",
      "     25        \u001b[36m4.8598\u001b[0m       0.1768        \u001b[35m4.8583\u001b[0m  6.7853\n",
      "     26        \u001b[36m4.8530\u001b[0m       \u001b[32m0.1821\u001b[0m        \u001b[35m4.8517\u001b[0m  6.6341\n",
      "     27        \u001b[36m4.8481\u001b[0m       \u001b[32m0.1924\u001b[0m        \u001b[35m4.8469\u001b[0m  6.5371\n",
      "     28        \u001b[36m4.8406\u001b[0m       \u001b[32m0.1974\u001b[0m        \u001b[35m4.8405\u001b[0m  6.4996\n",
      "     29        \u001b[36m4.8329\u001b[0m       \u001b[32m0.2076\u001b[0m        \u001b[35m4.8291\u001b[0m  6.4369\n",
      "     30        \u001b[36m4.8251\u001b[0m       \u001b[32m0.2109\u001b[0m        \u001b[35m4.8245\u001b[0m  6.4191\n",
      "     31        \u001b[36m4.8181\u001b[0m       \u001b[32m0.2199\u001b[0m        \u001b[35m4.8176\u001b[0m  6.5277\n",
      "     32        \u001b[36m4.8123\u001b[0m       \u001b[32m0.2281\u001b[0m        \u001b[35m4.8111\u001b[0m  6.6726\n",
      "     33        \u001b[36m4.8068\u001b[0m       0.2275        \u001b[35m4.8066\u001b[0m  6.7050\n",
      "     34        \u001b[36m4.8033\u001b[0m       \u001b[32m0.2341\u001b[0m        \u001b[35m4.8034\u001b[0m  6.5974\n",
      "     35        \u001b[36m4.7984\u001b[0m       \u001b[32m0.2394\u001b[0m        \u001b[35m4.7973\u001b[0m  6.6528\n",
      "     36        \u001b[36m4.7930\u001b[0m       0.2391        \u001b[35m4.7939\u001b[0m  6.5318\n",
      "     37        \u001b[36m4.7889\u001b[0m       0.2391        \u001b[35m4.7916\u001b[0m  6.3600\n",
      "     38        \u001b[36m4.7852\u001b[0m       \u001b[32m0.2474\u001b[0m        \u001b[35m4.7870\u001b[0m  6.2210\n",
      "     39        \u001b[36m4.7803\u001b[0m       \u001b[32m0.2533\u001b[0m        \u001b[35m4.7815\u001b[0m  6.2102\n",
      "     40        \u001b[36m4.7741\u001b[0m       \u001b[32m0.2685\u001b[0m        \u001b[35m4.7754\u001b[0m  6.1914\n",
      "     41        \u001b[36m4.7670\u001b[0m       \u001b[32m0.2689\u001b[0m        \u001b[35m4.7692\u001b[0m  6.1983\n",
      "     42        \u001b[36m4.7605\u001b[0m       \u001b[32m0.2719\u001b[0m        \u001b[35m4.7643\u001b[0m  6.2198\n",
      "     43        \u001b[36m4.7568\u001b[0m       \u001b[32m0.2768\u001b[0m        \u001b[35m4.7614\u001b[0m  6.1965\n",
      "     44        \u001b[36m4.7514\u001b[0m       \u001b[32m0.2871\u001b[0m        \u001b[35m4.7563\u001b[0m  6.2316\n",
      "     45        \u001b[36m4.7456\u001b[0m       \u001b[32m0.2950\u001b[0m        \u001b[35m4.7498\u001b[0m  6.2009\n",
      "     46        \u001b[36m4.7373\u001b[0m       \u001b[32m0.2957\u001b[0m        \u001b[35m4.7434\u001b[0m  6.2584\n",
      "     47        \u001b[36m4.7329\u001b[0m       \u001b[32m0.3033\u001b[0m        \u001b[35m4.7385\u001b[0m  6.5611\n",
      "     48        \u001b[36m4.7295\u001b[0m       \u001b[32m0.3053\u001b[0m        \u001b[35m4.7335\u001b[0m  6.5807\n",
      "     49        \u001b[36m4.7227\u001b[0m       \u001b[32m0.3159\u001b[0m        \u001b[35m4.7285\u001b[0m  6.3803\n",
      "     50        \u001b[36m4.7128\u001b[0m       \u001b[32m0.3291\u001b[0m        \u001b[35m4.7164\u001b[0m  6.4650\n",
      "     51        \u001b[36m4.7036\u001b[0m       \u001b[32m0.3391\u001b[0m        \u001b[35m4.7063\u001b[0m  6.5208\n",
      "     52        \u001b[36m4.6949\u001b[0m       \u001b[32m0.3424\u001b[0m        \u001b[35m4.6984\u001b[0m  6.5329\n",
      "     53        \u001b[36m4.6893\u001b[0m       0.3397        4.7011  6.5360\n",
      "     54        \u001b[36m4.6868\u001b[0m       \u001b[32m0.3477\u001b[0m        \u001b[35m4.6917\u001b[0m  6.5511\n",
      "     55        \u001b[36m4.6827\u001b[0m       \u001b[32m0.3543\u001b[0m        \u001b[35m4.6874\u001b[0m  6.5456\n",
      "     56        \u001b[36m4.6768\u001b[0m       \u001b[32m0.3563\u001b[0m        \u001b[35m4.6811\u001b[0m  6.6440\n",
      "     57        \u001b[36m4.6731\u001b[0m       \u001b[32m0.3579\u001b[0m        \u001b[35m4.6781\u001b[0m  6.5648\n",
      "     58        \u001b[36m4.6693\u001b[0m       \u001b[32m0.3626\u001b[0m        \u001b[35m4.6749\u001b[0m  6.6072\n",
      "     59        \u001b[36m4.6637\u001b[0m       \u001b[32m0.3679\u001b[0m        \u001b[35m4.6695\u001b[0m  6.5954\n",
      "     60        \u001b[36m4.6607\u001b[0m       \u001b[32m0.3685\u001b[0m        \u001b[35m4.6665\u001b[0m  6.5784\n",
      "     61        \u001b[36m4.6572\u001b[0m       \u001b[32m0.3695\u001b[0m        4.6672  6.5479\n",
      "     62        \u001b[36m4.6524\u001b[0m       \u001b[32m0.3868\u001b[0m        \u001b[35m4.6589\u001b[0m  6.5562\n",
      "     63        \u001b[36m4.6429\u001b[0m       \u001b[32m0.3921\u001b[0m        \u001b[35m4.6510\u001b[0m  6.5693\n",
      "     64        \u001b[36m4.6366\u001b[0m       \u001b[32m0.3964\u001b[0m        \u001b[35m4.6441\u001b[0m  6.5635\n",
      "     65        \u001b[36m4.6305\u001b[0m       \u001b[32m0.3987\u001b[0m        \u001b[35m4.6404\u001b[0m  6.5365\n",
      "     66        \u001b[36m4.6279\u001b[0m       \u001b[32m0.4020\u001b[0m        \u001b[35m4.6367\u001b[0m  6.5887\n",
      "     67        \u001b[36m4.6219\u001b[0m       \u001b[32m0.4119\u001b[0m        \u001b[35m4.6297\u001b[0m  6.4824\n",
      "     68        \u001b[36m4.6158\u001b[0m       \u001b[32m0.4162\u001b[0m        \u001b[35m4.6256\u001b[0m  6.2057\n",
      "     69        \u001b[36m4.6120\u001b[0m       0.4156        \u001b[35m4.6230\u001b[0m  6.2480\n",
      "     70        \u001b[36m4.6081\u001b[0m       \u001b[32m0.4172\u001b[0m        \u001b[35m4.6199\u001b[0m  6.2440\n",
      "     71        \u001b[36m4.6056\u001b[0m       \u001b[32m0.4219\u001b[0m        \u001b[35m4.6163\u001b[0m  6.2315\n",
      "     72        \u001b[36m4.6019\u001b[0m       \u001b[32m0.4305\u001b[0m        \u001b[35m4.6119\u001b[0m  6.1713\n",
      "     73        \u001b[36m4.5978\u001b[0m       \u001b[32m0.4308\u001b[0m        \u001b[35m4.6080\u001b[0m  6.0472\n",
      "     74        \u001b[36m4.5933\u001b[0m       \u001b[32m0.4328\u001b[0m        \u001b[35m4.6055\u001b[0m  6.1829\n",
      "     75        \u001b[36m4.5912\u001b[0m       \u001b[32m0.4401\u001b[0m        \u001b[35m4.6017\u001b[0m  6.2120\n",
      "     76        \u001b[36m4.5856\u001b[0m       \u001b[32m0.4447\u001b[0m        \u001b[35m4.5961\u001b[0m  6.4773\n",
      "     77        \u001b[36m4.5817\u001b[0m       \u001b[32m0.4460\u001b[0m        \u001b[35m4.5930\u001b[0m  6.2720\n",
      "     78        \u001b[36m4.5788\u001b[0m       0.4460        4.5945  6.3177\n",
      "     79        \u001b[36m4.5751\u001b[0m       \u001b[32m0.4550\u001b[0m        \u001b[35m4.5862\u001b[0m  6.4223\n",
      "     80        \u001b[36m4.5687\u001b[0m       0.4533        \u001b[35m4.5837\u001b[0m  6.7299\n",
      "     81        \u001b[36m4.5654\u001b[0m       \u001b[32m0.4609\u001b[0m        \u001b[35m4.5794\u001b[0m  6.3715\n",
      "     82        \u001b[36m4.5608\u001b[0m       \u001b[32m0.4662\u001b[0m        \u001b[35m4.5743\u001b[0m  6.2775\n",
      "     83        \u001b[36m4.5553\u001b[0m       \u001b[32m0.4732\u001b[0m        \u001b[35m4.5694\u001b[0m  6.5413\n",
      "     84        \u001b[36m4.5499\u001b[0m       \u001b[32m0.4788\u001b[0m        \u001b[35m4.5639\u001b[0m  6.2084\n",
      "     85        \u001b[36m4.5444\u001b[0m       \u001b[32m0.4798\u001b[0m        \u001b[35m4.5591\u001b[0m  6.2536\n",
      "     86        \u001b[36m4.5419\u001b[0m       \u001b[32m0.4811\u001b[0m        \u001b[35m4.5575\u001b[0m  6.2104\n",
      "     87        \u001b[36m4.5400\u001b[0m       \u001b[32m0.4821\u001b[0m        \u001b[35m4.5567\u001b[0m  6.1976\n",
      "     88        \u001b[36m4.5376\u001b[0m       0.4811        \u001b[35m4.5566\u001b[0m  6.4277\n",
      "     89        \u001b[36m4.5352\u001b[0m       \u001b[32m0.4831\u001b[0m        \u001b[35m4.5540\u001b[0m  6.3838\n",
      "     90        \u001b[36m4.5328\u001b[0m       \u001b[32m0.4854\u001b[0m        \u001b[35m4.5503\u001b[0m  6.3790\n",
      "     91        \u001b[36m4.5301\u001b[0m       \u001b[32m0.4911\u001b[0m        \u001b[35m4.5477\u001b[0m  6.6476\n",
      "     92        \u001b[36m4.5269\u001b[0m       \u001b[32m0.4917\u001b[0m        \u001b[35m4.5459\u001b[0m  6.5188\n",
      "     93        \u001b[36m4.5244\u001b[0m       \u001b[32m0.4997\u001b[0m        \u001b[35m4.5408\u001b[0m  6.3621\n",
      "     94        \u001b[36m4.5192\u001b[0m       \u001b[32m0.5116\u001b[0m        \u001b[35m4.5339\u001b[0m  6.2608\n",
      "     95        \u001b[36m4.5124\u001b[0m       0.5096        \u001b[35m4.5310\u001b[0m  6.2551\n",
      "     96        \u001b[36m4.5086\u001b[0m       0.5113        \u001b[35m4.5259\u001b[0m  6.2453\n",
      "     97        \u001b[36m4.5060\u001b[0m       \u001b[32m0.5149\u001b[0m        \u001b[35m4.5235\u001b[0m  6.2325\n",
      "     98        \u001b[36m4.4985\u001b[0m       \u001b[32m0.5308\u001b[0m        \u001b[35m4.5139\u001b[0m  6.1816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     99        \u001b[36m4.4890\u001b[0m       \u001b[32m0.5397\u001b[0m        \u001b[35m4.5048\u001b[0m  6.1875\n",
      "    100        \u001b[36m4.4811\u001b[0m       \u001b[32m0.5430\u001b[0m        \u001b[35m4.4979\u001b[0m  6.1579\n",
      "    101        \u001b[36m4.4782\u001b[0m       \u001b[32m0.5440\u001b[0m        \u001b[35m4.4963\u001b[0m  6.2313\n",
      "    102        \u001b[36m4.4745\u001b[0m       \u001b[32m0.5450\u001b[0m        \u001b[35m4.4946\u001b[0m  6.2708\n",
      "    103        \u001b[36m4.4709\u001b[0m       \u001b[32m0.5536\u001b[0m        \u001b[35m4.4893\u001b[0m  6.1081\n",
      "    104        \u001b[36m4.4665\u001b[0m       0.5490        4.4894  6.2632\n",
      "    105        \u001b[36m4.4626\u001b[0m       \u001b[32m0.5570\u001b[0m        \u001b[35m4.4842\u001b[0m  6.3135\n",
      "    106        \u001b[36m4.4574\u001b[0m       \u001b[32m0.5649\u001b[0m        \u001b[35m4.4805\u001b[0m  6.5914\n",
      "    107        \u001b[36m4.4534\u001b[0m       \u001b[32m0.5679\u001b[0m        \u001b[35m4.4777\u001b[0m  6.9639\n",
      "    108        \u001b[36m4.4498\u001b[0m       \u001b[32m0.5712\u001b[0m        \u001b[35m4.4723\u001b[0m  6.9868\n",
      "    109        \u001b[36m4.4454\u001b[0m       \u001b[32m0.5758\u001b[0m        \u001b[35m4.4709\u001b[0m  6.9394\n",
      "    110        \u001b[36m4.4409\u001b[0m       \u001b[32m0.5772\u001b[0m        \u001b[35m4.4665\u001b[0m  7.0651\n",
      "    111        \u001b[36m4.4377\u001b[0m       \u001b[32m0.5785\u001b[0m        \u001b[35m4.4619\u001b[0m  7.1449\n",
      "    112        \u001b[36m4.4352\u001b[0m       \u001b[32m0.5805\u001b[0m        \u001b[35m4.4593\u001b[0m  7.1906\n",
      "    113        \u001b[36m4.4343\u001b[0m       \u001b[32m0.5821\u001b[0m        \u001b[35m4.4581\u001b[0m  6.4159\n",
      "    114        \u001b[36m4.4327\u001b[0m       \u001b[32m0.5841\u001b[0m        \u001b[35m4.4569\u001b[0m  6.2426\n",
      "    115        \u001b[36m4.4297\u001b[0m       \u001b[32m0.5874\u001b[0m        \u001b[35m4.4524\u001b[0m  6.2408\n",
      "    116        \u001b[36m4.4276\u001b[0m       0.5851        4.4537  6.2298\n",
      "    117        \u001b[36m4.4237\u001b[0m       \u001b[32m0.5927\u001b[0m        \u001b[35m4.4466\u001b[0m  6.2208\n",
      "    118        \u001b[36m4.4203\u001b[0m       0.5901        \u001b[35m4.4462\u001b[0m  6.2251\n",
      "    119        \u001b[36m4.4167\u001b[0m       \u001b[32m0.6023\u001b[0m        \u001b[35m4.4400\u001b[0m  6.2307\n",
      "    120        \u001b[36m4.4096\u001b[0m       \u001b[32m0.6116\u001b[0m        \u001b[35m4.4336\u001b[0m  6.2333\n",
      "    121        \u001b[36m4.4038\u001b[0m       \u001b[32m0.6142\u001b[0m        \u001b[35m4.4284\u001b[0m  6.2520\n",
      "    122        \u001b[36m4.3998\u001b[0m       \u001b[32m0.6162\u001b[0m        \u001b[35m4.4266\u001b[0m  6.2149\n",
      "    123        \u001b[36m4.3938\u001b[0m       \u001b[32m0.6215\u001b[0m        \u001b[35m4.4224\u001b[0m  6.2191\n",
      "    124        \u001b[36m4.3894\u001b[0m       \u001b[32m0.6295\u001b[0m        \u001b[35m4.4152\u001b[0m  6.2600\n",
      "    125        \u001b[36m4.3859\u001b[0m       \u001b[32m0.6325\u001b[0m        \u001b[35m4.4130\u001b[0m  6.2208\n",
      "    126        \u001b[36m4.3766\u001b[0m       \u001b[32m0.6387\u001b[0m        \u001b[35m4.4037\u001b[0m  6.2323\n",
      "    127        \u001b[36m4.3724\u001b[0m       \u001b[32m0.6434\u001b[0m        \u001b[35m4.3998\u001b[0m  6.2431\n",
      "    128        \u001b[36m4.3696\u001b[0m       \u001b[32m0.6474\u001b[0m        \u001b[35m4.3963\u001b[0m  6.2288\n",
      "    129        \u001b[36m4.3648\u001b[0m       \u001b[32m0.6536\u001b[0m        \u001b[35m4.3891\u001b[0m  6.2323\n",
      "    130        \u001b[36m4.3602\u001b[0m       \u001b[32m0.6553\u001b[0m        \u001b[35m4.3865\u001b[0m  6.2751\n",
      "    131        \u001b[36m4.3568\u001b[0m       0.6550        \u001b[35m4.3853\u001b[0m  6.3887\n",
      "    132        \u001b[36m4.3559\u001b[0m       \u001b[32m0.6576\u001b[0m        \u001b[35m4.3825\u001b[0m  6.1777\n",
      "    133        \u001b[36m4.3547\u001b[0m       0.6573        \u001b[35m4.3819\u001b[0m  6.3112\n",
      "    134        \u001b[36m4.3540\u001b[0m       \u001b[32m0.6589\u001b[0m        4.3823  6.3102\n",
      "    135        \u001b[36m4.3511\u001b[0m       0.6576        \u001b[35m4.3815\u001b[0m  6.3131\n",
      "    136        \u001b[36m4.3487\u001b[0m       \u001b[32m0.6593\u001b[0m        4.3817  6.3095\n",
      "    137        \u001b[36m4.3469\u001b[0m       \u001b[32m0.6599\u001b[0m        \u001b[35m4.3788\u001b[0m  6.2922\n",
      "    138        \u001b[36m4.3462\u001b[0m       \u001b[32m0.6626\u001b[0m        \u001b[35m4.3752\u001b[0m  6.2526\n",
      "    139        \u001b[36m4.3444\u001b[0m       \u001b[32m0.6656\u001b[0m        4.3752  6.3579\n",
      "    140        \u001b[36m4.3429\u001b[0m       0.6626        \u001b[35m4.3752\u001b[0m  6.4180\n",
      "    141        \u001b[36m4.3395\u001b[0m       \u001b[32m0.6675\u001b[0m        \u001b[35m4.3731\u001b[0m  6.5377\n",
      "    142        \u001b[36m4.3374\u001b[0m       \u001b[32m0.6722\u001b[0m        \u001b[35m4.3685\u001b[0m  6.3603\n",
      "    143        \u001b[36m4.3356\u001b[0m       0.6705        4.3686  6.3276\n",
      "    144        \u001b[36m4.3336\u001b[0m       \u001b[32m0.6728\u001b[0m        \u001b[35m4.3679\u001b[0m  6.2680\n",
      "    145        \u001b[36m4.3304\u001b[0m       \u001b[32m0.6785\u001b[0m        \u001b[35m4.3622\u001b[0m  6.3005\n",
      "    146        \u001b[36m4.3283\u001b[0m       \u001b[32m0.6798\u001b[0m        \u001b[35m4.3598\u001b[0m  6.2885\n",
      "    147        \u001b[36m4.3274\u001b[0m       0.6795        4.3599  6.3197\n",
      "    148        \u001b[36m4.3261\u001b[0m       \u001b[32m0.6811\u001b[0m        \u001b[35m4.3567\u001b[0m  6.3557\n",
      "    149        \u001b[36m4.3261\u001b[0m       \u001b[32m0.6815\u001b[0m        4.3572  6.4290\n",
      "    150        \u001b[36m4.3238\u001b[0m       \u001b[32m0.6854\u001b[0m        \u001b[35m4.3556\u001b[0m  6.3141\n",
      "    151        \u001b[36m4.3210\u001b[0m       0.6841        \u001b[35m4.3542\u001b[0m  6.3738\n",
      "    152        \u001b[36m4.3199\u001b[0m       \u001b[32m0.6901\u001b[0m        \u001b[35m4.3493\u001b[0m  6.3234\n",
      "    153        \u001b[36m4.3166\u001b[0m       \u001b[32m0.6917\u001b[0m        \u001b[35m4.3464\u001b[0m  6.4233\n",
      "    154        \u001b[36m4.3143\u001b[0m       \u001b[32m0.6930\u001b[0m        \u001b[35m4.3455\u001b[0m  6.4439\n",
      "    155        \u001b[36m4.3130\u001b[0m       0.6914        4.3459  6.5338\n",
      "    156        \u001b[36m4.3100\u001b[0m       \u001b[32m0.6947\u001b[0m        \u001b[35m4.3450\u001b[0m  6.3416\n",
      "    157        \u001b[36m4.3086\u001b[0m       0.6937        \u001b[35m4.3436\u001b[0m  6.2808\n",
      "    158        \u001b[36m4.3072\u001b[0m       0.6947        4.3438  6.3689\n",
      "    159        \u001b[36m4.3061\u001b[0m       \u001b[32m0.6950\u001b[0m        \u001b[35m4.3427\u001b[0m  6.3998\n",
      "    160        \u001b[36m4.3058\u001b[0m       \u001b[32m0.6970\u001b[0m        \u001b[35m4.3408\u001b[0m  6.5226\n",
      "    161        \u001b[36m4.3055\u001b[0m       \u001b[32m0.6987\u001b[0m        \u001b[35m4.3387\u001b[0m  6.3667\n",
      "    162        \u001b[36m4.3046\u001b[0m       0.6970        4.3399  6.4467\n",
      "    163        \u001b[36m4.3023\u001b[0m       0.6983        \u001b[35m4.3385\u001b[0m  6.3274\n",
      "    164        \u001b[36m4.2998\u001b[0m       \u001b[32m0.7040\u001b[0m        \u001b[35m4.3340\u001b[0m  6.3975\n",
      "    165        \u001b[36m4.2986\u001b[0m       \u001b[32m0.7043\u001b[0m        4.3354  6.3519\n",
      "    166        \u001b[36m4.2949\u001b[0m       \u001b[32m0.7079\u001b[0m        \u001b[35m4.3313\u001b[0m  6.4344\n",
      "    167        \u001b[36m4.2937\u001b[0m       0.7050        4.3325  6.3139\n",
      "    168        \u001b[36m4.2924\u001b[0m       \u001b[32m0.7093\u001b[0m        \u001b[35m4.3276\u001b[0m  6.3376\n",
      "    169        \u001b[36m4.2916\u001b[0m       \u001b[32m0.7099\u001b[0m        \u001b[35m4.3272\u001b[0m  6.4612\n",
      "    170        4.2919       0.7099        \u001b[35m4.3260\u001b[0m  6.2902\n",
      "    171        \u001b[36m4.2915\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m4.3241\u001b[0m  6.2594\n",
      "    172        \u001b[36m4.2880\u001b[0m       \u001b[32m0.7159\u001b[0m        \u001b[35m4.3220\u001b[0m  6.3195\n",
      "    173        \u001b[36m4.2855\u001b[0m       0.7152        \u001b[35m4.3214\u001b[0m  6.3586\n",
      "    174        \u001b[36m4.2845\u001b[0m       0.7146        4.3216  6.3688\n",
      "    175        \u001b[36m4.2843\u001b[0m       0.7129        4.3222  6.3377\n",
      "    176        \u001b[36m4.2828\u001b[0m       0.7109        4.3264  6.4019\n",
      "    177        \u001b[36m4.2780\u001b[0m       \u001b[32m0.7219\u001b[0m        \u001b[35m4.3179\u001b[0m  6.4109\n",
      "    178        \u001b[36m4.2714\u001b[0m       \u001b[32m0.7255\u001b[0m        \u001b[35m4.3136\u001b[0m  6.3908\n",
      "    179        \u001b[36m4.2655\u001b[0m       \u001b[32m0.7321\u001b[0m        \u001b[35m4.3094\u001b[0m  6.3999\n",
      "    180        \u001b[36m4.2604\u001b[0m       \u001b[32m0.7407\u001b[0m        \u001b[35m4.3025\u001b[0m  6.3524\n",
      "    181        \u001b[36m4.2579\u001b[0m       0.7404        \u001b[35m4.3001\u001b[0m  6.3332\n",
      "    182        \u001b[36m4.2558\u001b[0m       \u001b[32m0.7437\u001b[0m        \u001b[35m4.2975\u001b[0m  6.3219\n",
      "    183        \u001b[36m4.2550\u001b[0m       0.7424        \u001b[35m4.2960\u001b[0m  6.2989\n",
      "    184        \u001b[36m4.2538\u001b[0m       0.7434        4.2961  6.3436\n",
      "    185        \u001b[36m4.2530\u001b[0m       \u001b[32m0.7450\u001b[0m        \u001b[35m4.2936\u001b[0m  6.3216\n",
      "    186        \u001b[36m4.2527\u001b[0m       0.7447        4.2938  6.2667\n",
      "    187        \u001b[36m4.2523\u001b[0m       \u001b[32m0.7480\u001b[0m        \u001b[35m4.2915\u001b[0m  6.2424\n",
      "    188        \u001b[36m4.2513\u001b[0m       \u001b[32m0.7497\u001b[0m        4.2925  6.4138\n",
      "    189        \u001b[36m4.2479\u001b[0m       \u001b[32m0.7517\u001b[0m        \u001b[35m4.2875\u001b[0m  6.5038\n",
      "    190        \u001b[36m4.2465\u001b[0m       \u001b[32m0.7526\u001b[0m        4.2877  6.5952\n",
      "    191        \u001b[36m4.2464\u001b[0m       0.7523        \u001b[35m4.2853\u001b[0m  6.7868\n",
      "    192        \u001b[36m4.2452\u001b[0m       \u001b[32m0.7530\u001b[0m        4.2856  6.6811\n",
      "    193        \u001b[36m4.2450\u001b[0m       \u001b[32m0.7533\u001b[0m        \u001b[35m4.2827\u001b[0m  6.6707\n",
      "    194        \u001b[36m4.2449\u001b[0m       \u001b[32m0.7540\u001b[0m        \u001b[35m4.2826\u001b[0m  6.7474\n",
      "    195        \u001b[36m4.2442\u001b[0m       0.7530        4.2827  6.7007\n",
      "    196        \u001b[36m4.2431\u001b[0m       \u001b[32m0.7563\u001b[0m        \u001b[35m4.2825\u001b[0m  6.8539\n",
      "    197        \u001b[36m4.2388\u001b[0m       0.7533        4.2876  6.3848\n",
      "    198        \u001b[36m4.2361\u001b[0m       \u001b[32m0.7570\u001b[0m        4.2830  6.3258\n",
      "    199        \u001b[36m4.2349\u001b[0m       \u001b[32m0.7583\u001b[0m        \u001b[35m4.2793\u001b[0m  6.2748\n",
      "    200        \u001b[36m4.2338\u001b[0m       \u001b[32m0.7593\u001b[0m        \u001b[35m4.2775\u001b[0m  6.2407\n",
      "    201        \u001b[36m4.2331\u001b[0m       0.7576        4.2792  6.2952\n",
      "    202        \u001b[36m4.2323\u001b[0m       \u001b[32m0.7603\u001b[0m        4.2776  6.4686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    203        \u001b[36m4.2315\u001b[0m       0.7553        4.2829  6.2813\n",
      "    204        \u001b[36m4.2279\u001b[0m       \u001b[32m0.7646\u001b[0m        \u001b[35m4.2717\u001b[0m  6.3001\n",
      "    205        \u001b[36m4.2254\u001b[0m       \u001b[32m0.7675\u001b[0m        4.2733  6.3484\n",
      "    206        \u001b[36m4.2227\u001b[0m       0.7662        4.2731  5.8018\n",
      "    207        \u001b[36m4.2219\u001b[0m       \u001b[32m0.7709\u001b[0m        \u001b[35m4.2678\u001b[0m  6.4278\n",
      "    208        \u001b[36m4.2206\u001b[0m       \u001b[32m0.7715\u001b[0m        4.2684  6.2424\n",
      "    209        \u001b[36m4.2201\u001b[0m       0.7692        4.2688  8.5317\n",
      "    210        \u001b[36m4.2193\u001b[0m       0.7705        4.2686  8.0056\n",
      "    211        \u001b[36m4.2175\u001b[0m       \u001b[32m0.7742\u001b[0m        \u001b[35m4.2653\u001b[0m  6.9680\n",
      "    212        \u001b[36m4.2154\u001b[0m       0.7735        4.2653  6.4788\n",
      "    213        \u001b[36m4.2140\u001b[0m       \u001b[32m0.7755\u001b[0m        \u001b[35m4.2637\u001b[0m  6.5176\n",
      "    214        4.2142       \u001b[32m0.7785\u001b[0m        \u001b[35m4.2607\u001b[0m  6.5550\n",
      "    215        \u001b[36m4.2134\u001b[0m       0.7748        4.2623  6.6556\n",
      "    216        \u001b[36m4.2131\u001b[0m       0.7728        4.2622  6.6729\n",
      "    217        \u001b[36m4.2128\u001b[0m       0.7778        \u001b[35m4.2602\u001b[0m  6.6288\n",
      "    218        \u001b[36m4.2122\u001b[0m       \u001b[32m0.7801\u001b[0m        \u001b[35m4.2586\u001b[0m  6.3800\n",
      "    219        \u001b[36m4.2117\u001b[0m       0.7785        \u001b[35m4.2582\u001b[0m  6.4649\n",
      "    220        \u001b[36m4.2116\u001b[0m       0.7758        4.2598  6.4040\n",
      "    221        \u001b[36m4.2112\u001b[0m       0.7781        4.2585  6.6555\n",
      "    222        4.2118       0.7798        \u001b[35m4.2552\u001b[0m  6.9658\n",
      "    223        \u001b[36m4.2109\u001b[0m       0.7768        4.2592  6.8741\n",
      "    224        4.2114       \u001b[32m0.7805\u001b[0m        4.2563  7.1096\n",
      "    225        \u001b[36m4.2106\u001b[0m       0.7788        4.2576  7.4523\n",
      "    226        \u001b[36m4.2080\u001b[0m       \u001b[32m0.7825\u001b[0m        4.2555  6.6093\n",
      "    227        \u001b[36m4.2057\u001b[0m       0.7821        \u001b[35m4.2548\u001b[0m  6.6912\n",
      "    228        \u001b[36m4.2046\u001b[0m       0.7821        \u001b[35m4.2532\u001b[0m  6.6662\n",
      "    229        \u001b[36m4.2045\u001b[0m       \u001b[32m0.7828\u001b[0m        \u001b[35m4.2525\u001b[0m  6.5372\n",
      "    230        \u001b[36m4.2042\u001b[0m       \u001b[32m0.7861\u001b[0m        \u001b[35m4.2509\u001b[0m  6.8227\n",
      "    231        \u001b[36m4.2020\u001b[0m       0.7851        4.2556  6.7528\n",
      "    232        \u001b[36m4.2006\u001b[0m       0.7848        4.2517  6.7999\n",
      "    233        \u001b[36m4.1994\u001b[0m       0.7861        \u001b[35m4.2506\u001b[0m  6.4998\n",
      "    234        \u001b[36m4.1986\u001b[0m       \u001b[32m0.7911\u001b[0m        \u001b[35m4.2501\u001b[0m  6.4399\n",
      "    235        \u001b[36m4.1951\u001b[0m       \u001b[32m0.7927\u001b[0m        \u001b[35m4.2483\u001b[0m  6.7855\n",
      "    236        \u001b[36m4.1903\u001b[0m       \u001b[32m0.7964\u001b[0m        \u001b[35m4.2447\u001b[0m  6.6053\n",
      "    237        \u001b[36m4.1888\u001b[0m       0.7964        \u001b[35m4.2439\u001b[0m  6.5511\n",
      "    238        \u001b[36m4.1877\u001b[0m       \u001b[32m0.7980\u001b[0m        \u001b[35m4.2405\u001b[0m  6.4573\n",
      "    239        \u001b[36m4.1873\u001b[0m       0.7967        \u001b[35m4.2404\u001b[0m  6.5652\n",
      "    240        \u001b[36m4.1868\u001b[0m       0.7970        4.2409  6.3910\n",
      "    241        \u001b[36m4.1859\u001b[0m       \u001b[32m0.8020\u001b[0m        \u001b[35m4.2383\u001b[0m  6.4839\n",
      "    242        \u001b[36m4.1827\u001b[0m       0.8010        \u001b[35m4.2376\u001b[0m  6.4984\n",
      "    243        \u001b[36m4.1785\u001b[0m       \u001b[32m0.8089\u001b[0m        \u001b[35m4.2339\u001b[0m  6.4867\n",
      "    244        \u001b[36m4.1738\u001b[0m       \u001b[32m0.8136\u001b[0m        \u001b[35m4.2284\u001b[0m  6.5545\n",
      "    245        \u001b[36m4.1706\u001b[0m       \u001b[32m0.8142\u001b[0m        \u001b[35m4.2276\u001b[0m  6.4898\n",
      "    246        \u001b[36m4.1689\u001b[0m       0.8142        \u001b[35m4.2253\u001b[0m  6.5375\n",
      "    247        \u001b[36m4.1679\u001b[0m       \u001b[32m0.8166\u001b[0m        \u001b[35m4.2236\u001b[0m  6.5210\n",
      "    248        \u001b[36m4.1655\u001b[0m       \u001b[32m0.8195\u001b[0m        \u001b[35m4.2216\u001b[0m  6.5048\n",
      "    249        \u001b[36m4.1627\u001b[0m       \u001b[32m0.8228\u001b[0m        \u001b[35m4.2177\u001b[0m  6.3925\n",
      "    250        \u001b[36m4.1618\u001b[0m       0.8222        \u001b[35m4.2169\u001b[0m  6.4830\n",
      "    251        \u001b[36m4.1595\u001b[0m       \u001b[32m0.8242\u001b[0m        \u001b[35m4.2157\u001b[0m  6.6728\n",
      "    252        \u001b[36m4.1551\u001b[0m       \u001b[32m0.8301\u001b[0m        \u001b[35m4.2110\u001b[0m  6.6827\n",
      "    253        \u001b[36m4.1525\u001b[0m       0.8272        4.2161  6.4409\n",
      "    254        \u001b[36m4.1506\u001b[0m       \u001b[32m0.8315\u001b[0m        \u001b[35m4.2099\u001b[0m  6.4829\n",
      "    255        \u001b[36m4.1496\u001b[0m       \u001b[32m0.8328\u001b[0m        \u001b[35m4.2085\u001b[0m  6.6289\n",
      "    256        \u001b[36m4.1490\u001b[0m       0.8318        \u001b[35m4.2079\u001b[0m  6.3922\n",
      "    257        \u001b[36m4.1482\u001b[0m       \u001b[32m0.8344\u001b[0m        \u001b[35m4.2066\u001b[0m  6.6679\n",
      "    258        \u001b[36m4.1456\u001b[0m       \u001b[32m0.8377\u001b[0m        \u001b[35m4.2039\u001b[0m  6.7582\n",
      "    259        \u001b[36m4.1427\u001b[0m       \u001b[32m0.8387\u001b[0m        \u001b[35m4.2018\u001b[0m  6.5515\n",
      "    260        \u001b[36m4.1420\u001b[0m       \u001b[32m0.8411\u001b[0m        \u001b[35m4.1997\u001b[0m  6.3790\n",
      "    261        \u001b[36m4.1411\u001b[0m       \u001b[32m0.8417\u001b[0m        \u001b[35m4.1994\u001b[0m  6.3811\n",
      "    262        \u001b[36m4.1404\u001b[0m       0.8407        \u001b[35m4.1980\u001b[0m  6.5371\n",
      "    263        \u001b[36m4.1402\u001b[0m       \u001b[32m0.8424\u001b[0m        \u001b[35m4.1970\u001b[0m  6.3805\n",
      "    264        \u001b[36m4.1398\u001b[0m       0.8414        \u001b[35m4.1966\u001b[0m  6.3722\n",
      "    265        4.1398       0.8411        4.1974  6.4145\n",
      "    266        \u001b[36m4.1397\u001b[0m       0.8401        4.1975  6.4252\n",
      "    267        \u001b[36m4.1389\u001b[0m       0.8411        4.1980  6.4800\n",
      "    268        \u001b[36m4.1379\u001b[0m       0.8401        4.1999  6.4684\n",
      "    269        \u001b[36m4.1372\u001b[0m       0.8421        4.1968  6.4593\n",
      "    270        \u001b[36m4.1363\u001b[0m       \u001b[32m0.8430\u001b[0m        4.1973  6.4129\n",
      "    271        \u001b[36m4.1354\u001b[0m       0.8430        \u001b[35m4.1955\u001b[0m  6.4909\n",
      "    272        \u001b[36m4.1348\u001b[0m       0.8427        \u001b[35m4.1943\u001b[0m  6.4181\n",
      "    273        \u001b[36m4.1328\u001b[0m       \u001b[32m0.8457\u001b[0m        4.1943  6.4256\n",
      "    274        \u001b[36m4.1292\u001b[0m       \u001b[32m0.8477\u001b[0m        \u001b[35m4.1915\u001b[0m  6.6145\n",
      "    275        \u001b[36m4.1285\u001b[0m       \u001b[32m0.8480\u001b[0m        \u001b[35m4.1913\u001b[0m  6.3968\n",
      "    276        4.1286       0.8480        \u001b[35m4.1913\u001b[0m  6.4145\n",
      "    277        \u001b[36m4.1279\u001b[0m       0.8470        \u001b[35m4.1896\u001b[0m  6.4720\n",
      "    278        4.1279       \u001b[32m0.8483\u001b[0m        \u001b[35m4.1895\u001b[0m  6.4468\n",
      "    279        \u001b[36m4.1266\u001b[0m       \u001b[32m0.8503\u001b[0m        \u001b[35m4.1888\u001b[0m  6.3239\n",
      "    280        \u001b[36m4.1266\u001b[0m       0.8487        4.1889  6.3173\n",
      "    281        4.1267       0.8483        \u001b[35m4.1870\u001b[0m  6.3220\n",
      "    282        \u001b[36m4.1261\u001b[0m       \u001b[32m0.8507\u001b[0m        \u001b[35m4.1852\u001b[0m  6.3528\n",
      "    283        \u001b[36m4.1254\u001b[0m       \u001b[32m0.8546\u001b[0m        \u001b[35m4.1844\u001b[0m  6.3102\n",
      "    284        \u001b[36m4.1209\u001b[0m       \u001b[32m0.8583\u001b[0m        \u001b[35m4.1828\u001b[0m  6.6607\n",
      "    285        \u001b[36m4.1157\u001b[0m       \u001b[32m0.8609\u001b[0m        \u001b[35m4.1792\u001b[0m  6.4919\n",
      "    286        \u001b[36m4.1141\u001b[0m       \u001b[32m0.8626\u001b[0m        \u001b[35m4.1765\u001b[0m  6.5118\n",
      "    287        \u001b[36m4.1139\u001b[0m       0.8619        \u001b[35m4.1762\u001b[0m  6.5320\n",
      "    288        \u001b[36m4.1132\u001b[0m       0.8616        4.1767  6.6240\n",
      "    289        \u001b[36m4.1129\u001b[0m       \u001b[32m0.8646\u001b[0m        \u001b[35m4.1742\u001b[0m  6.5612\n",
      "    290        \u001b[36m4.1127\u001b[0m       \u001b[32m0.8649\u001b[0m        \u001b[35m4.1725\u001b[0m  6.7350\n",
      "    291        \u001b[36m4.1124\u001b[0m       0.8619        4.1757  6.5247\n",
      "    292        4.1125       \u001b[32m0.8656\u001b[0m        4.1730  6.3945\n",
      "    293        \u001b[36m4.1121\u001b[0m       0.8632        4.1740  6.4125\n",
      "    294        \u001b[36m4.1107\u001b[0m       0.8586        4.1772  6.3472\n",
      "    295        \u001b[36m4.1093\u001b[0m       0.8629        4.1745  6.3935\n",
      "    296        \u001b[36m4.1088\u001b[0m       0.8623        4.1752  6.4229\n",
      "    297        \u001b[36m4.1084\u001b[0m       0.8639        4.1733  6.5655\n",
      "    298        \u001b[36m4.1077\u001b[0m       0.8626        4.1730  6.6488\n",
      "    299        \u001b[36m4.1068\u001b[0m       0.8599        4.1763  6.4162\n",
      "    300        \u001b[36m4.1067\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m4.1706\u001b[0m  6.4039\n",
      "    301        \u001b[36m4.1066\u001b[0m       0.8613        4.1728  6.4651\n",
      "    302        \u001b[36m4.1065\u001b[0m       0.8623        4.1728  6.5544\n",
      "    303        \u001b[36m4.1060\u001b[0m       0.8659        \u001b[35m4.1696\u001b[0m  6.5623\n",
      "    304        \u001b[36m4.1056\u001b[0m       0.8629        4.1717  6.6244\n",
      "    305        4.1062       \u001b[32m0.8666\u001b[0m        \u001b[35m4.1687\u001b[0m  6.5589\n",
      "    306        4.1058       0.8623        4.1712  6.6233\n",
      "    307        4.1059       0.8652        4.1705  6.6222\n",
      "    308        \u001b[36m4.1016\u001b[0m       \u001b[32m0.8709\u001b[0m        \u001b[35m4.1660\u001b[0m  6.8286\n",
      "    309        \u001b[36m4.0996\u001b[0m       \u001b[32m0.8715\u001b[0m        \u001b[35m4.1652\u001b[0m  6.5257\n",
      "    310        \u001b[36m4.0994\u001b[0m       0.8695        4.1668  6.3536\n",
      "    311        \u001b[36m4.0989\u001b[0m       0.8692        4.1664  6.3567\n",
      "    312        \u001b[36m4.0988\u001b[0m       0.8692        4.1660  6.6162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    313        \u001b[36m4.0988\u001b[0m       \u001b[32m0.8742\u001b[0m        \u001b[35m4.1639\u001b[0m  6.7759\n",
      "    314        4.0990       0.8705        4.1657  7.0871\n",
      "    315        \u001b[36m4.0987\u001b[0m       0.8735        \u001b[35m4.1638\u001b[0m  6.6992\n",
      "    316        4.0989       0.8689        4.1655  6.3662\n",
      "    317        \u001b[36m4.0981\u001b[0m       0.8722        \u001b[35m4.1631\u001b[0m  6.3561\n",
      "    318        4.0985       0.8712        4.1636  6.3542\n",
      "    319        4.0986       \u001b[32m0.8748\u001b[0m        \u001b[35m4.1618\u001b[0m  6.3413\n",
      "    320        \u001b[36m4.0980\u001b[0m       0.8712        \u001b[35m4.1617\u001b[0m  6.5516\n",
      "    321        \u001b[36m4.0979\u001b[0m       0.8719        4.1627  6.5108\n",
      "    322        4.0981       0.8722        \u001b[35m4.1611\u001b[0m  6.7265\n",
      "    323        4.0980       0.8738        4.1612  6.6053\n",
      "    324        4.0980       0.8705        4.1625  6.6099\n",
      "    325        4.0981       \u001b[32m0.8768\u001b[0m        \u001b[35m4.1605\u001b[0m  6.6186\n",
      "    326        4.0979       0.8725        4.1624  6.5841\n",
      "    327        \u001b[36m4.0971\u001b[0m       0.8752        4.1613  6.7656\n",
      "    328        \u001b[36m4.0935\u001b[0m       \u001b[32m0.8805\u001b[0m        \u001b[35m4.1572\u001b[0m  6.7401\n",
      "    329        \u001b[36m4.0929\u001b[0m       0.8765        4.1590  6.6377\n",
      "    330        \u001b[36m4.0923\u001b[0m       0.8795        \u001b[35m4.1568\u001b[0m  6.5081\n",
      "    331        \u001b[36m4.0922\u001b[0m       0.8798        \u001b[35m4.1540\u001b[0m  6.5392\n",
      "    332        \u001b[36m4.0919\u001b[0m       0.8778        4.1589  6.3566\n",
      "    333        \u001b[36m4.0913\u001b[0m       0.8795        4.1560  6.3803\n",
      "    334        4.0915       \u001b[32m0.8808\u001b[0m        4.1544  6.3621\n",
      "    335        4.0915       \u001b[32m0.8815\u001b[0m        \u001b[35m4.1535\u001b[0m  6.3632\n",
      "    336        4.0913       0.8791        4.1555  6.4632\n",
      "    337        \u001b[36m4.0913\u001b[0m       0.8808        \u001b[35m4.1532\u001b[0m  6.3773\n",
      "    338        \u001b[36m4.0911\u001b[0m       0.8815        4.1539  6.3489\n",
      "    339        4.0912       0.8788        4.1549  6.3553\n",
      "    340        4.0912       \u001b[32m0.8821\u001b[0m        4.1537  6.4399\n",
      "    341        \u001b[36m4.0909\u001b[0m       \u001b[32m0.8825\u001b[0m        4.1535  6.3828\n",
      "    342        4.0911       0.8805        4.1544  6.3626\n",
      "    343        4.0909       \u001b[32m0.8834\u001b[0m        \u001b[35m4.1514\u001b[0m  6.4213\n",
      "    344        \u001b[36m4.0905\u001b[0m       0.8811        4.1536  6.4332\n",
      "    345        4.0909       0.8798        4.1550  6.5587\n",
      "    346        4.0912       0.8798        4.1543  6.2773\n",
      "    347        4.0908       0.8825        \u001b[35m4.1510\u001b[0m  6.4792\n",
      "    348        4.0911       \u001b[32m0.8848\u001b[0m        4.1513  6.5838\n",
      "    349        4.0905       0.8765        4.1562  6.6588\n",
      "    350        \u001b[36m4.0884\u001b[0m       0.8801        4.1562  6.4141\n",
      "    351        \u001b[36m4.0878\u001b[0m       0.8742        4.1581  6.4652\n",
      "    352        \u001b[36m4.0871\u001b[0m       0.8828        4.1531  6.3980\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{800: 0.931523178807947}\n",
      "Val accuracy\n",
      "{800: 0.849}\n",
      "pred time\n",
      "{800: 0.4518411159515381}\n",
      "OOS Val Accuracy\n",
      "{800: 0.11}\n",
      "OOS pred time\n",
      "{800: 0.014149904251098633}\n",
      "sigmoid\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "hidden_dim = 800\n",
    "class CLINCModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim=vocab_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_dim=output_dim,\n",
    "            dropout=0.5\n",
    "    ):\n",
    "        super(CLINCModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = F.sigmoid(self.hidden(X)) #sigmoid activation function\n",
    "        X = self.dropout(X)\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "module=CLINCModule,\n",
    "lr=lr,\n",
    "criterion=torch.nn.CrossEntropyLoss,\n",
    "max_epochs=1000,\n",
    "optimizer=torch.optim.Adam,\n",
    "callbacks=[EarlyStopping(patience=10)],\n",
    ")\n",
    "\n",
    "net.fit(train_x, train_y)\n",
    "tlabels = net.predict(train_x)\n",
    "tacc[hidden_dim] = accuracy_score(tlabels, train_y)\n",
    "print('training accuracy')\n",
    "print(tacc)\n",
    "time0 = time.time()\n",
    "labels = net.predict(val_x)\n",
    "vacc[hidden_dim] = accuracy_score(labels, val_y)\n",
    "time1 = time.time()\n",
    "vtime[hidden_dim] = time1-time0\n",
    "print('Val accuracy')\n",
    "print(vacc)\n",
    "print('pred time')\n",
    "print(vtime)\n",
    "time2 = time.time()\n",
    "olabels = net.predict(val_oos_x)\n",
    "oacc[hidden_dim] = accuracy_score(olabels, val_oos_y)\n",
    "time3 = time.time()\n",
    "otime[hidden_dim]=time3-time2\n",
    "print('OOS Val Accuracy')\n",
    "print(oacc)\n",
    "print('OOS pred time')\n",
    "print(otime)\n",
    "print('sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0089\u001b[0m       \u001b[32m0.5252\u001b[0m        \u001b[35m4.9527\u001b[0m  6.3222\n",
      "      2        \u001b[36m4.6487\u001b[0m       \u001b[32m0.8070\u001b[0m        \u001b[35m4.3973\u001b[0m  6.4461\n",
      "      3        \u001b[36m4.2653\u001b[0m       \u001b[32m0.8957\u001b[0m        \u001b[35m4.2314\u001b[0m  6.8577\n",
      "      4        \u001b[36m4.1554\u001b[0m       \u001b[32m0.9199\u001b[0m        \u001b[35m4.1781\u001b[0m  6.8629\n",
      "      5        \u001b[36m4.1109\u001b[0m       \u001b[32m0.9288\u001b[0m        \u001b[35m4.1555\u001b[0m  6.5649\n",
      "      6        \u001b[36m4.0846\u001b[0m       \u001b[32m0.9328\u001b[0m        \u001b[35m4.1418\u001b[0m  6.4810\n",
      "      7        \u001b[36m4.0674\u001b[0m       \u001b[32m0.9394\u001b[0m        \u001b[35m4.1323\u001b[0m  6.7712\n",
      "      8        \u001b[36m4.0572\u001b[0m       0.9394        \u001b[35m4.1263\u001b[0m  6.4031\n",
      "      9        \u001b[36m4.0510\u001b[0m       \u001b[32m0.9414\u001b[0m        \u001b[35m4.1221\u001b[0m  6.3516\n",
      "     10        \u001b[36m4.0465\u001b[0m       0.9411        \u001b[35m4.1194\u001b[0m  6.3315\n",
      "     11        \u001b[36m4.0436\u001b[0m       \u001b[32m0.9427\u001b[0m        \u001b[35m4.1166\u001b[0m  6.3509\n",
      "     12        \u001b[36m4.0414\u001b[0m       \u001b[32m0.9437\u001b[0m        \u001b[35m4.1146\u001b[0m  6.3308\n",
      "     13        \u001b[36m4.0398\u001b[0m       0.9424        \u001b[35m4.1125\u001b[0m  6.3491\n",
      "     14        \u001b[36m4.0385\u001b[0m       0.9437        \u001b[35m4.1109\u001b[0m  6.2971\n",
      "     15        \u001b[36m4.0371\u001b[0m       \u001b[32m0.9447\u001b[0m        \u001b[35m4.1091\u001b[0m  6.2933\n",
      "     16        \u001b[36m4.0360\u001b[0m       0.9447        \u001b[35m4.1083\u001b[0m  6.3241\n",
      "     17        \u001b[36m4.0355\u001b[0m       0.9447        \u001b[35m4.1075\u001b[0m  6.3808\n",
      "     18        \u001b[36m4.0352\u001b[0m       0.9440        \u001b[35m4.1070\u001b[0m  6.3634\n",
      "     19        \u001b[36m4.0345\u001b[0m       0.9430        \u001b[35m4.1062\u001b[0m  6.3860\n",
      "     20        \u001b[36m4.0342\u001b[0m       0.9427        \u001b[35m4.1058\u001b[0m  6.3319\n",
      "     21        \u001b[36m4.0338\u001b[0m       0.9421        \u001b[35m4.1051\u001b[0m  6.3857\n",
      "     22        \u001b[36m4.0333\u001b[0m       0.9430        \u001b[35m4.1045\u001b[0m  6.7527\n",
      "     23        \u001b[36m4.0331\u001b[0m       0.9430        \u001b[35m4.1035\u001b[0m  6.3566\n",
      "     24        \u001b[36m4.0330\u001b[0m       0.9421        4.1037  6.5266\n",
      "     25        \u001b[36m4.0330\u001b[0m       0.9427        \u001b[35m4.1031\u001b[0m  6.7786\n",
      "     26        \u001b[36m4.0326\u001b[0m       0.9430        \u001b[35m4.1024\u001b[0m  6.5408\n",
      "     27        \u001b[36m4.0324\u001b[0m       0.9440        \u001b[35m4.1019\u001b[0m  6.3642\n",
      "     28        \u001b[36m4.0324\u001b[0m       0.9430        \u001b[35m4.1014\u001b[0m  6.3622\n",
      "     29        \u001b[36m4.0322\u001b[0m       0.9444        \u001b[35m4.1009\u001b[0m  6.4674\n",
      "     30        \u001b[36m4.0321\u001b[0m       \u001b[32m0.9450\u001b[0m        4.1009  6.5713\n",
      "     31        \u001b[36m4.0320\u001b[0m       0.9440        \u001b[35m4.1008\u001b[0m  6.3827\n",
      "     32        \u001b[36m4.0320\u001b[0m       0.9440        \u001b[35m4.1004\u001b[0m  6.4247\n",
      "     33        \u001b[36m4.0318\u001b[0m       0.9437        \u001b[35m4.1003\u001b[0m  6.5736\n",
      "     34        \u001b[36m4.0318\u001b[0m       0.9434        \u001b[35m4.0996\u001b[0m  6.3411\n",
      "     35        \u001b[36m4.0318\u001b[0m       0.9437        4.0997  6.3350\n",
      "     36        \u001b[36m4.0316\u001b[0m       0.9430        \u001b[35m4.0994\u001b[0m  6.3101\n",
      "     37        \u001b[36m4.0315\u001b[0m       0.9424        \u001b[35m4.0993\u001b[0m  6.4794\n",
      "     38        4.0316       0.9440        \u001b[35m4.0986\u001b[0m  7.0060\n",
      "     39        \u001b[36m4.0314\u001b[0m       0.9430        \u001b[35m4.0985\u001b[0m  6.3585\n",
      "     40        \u001b[36m4.0313\u001b[0m       0.9430        \u001b[35m4.0984\u001b[0m  6.6745\n",
      "     41        \u001b[36m4.0312\u001b[0m       0.9437        4.0984  6.5256\n",
      "     42        \u001b[36m4.0312\u001b[0m       0.9440        \u001b[35m4.0981\u001b[0m  6.3416\n",
      "     43        \u001b[36m4.0312\u001b[0m       0.9444        \u001b[35m4.0980\u001b[0m  6.3177\n",
      "     44        4.0312       0.9434        4.0981  6.3231\n",
      "     45        \u001b[36m4.0311\u001b[0m       0.9440        \u001b[35m4.0977\u001b[0m  6.4232\n",
      "     46        \u001b[36m4.0311\u001b[0m       0.9444        \u001b[35m4.0973\u001b[0m  6.3659\n",
      "     47        4.0312       0.9437        4.0975  6.3445\n",
      "     48        4.0312       0.9434        4.0974  6.3748\n",
      "     49        \u001b[36m4.0311\u001b[0m       0.9437        \u001b[35m4.0970\u001b[0m  6.3270\n",
      "     50        4.0311       0.9444        \u001b[35m4.0970\u001b[0m  6.3280\n",
      "     51        \u001b[36m4.0310\u001b[0m       0.9444        \u001b[35m4.0968\u001b[0m  6.3369\n",
      "     52        4.0311       0.9437        \u001b[35m4.0967\u001b[0m  6.3153\n",
      "     53        4.0311       0.9427        4.0970  6.3381\n",
      "     54        4.0311       0.9434        \u001b[35m4.0966\u001b[0m  6.3283\n",
      "     55        \u001b[36m4.0310\u001b[0m       0.9447        \u001b[35m4.0959\u001b[0m  6.3868\n",
      "     56        \u001b[36m4.0310\u001b[0m       0.9440        4.0960  6.3689\n",
      "     57        \u001b[36m4.0310\u001b[0m       0.9424        4.0963  6.4654\n",
      "     58        \u001b[36m4.0310\u001b[0m       0.9430        4.0960  6.7966\n",
      "     59        4.0310       0.9437        4.0961  6.9471\n",
      "     60        \u001b[36m4.0310\u001b[0m       0.9440        \u001b[35m4.0956\u001b[0m  6.4561\n",
      "     61        4.0310       0.9440        \u001b[35m4.0955\u001b[0m  6.3775\n",
      "     62        \u001b[36m4.0310\u001b[0m       0.9437        4.0957  6.3855\n",
      "     63        \u001b[36m4.0310\u001b[0m       0.9417        4.0957  6.4790\n",
      "     64        \u001b[36m4.0309\u001b[0m       0.9430        \u001b[35m4.0952\u001b[0m  6.5380\n",
      "     65        4.0310       0.9424        4.0954  6.5265\n",
      "     66        \u001b[36m4.0309\u001b[0m       0.9424        \u001b[35m4.0948\u001b[0m  6.4086\n",
      "     67        \u001b[36m4.0309\u001b[0m       0.9427        4.0949  6.4112\n",
      "     68        4.0310       0.9427        4.0954  6.5308\n",
      "     69        4.0309       0.9434        4.0953  6.4253\n",
      "     70        4.0309       0.9427        4.0955  6.5600\n",
      "     71        \u001b[36m4.0308\u001b[0m       0.9421        4.0953  6.7029\n",
      "     72        \u001b[36m4.0308\u001b[0m       0.9421        4.0956  6.5116\n",
      "     73        \u001b[36m4.0308\u001b[0m       0.9421        4.0953  6.4539\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{800: 0.9866887417218543}\n",
      "Val accuracy\n",
      "{800: 0.8996666666666666}\n",
      "pred time\n",
      "{800: 0.36339783668518066}\n",
      "OOS Val Accuracy\n",
      "{800: 0.12}\n",
      "OOS pred time\n",
      "{800: 0.013499975204467773}\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "hidden_dim = 800\n",
    "class CLINCModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim=vocab_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_dim=output_dim,\n",
    "            dropout=0.5\n",
    "    ):\n",
    "        super(CLINCModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.hidden(X) #no activation function (linear)\n",
    "        X = self.dropout(X)\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "module=CLINCModule,\n",
    "lr=lr,\n",
    "criterion=torch.nn.CrossEntropyLoss,\n",
    "max_epochs=1000,\n",
    "optimizer=torch.optim.Adam,\n",
    "callbacks=[EarlyStopping(patience=10)],\n",
    ")\n",
    "\n",
    "net.fit(train_x, train_y)\n",
    "tlabels = net.predict(train_x)\n",
    "tacc[hidden_dim] = accuracy_score(tlabels, train_y)\n",
    "print('training accuracy')\n",
    "print(tacc)\n",
    "time0 = time.time()\n",
    "labels = net.predict(val_x)\n",
    "vacc[hidden_dim] = accuracy_score(labels, val_y)\n",
    "time1 = time.time()\n",
    "vtime[hidden_dim] = time1-time0\n",
    "print('Val accuracy')\n",
    "print(vacc)\n",
    "print('pred time')\n",
    "print(vtime)\n",
    "time2 = time.time()\n",
    "olabels = net.predict(val_oos_x)\n",
    "oacc[hidden_dim] = accuracy_score(olabels, val_oos_y)\n",
    "time3 = time.time()\n",
    "otime[hidden_dim]=time3-time2\n",
    "print('OOS Val Accuracy')\n",
    "print(oacc)\n",
    "print('OOS pred time')\n",
    "print(otime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU found to be best. Re-iterating through variables previously optimised for tanh activation. Dropouts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0158\u001b[0m       \u001b[32m0.4315\u001b[0m        \u001b[35m5.0101\u001b[0m  6.6061\n",
      "      2        \u001b[36m4.9120\u001b[0m       \u001b[32m0.4679\u001b[0m        \u001b[35m4.7299\u001b[0m  6.5239\n",
      "      3        \u001b[36m4.6053\u001b[0m       \u001b[32m0.6715\u001b[0m        \u001b[35m4.4840\u001b[0m  6.4711\n",
      "      4        \u001b[36m4.4244\u001b[0m       \u001b[32m0.7596\u001b[0m        \u001b[35m4.3682\u001b[0m  6.2988\n",
      "      5        \u001b[36m4.3288\u001b[0m       \u001b[32m0.7964\u001b[0m        \u001b[35m4.3018\u001b[0m  6.3068\n",
      "      6        \u001b[36m4.2741\u001b[0m       \u001b[32m0.8225\u001b[0m        \u001b[35m4.2652\u001b[0m  6.3612\n",
      "      7        \u001b[36m4.2322\u001b[0m       \u001b[32m0.8543\u001b[0m        \u001b[35m4.2316\u001b[0m  6.3762\n",
      "      8        \u001b[36m4.1990\u001b[0m       \u001b[32m0.8689\u001b[0m        \u001b[35m4.2087\u001b[0m  6.3063\n",
      "      9        \u001b[36m4.1730\u001b[0m       \u001b[32m0.8798\u001b[0m        \u001b[35m4.1914\u001b[0m  6.2668\n",
      "     10        \u001b[36m4.1551\u001b[0m       \u001b[32m0.8987\u001b[0m        \u001b[35m4.1729\u001b[0m  6.2441\n",
      "     11        \u001b[36m4.1317\u001b[0m       \u001b[32m0.9073\u001b[0m        \u001b[35m4.1595\u001b[0m  6.2421\n",
      "     12        \u001b[36m4.1193\u001b[0m       0.9073        \u001b[35m4.1520\u001b[0m  6.2562\n",
      "     13        \u001b[36m4.1092\u001b[0m       \u001b[32m0.9132\u001b[0m        \u001b[35m4.1462\u001b[0m  6.2718\n",
      "     14        \u001b[36m4.0980\u001b[0m       \u001b[32m0.9189\u001b[0m        \u001b[35m4.1392\u001b[0m  6.2936\n",
      "     15        \u001b[36m4.0893\u001b[0m       \u001b[32m0.9298\u001b[0m        \u001b[35m4.1322\u001b[0m  6.3823\n",
      "     16        \u001b[36m4.0811\u001b[0m       \u001b[32m0.9315\u001b[0m        \u001b[35m4.1272\u001b[0m  6.3158\n",
      "     17        \u001b[36m4.0754\u001b[0m       \u001b[32m0.9328\u001b[0m        \u001b[35m4.1246\u001b[0m  6.3195\n",
      "     18        \u001b[36m4.0713\u001b[0m       0.9321        \u001b[35m4.1228\u001b[0m  6.3543\n",
      "     19        \u001b[36m4.0643\u001b[0m       \u001b[32m0.9338\u001b[0m        \u001b[35m4.1205\u001b[0m  6.3410\n",
      "     20        \u001b[36m4.0611\u001b[0m       \u001b[32m0.9348\u001b[0m        \u001b[35m4.1177\u001b[0m  6.3776\n",
      "     21        \u001b[36m4.0574\u001b[0m       \u001b[32m0.9368\u001b[0m        \u001b[35m4.1159\u001b[0m  6.3443\n",
      "     22        \u001b[36m4.0533\u001b[0m       \u001b[32m0.9374\u001b[0m        \u001b[35m4.1127\u001b[0m  6.3345\n",
      "     23        \u001b[36m4.0510\u001b[0m       0.9361        \u001b[35m4.1108\u001b[0m  6.3581\n",
      "     24        \u001b[36m4.0483\u001b[0m       \u001b[32m0.9381\u001b[0m        \u001b[35m4.1099\u001b[0m  6.3914\n",
      "     25        \u001b[36m4.0473\u001b[0m       \u001b[32m0.9411\u001b[0m        \u001b[35m4.1074\u001b[0m  6.3780\n",
      "     26        \u001b[36m4.0454\u001b[0m       0.9397        \u001b[35m4.1064\u001b[0m  6.3688\n",
      "     27        \u001b[36m4.0445\u001b[0m       \u001b[32m0.9414\u001b[0m        \u001b[35m4.1056\u001b[0m  6.3780\n",
      "     28        \u001b[36m4.0434\u001b[0m       \u001b[32m0.9421\u001b[0m        \u001b[35m4.1047\u001b[0m  6.3787\n",
      "     29        \u001b[36m4.0425\u001b[0m       0.9404        \u001b[35m4.1042\u001b[0m  6.3784\n",
      "     30        \u001b[36m4.0408\u001b[0m       0.9417        \u001b[35m4.1030\u001b[0m  6.3770\n",
      "     31        4.0416       \u001b[32m0.9444\u001b[0m        \u001b[35m4.1028\u001b[0m  6.3841\n",
      "     32        \u001b[36m4.0402\u001b[0m       0.9440        \u001b[35m4.1015\u001b[0m  6.3876\n",
      "     33        \u001b[36m4.0392\u001b[0m       0.9421        \u001b[35m4.1014\u001b[0m  6.4125\n",
      "     34        \u001b[36m4.0390\u001b[0m       \u001b[32m0.9450\u001b[0m        \u001b[35m4.1006\u001b[0m  6.3839\n",
      "     35        \u001b[36m4.0382\u001b[0m       0.9440        \u001b[35m4.1003\u001b[0m  6.4002\n",
      "     36        \u001b[36m4.0379\u001b[0m       0.9437        \u001b[35m4.0999\u001b[0m  6.4019\n",
      "     37        \u001b[36m4.0371\u001b[0m       0.9444        \u001b[35m4.0988\u001b[0m  6.4265\n",
      "     38        \u001b[36m4.0370\u001b[0m       \u001b[32m0.9467\u001b[0m        \u001b[35m4.0986\u001b[0m  6.4131\n",
      "     39        \u001b[36m4.0366\u001b[0m       0.9440        4.0987  6.4136\n",
      "     40        \u001b[36m4.0364\u001b[0m       0.9440        \u001b[35m4.0980\u001b[0m  6.4019\n",
      "     41        4.0364       0.9434        \u001b[35m4.0978\u001b[0m  6.3943\n",
      "     42        \u001b[36m4.0356\u001b[0m       0.9440        \u001b[35m4.0976\u001b[0m  6.4218\n",
      "     43        \u001b[36m4.0355\u001b[0m       0.9457        \u001b[35m4.0970\u001b[0m  6.4234\n",
      "     44        \u001b[36m4.0352\u001b[0m       0.9450        4.0970  6.4172\n",
      "     45        4.0354       0.9430        4.0972  6.4332\n",
      "     46        \u001b[36m4.0349\u001b[0m       0.9454        \u001b[35m4.0966\u001b[0m  6.4189\n",
      "     47        \u001b[36m4.0347\u001b[0m       0.9421        4.0971  6.4470\n",
      "     48        \u001b[36m4.0343\u001b[0m       0.9430        4.0971  6.4159\n",
      "     49        \u001b[36m4.0343\u001b[0m       0.9437        4.0973  6.4292\n",
      "     50        4.0344       0.9437        4.0968  6.4861\n",
      "     51        4.0347       0.9460        \u001b[35m4.0949\u001b[0m  6.9767\n",
      "     52        \u001b[36m4.0343\u001b[0m       0.9454        4.0955  7.2325\n",
      "     53        \u001b[36m4.0338\u001b[0m       0.9460        4.0957  6.4122\n",
      "     54        \u001b[36m4.0335\u001b[0m       0.9457        \u001b[35m4.0946\u001b[0m  6.3755\n",
      "     55        \u001b[36m4.0334\u001b[0m       0.9464        \u001b[35m4.0944\u001b[0m  32.4726\n",
      "     56        4.0336       0.9450        4.0948  6.9006\n",
      "     57        \u001b[36m4.0331\u001b[0m       0.9444        4.0947  235.2436\n",
      "     58        \u001b[36m4.0329\u001b[0m       0.9447        4.0944  7.0498\n",
      "     59        4.0332       0.9454        \u001b[35m4.0940\u001b[0m  19.8652\n",
      "     60        4.0331       0.9444        \u001b[35m4.0940\u001b[0m  115.1962\n",
      "     61        \u001b[36m4.0328\u001b[0m       0.9424        4.0942  8.1466\n",
      "     62        4.0331       0.9457        \u001b[35m4.0939\u001b[0m  7.4637\n",
      "     63        \u001b[36m4.0325\u001b[0m       0.9457        \u001b[35m4.0937\u001b[0m  7.5334\n",
      "     64        4.0326       0.9447        4.0941  7.5935\n",
      "     65        \u001b[36m4.0324\u001b[0m       0.9434        4.0940  7.4345\n",
      "     66        4.0326       0.9434        \u001b[35m4.0935\u001b[0m  7.2250\n",
      "     67        \u001b[36m4.0323\u001b[0m       0.9447        \u001b[35m4.0934\u001b[0m  6.6189\n",
      "     68        4.0324       \u001b[32m0.9470\u001b[0m        \u001b[35m4.0928\u001b[0m  6.5088\n",
      "     69        4.0325       0.9447        4.0934  6.3438\n",
      "     70        \u001b[36m4.0322\u001b[0m       0.9447        4.0931  6.3148\n",
      "     71        \u001b[36m4.0321\u001b[0m       0.9437        4.0934  6.3332\n",
      "     72        \u001b[36m4.0321\u001b[0m       0.9457        \u001b[35m4.0926\u001b[0m  6.3191\n",
      "     73        4.0321       0.9454        \u001b[35m4.0923\u001b[0m  6.2985\n",
      "     74        4.0323       0.9457        4.0924  6.3179\n",
      "     75        \u001b[36m4.0320\u001b[0m       0.9464        \u001b[35m4.0920\u001b[0m  6.3161\n",
      "     76        \u001b[36m4.0320\u001b[0m       0.9457        \u001b[35m4.0917\u001b[0m  6.3495\n",
      "     77        4.0321       0.9444        4.0930  6.3748\n",
      "     78        4.0320       0.9424        4.0934  6.3618\n",
      "     79        4.0321       0.9444        4.0918  6.3255\n",
      "     80        \u001b[36m4.0318\u001b[0m       0.9454        4.0921  6.3921\n",
      "     81        4.0319       0.9450        \u001b[35m4.0917\u001b[0m  6.3252\n",
      "     82        4.0319       0.9434        4.0923  6.3273\n",
      "     83        \u001b[36m4.0318\u001b[0m       0.9437        \u001b[35m4.0914\u001b[0m  6.3589\n",
      "     84        4.0320       0.9457        \u001b[35m4.0913\u001b[0m  6.3266\n",
      "     85        4.0320       0.9454        4.0913  6.3931\n",
      "     86        4.0318       0.9447        4.0916  6.3491\n",
      "     87        \u001b[36m4.0318\u001b[0m       0.9470        \u001b[35m4.0912\u001b[0m  6.3804\n",
      "     88        \u001b[36m4.0316\u001b[0m       0.9460        4.0914  6.4789\n",
      "     89        \u001b[36m4.0316\u001b[0m       0.9457        4.0917  6.4064\n",
      "     90        \u001b[36m4.0315\u001b[0m       0.9454        4.0912  6.4251\n",
      "     91        4.0316       0.9447        4.0917  6.5390\n",
      "     92        4.0316       0.9450        4.0913  6.4888\n",
      "     93        \u001b[36m4.0314\u001b[0m       0.9454        \u001b[35m4.0906\u001b[0m  6.4049\n",
      "     94        4.0314       0.9444        4.0919  6.3910\n",
      "     95        4.0314       0.9447        4.0916  6.3953\n",
      "     96        4.0314       0.9444        4.0915  6.4266\n",
      "     97        \u001b[36m4.0314\u001b[0m       0.9460        4.0920  6.6735\n",
      "     98        \u001b[36m4.0313\u001b[0m       0.9427        4.0926  6.6333\n",
      "     99        \u001b[36m4.0312\u001b[0m       0.9424        4.0924  6.8556\n",
      "    100        4.0314       0.9424        4.0920  6.7608\n",
      "    101        \u001b[36m4.0312\u001b[0m       0.9437        4.0919  6.7480\n",
      "    102        \u001b[36m4.0312\u001b[0m       0.9424        4.0913  6.4925\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{0.75: 0.9866887417218543}\n",
      "Val accuracy\n",
      "{0.75: 0.9066666666666666}\n",
      "pred time\n",
      "{0.75: 0.49721789360046387}\n",
      "OOS Val Accuracy\n",
      "{0.75: 0.18}\n",
      "OOS pred time\n",
      "{0.75: 0.014636039733886719}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0130\u001b[0m       \u001b[32m0.3225\u001b[0m        \u001b[35m4.9847\u001b[0m  6.9638\n",
      "      2        \u001b[36m4.7648\u001b[0m       \u001b[32m0.5921\u001b[0m        \u001b[35m4.5591\u001b[0m  6.5738\n",
      "      3        \u001b[36m4.4417\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m4.3833\u001b[0m  6.3434\n",
      "      4        \u001b[36m4.3198\u001b[0m       \u001b[32m0.7947\u001b[0m        \u001b[35m4.3062\u001b[0m  6.2947\n",
      "      5        \u001b[36m4.2412\u001b[0m       \u001b[32m0.8434\u001b[0m        \u001b[35m4.2484\u001b[0m  6.5644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6        \u001b[36m4.1918\u001b[0m       \u001b[32m0.8583\u001b[0m        \u001b[35m4.2205\u001b[0m  6.7897\n",
      "      7        \u001b[36m4.1625\u001b[0m       \u001b[32m0.8778\u001b[0m        \u001b[35m4.1984\u001b[0m  6.3732\n",
      "      8        \u001b[36m4.1357\u001b[0m       \u001b[32m0.8947\u001b[0m        \u001b[35m4.1771\u001b[0m  6.6081\n",
      "      9        \u001b[36m4.1153\u001b[0m       \u001b[32m0.9036\u001b[0m        \u001b[35m4.1650\u001b[0m  6.4892\n",
      "     10        \u001b[36m4.0983\u001b[0m       \u001b[32m0.9096\u001b[0m        \u001b[35m4.1528\u001b[0m  6.6590\n",
      "     11        \u001b[36m4.0899\u001b[0m       \u001b[32m0.9126\u001b[0m        \u001b[35m4.1469\u001b[0m  6.5947\n",
      "     12        \u001b[36m4.0856\u001b[0m       0.9113        \u001b[35m4.1456\u001b[0m  6.4069\n",
      "     13        \u001b[36m4.0804\u001b[0m       \u001b[32m0.9156\u001b[0m        \u001b[35m4.1404\u001b[0m  6.2320\n",
      "     14        \u001b[36m4.0745\u001b[0m       0.9146        4.1415  6.1545\n",
      "     15        \u001b[36m4.0693\u001b[0m       \u001b[32m0.9212\u001b[0m        \u001b[35m4.1359\u001b[0m  6.1887\n",
      "     16        \u001b[36m4.0600\u001b[0m       \u001b[32m0.9262\u001b[0m        \u001b[35m4.1274\u001b[0m  6.1672\n",
      "     17        \u001b[36m4.0554\u001b[0m       \u001b[32m0.9321\u001b[0m        \u001b[35m4.1217\u001b[0m  6.1663\n",
      "     18        \u001b[36m4.0495\u001b[0m       \u001b[32m0.9331\u001b[0m        \u001b[35m4.1175\u001b[0m  6.1480\n",
      "     19        \u001b[36m4.0463\u001b[0m       \u001b[32m0.9348\u001b[0m        \u001b[35m4.1148\u001b[0m  6.2277\n",
      "     20        \u001b[36m4.0449\u001b[0m       \u001b[32m0.9358\u001b[0m        \u001b[35m4.1133\u001b[0m  6.2520\n",
      "     21        \u001b[36m4.0440\u001b[0m       \u001b[32m0.9387\u001b[0m        \u001b[35m4.1114\u001b[0m  6.1674\n",
      "     22        \u001b[36m4.0431\u001b[0m       0.9371        \u001b[35m4.1103\u001b[0m  6.1559\n",
      "     23        \u001b[36m4.0424\u001b[0m       0.9358        \u001b[35m4.1094\u001b[0m  6.1526\n",
      "     24        \u001b[36m4.0418\u001b[0m       0.9377        \u001b[35m4.1082\u001b[0m  6.2385\n",
      "     25        \u001b[36m4.0414\u001b[0m       \u001b[32m0.9401\u001b[0m        \u001b[35m4.1074\u001b[0m  6.1373\n",
      "     26        \u001b[36m4.0409\u001b[0m       \u001b[32m0.9404\u001b[0m        \u001b[35m4.1070\u001b[0m  6.4133\n",
      "     27        \u001b[36m4.0403\u001b[0m       0.9384        4.1095  6.7899\n",
      "     28        \u001b[36m4.0372\u001b[0m       \u001b[32m0.9417\u001b[0m        \u001b[35m4.1062\u001b[0m  6.4050\n",
      "     29        \u001b[36m4.0357\u001b[0m       0.9381        \u001b[35m4.1062\u001b[0m  6.1412\n",
      "     30        \u001b[36m4.0351\u001b[0m       0.9411        \u001b[35m4.1045\u001b[0m  6.5307\n",
      "     31        \u001b[36m4.0344\u001b[0m       \u001b[32m0.9430\u001b[0m        \u001b[35m4.1028\u001b[0m  6.2352\n",
      "     32        \u001b[36m4.0339\u001b[0m       0.9417        4.1034  6.1106\n",
      "     33        \u001b[36m4.0337\u001b[0m       0.9427        \u001b[35m4.1018\u001b[0m  6.1410\n",
      "     34        \u001b[36m4.0335\u001b[0m       0.9430        4.1024  6.1087\n",
      "     35        \u001b[36m4.0330\u001b[0m       0.9417        \u001b[35m4.1011\u001b[0m  6.1106\n",
      "     36        4.0330       \u001b[32m0.9440\u001b[0m        \u001b[35m4.1010\u001b[0m  6.1254\n",
      "     37        \u001b[36m4.0328\u001b[0m       0.9434        \u001b[35m4.0998\u001b[0m  6.1180\n",
      "     38        \u001b[36m4.0325\u001b[0m       0.9434        \u001b[35m4.0995\u001b[0m  6.1262\n",
      "     39        4.0325       0.9414        4.1002  6.2069\n",
      "     40        \u001b[36m4.0323\u001b[0m       0.9434        \u001b[35m4.0985\u001b[0m  6.1263\n",
      "     41        \u001b[36m4.0321\u001b[0m       \u001b[32m0.9444\u001b[0m        \u001b[35m4.0978\u001b[0m  6.1243\n",
      "     42        4.0321       0.9430        4.0982  6.1040\n",
      "     43        \u001b[36m4.0320\u001b[0m       0.9424        4.0979  6.1300\n",
      "     44        \u001b[36m4.0320\u001b[0m       0.9437        \u001b[35m4.0976\u001b[0m  6.1110\n",
      "     45        \u001b[36m4.0317\u001b[0m       0.9430        \u001b[35m4.0969\u001b[0m  6.1105\n",
      "     46        4.0318       0.9444        \u001b[35m4.0961\u001b[0m  6.1134\n",
      "     47        \u001b[36m4.0315\u001b[0m       0.9437        4.0963  6.1080\n",
      "     48        4.0315       \u001b[32m0.9447\u001b[0m        \u001b[35m4.0959\u001b[0m  6.1195\n",
      "     49        \u001b[36m4.0314\u001b[0m       0.9447        4.0962  6.1453\n",
      "     50        4.0316       0.9447        \u001b[35m4.0956\u001b[0m  6.1336\n",
      "     51        \u001b[36m4.0313\u001b[0m       0.9434        4.0957  6.1214\n",
      "     52        \u001b[36m4.0313\u001b[0m       0.9421        4.0961  6.1565\n",
      "     53        \u001b[36m4.0312\u001b[0m       0.9434        4.0963  6.1106\n",
      "     54        \u001b[36m4.0312\u001b[0m       0.9437        4.0957  6.1153\n",
      "     55        4.0312       0.9424        4.0960  6.1114\n",
      "     56        \u001b[36m4.0311\u001b[0m       0.9430        \u001b[35m4.0949\u001b[0m  6.1108\n",
      "     57        \u001b[36m4.0311\u001b[0m       0.9437        4.0952  6.1294\n",
      "     58        4.0311       0.9437        4.0957  6.1603\n",
      "     59        \u001b[36m4.0310\u001b[0m       0.9417        \u001b[35m4.0942\u001b[0m  6.1405\n",
      "     60        4.0310       0.9440        \u001b[35m4.0939\u001b[0m  6.2225\n",
      "     61        \u001b[36m4.0310\u001b[0m       0.9424        4.0943  6.5339\n",
      "     62        4.0311       0.9437        4.0947  6.6516\n",
      "     63        4.0311       0.9437        4.0942  6.2459\n",
      "     64        \u001b[36m4.0309\u001b[0m       0.9434        4.0943  6.1489\n",
      "     65        4.0310       \u001b[32m0.9460\u001b[0m        4.0940  6.1100\n",
      "     66        \u001b[36m4.0309\u001b[0m       0.9450        4.0940  6.1292\n",
      "     67        4.0309       \u001b[32m0.9464\u001b[0m        \u001b[35m4.0921\u001b[0m  6.1372\n",
      "     68        \u001b[36m4.0308\u001b[0m       0.9417        4.0942  6.1252\n",
      "     69        \u001b[36m4.0308\u001b[0m       0.9454        4.0933  6.2602\n",
      "     70        \u001b[36m4.0307\u001b[0m       0.9457        4.0925  6.2156\n",
      "     71        4.0308       0.9437        4.0930  6.1238\n",
      "     72        4.0308       0.9460        4.0924  6.1450\n",
      "     73        4.0308       0.9440        4.0927  6.1217\n",
      "     74        \u001b[36m4.0307\u001b[0m       0.9447        4.0925  6.1193\n",
      "     75        4.0307       0.9437        4.0933  6.1566\n",
      "     76        4.0308       0.9427        4.0927  6.1832\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{0.75: 0.9866887417218543, 0.5: 0.9866887417218543}\n",
      "Val accuracy\n",
      "{0.75: 0.9066666666666666, 0.5: 0.9053333333333333}\n",
      "pred time\n",
      "{0.75: 0.49721789360046387, 0.5: 0.42409491539001465}\n",
      "OOS Val Accuracy\n",
      "{0.75: 0.18, 0.5: 0.2}\n",
      "OOS pred time\n",
      "{0.75: 0.014636039733886719, 0.5: 0.014017105102539062}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0081\u001b[0m       \u001b[32m0.3232\u001b[0m        \u001b[35m4.9384\u001b[0m  6.3892\n",
      "      2        \u001b[36m4.6697\u001b[0m       \u001b[32m0.6579\u001b[0m        \u001b[35m4.4789\u001b[0m  6.2925\n",
      "      3        \u001b[36m4.3765\u001b[0m       \u001b[32m0.7669\u001b[0m        \u001b[35m4.3430\u001b[0m  6.1568\n",
      "      4        \u001b[36m4.2628\u001b[0m       \u001b[32m0.8245\u001b[0m        \u001b[35m4.2687\u001b[0m  6.1635\n",
      "      5        \u001b[36m4.2028\u001b[0m       \u001b[32m0.8424\u001b[0m        \u001b[35m4.2359\u001b[0m  6.3060\n",
      "      6        \u001b[36m4.1729\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m4.2170\u001b[0m  6.5813\n",
      "      7        \u001b[36m4.1479\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m4.1993\u001b[0m  6.5208\n",
      "      8        \u001b[36m4.1262\u001b[0m       \u001b[32m0.8854\u001b[0m        \u001b[35m4.1804\u001b[0m  6.2878\n",
      "      9        \u001b[36m4.1086\u001b[0m       \u001b[32m0.9007\u001b[0m        \u001b[35m4.1660\u001b[0m  6.1977\n",
      "     10        \u001b[36m4.0913\u001b[0m       \u001b[32m0.9076\u001b[0m        \u001b[35m4.1549\u001b[0m  6.2004\n",
      "     11        \u001b[36m4.0815\u001b[0m       \u001b[32m0.9172\u001b[0m        \u001b[35m4.1484\u001b[0m  5.9680\n",
      "     12        \u001b[36m4.0717\u001b[0m       \u001b[32m0.9182\u001b[0m        \u001b[35m4.1393\u001b[0m  6.1917\n",
      "     13        \u001b[36m4.0645\u001b[0m       \u001b[32m0.9215\u001b[0m        \u001b[35m4.1366\u001b[0m  6.1979\n",
      "     14        \u001b[36m4.0565\u001b[0m       \u001b[32m0.9265\u001b[0m        \u001b[35m4.1294\u001b[0m  6.1826\n",
      "     15        \u001b[36m4.0520\u001b[0m       \u001b[32m0.9295\u001b[0m        \u001b[35m4.1249\u001b[0m  6.1990\n",
      "     16        \u001b[36m4.0447\u001b[0m       \u001b[32m0.9354\u001b[0m        \u001b[35m4.1171\u001b[0m  6.1769\n",
      "     17        \u001b[36m4.0399\u001b[0m       \u001b[32m0.9377\u001b[0m        \u001b[35m4.1144\u001b[0m  6.1802\n",
      "     18        \u001b[36m4.0375\u001b[0m       \u001b[32m0.9381\u001b[0m        \u001b[35m4.1129\u001b[0m  6.3410\n",
      "     19        \u001b[36m4.0363\u001b[0m       \u001b[32m0.9394\u001b[0m        \u001b[35m4.1113\u001b[0m  6.3667\n",
      "     20        \u001b[36m4.0355\u001b[0m       0.9384        \u001b[35m4.1088\u001b[0m  6.2581\n",
      "     21        \u001b[36m4.0346\u001b[0m       \u001b[32m0.9407\u001b[0m        \u001b[35m4.1073\u001b[0m  6.1944\n",
      "     22        \u001b[36m4.0341\u001b[0m       0.9391        4.1079  6.1882\n",
      "     23        \u001b[36m4.0338\u001b[0m       0.9391        \u001b[35m4.1063\u001b[0m  6.1960\n",
      "     24        \u001b[36m4.0335\u001b[0m       0.9401        \u001b[35m4.1051\u001b[0m  6.1790\n",
      "     25        \u001b[36m4.0330\u001b[0m       \u001b[32m0.9427\u001b[0m        \u001b[35m4.1034\u001b[0m  6.1767\n",
      "     26        \u001b[36m4.0327\u001b[0m       0.9411        \u001b[35m4.1032\u001b[0m  6.1649\n",
      "     27        \u001b[36m4.0326\u001b[0m       0.9401        \u001b[35m4.1027\u001b[0m  6.2475\n",
      "     28        \u001b[36m4.0325\u001b[0m       0.9414        4.1028  6.3503\n",
      "     29        \u001b[36m4.0324\u001b[0m       0.9411        \u001b[35m4.1022\u001b[0m  6.2054\n",
      "     30        \u001b[36m4.0320\u001b[0m       0.9421        \u001b[35m4.1021\u001b[0m  6.2296\n",
      "     31        4.0320       0.9404        \u001b[35m4.1015\u001b[0m  6.2094\n",
      "     32        \u001b[36m4.0318\u001b[0m       0.9417        \u001b[35m4.1005\u001b[0m  6.1947\n",
      "     33        \u001b[36m4.0317\u001b[0m       0.9407        \u001b[35m4.1000\u001b[0m  6.2566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     34        \u001b[36m4.0317\u001b[0m       0.9411        4.1002  6.3346\n",
      "     35        \u001b[36m4.0317\u001b[0m       0.9421        \u001b[35m4.0996\u001b[0m  6.3608\n",
      "     36        \u001b[36m4.0315\u001b[0m       0.9407        4.0997  6.2042\n",
      "     37        \u001b[36m4.0315\u001b[0m       0.9417        \u001b[35m4.0991\u001b[0m  6.3066\n",
      "     38        \u001b[36m4.0314\u001b[0m       0.9427        \u001b[35m4.0987\u001b[0m  6.3781\n",
      "     39        \u001b[36m4.0313\u001b[0m       0.9417        4.0987  6.3579\n",
      "     40        \u001b[36m4.0313\u001b[0m       0.9414        \u001b[35m4.0982\u001b[0m  6.4128\n",
      "     41        4.0313       0.9427        4.0983  6.2995\n",
      "     42        \u001b[36m4.0312\u001b[0m       \u001b[32m0.9434\u001b[0m        \u001b[35m4.0981\u001b[0m  6.4869\n",
      "     43        \u001b[36m4.0311\u001b[0m       \u001b[32m0.9444\u001b[0m        \u001b[35m4.0975\u001b[0m  6.6551\n",
      "     44        \u001b[36m4.0311\u001b[0m       0.9430        \u001b[35m4.0972\u001b[0m  6.7829\n",
      "     45        4.0311       0.9417        4.0973  6.8611\n",
      "     46        \u001b[36m4.0310\u001b[0m       0.9430        \u001b[35m4.0971\u001b[0m  6.5274\n",
      "     47        \u001b[36m4.0309\u001b[0m       0.9434        4.0973  6.2378\n",
      "     48        4.0310       \u001b[32m0.9447\u001b[0m        \u001b[35m4.0967\u001b[0m  6.1882\n",
      "     49        \u001b[36m4.0309\u001b[0m       0.9424        \u001b[35m4.0961\u001b[0m  6.1774\n",
      "     50        4.0309       0.9424        4.0965  6.1851\n",
      "     51        \u001b[36m4.0309\u001b[0m       0.9424        4.0964  6.2068\n",
      "     52        4.0309       0.9421        4.0971  6.1780\n",
      "     53        4.0310       0.9424        \u001b[35m4.0955\u001b[0m  6.1838\n",
      "     54        \u001b[36m4.0308\u001b[0m       0.9430        4.0958  6.4393\n",
      "     55        \u001b[36m4.0308\u001b[0m       0.9440        \u001b[35m4.0952\u001b[0m  6.3722\n",
      "     56        \u001b[36m4.0308\u001b[0m       0.9427        4.0954  6.4375\n",
      "     57        \u001b[36m4.0308\u001b[0m       0.9424        4.0957  6.2140\n",
      "     58        \u001b[36m4.0307\u001b[0m       0.9444        \u001b[35m4.0948\u001b[0m  6.2078\n",
      "     59        \u001b[36m4.0307\u001b[0m       0.9444        4.0952  6.1735\n",
      "     60        \u001b[36m4.0307\u001b[0m       \u001b[32m0.9450\u001b[0m        \u001b[35m4.0940\u001b[0m  6.1897\n",
      "     61        \u001b[36m4.0306\u001b[0m       0.9440        4.0946  6.1935\n",
      "     62        \u001b[36m4.0306\u001b[0m       0.9430        4.0949  6.2893\n",
      "     63        4.0306       0.9424        4.0945  6.2523\n",
      "     64        \u001b[36m4.0306\u001b[0m       \u001b[32m0.9454\u001b[0m        \u001b[35m4.0939\u001b[0m  6.2403\n",
      "     65        4.0307       0.9430        4.0946  6.1817\n",
      "     66        4.0307       0.9427        4.0941  6.2555\n",
      "     67        \u001b[36m4.0306\u001b[0m       0.9417        4.0946  6.1771\n",
      "     68        4.0306       0.9437        4.0939  6.2118\n",
      "     69        \u001b[36m4.0306\u001b[0m       0.9434        \u001b[35m4.0938\u001b[0m  6.2664\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{0.75: 0.9866887417218543, 0.5: 0.9866887417218543, 0.25: 0.9873509933774834}\n",
      "Val accuracy\n",
      "{0.75: 0.9066666666666666, 0.5: 0.9053333333333333, 0.25: 0.9036666666666666}\n",
      "pred time\n",
      "{0.75: 0.49721789360046387, 0.5: 0.42409491539001465, 0.25: 0.37950801849365234}\n",
      "OOS Val Accuracy\n",
      "{0.75: 0.18, 0.5: 0.2, 0.25: 0.27}\n",
      "OOS pred time\n",
      "{0.75: 0.014636039733886719, 0.5: 0.014017105102539062, 0.25: 0.012434005737304688}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0046\u001b[0m       \u001b[32m0.3238\u001b[0m        \u001b[35m4.9105\u001b[0m  6.4280\n",
      "      2        \u001b[36m4.6383\u001b[0m       \u001b[32m0.6765\u001b[0m        \u001b[35m4.4556\u001b[0m  6.3831\n",
      "      3        \u001b[36m4.3532\u001b[0m       \u001b[32m0.7805\u001b[0m        \u001b[35m4.3247\u001b[0m  6.3361\n",
      "      4        \u001b[36m4.2485\u001b[0m       \u001b[32m0.8172\u001b[0m        \u001b[35m4.2645\u001b[0m  6.3187\n",
      "      5        \u001b[36m4.2021\u001b[0m       \u001b[32m0.8325\u001b[0m        \u001b[35m4.2404\u001b[0m  6.3339\n",
      "      6        \u001b[36m4.1692\u001b[0m       \u001b[32m0.8533\u001b[0m        \u001b[35m4.2172\u001b[0m  6.3817\n",
      "      7        \u001b[36m4.1410\u001b[0m       \u001b[32m0.8801\u001b[0m        \u001b[35m4.1938\u001b[0m  6.4066\n",
      "      8        \u001b[36m4.1172\u001b[0m       \u001b[32m0.8887\u001b[0m        \u001b[35m4.1765\u001b[0m  6.2813\n",
      "      9        \u001b[36m4.1069\u001b[0m       \u001b[32m0.8960\u001b[0m        \u001b[35m4.1679\u001b[0m  6.2451\n",
      "     10        \u001b[36m4.0926\u001b[0m       \u001b[32m0.9020\u001b[0m        \u001b[35m4.1586\u001b[0m  6.2583\n",
      "     11        \u001b[36m4.0856\u001b[0m       \u001b[32m0.9050\u001b[0m        \u001b[35m4.1526\u001b[0m  6.2283\n",
      "     12        \u001b[36m4.0823\u001b[0m       0.9040        \u001b[35m4.1514\u001b[0m  6.2334\n",
      "     13        \u001b[36m4.0765\u001b[0m       0.9023        4.1531  6.2153\n",
      "     14        \u001b[36m4.0691\u001b[0m       \u001b[32m0.9166\u001b[0m        \u001b[35m4.1429\u001b[0m  6.2398\n",
      "     15        \u001b[36m4.0563\u001b[0m       \u001b[32m0.9252\u001b[0m        \u001b[35m4.1315\u001b[0m  6.2237\n",
      "     16        \u001b[36m4.0470\u001b[0m       \u001b[32m0.9331\u001b[0m        \u001b[35m4.1212\u001b[0m  6.2701\n",
      "     17        \u001b[36m4.0436\u001b[0m       \u001b[32m0.9368\u001b[0m        \u001b[35m4.1170\u001b[0m  6.2247\n",
      "     18        \u001b[36m4.0419\u001b[0m       0.9338        \u001b[35m4.1153\u001b[0m  6.2124\n",
      "     19        \u001b[36m4.0409\u001b[0m       0.9358        \u001b[35m4.1133\u001b[0m  6.2276\n",
      "     20        \u001b[36m4.0404\u001b[0m       \u001b[32m0.9371\u001b[0m        \u001b[35m4.1117\u001b[0m  6.1849\n",
      "     21        \u001b[36m4.0399\u001b[0m       0.9371        \u001b[35m4.1106\u001b[0m  6.2170\n",
      "     22        \u001b[36m4.0396\u001b[0m       \u001b[32m0.9377\u001b[0m        \u001b[35m4.1104\u001b[0m  6.2166\n",
      "     23        \u001b[36m4.0392\u001b[0m       0.9377        \u001b[35m4.1091\u001b[0m  6.2044\n",
      "     24        \u001b[36m4.0389\u001b[0m       \u001b[32m0.9381\u001b[0m        \u001b[35m4.1081\u001b[0m  6.2261\n",
      "     25        \u001b[36m4.0387\u001b[0m       0.9381        4.1096  6.3125\n",
      "     26        \u001b[36m4.0355\u001b[0m       \u001b[32m0.9417\u001b[0m        \u001b[35m4.1046\u001b[0m  6.2190\n",
      "     27        \u001b[36m4.0339\u001b[0m       0.9384        4.1076  6.2480\n",
      "     28        \u001b[36m4.0330\u001b[0m       0.9391        4.1065  6.1314\n",
      "     29        \u001b[36m4.0326\u001b[0m       0.9391        4.1050  6.1779\n",
      "     30        \u001b[36m4.0322\u001b[0m       0.9417        \u001b[35m4.1031\u001b[0m  6.2380\n",
      "     31        \u001b[36m4.0320\u001b[0m       0.9404        4.1033  6.2469\n",
      "     32        \u001b[36m4.0319\u001b[0m       0.9414        \u001b[35m4.1019\u001b[0m  6.2399\n",
      "     33        \u001b[36m4.0317\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m4.1015\u001b[0m  6.2227\n",
      "     34        \u001b[36m4.0316\u001b[0m       0.9411        \u001b[35m4.1012\u001b[0m  6.2374\n",
      "     35        \u001b[36m4.0315\u001b[0m       0.9414        \u001b[35m4.1010\u001b[0m  6.2405\n",
      "     36        \u001b[36m4.0314\u001b[0m       0.9417        \u001b[35m4.1003\u001b[0m  6.2648\n",
      "     37        \u001b[36m4.0314\u001b[0m       0.9424        \u001b[35m4.1002\u001b[0m  6.2347\n",
      "     38        \u001b[36m4.0314\u001b[0m       0.9417        \u001b[35m4.0999\u001b[0m  6.2534\n",
      "     39        \u001b[36m4.0312\u001b[0m       0.9417        4.1000  6.2302\n",
      "     40        \u001b[36m4.0311\u001b[0m       0.9407        \u001b[35m4.0994\u001b[0m  6.2182\n",
      "     41        \u001b[36m4.0311\u001b[0m       0.9401        4.1006  6.2261\n",
      "     42        4.0311       0.9414        \u001b[35m4.0991\u001b[0m  6.2658\n",
      "     43        \u001b[36m4.0309\u001b[0m       0.9404        4.1000  6.2412\n",
      "     44        \u001b[36m4.0308\u001b[0m       0.9417        \u001b[35m4.0990\u001b[0m  6.3742\n",
      "     45        \u001b[36m4.0308\u001b[0m       0.9417        \u001b[35m4.0985\u001b[0m  6.2729\n",
      "     46        \u001b[36m4.0307\u001b[0m       0.9421        \u001b[35m4.0982\u001b[0m  6.2256\n",
      "     47        \u001b[36m4.0307\u001b[0m       0.9401        4.0982  6.2509\n",
      "     48        \u001b[36m4.0307\u001b[0m       0.9424        \u001b[35m4.0975\u001b[0m  6.2381\n",
      "     49        \u001b[36m4.0306\u001b[0m       0.9421        \u001b[35m4.0972\u001b[0m  6.2240\n",
      "     50        4.0306       0.9407        4.0973  6.3448\n",
      "     51        \u001b[36m4.0306\u001b[0m       0.9414        \u001b[35m4.0970\u001b[0m  6.1719\n",
      "     52        \u001b[36m4.0306\u001b[0m       0.9414        4.0970  6.2178\n",
      "     53        \u001b[36m4.0306\u001b[0m       0.9414        \u001b[35m4.0968\u001b[0m  6.2253\n",
      "     54        \u001b[36m4.0306\u001b[0m       0.9414        \u001b[35m4.0967\u001b[0m  6.2052\n",
      "     55        \u001b[36m4.0306\u001b[0m       0.9424        \u001b[35m4.0965\u001b[0m  6.2940\n",
      "     56        4.0306       0.9417        \u001b[35m4.0962\u001b[0m  6.2334\n",
      "     57        4.0306       0.9411        \u001b[35m4.0961\u001b[0m  6.2502\n",
      "     58        4.0306       0.9417        4.0964  6.2607\n",
      "     59        \u001b[36m4.0305\u001b[0m       \u001b[32m0.9430\u001b[0m        \u001b[35m4.0956\u001b[0m  6.2243\n",
      "     60        \u001b[36m4.0305\u001b[0m       0.9424        4.0958  6.2419\n",
      "     61        \u001b[36m4.0305\u001b[0m       0.9417        \u001b[35m4.0956\u001b[0m  6.2285\n",
      "     62        4.0305       0.9414        \u001b[35m4.0953\u001b[0m  6.3578\n",
      "     63        \u001b[36m4.0305\u001b[0m       0.9417        \u001b[35m4.0952\u001b[0m  6.3296\n",
      "     64        \u001b[36m4.0305\u001b[0m       0.9417        \u001b[35m4.0949\u001b[0m  6.2640\n",
      "     65        \u001b[36m4.0305\u001b[0m       0.9421        4.0949  6.2299\n",
      "     66        \u001b[36m4.0305\u001b[0m       0.9421        4.0950  6.2216\n",
      "     67        4.0305       0.9411        4.0951  6.2324\n",
      "     68        \u001b[36m4.0305\u001b[0m       0.9424        \u001b[35m4.0946\u001b[0m  6.2249\n",
      "     69        \u001b[36m4.0305\u001b[0m       0.9427        4.0951  6.2253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     70        4.0305       0.9407        4.0958  6.2372\n",
      "     71        4.0306       0.9417        4.0955  6.2266\n",
      "     72        \u001b[36m4.0304\u001b[0m       0.9424        4.0956  6.2432\n",
      "     73        \u001b[36m4.0304\u001b[0m       0.9411        4.0959  6.2296\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{0.75: 0.9866887417218543, 0.5: 0.9866887417218543, 0.25: 0.9873509933774834, 0.1: 0.9871523178807947}\n",
      "Val accuracy\n",
      "{0.75: 0.9066666666666666, 0.5: 0.9053333333333333, 0.25: 0.9036666666666666, 0.1: 0.9056666666666666}\n",
      "pred time\n",
      "{0.75: 0.49721789360046387, 0.5: 0.42409491539001465, 0.25: 0.37950801849365234, 0.1: 0.3557312488555908}\n",
      "OOS Val Accuracy\n",
      "{0.75: 0.18, 0.5: 0.2, 0.25: 0.27, 0.1: 0.27}\n",
      "OOS pred time\n",
      "{0.75: 0.014636039733886719, 0.5: 0.014017105102539062, 0.25: 0.012434005737304688, 0.1: 0.012111186981201172}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0026\u001b[0m       \u001b[32m0.3546\u001b[0m        \u001b[35m4.8944\u001b[0m  6.2924\n",
      "      2        \u001b[36m4.6128\u001b[0m       \u001b[32m0.6864\u001b[0m        \u001b[35m4.4393\u001b[0m  6.3053\n",
      "      3        \u001b[36m4.3371\u001b[0m       \u001b[32m0.7762\u001b[0m        \u001b[35m4.3176\u001b[0m  6.3090\n",
      "      4        \u001b[36m4.2457\u001b[0m       \u001b[32m0.8182\u001b[0m        \u001b[35m4.2645\u001b[0m  6.3073\n",
      "      5        \u001b[36m4.1910\u001b[0m       \u001b[32m0.8417\u001b[0m        \u001b[35m4.2314\u001b[0m  6.3080\n",
      "      6        \u001b[36m4.1599\u001b[0m       \u001b[32m0.8675\u001b[0m        \u001b[35m4.2085\u001b[0m  6.3022\n",
      "      7        \u001b[36m4.1315\u001b[0m       \u001b[32m0.8834\u001b[0m        \u001b[35m4.1903\u001b[0m  6.3168\n",
      "      8        \u001b[36m4.1137\u001b[0m       \u001b[32m0.8891\u001b[0m        \u001b[35m4.1762\u001b[0m  6.3392\n",
      "      9        \u001b[36m4.1002\u001b[0m       \u001b[32m0.9023\u001b[0m        \u001b[35m4.1625\u001b[0m  6.2843\n",
      "     10        \u001b[36m4.0873\u001b[0m       \u001b[32m0.9070\u001b[0m        \u001b[35m4.1545\u001b[0m  6.2553\n",
      "     11        \u001b[36m4.0786\u001b[0m       \u001b[32m0.9132\u001b[0m        \u001b[35m4.1473\u001b[0m  6.2475\n",
      "     12        \u001b[36m4.0712\u001b[0m       \u001b[32m0.9189\u001b[0m        \u001b[35m4.1400\u001b[0m  6.2624\n",
      "     13        \u001b[36m4.0626\u001b[0m       \u001b[32m0.9195\u001b[0m        4.1408  6.2576\n",
      "     14        \u001b[36m4.0535\u001b[0m       \u001b[32m0.9248\u001b[0m        \u001b[35m4.1333\u001b[0m  6.4059\n",
      "     15        \u001b[36m4.0460\u001b[0m       \u001b[32m0.9318\u001b[0m        \u001b[35m4.1222\u001b[0m  6.2528\n",
      "     16        \u001b[36m4.0431\u001b[0m       \u001b[32m0.9328\u001b[0m        \u001b[35m4.1182\u001b[0m  6.4209\n",
      "     17        \u001b[36m4.0417\u001b[0m       \u001b[32m0.9344\u001b[0m        \u001b[35m4.1162\u001b[0m  7.1680\n",
      "     18        \u001b[36m4.0409\u001b[0m       0.9341        \u001b[35m4.1147\u001b[0m  6.8174\n",
      "     19        \u001b[36m4.0403\u001b[0m       \u001b[32m0.9348\u001b[0m        \u001b[35m4.1135\u001b[0m  6.3872\n",
      "     20        \u001b[36m4.0399\u001b[0m       0.9338        \u001b[35m4.1130\u001b[0m  6.2857\n",
      "     21        \u001b[36m4.0396\u001b[0m       \u001b[32m0.9368\u001b[0m        \u001b[35m4.1112\u001b[0m  6.2565\n",
      "     22        \u001b[36m4.0393\u001b[0m       \u001b[32m0.9381\u001b[0m        \u001b[35m4.1101\u001b[0m  6.7055\n",
      "     23        \u001b[36m4.0392\u001b[0m       \u001b[32m0.9391\u001b[0m        \u001b[35m4.1095\u001b[0m  6.7974\n",
      "     24        \u001b[36m4.0374\u001b[0m       \u001b[32m0.9407\u001b[0m        \u001b[35m4.1083\u001b[0m  6.7010\n",
      "     25        \u001b[36m4.0348\u001b[0m       0.9384        4.1093  6.9924\n",
      "     26        \u001b[36m4.0335\u001b[0m       0.9368        4.1089  6.7945\n",
      "     27        \u001b[36m4.0330\u001b[0m       0.9381        \u001b[35m4.1071\u001b[0m  6.3390\n",
      "     28        \u001b[36m4.0327\u001b[0m       0.9387        \u001b[35m4.1061\u001b[0m  6.2756\n",
      "     29        \u001b[36m4.0325\u001b[0m       0.9391        \u001b[35m4.1049\u001b[0m  6.2594\n",
      "     30        \u001b[36m4.0323\u001b[0m       0.9397        \u001b[35m4.1040\u001b[0m  6.2903\n",
      "     31        \u001b[36m4.0321\u001b[0m       0.9404        \u001b[35m4.1030\u001b[0m  6.2651\n",
      "     32        \u001b[36m4.0319\u001b[0m       0.9401        \u001b[35m4.1026\u001b[0m  6.2489\n",
      "     33        \u001b[36m4.0317\u001b[0m       \u001b[32m0.9414\u001b[0m        \u001b[35m4.1016\u001b[0m  6.2579\n",
      "     34        \u001b[36m4.0316\u001b[0m       0.9404        \u001b[35m4.1014\u001b[0m  6.2517\n",
      "     35        \u001b[36m4.0315\u001b[0m       0.9401        \u001b[35m4.1011\u001b[0m  6.2661\n",
      "     36        \u001b[36m4.0314\u001b[0m       0.9401        \u001b[35m4.1009\u001b[0m  6.2729\n",
      "     37        \u001b[36m4.0314\u001b[0m       0.9404        \u001b[35m4.1005\u001b[0m  6.2673\n",
      "     38        \u001b[36m4.0313\u001b[0m       0.9401        \u001b[35m4.1004\u001b[0m  6.3206\n",
      "     39        \u001b[36m4.0312\u001b[0m       0.9404        \u001b[35m4.1001\u001b[0m  6.2780\n",
      "     40        \u001b[36m4.0312\u001b[0m       0.9404        \u001b[35m4.1000\u001b[0m  6.2632\n",
      "     41        4.0312       0.9397        4.1007  6.2801\n",
      "     42        \u001b[36m4.0312\u001b[0m       0.9404        \u001b[35m4.0996\u001b[0m  6.2482\n",
      "     43        \u001b[36m4.0311\u001b[0m       0.9391        4.1007  6.2748\n",
      "     44        4.0311       0.9387        4.1002  6.3104\n",
      "     45        \u001b[36m4.0310\u001b[0m       0.9397        \u001b[35m4.0991\u001b[0m  6.3859\n",
      "     46        \u001b[36m4.0310\u001b[0m       0.9401        \u001b[35m4.0989\u001b[0m  6.2828\n",
      "     47        \u001b[36m4.0309\u001b[0m       0.9404        4.0990  6.2969\n",
      "     48        4.0310       0.9401        \u001b[35m4.0985\u001b[0m  6.2313\n",
      "     49        \u001b[36m4.0309\u001b[0m       0.9404        \u001b[35m4.0984\u001b[0m  6.1156\n",
      "     50        \u001b[36m4.0308\u001b[0m       0.9401        \u001b[35m4.0981\u001b[0m  6.2366\n",
      "     51        \u001b[36m4.0308\u001b[0m       0.9411        \u001b[35m4.0980\u001b[0m  6.2600\n",
      "     52        \u001b[36m4.0308\u001b[0m       0.9407        \u001b[35m4.0976\u001b[0m  6.2396\n",
      "     53        \u001b[36m4.0308\u001b[0m       0.9407        \u001b[35m4.0975\u001b[0m  6.2412\n",
      "     54        \u001b[36m4.0308\u001b[0m       0.9411        \u001b[35m4.0974\u001b[0m  6.2670\n",
      "     55        \u001b[36m4.0308\u001b[0m       0.9411        \u001b[35m4.0971\u001b[0m  6.2681\n",
      "     56        \u001b[36m4.0307\u001b[0m       0.9401        4.0975  6.2438\n",
      "     57        \u001b[36m4.0306\u001b[0m       0.9411        \u001b[35m4.0968\u001b[0m  6.2524\n",
      "     58        4.0306       0.9397        4.0968  6.2423\n",
      "     59        \u001b[36m4.0305\u001b[0m       0.9404        \u001b[35m4.0965\u001b[0m  6.2900\n",
      "     60        \u001b[36m4.0305\u001b[0m       0.9407        \u001b[35m4.0964\u001b[0m  6.2649\n",
      "     61        \u001b[36m4.0305\u001b[0m       0.9407        \u001b[35m4.0963\u001b[0m  6.2731\n",
      "     62        \u001b[36m4.0305\u001b[0m       0.9411        \u001b[35m4.0963\u001b[0m  6.2557\n",
      "     63        \u001b[36m4.0305\u001b[0m       \u001b[32m0.9417\u001b[0m        \u001b[35m4.0961\u001b[0m  6.2665\n",
      "     64        \u001b[36m4.0305\u001b[0m       0.9411        \u001b[35m4.0960\u001b[0m  6.2964\n",
      "     65        \u001b[36m4.0305\u001b[0m       0.9417        \u001b[35m4.0958\u001b[0m  6.2918\n",
      "     66        \u001b[36m4.0305\u001b[0m       0.9407        \u001b[35m4.0957\u001b[0m  6.2752\n",
      "     67        \u001b[36m4.0305\u001b[0m       0.9411        \u001b[35m4.0955\u001b[0m  6.2835\n",
      "     68        \u001b[36m4.0305\u001b[0m       0.9417        \u001b[35m4.0955\u001b[0m  6.2656\n",
      "     69        \u001b[36m4.0305\u001b[0m       \u001b[32m0.9421\u001b[0m        \u001b[35m4.0954\u001b[0m  6.2549\n",
      "     70        \u001b[36m4.0305\u001b[0m       0.9417        \u001b[35m4.0953\u001b[0m  6.2511\n",
      "     71        \u001b[36m4.0305\u001b[0m       0.9414        \u001b[35m4.0953\u001b[0m  6.2664\n",
      "     72        \u001b[36m4.0305\u001b[0m       0.9414        \u001b[35m4.0951\u001b[0m  6.2374\n",
      "     73        \u001b[36m4.0305\u001b[0m       0.9421        \u001b[35m4.0950\u001b[0m  6.2660\n",
      "     74        \u001b[36m4.0305\u001b[0m       0.9417        \u001b[35m4.0949\u001b[0m  6.2537\n",
      "     75        \u001b[36m4.0305\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m4.0949\u001b[0m  6.2472\n",
      "     76        \u001b[36m4.0305\u001b[0m       0.9424        \u001b[35m4.0947\u001b[0m  6.2458\n",
      "     77        \u001b[36m4.0304\u001b[0m       0.9417        \u001b[35m4.0946\u001b[0m  6.2712\n",
      "     78        \u001b[36m4.0304\u001b[0m       0.9424        \u001b[35m4.0946\u001b[0m  6.2585\n",
      "     79        \u001b[36m4.0304\u001b[0m       0.9417        \u001b[35m4.0945\u001b[0m  6.2532\n",
      "     80        \u001b[36m4.0304\u001b[0m       0.9417        4.0947  6.2549\n",
      "     81        \u001b[36m4.0304\u001b[0m       0.9414        4.0947  6.2453\n",
      "     82        \u001b[36m4.0304\u001b[0m       0.9414        4.0960  6.2321\n",
      "     83        \u001b[36m4.0304\u001b[0m       0.9387        4.0979  6.2564\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{0.75: 0.9866887417218543, 0.5: 0.9866887417218543, 0.25: 0.9873509933774834, 0.1: 0.9871523178807947, 0.01: 0.9860927152317881}\n",
      "Val accuracy\n",
      "{0.75: 0.9066666666666666, 0.5: 0.9053333333333333, 0.25: 0.9036666666666666, 0.1: 0.9056666666666666, 0.01: 0.9033333333333333}\n",
      "pred time\n",
      "{0.75: 0.49721789360046387, 0.5: 0.42409491539001465, 0.25: 0.37950801849365234, 0.1: 0.3557312488555908, 0.01: 0.35977888107299805}\n",
      "OOS Val Accuracy\n",
      "{0.75: 0.18, 0.5: 0.2, 0.25: 0.27, 0.1: 0.27, 0.01: 0.21}\n",
      "OOS pred time\n",
      "{0.75: 0.014636039733886719, 0.5: 0.014017105102539062, 0.25: 0.012434005737304688, 0.1: 0.012111186981201172, 0.01: 0.010854005813598633}\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "hidden_dim = 800\n",
    "dropout_list = [0.75, 0.5, 0.25, 0.1, 0.01] #adjusting dropout rate\n",
    "for dropout in dropout_list:    #looping for dropouts\n",
    "    print(lr)\n",
    "    class CLINCModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                input_dim=vocab_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim,\n",
    "                dropout=dropout #setting dropout rate\n",
    "        ):\n",
    "            super(CLINCModule, self).__init__()\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "            self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = F.relu(self.hidden(X))\n",
    "            X = self.dropout(X)\n",
    "            X = F.softmax(self.output(X), dim=-1)\n",
    "            return X\n",
    "   \n",
    "    net = NeuralNetClassifier(\n",
    "    module=CLINCModule,\n",
    "    lr=lr,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    max_epochs=1000,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    callbacks=[EarlyStopping(patience=10)],\n",
    "    )\n",
    "    \n",
    "    net.fit(train_x, train_y)\n",
    "    tlabels = net.predict(train_x)\n",
    "    tacc[dropout] = accuracy_score(tlabels, train_y)\n",
    "    print('training accuracy')\n",
    "    print(tacc)\n",
    "    time0 = time.time()\n",
    "    labels = net.predict(val_x)\n",
    "    vacc[dropout] = accuracy_score(labels, val_y)\n",
    "    time1 = time.time()\n",
    "    vtime[dropout] = time1-time0\n",
    "    print('Val accuracy')\n",
    "    print(vacc)\n",
    "    print('pred time')\n",
    "    print(vtime)\n",
    "    time2 = time.time()\n",
    "    olabels = net.predict(val_oos_x)\n",
    "    oacc[dropout] = accuracy_score(olabels, val_oos_y)\n",
    "    time3 = time.time()\n",
    "    otime[dropout]=time3-time2\n",
    "    print('OOS Val Accuracy')\n",
    "    print(oacc)\n",
    "    print('OOS pred time')\n",
    "    print(otime)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0070\u001b[0m        \u001b[35m5.0173\u001b[0m  6.2591\n",
      "      2        \u001b[36m5.0173\u001b[0m       0.0060        5.0173  6.2635\n",
      "      3        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0073\u001b[0m        5.0173  6.2483\n",
      "      4        \u001b[36m5.0173\u001b[0m       0.0063        5.0173  6.2667\n",
      "      5        5.0173       0.0066        5.0173  6.2426\n",
      "      6        5.0173       0.0066        5.0173  6.2644\n",
      "      7        5.0173       0.0066        5.0173  6.2378\n",
      "      8        5.0173       0.0066        5.0173  6.2465\n",
      "      9        \u001b[36m5.0173\u001b[0m       0.0066        \u001b[35m5.0173\u001b[0m  6.2433\n",
      "     10        \u001b[36m5.0173\u001b[0m       0.0066        \u001b[35m5.0173\u001b[0m  6.2304\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{1: 0.006622516556291391}\n",
      "Val accuracy\n",
      "{1: 0.006666666666666667}\n",
      "pred time\n",
      "{1: 0.37184715270996094}\n",
      "OOS Val Accuracy\n",
      "{1: 0.0}\n",
      "OOS pred time\n",
      "{1: 0.01224207878112793}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0168\u001b[0m       \u001b[32m0.6205\u001b[0m        \u001b[35m5.0153\u001b[0m  6.2881\n",
      "      2        \u001b[36m5.0041\u001b[0m       0.3636        \u001b[35m4.9661\u001b[0m  6.2900\n",
      "      3        \u001b[36m4.8768\u001b[0m       0.4821        \u001b[35m4.7404\u001b[0m  6.3123\n",
      "      4        \u001b[36m4.7013\u001b[0m       0.6060        \u001b[35m4.5745\u001b[0m  6.3427\n",
      "      5        \u001b[36m4.5753\u001b[0m       \u001b[32m0.6960\u001b[0m        \u001b[35m4.4589\u001b[0m  6.3097\n",
      "      6        \u001b[36m4.4805\u001b[0m       \u001b[32m0.7503\u001b[0m        \u001b[35m4.3857\u001b[0m  6.3585\n",
      "      7        \u001b[36m4.4164\u001b[0m       \u001b[32m0.7858\u001b[0m        \u001b[35m4.3314\u001b[0m  6.4155\n",
      "      8        \u001b[36m4.3641\u001b[0m       \u001b[32m0.8079\u001b[0m        \u001b[35m4.2924\u001b[0m  6.2775\n",
      "      9        \u001b[36m4.3280\u001b[0m       \u001b[32m0.8159\u001b[0m        \u001b[35m4.2676\u001b[0m  6.2206\n",
      "     10        \u001b[36m4.2987\u001b[0m       \u001b[32m0.8364\u001b[0m        \u001b[35m4.2460\u001b[0m  6.3032\n",
      "     11        \u001b[36m4.2741\u001b[0m       \u001b[32m0.8500\u001b[0m        \u001b[35m4.2277\u001b[0m  6.3139\n",
      "     12        \u001b[36m4.2511\u001b[0m       \u001b[32m0.8609\u001b[0m        \u001b[35m4.2138\u001b[0m  6.4502\n",
      "     13        \u001b[36m4.2329\u001b[0m       \u001b[32m0.8672\u001b[0m        \u001b[35m4.2029\u001b[0m  6.3942\n",
      "     14        \u001b[36m4.2189\u001b[0m       \u001b[32m0.8798\u001b[0m        \u001b[35m4.1923\u001b[0m  6.4263\n",
      "     15        \u001b[36m4.2037\u001b[0m       \u001b[32m0.8911\u001b[0m        \u001b[35m4.1797\u001b[0m  6.4531\n",
      "     16        \u001b[36m4.1892\u001b[0m       \u001b[32m0.9007\u001b[0m        \u001b[35m4.1697\u001b[0m  6.4554\n",
      "     17        \u001b[36m4.1774\u001b[0m       \u001b[32m0.9056\u001b[0m        \u001b[35m4.1607\u001b[0m  6.4734\n",
      "     18        \u001b[36m4.1688\u001b[0m       \u001b[32m0.9060\u001b[0m        \u001b[35m4.1547\u001b[0m  6.4984\n",
      "     19        \u001b[36m4.1584\u001b[0m       \u001b[32m0.9109\u001b[0m        \u001b[35m4.1493\u001b[0m  6.5144\n",
      "     20        \u001b[36m4.1485\u001b[0m       \u001b[32m0.9182\u001b[0m        \u001b[35m4.1421\u001b[0m  6.5158\n",
      "     21        \u001b[36m4.1404\u001b[0m       \u001b[32m0.9189\u001b[0m        \u001b[35m4.1377\u001b[0m  6.4967\n",
      "     22        \u001b[36m4.1332\u001b[0m       \u001b[32m0.9215\u001b[0m        \u001b[35m4.1344\u001b[0m  6.5130\n",
      "     23        \u001b[36m4.1301\u001b[0m       \u001b[32m0.9225\u001b[0m        \u001b[35m4.1320\u001b[0m  6.5142\n",
      "     24        \u001b[36m4.1244\u001b[0m       0.9225        \u001b[35m4.1302\u001b[0m  6.5289\n",
      "     25        \u001b[36m4.1192\u001b[0m       \u001b[32m0.9245\u001b[0m        \u001b[35m4.1284\u001b[0m  7.0699\n",
      "     26        \u001b[36m4.1162\u001b[0m       0.9228        \u001b[35m4.1270\u001b[0m  6.5518\n",
      "     27        \u001b[36m4.1129\u001b[0m       0.9235        \u001b[35m4.1262\u001b[0m  6.5060\n",
      "     28        \u001b[36m4.1084\u001b[0m       \u001b[32m0.9255\u001b[0m        \u001b[35m4.1247\u001b[0m  6.5249\n",
      "     29        \u001b[36m4.1059\u001b[0m       \u001b[32m0.9281\u001b[0m        \u001b[35m4.1226\u001b[0m  6.5754\n",
      "     30        \u001b[36m4.1014\u001b[0m       \u001b[32m0.9305\u001b[0m        \u001b[35m4.1207\u001b[0m  6.5321\n",
      "     31        \u001b[36m4.0976\u001b[0m       0.9301        \u001b[35m4.1192\u001b[0m  6.5312\n",
      "     32        \u001b[36m4.0950\u001b[0m       0.9291        \u001b[35m4.1182\u001b[0m  6.5268\n",
      "     33        \u001b[36m4.0909\u001b[0m       0.9305        \u001b[35m4.1171\u001b[0m  6.5434\n",
      "     34        \u001b[36m4.0903\u001b[0m       \u001b[32m0.9325\u001b[0m        \u001b[35m4.1158\u001b[0m  6.5434\n",
      "     35        \u001b[36m4.0837\u001b[0m       0.9318        \u001b[35m4.1146\u001b[0m  6.5486\n",
      "     36        4.0848       \u001b[32m0.9351\u001b[0m        \u001b[35m4.1131\u001b[0m  6.5791\n",
      "     37        4.0840       \u001b[32m0.9381\u001b[0m        \u001b[35m4.1114\u001b[0m  6.5595\n",
      "     38        \u001b[36m4.0805\u001b[0m       0.9361        \u001b[35m4.1104\u001b[0m  6.5438\n",
      "     39        \u001b[36m4.0764\u001b[0m       \u001b[32m0.9387\u001b[0m        \u001b[35m4.1091\u001b[0m  6.5809\n",
      "     40        \u001b[36m4.0754\u001b[0m       0.9384        \u001b[35m4.1081\u001b[0m  6.5287\n",
      "     41        \u001b[36m4.0727\u001b[0m       0.9381        \u001b[35m4.1080\u001b[0m  6.5581\n",
      "     42        \u001b[36m4.0709\u001b[0m       0.9387        \u001b[35m4.1066\u001b[0m  6.5875\n",
      "     43        \u001b[36m4.0704\u001b[0m       \u001b[32m0.9417\u001b[0m        \u001b[35m4.1060\u001b[0m  6.6639\n",
      "     44        4.0708       0.9414        \u001b[35m4.1052\u001b[0m  6.6925\n",
      "     45        \u001b[36m4.0674\u001b[0m       0.9411        \u001b[35m4.1046\u001b[0m  6.5435\n",
      "     46        \u001b[36m4.0656\u001b[0m       0.9414        \u001b[35m4.1040\u001b[0m  6.4857\n",
      "     47        \u001b[36m4.0648\u001b[0m       0.9401        \u001b[35m4.1040\u001b[0m  6.4683\n",
      "     48        \u001b[36m4.0638\u001b[0m       0.9411        \u001b[35m4.1031\u001b[0m  6.5223\n",
      "     49        \u001b[36m4.0634\u001b[0m       0.9407        \u001b[35m4.1028\u001b[0m  6.5351\n",
      "     50        \u001b[36m4.0614\u001b[0m       0.9407        \u001b[35m4.1024\u001b[0m  6.5305\n",
      "     51        \u001b[36m4.0608\u001b[0m       0.9417        \u001b[35m4.1023\u001b[0m  6.5400\n",
      "     52        4.0614       0.9407        \u001b[35m4.1023\u001b[0m  6.5590\n",
      "     53        \u001b[36m4.0597\u001b[0m       0.9384        4.1024  6.5456\n",
      "     54        \u001b[36m4.0594\u001b[0m       0.9397        \u001b[35m4.1017\u001b[0m  6.5500\n",
      "     55        \u001b[36m4.0573\u001b[0m       0.9397        \u001b[35m4.1015\u001b[0m  6.5670\n",
      "     56        \u001b[36m4.0569\u001b[0m       0.9394        \u001b[35m4.1014\u001b[0m  6.5666\n",
      "     57        \u001b[36m4.0565\u001b[0m       0.9404        \u001b[35m4.1010\u001b[0m  6.5348\n",
      "     58        4.0567       0.9401        \u001b[35m4.1007\u001b[0m  6.5300\n",
      "     59        \u001b[36m4.0546\u001b[0m       0.9394        4.1008  6.5369\n",
      "     60        4.0553       0.9397        \u001b[35m4.1002\u001b[0m  6.5568\n",
      "     61        \u001b[36m4.0537\u001b[0m       0.9404        \u001b[35m4.0997\u001b[0m  6.5597\n",
      "     62        \u001b[36m4.0532\u001b[0m       0.9407        \u001b[35m4.0996\u001b[0m  6.6409\n",
      "     63        \u001b[36m4.0529\u001b[0m       0.9414        \u001b[35m4.0993\u001b[0m  6.5812\n",
      "     64        \u001b[36m4.0514\u001b[0m       0.9407        4.0996  6.5648\n",
      "     65        \u001b[36m4.0509\u001b[0m       0.9411        4.0996  6.5823\n",
      "     66        4.0513       0.9414        \u001b[35m4.0988\u001b[0m  6.5777\n",
      "     67        \u001b[36m4.0506\u001b[0m       0.9411        4.0989  6.5668\n",
      "     68        \u001b[36m4.0499\u001b[0m       0.9404        4.0990  6.8632\n",
      "     69        4.0501       0.9404        \u001b[35m4.0988\u001b[0m  6.9379\n",
      "     70        4.0500       0.9394        \u001b[35m4.0982\u001b[0m  6.9351\n",
      "     71        \u001b[36m4.0491\u001b[0m       0.9391        4.0987  6.9442\n",
      "     72        \u001b[36m4.0488\u001b[0m       0.9411        \u001b[35m4.0980\u001b[0m  6.8955\n",
      "     73        \u001b[36m4.0481\u001b[0m       \u001b[32m0.9421\u001b[0m        \u001b[35m4.0977\u001b[0m  7.2480\n",
      "     74        \u001b[36m4.0466\u001b[0m       0.9417        \u001b[35m4.0974\u001b[0m  6.5202\n",
      "     75        4.0469       \u001b[32m0.9437\u001b[0m        \u001b[35m4.0968\u001b[0m  6.2827\n",
      "     76        4.0469       0.9427        4.0969  7.3586\n",
      "     77        \u001b[36m4.0462\u001b[0m       0.9427        4.0970  6.8091\n",
      "     78        4.0474       0.9430        4.0972  6.6666\n",
      "     79        4.0463       0.9427        \u001b[35m4.0966\u001b[0m  6.6807\n",
      "     80        \u001b[36m4.0455\u001b[0m       0.9421        4.0969  6.6327\n",
      "     81        \u001b[36m4.0447\u001b[0m       0.9421        \u001b[35m4.0962\u001b[0m  6.6462\n",
      "     82        4.0461       0.9437        \u001b[35m4.0957\u001b[0m  6.7046\n",
      "     83        \u001b[36m4.0434\u001b[0m       0.9430        4.0959  6.9079\n",
      "     84        4.0449       0.9414        4.0964  7.0346\n",
      "     85        4.0440       0.9421        4.0959  6.9320\n",
      "     86        4.0444       0.9417        4.0959  6.9007\n",
      "     87        4.0435       0.9434        \u001b[35m4.0954\u001b[0m  6.7127\n",
      "     88        \u001b[36m4.0429\u001b[0m       0.9421        \u001b[35m4.0948\u001b[0m  6.8938\n",
      "     89        4.0432       0.9427        4.0949  7.0103\n",
      "     90        4.0429       0.9427        \u001b[35m4.0945\u001b[0m  6.9735\n",
      "     91        \u001b[36m4.0424\u001b[0m       0.9394        4.0957  6.9600\n",
      "     92        4.0431       0.9401        4.0961  7.2508\n",
      "     93        \u001b[36m4.0423\u001b[0m       0.9414        4.0954  6.9602\n",
      "     94        \u001b[36m4.0418\u001b[0m       0.9414        4.0952  6.6699\n",
      "     95        4.0419       0.9411        4.0948  6.7121\n",
      "     96        4.0431       0.9421        4.0947  6.6065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     97        4.0419       0.9417        \u001b[35m4.0944\u001b[0m  6.5697\n",
      "     98        4.0419       0.9421        \u001b[35m4.0941\u001b[0m  6.7414\n",
      "     99        \u001b[36m4.0407\u001b[0m       0.9437        \u001b[35m4.0941\u001b[0m  6.6712\n",
      "    100        \u001b[36m4.0404\u001b[0m       \u001b[32m0.9440\u001b[0m        4.0942  6.7380\n",
      "    101        4.0408       0.9434        4.0941  6.5589\n",
      "    102        4.0407       \u001b[32m0.9444\u001b[0m        4.0941  6.6832\n",
      "    103        \u001b[36m4.0402\u001b[0m       0.9427        4.0941  6.6383\n",
      "    104        \u001b[36m4.0396\u001b[0m       0.9427        \u001b[35m4.0938\u001b[0m  6.6133\n",
      "    105        \u001b[36m4.0395\u001b[0m       0.9404        4.0940  6.6393\n",
      "    106        4.0399       0.9414        \u001b[35m4.0932\u001b[0m  6.7592\n",
      "    107        4.0396       0.9414        4.0935  6.7308\n",
      "    108        4.0402       0.9421        \u001b[35m4.0930\u001b[0m  6.6406\n",
      "    109        4.0396       0.9417        4.0936  6.9146\n",
      "    110        4.0397       0.9440        4.0936  6.6158\n",
      "    111        \u001b[36m4.0394\u001b[0m       0.9414        4.0938  6.5966\n",
      "    112        \u001b[36m4.0392\u001b[0m       0.9394        4.0939  6.5071\n",
      "    113        4.0398       0.9407        4.0938  6.5118\n",
      "    114        \u001b[36m4.0391\u001b[0m       0.9414        4.0933  6.5192\n",
      "    115        \u001b[36m4.0384\u001b[0m       0.9430        4.0933  6.5657\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{1: 0.006622516556291391, 0.9: 0.986158940397351}\n",
      "Val accuracy\n",
      "{1: 0.006666666666666667, 0.9: 0.9053333333333333}\n",
      "pred time\n",
      "{1: 0.37184715270996094, 0.9: 0.3441929817199707}\n",
      "OOS Val Accuracy\n",
      "{1: 0.0, 0.9: 0.21}\n",
      "OOS pred time\n",
      "{1: 0.01224207878112793, 0.9: 0.01036524772644043}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0161\u001b[0m       \u001b[32m0.6033\u001b[0m        \u001b[35m5.0125\u001b[0m  6.3328\n",
      "      2        \u001b[36m4.9470\u001b[0m       0.4334        \u001b[35m4.7937\u001b[0m  6.3403\n",
      "      3        \u001b[36m4.6665\u001b[0m       \u001b[32m0.6374\u001b[0m        \u001b[35m4.5320\u001b[0m  6.3004\n",
      "      4        \u001b[36m4.4721\u001b[0m       \u001b[32m0.7411\u001b[0m        \u001b[35m4.3923\u001b[0m  6.2806\n",
      "      5        \u001b[36m4.3601\u001b[0m       \u001b[32m0.8000\u001b[0m        \u001b[35m4.3140\u001b[0m  6.2809\n",
      "      6        \u001b[36m4.2943\u001b[0m       \u001b[32m0.8278\u001b[0m        \u001b[35m4.2703\u001b[0m  6.2863\n",
      "      7        \u001b[36m4.2528\u001b[0m       \u001b[32m0.8450\u001b[0m        \u001b[35m4.2394\u001b[0m  6.2802\n",
      "      8        \u001b[36m4.2219\u001b[0m       \u001b[32m0.8636\u001b[0m        \u001b[35m4.2179\u001b[0m  6.2093\n",
      "      9        \u001b[36m4.1964\u001b[0m       \u001b[32m0.8672\u001b[0m        \u001b[35m4.2043\u001b[0m  6.1913\n",
      "     10        \u001b[36m4.1795\u001b[0m       \u001b[32m0.8834\u001b[0m        \u001b[35m4.1897\u001b[0m  6.1790\n",
      "     11        \u001b[36m4.1598\u001b[0m       \u001b[32m0.8980\u001b[0m        \u001b[35m4.1732\u001b[0m  6.2148\n",
      "     12        \u001b[36m4.1432\u001b[0m       \u001b[32m0.8990\u001b[0m        \u001b[35m4.1639\u001b[0m  6.3068\n",
      "     13        \u001b[36m4.1305\u001b[0m       \u001b[32m0.9056\u001b[0m        \u001b[35m4.1558\u001b[0m  6.3456\n",
      "     14        \u001b[36m4.1214\u001b[0m       \u001b[32m0.9123\u001b[0m        \u001b[35m4.1489\u001b[0m  6.4424\n",
      "     15        \u001b[36m4.1097\u001b[0m       \u001b[32m0.9192\u001b[0m        \u001b[35m4.1409\u001b[0m  6.6581\n",
      "     16        \u001b[36m4.1002\u001b[0m       \u001b[32m0.9232\u001b[0m        \u001b[35m4.1353\u001b[0m  7.1847\n",
      "     17        \u001b[36m4.0930\u001b[0m       \u001b[32m0.9272\u001b[0m        \u001b[35m4.1315\u001b[0m  7.1850\n",
      "     18        \u001b[36m4.0862\u001b[0m       \u001b[32m0.9308\u001b[0m        \u001b[35m4.1259\u001b[0m  7.2885\n",
      "     19        \u001b[36m4.0799\u001b[0m       \u001b[32m0.9311\u001b[0m        \u001b[35m4.1240\u001b[0m  7.2182\n",
      "     20        \u001b[36m4.0754\u001b[0m       \u001b[32m0.9325\u001b[0m        \u001b[35m4.1213\u001b[0m  7.4512\n",
      "     21        \u001b[36m4.0710\u001b[0m       \u001b[32m0.9344\u001b[0m        \u001b[35m4.1194\u001b[0m  7.6193\n",
      "     22        \u001b[36m4.0662\u001b[0m       \u001b[32m0.9397\u001b[0m        \u001b[35m4.1161\u001b[0m  7.2114\n",
      "     23        \u001b[36m4.0629\u001b[0m       0.9391        \u001b[35m4.1137\u001b[0m  7.2633\n",
      "     24        \u001b[36m4.0592\u001b[0m       \u001b[32m0.9414\u001b[0m        \u001b[35m4.1116\u001b[0m  6.6123\n",
      "     25        \u001b[36m4.0564\u001b[0m       0.9377        \u001b[35m4.1104\u001b[0m  6.8842\n",
      "     26        \u001b[36m4.0541\u001b[0m       0.9407        \u001b[35m4.1087\u001b[0m  6.9398\n",
      "     27        \u001b[36m4.0524\u001b[0m       \u001b[32m0.9417\u001b[0m        \u001b[35m4.1072\u001b[0m  6.5391\n",
      "     28        \u001b[36m4.0509\u001b[0m       \u001b[32m0.9434\u001b[0m        \u001b[35m4.1063\u001b[0m  6.6098\n",
      "     29        \u001b[36m4.0491\u001b[0m       \u001b[32m0.9440\u001b[0m        \u001b[35m4.1055\u001b[0m  6.4659\n",
      "     30        \u001b[36m4.0471\u001b[0m       0.9430        \u001b[35m4.1046\u001b[0m  6.5283\n",
      "     31        \u001b[36m4.0468\u001b[0m       0.9430        \u001b[35m4.1034\u001b[0m  6.4124\n",
      "     32        \u001b[36m4.0457\u001b[0m       0.9434        \u001b[35m4.1030\u001b[0m  6.4018\n",
      "     33        \u001b[36m4.0449\u001b[0m       0.9437        \u001b[35m4.1021\u001b[0m  6.4161\n",
      "     34        \u001b[36m4.0434\u001b[0m       0.9440        \u001b[35m4.1018\u001b[0m  6.3944\n",
      "     35        \u001b[36m4.0425\u001b[0m       \u001b[32m0.9450\u001b[0m        \u001b[35m4.1012\u001b[0m  6.4280\n",
      "     36        \u001b[36m4.0425\u001b[0m       0.9437        4.1012  6.4106\n",
      "     37        \u001b[36m4.0415\u001b[0m       \u001b[32m0.9454\u001b[0m        \u001b[35m4.1006\u001b[0m  6.4197\n",
      "     38        \u001b[36m4.0406\u001b[0m       0.9444        \u001b[35m4.1004\u001b[0m  6.5327\n",
      "     39        \u001b[36m4.0405\u001b[0m       \u001b[32m0.9460\u001b[0m        \u001b[35m4.0991\u001b[0m  6.6656\n",
      "     40        \u001b[36m4.0396\u001b[0m       0.9447        4.0991  6.9605\n",
      "     41        \u001b[36m4.0394\u001b[0m       0.9450        \u001b[35m4.0990\u001b[0m  6.5777\n",
      "     42        \u001b[36m4.0394\u001b[0m       0.9450        \u001b[35m4.0984\u001b[0m  6.7809\n",
      "     43        \u001b[36m4.0384\u001b[0m       \u001b[32m0.9464\u001b[0m        \u001b[35m4.0980\u001b[0m  6.9180\n",
      "     44        \u001b[36m4.0382\u001b[0m       0.9454        \u001b[35m4.0979\u001b[0m  6.6897\n",
      "     45        \u001b[36m4.0377\u001b[0m       0.9454        \u001b[35m4.0973\u001b[0m  7.0853\n",
      "     46        \u001b[36m4.0373\u001b[0m       0.9447        \u001b[35m4.0973\u001b[0m  6.6131\n",
      "     47        4.0375       0.9457        4.0977  6.5507\n",
      "     48        \u001b[36m4.0372\u001b[0m       0.9450        \u001b[35m4.0972\u001b[0m  7.0131\n",
      "     49        \u001b[36m4.0371\u001b[0m       \u001b[32m0.9467\u001b[0m        \u001b[35m4.0969\u001b[0m  7.2018\n",
      "     50        \u001b[36m4.0360\u001b[0m       0.9434        4.0970  7.4262\n",
      "     51        4.0363       0.9450        \u001b[35m4.0965\u001b[0m  7.3020\n",
      "     52        4.0363       0.9447        \u001b[35m4.0957\u001b[0m  6.6753\n",
      "     53        4.0367       0.9450        4.0963  6.5127\n",
      "     54        \u001b[36m4.0356\u001b[0m       0.9450        \u001b[35m4.0954\u001b[0m  6.4910\n",
      "     55        \u001b[36m4.0352\u001b[0m       0.9454        \u001b[35m4.0945\u001b[0m  6.7372\n",
      "     56        4.0353       0.9454        4.0947  6.8283\n",
      "     57        4.0354       0.9437        4.0953  6.8068\n",
      "     58        \u001b[36m4.0345\u001b[0m       0.9460        4.0952  6.8070\n",
      "     59        4.0348       0.9464        \u001b[35m4.0944\u001b[0m  6.9756\n",
      "     60        4.0346       0.9460        4.0946  6.5198\n",
      "     61        \u001b[36m4.0343\u001b[0m       0.9457        \u001b[35m4.0942\u001b[0m  6.5301\n",
      "     62        \u001b[36m4.0343\u001b[0m       \u001b[32m0.9470\u001b[0m        \u001b[35m4.0940\u001b[0m  6.5706\n",
      "     63        4.0345       0.9470        \u001b[35m4.0938\u001b[0m  6.5164\n",
      "     64        4.0343       0.9447        \u001b[35m4.0936\u001b[0m  6.4698\n",
      "     65        \u001b[36m4.0340\u001b[0m       0.9457        4.0939  6.3991\n",
      "     66        4.0342       0.9464        \u001b[35m4.0935\u001b[0m  6.4619\n",
      "     67        \u001b[36m4.0336\u001b[0m       0.9467        \u001b[35m4.0929\u001b[0m  6.4838\n",
      "     68        \u001b[36m4.0334\u001b[0m       0.9460        4.0936  6.3799\n",
      "     69        \u001b[36m4.0334\u001b[0m       0.9470        \u001b[35m4.0928\u001b[0m  6.3901\n",
      "     70        \u001b[36m4.0334\u001b[0m       \u001b[32m0.9480\u001b[0m        \u001b[35m4.0921\u001b[0m  6.4416\n",
      "     71        4.0338       0.9464        4.0926  6.4397\n",
      "     72        4.0334       0.9464        4.0927  6.3742\n",
      "     73        \u001b[36m4.0329\u001b[0m       0.9457        4.0930  6.3928\n",
      "     74        4.0333       0.9474        \u001b[35m4.0920\u001b[0m  6.4019\n",
      "     75        4.0332       0.9480        4.0921  6.3742\n",
      "     76        4.0329       0.9450        4.0925  6.3697\n",
      "     77        4.0330       0.9467        \u001b[35m4.0914\u001b[0m  6.3865\n",
      "     78        4.0332       0.9460        4.0916  6.3959\n",
      "     79        \u001b[36m4.0328\u001b[0m       0.9467        4.0917  6.3848\n",
      "     80        \u001b[36m4.0328\u001b[0m       0.9454        4.0924  6.4739\n",
      "     81        \u001b[36m4.0324\u001b[0m       0.9464        4.0922  6.0671\n",
      "     82        4.0325       0.9477        4.0921  6.3780\n",
      "     83        4.0325       0.9450        4.0927  6.3775\n",
      "     84        4.0325       0.9450        4.0921  6.3724\n",
      "     85        \u001b[36m4.0323\u001b[0m       0.9467        4.0919  6.3731\n",
      "     86        \u001b[36m4.0322\u001b[0m       0.9470        4.0917  6.3578\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{1: 0.006622516556291391, 0.9: 0.986158940397351, 0.8: 0.9876158940397352}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy\n",
      "{1: 0.006666666666666667, 0.9: 0.9053333333333333, 0.8: 0.9046666666666666}\n",
      "pred time\n",
      "{1: 0.37184715270996094, 0.9: 0.3441929817199707, 0.8: 0.36145877838134766}\n",
      "OOS Val Accuracy\n",
      "{1: 0.0, 0.9: 0.21, 0.8: 0.2}\n",
      "OOS pred time\n",
      "{1: 0.01224207878112793, 0.9: 0.01036524772644043, 0.8: 0.01233983039855957}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0019\u001b[0m       \u001b[32m0.3301\u001b[0m        \u001b[35m4.8913\u001b[0m  6.1668\n",
      "      2        \u001b[36m4.6103\u001b[0m       \u001b[32m0.6781\u001b[0m        \u001b[35m4.4432\u001b[0m  6.1750\n",
      "      3        \u001b[36m4.3458\u001b[0m       \u001b[32m0.7884\u001b[0m        \u001b[35m4.3179\u001b[0m  6.2022\n",
      "      4        \u001b[36m4.2375\u001b[0m       \u001b[32m0.8222\u001b[0m        \u001b[35m4.2582\u001b[0m  6.2215\n",
      "      5        \u001b[36m4.1896\u001b[0m       \u001b[32m0.8384\u001b[0m        \u001b[35m4.2339\u001b[0m  6.2444\n",
      "      6        \u001b[36m4.1660\u001b[0m       \u001b[32m0.8606\u001b[0m        \u001b[35m4.2146\u001b[0m  6.2118\n",
      "      7        \u001b[36m4.1396\u001b[0m       \u001b[32m0.8825\u001b[0m        \u001b[35m4.1958\u001b[0m  6.2041\n",
      "      8        \u001b[36m4.1135\u001b[0m       \u001b[32m0.8911\u001b[0m        \u001b[35m4.1750\u001b[0m  6.2062\n",
      "      9        \u001b[36m4.0982\u001b[0m       \u001b[32m0.8980\u001b[0m        \u001b[35m4.1637\u001b[0m  6.1601\n",
      "     10        \u001b[36m4.0895\u001b[0m       \u001b[32m0.9089\u001b[0m        \u001b[35m4.1540\u001b[0m  6.1890\n",
      "     11        \u001b[36m4.0786\u001b[0m       \u001b[32m0.9096\u001b[0m        \u001b[35m4.1486\u001b[0m  6.1965\n",
      "     12        \u001b[36m4.0717\u001b[0m       \u001b[32m0.9159\u001b[0m        \u001b[35m4.1394\u001b[0m  6.2162\n",
      "     13        \u001b[36m4.0644\u001b[0m       \u001b[32m0.9166\u001b[0m        \u001b[35m4.1391\u001b[0m  6.1811\n",
      "     14        \u001b[36m4.0567\u001b[0m       \u001b[32m0.9232\u001b[0m        \u001b[35m4.1318\u001b[0m  6.1863\n",
      "     15        \u001b[36m4.0503\u001b[0m       \u001b[32m0.9278\u001b[0m        \u001b[35m4.1281\u001b[0m  6.1879\n",
      "     16        \u001b[36m4.0443\u001b[0m       \u001b[32m0.9318\u001b[0m        \u001b[35m4.1201\u001b[0m  6.1718\n",
      "     17        \u001b[36m4.0422\u001b[0m       \u001b[32m0.9328\u001b[0m        \u001b[35m4.1173\u001b[0m  6.1939\n",
      "     18        \u001b[36m4.0411\u001b[0m       \u001b[32m0.9331\u001b[0m        \u001b[35m4.1156\u001b[0m  6.3120\n",
      "     19        \u001b[36m4.0404\u001b[0m       0.9331        \u001b[35m4.1141\u001b[0m  6.1949\n",
      "     20        \u001b[36m4.0400\u001b[0m       \u001b[32m0.9351\u001b[0m        \u001b[35m4.1131\u001b[0m  6.2033\n",
      "     21        \u001b[36m4.0396\u001b[0m       \u001b[32m0.9364\u001b[0m        \u001b[35m4.1118\u001b[0m  6.1421\n",
      "     22        \u001b[36m4.0393\u001b[0m       \u001b[32m0.9371\u001b[0m        \u001b[35m4.1106\u001b[0m  6.1676\n",
      "     23        \u001b[36m4.0392\u001b[0m       0.9371        \u001b[35m4.1096\u001b[0m  6.1517\n",
      "     24        \u001b[36m4.0390\u001b[0m       0.9371        \u001b[35m4.1089\u001b[0m  6.1417\n",
      "     25        \u001b[36m4.0386\u001b[0m       0.9364        4.1100  6.0972\n",
      "     26        \u001b[36m4.0354\u001b[0m       \u001b[32m0.9387\u001b[0m        \u001b[35m4.1081\u001b[0m  6.1663\n",
      "     27        \u001b[36m4.0338\u001b[0m       0.9348        4.1100  6.2150\n",
      "     28        \u001b[36m4.0331\u001b[0m       0.9381        \u001b[35m4.1078\u001b[0m  6.1850\n",
      "     29        \u001b[36m4.0327\u001b[0m       \u001b[32m0.9394\u001b[0m        \u001b[35m4.1064\u001b[0m  6.1790\n",
      "     30        \u001b[36m4.0324\u001b[0m       0.9384        \u001b[35m4.1052\u001b[0m  6.1570\n",
      "     31        \u001b[36m4.0321\u001b[0m       0.9391        \u001b[35m4.1044\u001b[0m  6.1586\n",
      "     32        \u001b[36m4.0319\u001b[0m       0.9394        \u001b[35m4.1036\u001b[0m  6.2214\n",
      "     33        \u001b[36m4.0318\u001b[0m       0.9394        \u001b[35m4.1031\u001b[0m  6.1523\n",
      "     34        \u001b[36m4.0316\u001b[0m       \u001b[32m0.9397\u001b[0m        4.1031  6.1560\n",
      "     35        \u001b[36m4.0315\u001b[0m       \u001b[32m0.9404\u001b[0m        \u001b[35m4.1024\u001b[0m  6.1673\n",
      "     36        \u001b[36m4.0312\u001b[0m       \u001b[32m0.9414\u001b[0m        \u001b[35m4.1019\u001b[0m  6.1686\n",
      "     37        \u001b[36m4.0312\u001b[0m       0.9414        \u001b[35m4.1015\u001b[0m  6.1724\n",
      "     38        \u001b[36m4.0312\u001b[0m       \u001b[32m0.9421\u001b[0m        \u001b[35m4.1012\u001b[0m  6.1848\n",
      "     39        \u001b[36m4.0311\u001b[0m       0.9414        \u001b[35m4.1009\u001b[0m  6.1781\n",
      "     40        \u001b[36m4.0311\u001b[0m       0.9414        \u001b[35m4.1007\u001b[0m  6.1754\n",
      "     41        \u001b[36m4.0310\u001b[0m       0.9414        \u001b[35m4.1004\u001b[0m  6.1315\n",
      "     42        \u001b[36m4.0309\u001b[0m       0.9417        \u001b[35m4.1000\u001b[0m  6.1935\n",
      "     43        \u001b[36m4.0309\u001b[0m       0.9421        \u001b[35m4.0995\u001b[0m  6.1816\n",
      "     44        \u001b[36m4.0308\u001b[0m       0.9421        \u001b[35m4.0992\u001b[0m  6.1868\n",
      "     45        \u001b[36m4.0308\u001b[0m       0.9421        \u001b[35m4.0990\u001b[0m  6.1759\n",
      "     46        \u001b[36m4.0308\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m4.0988\u001b[0m  6.2940\n",
      "     47        \u001b[36m4.0308\u001b[0m       0.9424        \u001b[35m4.0986\u001b[0m  6.1291\n",
      "     48        \u001b[36m4.0308\u001b[0m       0.9424        \u001b[35m4.0984\u001b[0m  6.1381\n",
      "     49        \u001b[36m4.0308\u001b[0m       0.9424        \u001b[35m4.0982\u001b[0m  6.1648\n",
      "     50        \u001b[36m4.0307\u001b[0m       0.9424        \u001b[35m4.0980\u001b[0m  6.1535\n",
      "     51        \u001b[36m4.0307\u001b[0m       0.9424        \u001b[35m4.0978\u001b[0m  6.1989\n",
      "     52        \u001b[36m4.0307\u001b[0m       0.9424        \u001b[35m4.0976\u001b[0m  6.1802\n",
      "     53        \u001b[36m4.0307\u001b[0m       0.9424        \u001b[35m4.0975\u001b[0m  6.1819\n",
      "     54        \u001b[36m4.0307\u001b[0m       \u001b[32m0.9427\u001b[0m        \u001b[35m4.0973\u001b[0m  6.1845\n",
      "     55        \u001b[36m4.0307\u001b[0m       0.9427        \u001b[35m4.0971\u001b[0m  6.1549\n",
      "     56        \u001b[36m4.0307\u001b[0m       0.9427        \u001b[35m4.0969\u001b[0m  6.1670\n",
      "     57        \u001b[36m4.0307\u001b[0m       0.9427        \u001b[35m4.0967\u001b[0m  6.1581\n",
      "     58        \u001b[36m4.0307\u001b[0m       0.9427        \u001b[35m4.0965\u001b[0m  6.1869\n",
      "     59        \u001b[36m4.0307\u001b[0m       \u001b[32m0.9434\u001b[0m        \u001b[35m4.0963\u001b[0m  6.3031\n",
      "     60        4.0307       0.9424        4.0966  6.1730\n",
      "     61        \u001b[36m4.0306\u001b[0m       0.9414        4.0981  6.1497\n",
      "     62        \u001b[36m4.0306\u001b[0m       0.9424        4.0975  6.2044\n",
      "     63        \u001b[36m4.0305\u001b[0m       0.9430        4.0964  6.3995\n",
      "     64        \u001b[36m4.0305\u001b[0m       0.9434        \u001b[35m4.0962\u001b[0m  6.3924\n",
      "     65        \u001b[36m4.0305\u001b[0m       \u001b[32m0.9440\u001b[0m        \u001b[35m4.0960\u001b[0m  6.6044\n",
      "     66        \u001b[36m4.0305\u001b[0m       0.9440        \u001b[35m4.0958\u001b[0m  6.1651\n",
      "     67        \u001b[36m4.0305\u001b[0m       0.9437        \u001b[35m4.0957\u001b[0m  6.1845\n",
      "     68        \u001b[36m4.0305\u001b[0m       0.9437        \u001b[35m4.0957\u001b[0m  6.3041\n",
      "     69        \u001b[36m4.0305\u001b[0m       0.9434        \u001b[35m4.0955\u001b[0m  6.1724\n",
      "     70        \u001b[36m4.0305\u001b[0m       0.9434        \u001b[35m4.0953\u001b[0m  6.2223\n",
      "     71        4.0305       0.9417        4.0972  6.1532\n",
      "     72        \u001b[36m4.0305\u001b[0m       0.9424        4.0961  6.2349\n",
      "     73        \u001b[36m4.0304\u001b[0m       0.9430        4.0959  6.2243\n",
      "     74        \u001b[36m4.0303\u001b[0m       0.9427        4.0957  6.1591\n",
      "     75        \u001b[36m4.0303\u001b[0m       0.9427        \u001b[35m4.0952\u001b[0m  6.1481\n",
      "     76        \u001b[36m4.0303\u001b[0m       0.9434        4.0952  6.1394\n",
      "     77        \u001b[36m4.0303\u001b[0m       0.9430        \u001b[35m4.0950\u001b[0m  6.1801\n",
      "     78        \u001b[36m4.0303\u001b[0m       0.9430        \u001b[35m4.0949\u001b[0m  6.1768\n",
      "     79        \u001b[36m4.0303\u001b[0m       0.9430        \u001b[35m4.0948\u001b[0m  6.1312\n",
      "     80        \u001b[36m4.0303\u001b[0m       0.9430        \u001b[35m4.0947\u001b[0m  6.1806\n",
      "     81        \u001b[36m4.0303\u001b[0m       0.9430        \u001b[35m4.0946\u001b[0m  6.1401\n",
      "     82        \u001b[36m4.0303\u001b[0m       0.9427        \u001b[35m4.0945\u001b[0m  6.1798\n",
      "     83        \u001b[36m4.0303\u001b[0m       0.9427        \u001b[35m4.0945\u001b[0m  6.1594\n",
      "     84        \u001b[36m4.0303\u001b[0m       0.9427        \u001b[35m4.0944\u001b[0m  5.2874\n",
      "     85        \u001b[36m4.0303\u001b[0m       0.9427        \u001b[35m4.0943\u001b[0m  6.1995\n",
      "     86        \u001b[36m4.0303\u001b[0m       0.9427        4.0943  6.3452\n",
      "     87        4.0303       0.9377        4.0989  6.1861\n",
      "     88        4.0305       0.9421        4.0946  6.2094\n",
      "     89        \u001b[36m4.0302\u001b[0m       0.9424        \u001b[35m4.0941\u001b[0m  6.2090\n",
      "     90        \u001b[36m4.0302\u001b[0m       0.9424        \u001b[35m4.0940\u001b[0m  6.2928\n",
      "     91        \u001b[36m4.0302\u001b[0m       0.9424        \u001b[35m4.0939\u001b[0m  6.1610\n",
      "     92        \u001b[36m4.0302\u001b[0m       0.9424        \u001b[35m4.0938\u001b[0m  6.1637\n",
      "     93        \u001b[36m4.0302\u001b[0m       0.9421        \u001b[35m4.0937\u001b[0m  6.1634\n",
      "     94        \u001b[36m4.0302\u001b[0m       0.9417        \u001b[35m4.0936\u001b[0m  6.1922\n",
      "     95        \u001b[36m4.0302\u001b[0m       0.9417        \u001b[35m4.0936\u001b[0m  6.1187\n",
      "     96        \u001b[36m4.0302\u001b[0m       0.9417        \u001b[35m4.0935\u001b[0m  6.1278\n",
      "     97        \u001b[36m4.0302\u001b[0m       0.9421        \u001b[35m4.0935\u001b[0m  6.1385\n",
      "     98        \u001b[36m4.0302\u001b[0m       0.9421        \u001b[35m4.0934\u001b[0m  6.1480\n",
      "     99        \u001b[36m4.0302\u001b[0m       0.9421        \u001b[35m4.0933\u001b[0m  6.1479\n",
      "    100        \u001b[36m4.0302\u001b[0m       0.9421        \u001b[35m4.0933\u001b[0m  6.1982\n",
      "    101        \u001b[36m4.0302\u001b[0m       0.9421        \u001b[35m4.0932\u001b[0m  6.1526\n",
      "    102        \u001b[36m4.0302\u001b[0m       0.9421        \u001b[35m4.0932\u001b[0m  6.2409\n",
      "    103        \u001b[36m4.0302\u001b[0m       0.9421        \u001b[35m4.0931\u001b[0m  6.2523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    104        \u001b[36m4.0302\u001b[0m       0.9421        \u001b[35m4.0930\u001b[0m  6.1516\n",
      "    105        \u001b[36m4.0302\u001b[0m       0.9421        \u001b[35m4.0930\u001b[0m  6.1369\n",
      "    106        \u001b[36m4.0302\u001b[0m       0.9421        \u001b[35m4.0929\u001b[0m  6.2087\n",
      "    107        \u001b[36m4.0302\u001b[0m       0.9424        \u001b[35m4.0929\u001b[0m  6.1217\n",
      "    108        \u001b[36m4.0302\u001b[0m       0.9424        \u001b[35m4.0928\u001b[0m  6.1294\n",
      "    109        \u001b[36m4.0302\u001b[0m       0.9427        \u001b[35m4.0928\u001b[0m  6.2150\n",
      "    110        \u001b[36m4.0302\u001b[0m       0.9424        \u001b[35m4.0927\u001b[0m  6.1270\n",
      "    111        \u001b[36m4.0302\u001b[0m       0.9424        \u001b[35m4.0927\u001b[0m  6.1530\n",
      "    112        \u001b[36m4.0302\u001b[0m       0.9417        \u001b[35m4.0926\u001b[0m  6.1249\n",
      "    113        \u001b[36m4.0302\u001b[0m       0.9417        \u001b[35m4.0926\u001b[0m  6.1259\n",
      "    114        \u001b[36m4.0302\u001b[0m       0.9414        \u001b[35m4.0925\u001b[0m  6.1312\n",
      "    115        \u001b[36m4.0302\u001b[0m       0.9417        \u001b[35m4.0925\u001b[0m  6.1283\n",
      "    116        \u001b[36m4.0302\u001b[0m       0.9414        \u001b[35m4.0925\u001b[0m  6.1311\n",
      "    117        \u001b[36m4.0302\u001b[0m       0.9421        \u001b[35m4.0924\u001b[0m  6.1440\n",
      "    118        \u001b[36m4.0302\u001b[0m       0.9417        \u001b[35m4.0924\u001b[0m  6.3403\n",
      "    119        \u001b[36m4.0302\u001b[0m       0.9421        \u001b[35m4.0923\u001b[0m  6.2250\n",
      "    120        \u001b[36m4.0302\u001b[0m       0.9417        4.0923  5.9141\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{1: 0.006622516556291391, 0.9: 0.986158940397351, 0.8: 0.9876158940397352, 0: 0.9871523178807947}\n",
      "Val accuracy\n",
      "{1: 0.006666666666666667, 0.9: 0.9053333333333333, 0.8: 0.9046666666666666, 0: 0.9056666666666666}\n",
      "pred time\n",
      "{1: 0.37184715270996094, 0.9: 0.3441929817199707, 0.8: 0.36145877838134766, 0: 0.3883631229400635}\n",
      "OOS Val Accuracy\n",
      "{1: 0.0, 0.9: 0.21, 0.8: 0.2, 0: 0.21}\n",
      "OOS pred time\n",
      "{1: 0.01224207878112793, 0.9: 0.01036524772644043, 0.8: 0.01233983039855957, 0: 0.010436773300170898}\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "hidden_dim = 800\n",
    "dropout_list = [1, 0.9, 0.8, 0] #some further values for dropout\n",
    "for dropout in dropout_list:    \n",
    "    print(lr)\n",
    "    class CLINCModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                input_dim=vocab_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim,\n",
    "                dropout=dropout\n",
    "        ):\n",
    "            super(CLINCModule, self).__init__()\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "            self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = F.relu(self.hidden(X))\n",
    "            X = self.dropout(X)\n",
    "            X = F.softmax(self.output(X), dim=-1)\n",
    "            return X\n",
    "   \n",
    "    net = NeuralNetClassifier(\n",
    "    module=CLINCModule,\n",
    "    lr=lr,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    max_epochs=1000,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    callbacks=[EarlyStopping(patience=10)],\n",
    "    )\n",
    "    \n",
    "    net.fit(train_x, train_y)\n",
    "    tlabels = net.predict(train_x)\n",
    "    tacc[dropout] = accuracy_score(tlabels, train_y)\n",
    "    print('training accuracy')\n",
    "    print(tacc)\n",
    "    time0 = time.time()\n",
    "    labels = net.predict(val_x)\n",
    "    vacc[dropout] = accuracy_score(labels, val_y)\n",
    "    time1 = time.time()\n",
    "    vtime[dropout] = time1-time0\n",
    "    print('Val accuracy')\n",
    "    print(vacc)\n",
    "    print('pred time')\n",
    "    print(vtime)\n",
    "    time2 = time.time()\n",
    "    olabels = net.predict(val_oos_x)\n",
    "    oacc[dropout] = accuracy_score(olabels, val_oos_y)\n",
    "    time3 = time.time()\n",
    "    otime[dropout]=time3-time2\n",
    "    print('OOS Val Accuracy')\n",
    "    print(oacc)\n",
    "    print('OOS pred time')\n",
    "    print(otime)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.75 found to be most accurate, but not much in it. Will adjust learning rate adjustment by factor of 10 either way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m4.7507\u001b[0m       \u001b[32m0.7474\u001b[0m        \u001b[35m4.3177\u001b[0m  6.5751\n",
      "      2        \u001b[36m4.2561\u001b[0m       \u001b[32m0.8609\u001b[0m        \u001b[35m4.1816\u001b[0m  6.1611\n",
      "      3        \u001b[36m4.1629\u001b[0m       \u001b[32m0.8831\u001b[0m        \u001b[35m4.1560\u001b[0m  6.1635\n",
      "      4        \u001b[36m4.1261\u001b[0m       \u001b[32m0.9063\u001b[0m        \u001b[35m4.1288\u001b[0m  6.2263\n",
      "      5        \u001b[36m4.1001\u001b[0m       \u001b[32m0.9225\u001b[0m        \u001b[35m4.1133\u001b[0m  6.1903\n",
      "      6        \u001b[36m4.0816\u001b[0m       \u001b[32m0.9242\u001b[0m        \u001b[35m4.1082\u001b[0m  6.2384\n",
      "      7        \u001b[36m4.0693\u001b[0m       \u001b[32m0.9248\u001b[0m        \u001b[35m4.1080\u001b[0m  6.2755\n",
      "      8        \u001b[36m4.0661\u001b[0m       \u001b[32m0.9275\u001b[0m        \u001b[35m4.1060\u001b[0m  6.1246\n",
      "      9        \u001b[36m4.0610\u001b[0m       \u001b[32m0.9281\u001b[0m        \u001b[35m4.1045\u001b[0m  6.2033\n",
      "     10        \u001b[36m4.0602\u001b[0m       \u001b[32m0.9298\u001b[0m        \u001b[35m4.1043\u001b[0m  6.2742\n",
      "     11        \u001b[36m4.0562\u001b[0m       0.9255        4.1049  6.3306\n",
      "     12        \u001b[36m4.0548\u001b[0m       0.9258        4.1054  6.3616\n",
      "     13        \u001b[36m4.0536\u001b[0m       0.9291        \u001b[35m4.1029\u001b[0m  6.4214\n",
      "     14        4.0537       0.9288        4.1029  6.3477\n",
      "     15        \u001b[36m4.0526\u001b[0m       \u001b[32m0.9308\u001b[0m        \u001b[35m4.1013\u001b[0m  6.3679\n",
      "     16        \u001b[36m4.0495\u001b[0m       \u001b[32m0.9315\u001b[0m        \u001b[35m4.1004\u001b[0m  6.4880\n",
      "     17        \u001b[36m4.0485\u001b[0m       0.9308        4.1005  6.3382\n",
      "     18        \u001b[36m4.0459\u001b[0m       \u001b[32m0.9318\u001b[0m        \u001b[35m4.0988\u001b[0m  6.3416\n",
      "     19        4.0477       \u001b[32m0.9334\u001b[0m        \u001b[35m4.0974\u001b[0m  6.3562\n",
      "     20        4.0465       0.9325        \u001b[35m4.0973\u001b[0m  6.3792\n",
      "     21        4.0464       \u001b[32m0.9351\u001b[0m        \u001b[35m4.0964\u001b[0m  6.3866\n",
      "     22        4.0467       0.9338        4.0979  6.4167\n",
      "     23        \u001b[36m4.0453\u001b[0m       0.9315        4.0991  6.4543\n",
      "     24        \u001b[36m4.0450\u001b[0m       \u001b[32m0.9354\u001b[0m        \u001b[35m4.0952\u001b[0m  6.5567\n",
      "     25        \u001b[36m4.0447\u001b[0m       0.9338        4.0963  6.5156\n",
      "     26        4.0456       0.9295        4.1008  6.6369\n",
      "     27        4.0456       0.9328        4.0967  6.6413\n",
      "     28        \u001b[36m4.0442\u001b[0m       0.9275        4.1003  6.7877\n",
      "     29        \u001b[36m4.0438\u001b[0m       0.9305        4.0978  6.8025\n",
      "     30        4.0438       0.9325        4.0973  6.7674\n",
      "     31        4.0452       0.9308        4.0980  6.8314\n",
      "     32        4.0440       0.9305        4.1004  6.9767\n",
      "     33        \u001b[36m4.0426\u001b[0m       0.9308        4.1003  7.0550\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{0.01: 0.9826490066225165}\n",
      "Val accuracy\n",
      "{0.01: 0.899}\n",
      "pred time\n",
      "{0.01: 0.3452422618865967}\n",
      "OOS Val Accuracy\n",
      "{0.01: 0.18}\n",
      "OOS pred time\n",
      "{0.01: 0.010214090347290039}\n",
      "0.0001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0791\u001b[0m        \u001b[35m5.0172\u001b[0m  6.2127\n",
      "      2        \u001b[36m5.0171\u001b[0m       \u001b[32m0.3897\u001b[0m        \u001b[35m5.0170\u001b[0m  6.2280\n",
      "      3        \u001b[36m5.0168\u001b[0m       \u001b[32m0.6629\u001b[0m        \u001b[35m5.0166\u001b[0m  6.2537\n",
      "      4        \u001b[36m5.0163\u001b[0m       \u001b[32m0.7374\u001b[0m        \u001b[35m5.0161\u001b[0m  6.2068\n",
      "      5        \u001b[36m5.0156\u001b[0m       \u001b[32m0.7513\u001b[0m        \u001b[35m5.0153\u001b[0m  6.1879\n",
      "      6        \u001b[36m5.0146\u001b[0m       0.7371        \u001b[35m5.0141\u001b[0m  6.6782\n",
      "      7        \u001b[36m5.0128\u001b[0m       0.6960        \u001b[35m5.0119\u001b[0m  6.5596\n",
      "      8        \u001b[36m5.0095\u001b[0m       0.6073        \u001b[35m5.0074\u001b[0m  6.2202\n",
      "      9        \u001b[36m5.0014\u001b[0m       0.4341        \u001b[35m4.9954\u001b[0m  6.1006\n",
      "     10        \u001b[36m4.9796\u001b[0m       0.3305        \u001b[35m4.9649\u001b[0m  6.1115\n",
      "     11        \u001b[36m4.9414\u001b[0m       0.3258        \u001b[35m4.9234\u001b[0m  6.1236\n",
      "     12        \u001b[36m4.8990\u001b[0m       0.3444        \u001b[35m4.8824\u001b[0m  6.0984\n",
      "     13        \u001b[36m4.8602\u001b[0m       0.3652        \u001b[35m4.8444\u001b[0m  6.0818\n",
      "     14        \u001b[36m4.8231\u001b[0m       0.3884        \u001b[35m4.8094\u001b[0m  6.0366\n",
      "     15        \u001b[36m4.7911\u001b[0m       0.4146        \u001b[35m4.7776\u001b[0m  6.1282\n",
      "     16        \u001b[36m4.7597\u001b[0m       0.4424        \u001b[35m4.7488\u001b[0m  6.0966\n",
      "     17        \u001b[36m4.7330\u001b[0m       0.4689        \u001b[35m4.7226\u001b[0m  6.1371\n",
      "     18        \u001b[36m4.7069\u001b[0m       0.4940        \u001b[35m4.6979\u001b[0m  6.0415\n",
      "     19        \u001b[36m4.6823\u001b[0m       0.5169        \u001b[35m4.6743\u001b[0m  6.1831\n",
      "     20        \u001b[36m4.6581\u001b[0m       0.5285        \u001b[35m4.6518\u001b[0m  6.0733\n",
      "     21        \u001b[36m4.6365\u001b[0m       0.5440        \u001b[35m4.6308\u001b[0m  6.0741\n",
      "     22        \u001b[36m4.6150\u001b[0m       0.5583        \u001b[35m4.6117\u001b[0m  6.0868\n",
      "     23        \u001b[36m4.5978\u001b[0m       0.5646        \u001b[35m4.5943\u001b[0m  6.0935\n",
      "     24        \u001b[36m4.5796\u001b[0m       0.5755        \u001b[35m4.5780\u001b[0m  6.0780\n",
      "     25        \u001b[36m4.5627\u001b[0m       0.5854        \u001b[35m4.5631\u001b[0m  6.1029\n",
      "     26        \u001b[36m4.5466\u001b[0m       0.6010        \u001b[35m4.5493\u001b[0m  6.0914\n",
      "     27        \u001b[36m4.5326\u001b[0m       0.6129        \u001b[35m4.5361\u001b[0m  6.0860\n",
      "     28        \u001b[36m4.5203\u001b[0m       0.6308        \u001b[35m4.5227\u001b[0m  6.1246\n",
      "     29        \u001b[36m4.5059\u001b[0m       0.6480        \u001b[35m4.5091\u001b[0m  6.0919\n",
      "     30        \u001b[36m4.4915\u001b[0m       0.6550        \u001b[35m4.4963\u001b[0m  6.0861\n",
      "     31        \u001b[36m4.4786\u001b[0m       0.6593        \u001b[35m4.4851\u001b[0m  6.1181\n",
      "     32        \u001b[36m4.4685\u001b[0m       0.6652        \u001b[35m4.4751\u001b[0m  6.0817\n",
      "     33        \u001b[36m4.4575\u001b[0m       0.6689        \u001b[35m4.4662\u001b[0m  6.1143\n",
      "     34        \u001b[36m4.4503\u001b[0m       0.6705        \u001b[35m4.4578\u001b[0m  6.0981\n",
      "     35        \u001b[36m4.4419\u001b[0m       0.6728        \u001b[35m4.4500\u001b[0m  6.0790\n",
      "     36        \u001b[36m4.4319\u001b[0m       0.6795        \u001b[35m4.4422\u001b[0m  6.1080\n",
      "     37        \u001b[36m4.4238\u001b[0m       0.6937        \u001b[35m4.4338\u001b[0m  6.1136\n",
      "     38        \u001b[36m4.4144\u001b[0m       0.7096        \u001b[35m4.4247\u001b[0m  6.1278\n",
      "     39        \u001b[36m4.4037\u001b[0m       0.7179        \u001b[35m4.4161\u001b[0m  6.1410\n",
      "     40        \u001b[36m4.3973\u001b[0m       0.7189        \u001b[35m4.4086\u001b[0m  6.1079\n",
      "     41        \u001b[36m4.3896\u001b[0m       0.7242        \u001b[35m4.4020\u001b[0m  6.1220\n",
      "     42        \u001b[36m4.3827\u001b[0m       0.7285        \u001b[35m4.3957\u001b[0m  6.1202\n",
      "     43        \u001b[36m4.3763\u001b[0m       0.7338        \u001b[35m4.3897\u001b[0m  6.0851\n",
      "     44        \u001b[36m4.3710\u001b[0m       0.7368        \u001b[35m4.3839\u001b[0m  6.0830\n",
      "     45        \u001b[36m4.3636\u001b[0m       0.7401        \u001b[35m4.3783\u001b[0m  6.0988\n",
      "     46        \u001b[36m4.3580\u001b[0m       0.7450        \u001b[35m4.3731\u001b[0m  6.1157\n",
      "     47        \u001b[36m4.3530\u001b[0m       0.7493        \u001b[35m4.3679\u001b[0m  6.1085\n",
      "     48        \u001b[36m4.3472\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m4.3626\u001b[0m  6.1102\n",
      "     49        \u001b[36m4.3413\u001b[0m       \u001b[32m0.7546\u001b[0m        \u001b[35m4.3578\u001b[0m  6.0975\n",
      "     50        \u001b[36m4.3365\u001b[0m       \u001b[32m0.7589\u001b[0m        \u001b[35m4.3531\u001b[0m  5.9827\n",
      "     51        \u001b[36m4.3320\u001b[0m       \u001b[32m0.7619\u001b[0m        \u001b[35m4.3483\u001b[0m  6.0791\n",
      "     52        \u001b[36m4.3253\u001b[0m       \u001b[32m0.7639\u001b[0m        \u001b[35m4.3436\u001b[0m  6.1085\n",
      "     53        \u001b[36m4.3201\u001b[0m       \u001b[32m0.7682\u001b[0m        \u001b[35m4.3389\u001b[0m  6.1149\n",
      "     54        \u001b[36m4.3164\u001b[0m       \u001b[32m0.7768\u001b[0m        \u001b[35m4.3334\u001b[0m  6.1280\n",
      "     55        \u001b[36m4.3103\u001b[0m       \u001b[32m0.7844\u001b[0m        \u001b[35m4.3274\u001b[0m  6.1254\n",
      "     56        \u001b[36m4.3039\u001b[0m       \u001b[32m0.7907\u001b[0m        \u001b[35m4.3222\u001b[0m  6.1332\n",
      "     57        \u001b[36m4.2982\u001b[0m       \u001b[32m0.7921\u001b[0m        \u001b[35m4.3176\u001b[0m  6.1137\n",
      "     58        \u001b[36m4.2939\u001b[0m       \u001b[32m0.7957\u001b[0m        \u001b[35m4.3132\u001b[0m  6.2086\n",
      "     59        \u001b[36m4.2878\u001b[0m       \u001b[32m0.7990\u001b[0m        \u001b[35m4.3088\u001b[0m  6.1411\n",
      "     60        \u001b[36m4.2842\u001b[0m       \u001b[32m0.8026\u001b[0m        \u001b[35m4.3045\u001b[0m  6.4211\n",
      "     61        \u001b[36m4.2787\u001b[0m       \u001b[32m0.8056\u001b[0m        \u001b[35m4.3006\u001b[0m  6.2543\n",
      "     62        \u001b[36m4.2741\u001b[0m       \u001b[32m0.8083\u001b[0m        \u001b[35m4.2967\u001b[0m  6.4284\n",
      "     63        \u001b[36m4.2704\u001b[0m       \u001b[32m0.8106\u001b[0m        \u001b[35m4.2931\u001b[0m  6.2778\n",
      "     64        \u001b[36m4.2654\u001b[0m       \u001b[32m0.8132\u001b[0m        \u001b[35m4.2896\u001b[0m  6.2544\n",
      "     65        \u001b[36m4.2626\u001b[0m       \u001b[32m0.8152\u001b[0m        \u001b[35m4.2863\u001b[0m  6.2168\n",
      "     66        \u001b[36m4.2583\u001b[0m       \u001b[32m0.8169\u001b[0m        \u001b[35m4.2831\u001b[0m  6.7967\n",
      "     67        \u001b[36m4.2549\u001b[0m       \u001b[32m0.8182\u001b[0m        \u001b[35m4.2799\u001b[0m  6.2117\n",
      "     68        \u001b[36m4.2530\u001b[0m       \u001b[32m0.8199\u001b[0m        \u001b[35m4.2768\u001b[0m  6.1191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     69        \u001b[36m4.2469\u001b[0m       \u001b[32m0.8238\u001b[0m        \u001b[35m4.2732\u001b[0m  6.1097\n",
      "     70        \u001b[36m4.2434\u001b[0m       \u001b[32m0.8255\u001b[0m        \u001b[35m4.2695\u001b[0m  6.1337\n",
      "     71        \u001b[36m4.2416\u001b[0m       \u001b[32m0.8265\u001b[0m        \u001b[35m4.2666\u001b[0m  6.1335\n",
      "     72        \u001b[36m4.2362\u001b[0m       0.8265        \u001b[35m4.2639\u001b[0m  6.2552\n",
      "     73        \u001b[36m4.2341\u001b[0m       \u001b[32m0.8281\u001b[0m        \u001b[35m4.2616\u001b[0m  6.0734\n",
      "     74        \u001b[36m4.2316\u001b[0m       0.8281        \u001b[35m4.2592\u001b[0m  6.1118\n",
      "     75        \u001b[36m4.2277\u001b[0m       \u001b[32m0.8291\u001b[0m        \u001b[35m4.2569\u001b[0m  6.2110\n",
      "     76        \u001b[36m4.2262\u001b[0m       \u001b[32m0.8305\u001b[0m        \u001b[35m4.2544\u001b[0m  6.1312\n",
      "     77        \u001b[36m4.2221\u001b[0m       \u001b[32m0.8354\u001b[0m        \u001b[35m4.2517\u001b[0m  6.1991\n",
      "     78        \u001b[36m4.2196\u001b[0m       \u001b[32m0.8364\u001b[0m        \u001b[35m4.2496\u001b[0m  6.1359\n",
      "     79        \u001b[36m4.2167\u001b[0m       \u001b[32m0.8368\u001b[0m        \u001b[35m4.2477\u001b[0m  6.1426\n",
      "     80        \u001b[36m4.2151\u001b[0m       \u001b[32m0.8394\u001b[0m        \u001b[35m4.2455\u001b[0m  6.1577\n",
      "     81        \u001b[36m4.2129\u001b[0m       \u001b[32m0.8417\u001b[0m        \u001b[35m4.2429\u001b[0m  6.1455\n",
      "     82        \u001b[36m4.2098\u001b[0m       \u001b[32m0.8424\u001b[0m        \u001b[35m4.2407\u001b[0m  6.1397\n",
      "     83        \u001b[36m4.2071\u001b[0m       \u001b[32m0.8430\u001b[0m        \u001b[35m4.2385\u001b[0m  6.1501\n",
      "     84        \u001b[36m4.2049\u001b[0m       \u001b[32m0.8450\u001b[0m        \u001b[35m4.2362\u001b[0m  6.1419\n",
      "     85        \u001b[36m4.2021\u001b[0m       \u001b[32m0.8467\u001b[0m        \u001b[35m4.2341\u001b[0m  6.1299\n",
      "     86        \u001b[36m4.1987\u001b[0m       \u001b[32m0.8483\u001b[0m        \u001b[35m4.2323\u001b[0m  6.1487\n",
      "     87        \u001b[36m4.1969\u001b[0m       \u001b[32m0.8503\u001b[0m        \u001b[35m4.2301\u001b[0m  6.1709\n",
      "     88        \u001b[36m4.1944\u001b[0m       \u001b[32m0.8536\u001b[0m        \u001b[35m4.2277\u001b[0m  6.1822\n",
      "     89        \u001b[36m4.1930\u001b[0m       \u001b[32m0.8553\u001b[0m        \u001b[35m4.2257\u001b[0m  6.1468\n",
      "     90        \u001b[36m4.1907\u001b[0m       0.8546        \u001b[35m4.2239\u001b[0m  6.1415\n",
      "     91        \u001b[36m4.1876\u001b[0m       0.8543        \u001b[35m4.2222\u001b[0m  6.1790\n",
      "     92        \u001b[36m4.1870\u001b[0m       0.8553        \u001b[35m4.2199\u001b[0m  6.1758\n",
      "     93        \u001b[36m4.1825\u001b[0m       \u001b[32m0.8646\u001b[0m        \u001b[35m4.2166\u001b[0m  6.1905\n",
      "     94        \u001b[36m4.1791\u001b[0m       \u001b[32m0.8682\u001b[0m        \u001b[35m4.2140\u001b[0m  6.2904\n",
      "     95        \u001b[36m4.1772\u001b[0m       \u001b[32m0.8705\u001b[0m        \u001b[35m4.2118\u001b[0m  6.1510\n",
      "     96        \u001b[36m4.1746\u001b[0m       0.8705        \u001b[35m4.2096\u001b[0m  6.1924\n",
      "     97        \u001b[36m4.1727\u001b[0m       \u001b[32m0.8722\u001b[0m        \u001b[35m4.2075\u001b[0m  6.1564\n",
      "     98        \u001b[36m4.1698\u001b[0m       \u001b[32m0.8752\u001b[0m        \u001b[35m4.2057\u001b[0m  6.1409\n",
      "     99        \u001b[36m4.1672\u001b[0m       0.8745        \u001b[35m4.2041\u001b[0m  6.1686\n",
      "    100        \u001b[36m4.1664\u001b[0m       \u001b[32m0.8755\u001b[0m        \u001b[35m4.2024\u001b[0m  6.1477\n",
      "    101        \u001b[36m4.1644\u001b[0m       \u001b[32m0.8768\u001b[0m        \u001b[35m4.2008\u001b[0m  6.1523\n",
      "    102        \u001b[36m4.1623\u001b[0m       \u001b[32m0.8795\u001b[0m        \u001b[35m4.1991\u001b[0m  6.1592\n",
      "    103        \u001b[36m4.1600\u001b[0m       \u001b[32m0.8808\u001b[0m        \u001b[35m4.1976\u001b[0m  6.2337\n",
      "    104        \u001b[36m4.1583\u001b[0m       \u001b[32m0.8831\u001b[0m        \u001b[35m4.1960\u001b[0m  6.1547\n",
      "    105        \u001b[36m4.1562\u001b[0m       \u001b[32m0.8844\u001b[0m        \u001b[35m4.1946\u001b[0m  6.2412\n",
      "    106        \u001b[36m4.1534\u001b[0m       0.8838        \u001b[35m4.1931\u001b[0m  6.1555\n",
      "    107        \u001b[36m4.1533\u001b[0m       \u001b[32m0.8848\u001b[0m        \u001b[35m4.1919\u001b[0m  6.1672\n",
      "    108        \u001b[36m4.1502\u001b[0m       \u001b[32m0.8858\u001b[0m        \u001b[35m4.1905\u001b[0m  6.1535\n",
      "    109        \u001b[36m4.1487\u001b[0m       0.8851        \u001b[35m4.1892\u001b[0m  6.1256\n",
      "    110        \u001b[36m4.1474\u001b[0m       0.8858        \u001b[35m4.1879\u001b[0m  6.1533\n",
      "    111        \u001b[36m4.1456\u001b[0m       0.8858        \u001b[35m4.1867\u001b[0m  6.1535\n",
      "    112        \u001b[36m4.1436\u001b[0m       \u001b[32m0.8864\u001b[0m        \u001b[35m4.1855\u001b[0m  6.1536\n",
      "    113        \u001b[36m4.1433\u001b[0m       \u001b[32m0.8874\u001b[0m        \u001b[35m4.1844\u001b[0m  6.1720\n",
      "    114        \u001b[36m4.1412\u001b[0m       0.8874        \u001b[35m4.1834\u001b[0m  6.1617\n",
      "    115        \u001b[36m4.1409\u001b[0m       \u001b[32m0.8897\u001b[0m        \u001b[35m4.1822\u001b[0m  6.1535\n",
      "    116        \u001b[36m4.1392\u001b[0m       \u001b[32m0.8904\u001b[0m        \u001b[35m4.1811\u001b[0m  6.2092\n",
      "    117        \u001b[36m4.1378\u001b[0m       \u001b[32m0.8914\u001b[0m        \u001b[35m4.1799\u001b[0m  6.1621\n",
      "    118        \u001b[36m4.1353\u001b[0m       \u001b[32m0.8930\u001b[0m        \u001b[35m4.1786\u001b[0m  6.3059\n",
      "    119        \u001b[36m4.1346\u001b[0m       \u001b[32m0.8950\u001b[0m        \u001b[35m4.1773\u001b[0m  6.1781\n",
      "    120        \u001b[36m4.1316\u001b[0m       \u001b[32m0.8964\u001b[0m        \u001b[35m4.1759\u001b[0m  6.1459\n",
      "    121        \u001b[36m4.1301\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m4.1747\u001b[0m  6.1507\n",
      "    122        \u001b[36m4.1296\u001b[0m       0.8974        \u001b[35m4.1736\u001b[0m  6.1775\n",
      "    123        \u001b[36m4.1260\u001b[0m       0.8970        \u001b[35m4.1726\u001b[0m  6.1869\n",
      "    124        4.1269       0.8970        \u001b[35m4.1716\u001b[0m  6.1870\n",
      "    125        \u001b[36m4.1256\u001b[0m       0.8970        \u001b[35m4.1705\u001b[0m  6.1789\n",
      "    126        \u001b[36m4.1237\u001b[0m       \u001b[32m0.8977\u001b[0m        \u001b[35m4.1697\u001b[0m  6.1686\n",
      "    127        \u001b[36m4.1227\u001b[0m       \u001b[32m0.8980\u001b[0m        \u001b[35m4.1687\u001b[0m  6.2656\n",
      "    128        \u001b[36m4.1226\u001b[0m       0.8977        \u001b[35m4.1678\u001b[0m  6.1969\n",
      "    129        \u001b[36m4.1210\u001b[0m       0.8977        \u001b[35m4.1671\u001b[0m  6.1605\n",
      "    130        \u001b[36m4.1206\u001b[0m       0.8980        \u001b[35m4.1663\u001b[0m  6.1673\n",
      "    131        \u001b[36m4.1194\u001b[0m       0.8980        \u001b[35m4.1655\u001b[0m  6.1732\n",
      "    132        \u001b[36m4.1184\u001b[0m       \u001b[32m0.8987\u001b[0m        \u001b[35m4.1648\u001b[0m  6.2893\n",
      "    133        \u001b[36m4.1174\u001b[0m       0.8987        \u001b[35m4.1643\u001b[0m  6.2287\n",
      "    134        \u001b[36m4.1162\u001b[0m       \u001b[32m0.8997\u001b[0m        \u001b[35m4.1637\u001b[0m  6.1644\n",
      "    135        4.1169       0.8997        \u001b[35m4.1630\u001b[0m  6.2734\n",
      "    136        \u001b[36m4.1156\u001b[0m       \u001b[32m0.9003\u001b[0m        \u001b[35m4.1623\u001b[0m  6.1705\n",
      "    137        \u001b[36m4.1144\u001b[0m       \u001b[32m0.9007\u001b[0m        \u001b[35m4.1617\u001b[0m  6.1849\n",
      "    138        \u001b[36m4.1131\u001b[0m       0.9007        \u001b[35m4.1611\u001b[0m  6.1704\n",
      "    139        \u001b[36m4.1128\u001b[0m       0.9007        \u001b[35m4.1604\u001b[0m  6.1764\n",
      "    140        \u001b[36m4.1125\u001b[0m       \u001b[32m0.9030\u001b[0m        \u001b[35m4.1592\u001b[0m  6.1961\n",
      "    141        \u001b[36m4.1113\u001b[0m       \u001b[32m0.9060\u001b[0m        \u001b[35m4.1577\u001b[0m  6.1854\n",
      "    142        \u001b[36m4.1092\u001b[0m       0.9060        \u001b[35m4.1569\u001b[0m  6.1862\n",
      "    143        \u001b[36m4.1076\u001b[0m       \u001b[32m0.9063\u001b[0m        \u001b[35m4.1564\u001b[0m  6.2351\n",
      "    144        4.1077       0.9060        \u001b[35m4.1559\u001b[0m  6.2211\n",
      "    145        \u001b[36m4.1068\u001b[0m       0.9060        \u001b[35m4.1554\u001b[0m  6.1999\n",
      "    146        \u001b[36m4.1053\u001b[0m       0.9060        \u001b[35m4.1548\u001b[0m  6.0977\n",
      "    147        \u001b[36m4.1049\u001b[0m       \u001b[32m0.9066\u001b[0m        \u001b[35m4.1542\u001b[0m  6.1158\n",
      "    148        \u001b[36m4.1044\u001b[0m       0.9063        \u001b[35m4.1538\u001b[0m  6.1964\n",
      "    149        \u001b[36m4.1039\u001b[0m       0.9060        \u001b[35m4.1533\u001b[0m  6.2346\n",
      "    150        \u001b[36m4.1032\u001b[0m       0.9063        \u001b[35m4.1526\u001b[0m  6.3282\n",
      "    151        \u001b[36m4.1024\u001b[0m       0.9063        \u001b[35m4.1521\u001b[0m  6.1827\n",
      "    152        4.1025       0.9063        \u001b[35m4.1514\u001b[0m  6.1921\n",
      "    153        \u001b[36m4.1005\u001b[0m       \u001b[32m0.9086\u001b[0m        \u001b[35m4.1499\u001b[0m  6.2146\n",
      "    154        \u001b[36m4.0975\u001b[0m       \u001b[32m0.9113\u001b[0m        \u001b[35m4.1488\u001b[0m  6.2746\n",
      "    155        \u001b[36m4.0970\u001b[0m       0.9109        \u001b[35m4.1482\u001b[0m  6.3026\n",
      "    156        \u001b[36m4.0955\u001b[0m       \u001b[32m0.9126\u001b[0m        \u001b[35m4.1475\u001b[0m  6.2929\n",
      "    157        \u001b[36m4.0946\u001b[0m       \u001b[32m0.9142\u001b[0m        \u001b[35m4.1468\u001b[0m  6.1891\n",
      "    158        \u001b[36m4.0928\u001b[0m       \u001b[32m0.9166\u001b[0m        \u001b[35m4.1463\u001b[0m  6.2109\n",
      "    159        \u001b[36m4.0922\u001b[0m       0.9166        \u001b[35m4.1457\u001b[0m  6.2070\n",
      "    160        \u001b[36m4.0917\u001b[0m       \u001b[32m0.9175\u001b[0m        \u001b[35m4.1454\u001b[0m  6.1941\n",
      "    161        \u001b[36m4.0910\u001b[0m       \u001b[32m0.9182\u001b[0m        \u001b[35m4.1449\u001b[0m  6.2310\n",
      "    162        \u001b[36m4.0904\u001b[0m       \u001b[32m0.9189\u001b[0m        \u001b[35m4.1443\u001b[0m  6.2027\n",
      "    163        \u001b[36m4.0891\u001b[0m       0.9189        \u001b[35m4.1439\u001b[0m  6.2452\n",
      "    164        \u001b[36m4.0887\u001b[0m       \u001b[32m0.9192\u001b[0m        \u001b[35m4.1434\u001b[0m  6.2443\n",
      "    165        \u001b[36m4.0876\u001b[0m       0.9179        \u001b[35m4.1431\u001b[0m  6.2039\n",
      "    166        \u001b[36m4.0873\u001b[0m       0.9189        \u001b[35m4.1426\u001b[0m  6.2024\n",
      "    167        \u001b[36m4.0860\u001b[0m       0.9182        \u001b[35m4.1421\u001b[0m  6.2162\n",
      "    168        4.0861       0.9179        \u001b[35m4.1417\u001b[0m  6.3939\n",
      "    169        \u001b[36m4.0851\u001b[0m       0.9179        \u001b[35m4.1414\u001b[0m  6.1442\n",
      "    170        \u001b[36m4.0847\u001b[0m       0.9179        \u001b[35m4.1410\u001b[0m  6.1856\n",
      "    171        \u001b[36m4.0839\u001b[0m       0.9179        \u001b[35m4.1405\u001b[0m  6.1920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    172        \u001b[36m4.0836\u001b[0m       0.9185        \u001b[35m4.1401\u001b[0m  6.2262\n",
      "    173        \u001b[36m4.0832\u001b[0m       0.9179        \u001b[35m4.1396\u001b[0m  6.3218\n",
      "    174        \u001b[36m4.0822\u001b[0m       0.9189        \u001b[35m4.1393\u001b[0m  6.2505\n",
      "    175        \u001b[36m4.0819\u001b[0m       0.9185        \u001b[35m4.1390\u001b[0m  6.2359\n",
      "    176        \u001b[36m4.0811\u001b[0m       \u001b[32m0.9195\u001b[0m        \u001b[35m4.1386\u001b[0m  6.2313\n",
      "    177        \u001b[36m4.0809\u001b[0m       0.9192        \u001b[35m4.1382\u001b[0m  6.2133\n",
      "    178        4.0811       \u001b[32m0.9199\u001b[0m        \u001b[35m4.1378\u001b[0m  6.2251\n",
      "    179        \u001b[36m4.0793\u001b[0m       0.9195        \u001b[35m4.1374\u001b[0m  6.5190\n",
      "    180        \u001b[36m4.0792\u001b[0m       0.9192        \u001b[35m4.1371\u001b[0m  6.4926\n",
      "    181        \u001b[36m4.0792\u001b[0m       \u001b[32m0.9205\u001b[0m        \u001b[35m4.1367\u001b[0m  6.3302\n",
      "    182        \u001b[36m4.0784\u001b[0m       0.9202        \u001b[35m4.1364\u001b[0m  6.3319\n",
      "    183        4.0785       0.9199        \u001b[35m4.1362\u001b[0m  6.3877\n",
      "    184        \u001b[36m4.0779\u001b[0m       0.9205        \u001b[35m4.1358\u001b[0m  6.3466\n",
      "    185        \u001b[36m4.0776\u001b[0m       0.9205        \u001b[35m4.1354\u001b[0m  6.2544\n",
      "    186        \u001b[36m4.0763\u001b[0m       0.9205        \u001b[35m4.1351\u001b[0m  6.2174\n",
      "    187        4.0770       0.9202        \u001b[35m4.1347\u001b[0m  6.2368\n",
      "    188        \u001b[36m4.0759\u001b[0m       \u001b[32m0.9215\u001b[0m        \u001b[35m4.1343\u001b[0m  6.2280\n",
      "    189        \u001b[36m4.0752\u001b[0m       \u001b[32m0.9219\u001b[0m        \u001b[35m4.1340\u001b[0m  6.2491\n",
      "    190        \u001b[36m4.0750\u001b[0m       \u001b[32m0.9232\u001b[0m        \u001b[35m4.1337\u001b[0m  6.2204\n",
      "    191        \u001b[36m4.0745\u001b[0m       \u001b[32m0.9248\u001b[0m        \u001b[35m4.1334\u001b[0m  6.2676\n",
      "    192        \u001b[36m4.0736\u001b[0m       0.9235        \u001b[35m4.1330\u001b[0m  6.2999\n",
      "    193        \u001b[36m4.0728\u001b[0m       0.9238        \u001b[35m4.1327\u001b[0m  6.2507\n",
      "    194        \u001b[36m4.0723\u001b[0m       \u001b[32m0.9262\u001b[0m        \u001b[35m4.1323\u001b[0m  6.5081\n",
      "    195        \u001b[36m4.0705\u001b[0m       \u001b[32m0.9265\u001b[0m        \u001b[35m4.1321\u001b[0m  6.5985\n",
      "    196        \u001b[36m4.0700\u001b[0m       0.9258        \u001b[35m4.1318\u001b[0m  6.5930\n",
      "    197        \u001b[36m4.0690\u001b[0m       0.9258        \u001b[35m4.1315\u001b[0m  6.7074\n",
      "    198        4.0691       0.9258        \u001b[35m4.1310\u001b[0m  6.3298\n",
      "    199        \u001b[36m4.0681\u001b[0m       0.9262        \u001b[35m4.1306\u001b[0m  6.3168\n",
      "    200        \u001b[36m4.0678\u001b[0m       0.9265        \u001b[35m4.1302\u001b[0m  6.3507\n",
      "    201        4.0679       \u001b[32m0.9268\u001b[0m        \u001b[35m4.1299\u001b[0m  6.4191\n",
      "    202        \u001b[36m4.0665\u001b[0m       0.9268        \u001b[35m4.1295\u001b[0m  6.3355\n",
      "    203        \u001b[36m4.0663\u001b[0m       \u001b[32m0.9272\u001b[0m        \u001b[35m4.1289\u001b[0m  6.3765\n",
      "    204        \u001b[36m4.0657\u001b[0m       0.9272        \u001b[35m4.1285\u001b[0m  6.4032\n",
      "    205        \u001b[36m4.0654\u001b[0m       0.9265        \u001b[35m4.1282\u001b[0m  6.3589\n",
      "    206        \u001b[36m4.0647\u001b[0m       0.9265        \u001b[35m4.1279\u001b[0m  6.4022\n",
      "    207        4.0648       0.9268        \u001b[35m4.1276\u001b[0m  6.4281\n",
      "    208        \u001b[36m4.0641\u001b[0m       0.9268        \u001b[35m4.1272\u001b[0m  6.6254\n",
      "    209        \u001b[36m4.0639\u001b[0m       \u001b[32m0.9278\u001b[0m        \u001b[35m4.1268\u001b[0m  6.2980\n",
      "    210        \u001b[36m4.0627\u001b[0m       0.9272        \u001b[35m4.1265\u001b[0m  6.3820\n",
      "    211        4.0629       \u001b[32m0.9281\u001b[0m        \u001b[35m4.1261\u001b[0m  6.3425\n",
      "    212        4.0633       0.9278        \u001b[35m4.1257\u001b[0m  6.3320\n",
      "    213        \u001b[36m4.0621\u001b[0m       0.9281        \u001b[35m4.1255\u001b[0m  6.2998\n",
      "    214        \u001b[36m4.0613\u001b[0m       0.9278        \u001b[35m4.1251\u001b[0m  6.3184\n",
      "    215        \u001b[36m4.0613\u001b[0m       0.9281        \u001b[35m4.1249\u001b[0m  6.2874\n",
      "    216        4.0616       \u001b[32m0.9288\u001b[0m        \u001b[35m4.1245\u001b[0m  6.2888\n",
      "    217        \u001b[36m4.0612\u001b[0m       0.9285        \u001b[35m4.1240\u001b[0m  6.3019\n",
      "    218        \u001b[36m4.0601\u001b[0m       0.9285        \u001b[35m4.1238\u001b[0m  6.2990\n",
      "    219        4.0610       0.9285        \u001b[35m4.1236\u001b[0m  6.8991\n",
      "    220        4.0607       0.9278        \u001b[35m4.1234\u001b[0m  6.7559\n",
      "    221        4.0603       0.9281        \u001b[35m4.1232\u001b[0m  6.2686\n",
      "    222        \u001b[36m4.0595\u001b[0m       0.9288        \u001b[35m4.1228\u001b[0m  6.3017\n",
      "    223        4.0597       0.9285        \u001b[35m4.1225\u001b[0m  6.4061\n",
      "    224        \u001b[36m4.0593\u001b[0m       0.9285        \u001b[35m4.1223\u001b[0m  6.2657\n",
      "    225        \u001b[36m4.0586\u001b[0m       \u001b[32m0.9291\u001b[0m        \u001b[35m4.1220\u001b[0m  6.2609\n",
      "    226        \u001b[36m4.0579\u001b[0m       0.9291        \u001b[35m4.1218\u001b[0m  6.2953\n",
      "    227        \u001b[36m4.0577\u001b[0m       0.9291        \u001b[35m4.1215\u001b[0m  6.3673\n",
      "    228        4.0579       0.9291        \u001b[35m4.1214\u001b[0m  6.3549\n",
      "    229        4.0577       \u001b[32m0.9298\u001b[0m        \u001b[35m4.1213\u001b[0m  6.3025\n",
      "    230        \u001b[36m4.0577\u001b[0m       0.9291        \u001b[35m4.1210\u001b[0m  6.2994\n",
      "    231        4.0578       0.9288        \u001b[35m4.1207\u001b[0m  6.3678\n",
      "    232        \u001b[36m4.0571\u001b[0m       0.9298        \u001b[35m4.1205\u001b[0m  6.3427\n",
      "    233        4.0571       0.9298        \u001b[35m4.1203\u001b[0m  6.3579\n",
      "    234        \u001b[36m4.0560\u001b[0m       0.9295        \u001b[35m4.1201\u001b[0m  6.4150\n",
      "    235        4.0563       0.9295        \u001b[35m4.1200\u001b[0m  6.3121\n",
      "    236        4.0566       0.9291        \u001b[35m4.1198\u001b[0m  6.6306\n",
      "    237        4.0566       0.9298        \u001b[35m4.1195\u001b[0m  6.9060\n",
      "    238        \u001b[36m4.0557\u001b[0m       0.9295        \u001b[35m4.1193\u001b[0m  6.5491\n",
      "    239        \u001b[36m4.0555\u001b[0m       0.9295        \u001b[35m4.1193\u001b[0m  6.6253\n",
      "    240        4.0557       0.9291        \u001b[35m4.1191\u001b[0m  6.5882\n",
      "    241        \u001b[36m4.0554\u001b[0m       0.9295        \u001b[35m4.1189\u001b[0m  6.6548\n",
      "    242        \u001b[36m4.0553\u001b[0m       0.9291        \u001b[35m4.1186\u001b[0m  6.5521\n",
      "    243        \u001b[36m4.0551\u001b[0m       0.9295        \u001b[35m4.1186\u001b[0m  6.3900\n",
      "    244        \u001b[36m4.0546\u001b[0m       0.9298        \u001b[35m4.1185\u001b[0m  6.8883\n",
      "    245        4.0547       \u001b[32m0.9301\u001b[0m        \u001b[35m4.1182\u001b[0m  6.6694\n",
      "    246        \u001b[36m4.0544\u001b[0m       0.9298        \u001b[35m4.1180\u001b[0m  6.6256\n",
      "    247        \u001b[36m4.0544\u001b[0m       0.9301        \u001b[35m4.1176\u001b[0m  6.4044\n",
      "    248        \u001b[36m4.0541\u001b[0m       0.9288        \u001b[35m4.1173\u001b[0m  6.4838\n",
      "    249        \u001b[36m4.0538\u001b[0m       0.9298        \u001b[35m4.1172\u001b[0m  6.5034\n",
      "    250        \u001b[36m4.0534\u001b[0m       0.9298        \u001b[35m4.1170\u001b[0m  6.4269\n",
      "    251        4.0539       0.9298        \u001b[35m4.1169\u001b[0m  6.4103\n",
      "    252        4.0536       \u001b[32m0.9305\u001b[0m        \u001b[35m4.1166\u001b[0m  6.4933\n",
      "    253        \u001b[36m4.0532\u001b[0m       0.9298        \u001b[35m4.1165\u001b[0m  6.6855\n",
      "    254        4.0533       0.9305        \u001b[35m4.1164\u001b[0m  6.6014\n",
      "    255        4.0534       0.9298        \u001b[35m4.1163\u001b[0m  6.6203\n",
      "    256        \u001b[36m4.0530\u001b[0m       0.9305        4.1163  6.7651\n",
      "    257        \u001b[36m4.0526\u001b[0m       0.9305        4.1163  6.6248\n",
      "    258        4.0528       0.9301        \u001b[35m4.1162\u001b[0m  7.1586\n",
      "    259        4.0527       0.9295        \u001b[35m4.1159\u001b[0m  6.6159\n",
      "    260        \u001b[36m4.0526\u001b[0m       0.9298        \u001b[35m4.1156\u001b[0m  6.6591\n",
      "    261        \u001b[36m4.0526\u001b[0m       0.9301        4.1156  6.4819\n",
      "    262        \u001b[36m4.0523\u001b[0m       0.9301        \u001b[35m4.1155\u001b[0m  6.4609\n",
      "    263        \u001b[36m4.0521\u001b[0m       0.9305        \u001b[35m4.1154\u001b[0m  6.7470\n",
      "    264        \u001b[36m4.0521\u001b[0m       0.9305        \u001b[35m4.1152\u001b[0m  7.1703\n",
      "    265        \u001b[36m4.0519\u001b[0m       0.9301        \u001b[35m4.1150\u001b[0m  6.7422\n",
      "    266        \u001b[36m4.0516\u001b[0m       0.9305        \u001b[35m4.1149\u001b[0m  6.6325\n",
      "    267        \u001b[36m4.0515\u001b[0m       0.9298        \u001b[35m4.1149\u001b[0m  6.4787\n",
      "    268        \u001b[36m4.0513\u001b[0m       0.9305        \u001b[35m4.1146\u001b[0m  6.4003\n",
      "    269        4.0518       \u001b[32m0.9308\u001b[0m        4.1146  6.6874\n",
      "    270        \u001b[36m4.0508\u001b[0m       0.9308        \u001b[35m4.1144\u001b[0m  6.7612\n",
      "    271        4.0514       \u001b[32m0.9315\u001b[0m        \u001b[35m4.1142\u001b[0m  6.6678\n",
      "    272        4.0514       0.9315        \u001b[35m4.1142\u001b[0m  7.0480\n",
      "    273        \u001b[36m4.0507\u001b[0m       0.9315        \u001b[35m4.1140\u001b[0m  6.6165\n",
      "    274        \u001b[36m4.0507\u001b[0m       0.9315        \u001b[35m4.1140\u001b[0m  6.5558\n",
      "    275        \u001b[36m4.0506\u001b[0m       0.9311        4.1140  6.5731\n",
      "    276        \u001b[36m4.0505\u001b[0m       0.9308        \u001b[35m4.1137\u001b[0m  6.4164\n",
      "    277        4.0507       0.9315        \u001b[35m4.1135\u001b[0m  6.4335\n",
      "    278        4.0506       \u001b[32m0.9318\u001b[0m        4.1136  6.4975\n",
      "    279        \u001b[36m4.0504\u001b[0m       0.9311        \u001b[35m4.1134\u001b[0m  6.5110\n",
      "    280        4.0505       0.9311        \u001b[35m4.1133\u001b[0m  6.6226\n",
      "    281        \u001b[36m4.0501\u001b[0m       0.9315        \u001b[35m4.1131\u001b[0m  6.8461\n",
      "    282        4.0503       0.9315        \u001b[35m4.1131\u001b[0m  6.7030\n",
      "    283        4.0504       0.9318        \u001b[35m4.1129\u001b[0m  6.5164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    284        4.0504       0.9318        4.1130  6.7190\n",
      "    285        \u001b[36m4.0496\u001b[0m       0.9315        \u001b[35m4.1128\u001b[0m  6.5241\n",
      "    286        4.0500       0.9311        \u001b[35m4.1125\u001b[0m  6.7529\n",
      "    287        4.0497       0.9308        \u001b[35m4.1124\u001b[0m  6.4807\n",
      "    288        4.0497       0.9308        \u001b[35m4.1123\u001b[0m  6.5640\n",
      "    289        4.0497       0.9311        \u001b[35m4.1122\u001b[0m  6.5109\n",
      "    290        4.0498       0.9308        4.1122  6.5659\n",
      "    291        4.0497       0.9305        \u001b[35m4.1120\u001b[0m  6.4801\n",
      "    292        4.0497       0.9315        \u001b[35m4.1118\u001b[0m  6.5687\n",
      "    293        \u001b[36m4.0492\u001b[0m       0.9318        \u001b[35m4.1117\u001b[0m  6.4580\n",
      "    294        4.0494       \u001b[32m0.9325\u001b[0m        \u001b[35m4.1115\u001b[0m  6.5823\n",
      "    295        \u001b[36m4.0492\u001b[0m       0.9325        4.1116  6.5719\n",
      "    296        \u001b[36m4.0490\u001b[0m       0.9325        \u001b[35m4.1114\u001b[0m  6.5568\n",
      "    297        4.0491       \u001b[32m0.9328\u001b[0m        4.1114  6.5844\n",
      "    298        \u001b[36m4.0488\u001b[0m       0.9321        \u001b[35m4.1113\u001b[0m  6.6224\n",
      "    299        \u001b[36m4.0487\u001b[0m       \u001b[32m0.9338\u001b[0m        \u001b[35m4.1107\u001b[0m  6.4403\n",
      "    300        \u001b[36m4.0480\u001b[0m       \u001b[32m0.9354\u001b[0m        \u001b[35m4.1094\u001b[0m  6.4622\n",
      "    301        \u001b[36m4.0464\u001b[0m       0.9351        \u001b[35m4.1094\u001b[0m  6.5628\n",
      "    302        \u001b[36m4.0458\u001b[0m       0.9351        4.1097  6.5424\n",
      "    303        \u001b[36m4.0452\u001b[0m       0.9348        4.1098  6.5330\n",
      "    304        \u001b[36m4.0449\u001b[0m       0.9348        4.1099  6.4867\n",
      "    305        4.0451       0.9348        4.1100  6.4772\n",
      "    306        \u001b[36m4.0444\u001b[0m       0.9351        4.1097  6.4670\n",
      "    307        4.0447       0.9348        4.1096  6.2658\n",
      "    308        \u001b[36m4.0440\u001b[0m       0.9354        4.1095  6.6821\n",
      "    309        \u001b[36m4.0440\u001b[0m       \u001b[32m0.9358\u001b[0m        \u001b[35m4.1093\u001b[0m  6.4605\n",
      "    310        4.0445       \u001b[32m0.9361\u001b[0m        \u001b[35m4.1090\u001b[0m  6.3444\n",
      "    311        4.0441       \u001b[32m0.9371\u001b[0m        \u001b[35m4.1087\u001b[0m  6.3910\n",
      "    312        \u001b[36m4.0438\u001b[0m       0.9364        \u001b[35m4.1087\u001b[0m  6.3149\n",
      "    313        \u001b[36m4.0438\u001b[0m       0.9361        \u001b[35m4.1086\u001b[0m  6.5585\n",
      "    314        4.0438       0.9354        \u001b[35m4.1084\u001b[0m  6.4252\n",
      "    315        \u001b[36m4.0436\u001b[0m       0.9354        \u001b[35m4.1084\u001b[0m  6.5650\n",
      "    316        \u001b[36m4.0435\u001b[0m       0.9351        4.1086  6.5386\n",
      "    317        4.0435       0.9354        \u001b[35m4.1082\u001b[0m  6.5129\n",
      "    318        \u001b[36m4.0434\u001b[0m       0.9358        \u001b[35m4.1081\u001b[0m  6.5227\n",
      "    319        \u001b[36m4.0431\u001b[0m       0.9358        \u001b[35m4.1079\u001b[0m  6.4999\n",
      "    320        \u001b[36m4.0428\u001b[0m       0.9358        4.1080  6.5546\n",
      "    321        4.0431       0.9358        \u001b[35m4.1079\u001b[0m  6.4625\n",
      "    322        4.0431       0.9361        \u001b[35m4.1076\u001b[0m  6.5143\n",
      "    323        \u001b[36m4.0427\u001b[0m       0.9354        \u001b[35m4.1076\u001b[0m  6.7330\n",
      "    324        4.0428       0.9358        4.1076  6.3375\n",
      "    325        \u001b[36m4.0423\u001b[0m       0.9364        \u001b[35m4.1074\u001b[0m  6.4171\n",
      "    326        4.0429       0.9354        \u001b[35m4.1074\u001b[0m  6.2920\n",
      "    327        4.0426       0.9358        \u001b[35m4.1073\u001b[0m  6.2643\n",
      "    328        4.0426       0.9354        4.1073  6.2692\n",
      "    329        4.0425       0.9358        \u001b[35m4.1070\u001b[0m  6.2274\n",
      "    330        \u001b[36m4.0422\u001b[0m       0.9361        \u001b[35m4.1069\u001b[0m  6.2340\n",
      "    331        \u001b[36m4.0421\u001b[0m       0.9368        \u001b[35m4.1067\u001b[0m  6.3026\n",
      "    332        4.0422       0.9368        \u001b[35m4.1066\u001b[0m  6.3053\n",
      "    333        \u001b[36m4.0420\u001b[0m       0.9364        \u001b[35m4.1064\u001b[0m  6.2759\n",
      "    334        \u001b[36m4.0419\u001b[0m       0.9364        \u001b[35m4.1063\u001b[0m  6.2947\n",
      "    335        \u001b[36m4.0416\u001b[0m       0.9361        4.1065  6.3136\n",
      "    336        4.0419       0.9361        4.1063  6.3083\n",
      "    337        4.0417       0.9358        4.1063  6.5324\n",
      "    338        4.0417       0.9361        4.1063  6.4587\n",
      "    339        \u001b[36m4.0416\u001b[0m       0.9361        \u001b[35m4.1061\u001b[0m  6.5490\n",
      "    340        4.0416       0.9361        \u001b[35m4.1060\u001b[0m  6.5484\n",
      "    341        4.0416       0.9364        \u001b[35m4.1057\u001b[0m  6.1397\n",
      "    342        \u001b[36m4.0415\u001b[0m       0.9364        \u001b[35m4.1057\u001b[0m  6.8569\n",
      "    343        \u001b[36m4.0414\u001b[0m       0.9364        \u001b[35m4.1055\u001b[0m  7.1500\n",
      "    344        \u001b[36m4.0413\u001b[0m       0.9361        \u001b[35m4.1053\u001b[0m  6.5526\n",
      "    345        \u001b[36m4.0410\u001b[0m       0.9361        4.1054  6.5294\n",
      "    346        4.0411       0.9361        4.1053  6.6778\n",
      "    347        4.0412       0.9354        \u001b[35m4.1052\u001b[0m  6.5903\n",
      "    348        \u001b[36m4.0406\u001b[0m       0.9361        4.1052  6.9278\n",
      "    349        4.0413       0.9361        \u001b[35m4.1050\u001b[0m  6.7271\n",
      "    350        4.0409       0.9364        \u001b[35m4.1049\u001b[0m  6.4890\n",
      "    351        4.0410       \u001b[32m0.9374\u001b[0m        \u001b[35m4.1047\u001b[0m  6.7864\n",
      "    352        4.0409       0.9368        4.1048  6.4780\n",
      "    353        4.0409       0.9371        \u001b[35m4.1045\u001b[0m  6.3975\n",
      "    354        4.0408       0.9368        4.1046  6.4063\n",
      "    355        4.0407       0.9364        4.1046  6.5454\n",
      "    356        4.0409       0.9368        \u001b[35m4.1045\u001b[0m  6.6061\n",
      "    357        4.0407       0.9374        \u001b[35m4.1043\u001b[0m  6.4057\n",
      "    358        \u001b[36m4.0404\u001b[0m       0.9374        \u001b[35m4.1041\u001b[0m  6.3606\n",
      "    359        4.0406       0.9371        \u001b[35m4.1040\u001b[0m  6.4348\n",
      "    360        4.0405       0.9364        4.1042  6.3086\n",
      "    361        \u001b[36m4.0404\u001b[0m       0.9361        4.1040  6.3168\n",
      "    362        \u001b[36m4.0403\u001b[0m       0.9361        4.1041  6.5522\n",
      "    363        \u001b[36m4.0402\u001b[0m       0.9358        \u001b[35m4.1039\u001b[0m  6.5826\n",
      "    364        4.0404       0.9364        \u001b[35m4.1037\u001b[0m  6.3803\n",
      "    365        4.0404       0.9368        \u001b[35m4.1034\u001b[0m  6.4436\n",
      "    366        \u001b[36m4.0401\u001b[0m       0.9371        \u001b[35m4.1033\u001b[0m  6.4146\n",
      "    367        4.0402       0.9371        4.1034  6.6985\n",
      "    368        4.0404       0.9368        \u001b[35m4.1033\u001b[0m  6.7409\n",
      "    369        4.0401       0.9374        \u001b[35m4.1031\u001b[0m  6.5004\n",
      "    370        4.0403       0.9371        4.1033  6.4716\n",
      "    371        \u001b[36m4.0400\u001b[0m       0.9371        4.1032  6.4882\n",
      "    372        \u001b[36m4.0398\u001b[0m       0.9364        4.1032  6.6052\n",
      "    373        4.0403       0.9374        4.1032  6.7085\n",
      "    374        4.0401       0.9371        \u001b[35m4.1030\u001b[0m  6.6624\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{0.01: 0.9826490066225165, 0.0001: 0.9804635761589404}\n",
      "Val accuracy\n",
      "{0.01: 0.899, 0.0001: 0.899}\n",
      "pred time\n",
      "{0.01: 0.3452422618865967, 0.0001: 0.42351818084716797}\n",
      "OOS Val Accuracy\n",
      "{0.01: 0.18, 0.0001: 0.21}\n",
      "OOS pred time\n",
      "{0.01: 0.010214090347290039, 0.0001: 0.010861873626708984}\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.01, 0.0001]\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "hidden_dim = 800\n",
    "dropout = 0.75\n",
    "for lr in learning_rates:    \n",
    "    print(lr)\n",
    "    class CLINCModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                input_dim=vocab_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim,\n",
    "                dropout=dropout\n",
    "        ):\n",
    "            super(CLINCModule, self).__init__()\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "            self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = F.relu(self.hidden(X))\n",
    "            X = self.dropout(X)\n",
    "            X = F.softmax(self.output(X), dim=-1)\n",
    "            return X\n",
    "   \n",
    "    net = NeuralNetClassifier(\n",
    "    module=CLINCModule,\n",
    "    lr=lr,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    max_epochs=1000,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    callbacks=[EarlyStopping(patience=10)],\n",
    "    )\n",
    "    \n",
    "    net.fit(train_x, train_y)\n",
    "    tlabels = net.predict(train_x)\n",
    "    tacc[lr] = accuracy_score(tlabels, train_y)\n",
    "    print('training accuracy')\n",
    "    print(tacc)\n",
    "    time0 = time.time()\n",
    "    labels = net.predict(val_x)\n",
    "    vacc[lr] = accuracy_score(labels, val_y)\n",
    "    time1 = time.time()\n",
    "    vtime[lr] = time1-time0\n",
    "    print('Val accuracy')\n",
    "    print(vacc)\n",
    "    print('pred time')\n",
    "    print(vtime)\n",
    "    time2 = time.time()\n",
    "    olabels = net.predict(val_oos_x)\n",
    "    oacc[lr] = accuracy_score(olabels, val_oos_y)\n",
    "    time3 = time.time()\n",
    "    otime[lr]=time3-time2\n",
    "    print('OOS Val Accuracy')\n",
    "    print(oacc)\n",
    "    print('OOS pred time')\n",
    "    print(otime)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate of 0.001 remains most accurate. Attempting SGD as optimizer again to see if that can improve on where we are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           nan       \u001b[32m0.0066\u001b[0m           nan  5.0247\n",
      "      2           nan       0.0066           nan  5.0387\n",
      "      3           nan       0.0066           nan  4.9342\n",
      "      4           nan       0.0066           nan  4.8973\n",
      "      5           nan       0.0066           nan  4.9366\n",
      "      6           nan       0.0066           nan  4.9376\n",
      "      7           nan       0.0066           nan  4.9249\n",
      "      8           nan       0.0066           nan  4.9357\n",
      "      9           nan       0.0066           nan  5.0245\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667}\n",
      "pred time\n",
      "{10: 0.35844969749450684}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.012405633926391602}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0073\u001b[0m        \u001b[35m5.0173\u001b[0m  4.9545\n",
      "      2        \u001b[36m5.0173\u001b[0m       0.0073        \u001b[35m5.0173\u001b[0m  4.9596\n",
      "      3        \u001b[36m5.0173\u001b[0m       0.0073        \u001b[35m5.0173\u001b[0m  5.0464\n",
      "      4        \u001b[36m5.0173\u001b[0m       0.0073        \u001b[35m5.0173\u001b[0m  5.0667\n",
      "      5        5.0173       0.0073        \u001b[35m5.0173\u001b[0m  5.1990\n",
      "      6        \u001b[36m5.0173\u001b[0m       0.0073        \u001b[35m5.0173\u001b[0m  5.0153\n",
      "      7        \u001b[36m5.0173\u001b[0m       0.0073        \u001b[35m5.0173\u001b[0m  4.9775\n",
      "      8        \u001b[36m5.0173\u001b[0m       0.0073        \u001b[35m5.0173\u001b[0m  5.1966\n",
      "      9        \u001b[36m5.0173\u001b[0m       0.0073        \u001b[35m5.0173\u001b[0m  5.2828\n",
      "     10        \u001b[36m5.0173\u001b[0m       0.0073        \u001b[35m5.0173\u001b[0m  5.2295\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391, 1: 0.00728476821192053}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667, 1: 0.007333333333333333}\n",
      "pred time\n",
      "{10: 0.35844969749450684, 1: 0.3615422248840332}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 1: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.012405633926391602, 1: 0.010332822799682617}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0073\u001b[0m        \u001b[35m5.0173\u001b[0m  4.8382\n",
      "      2        5.0173       0.0073        5.0173  4.7901\n",
      "      3        5.0173       0.0073        5.0173  4.8658\n",
      "      4        \u001b[36m5.0173\u001b[0m       0.0073        \u001b[35m5.0173\u001b[0m  4.8402\n",
      "      5        5.0173       0.0073        \u001b[35m5.0173\u001b[0m  4.7849\n",
      "      6        5.0173       0.0073        5.0173  4.8623\n",
      "      7        5.0173       0.0073        5.0173  5.0960\n",
      "      8        5.0173       0.0073        5.0173  4.8642\n",
      "      9        5.0173       0.0073        5.0173  4.8092\n",
      "     10        5.0173       0.0073        5.0173  4.9259\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391, 1: 0.00728476821192053, 0.1: 0.006754966887417219}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667, 1: 0.007333333333333333, 0.1: 0.005666666666666667}\n",
      "pred time\n",
      "{10: 0.35844969749450684, 1: 0.3615422248840332, 0.1: 0.3389120101928711}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 1: 0.0, 0.1: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.012405633926391602, 1: 0.010332822799682617, 0.1: 0.010457992553710938}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0056\u001b[0m        \u001b[35m5.0173\u001b[0m  4.7851\n",
      "      2        \u001b[36m5.0173\u001b[0m       0.0056        5.0173  4.9641\n",
      "      3        5.0173       0.0056        5.0173  4.8330\n",
      "      4        5.0173       0.0056        5.0173  4.7816\n",
      "      5        5.0173       0.0056        5.0173  4.8484\n",
      "      6        5.0173       0.0056        5.0173  4.9690\n",
      "      7        5.0173       0.0056        5.0173  4.8658\n",
      "      8        5.0173       0.0056        5.0173  4.9975\n",
      "      9        5.0173       0.0056        5.0173  5.0270\n",
      "     10        5.0173       0.0056        5.0173  4.9822\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391, 1: 0.00728476821192053, 0.1: 0.006754966887417219, 0.01: 0.005629139072847682}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667, 1: 0.007333333333333333, 0.1: 0.005666666666666667, 0.01: 0.005333333333333333}\n",
      "pred time\n",
      "{10: 0.35844969749450684, 1: 0.3615422248840332, 0.1: 0.3389120101928711, 0.01: 0.3617289066314697}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 1: 0.0, 0.1: 0.0, 0.01: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.012405633926391602, 1: 0.010332822799682617, 0.1: 0.010457992553710938, 0.01: 0.010313034057617188}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0053\u001b[0m        \u001b[35m5.0173\u001b[0m  4.9382\n",
      "      2        \u001b[36m5.0173\u001b[0m       0.0053        5.0173  4.9138\n",
      "      3        5.0173       0.0053        5.0173  4.8003\n",
      "      4        \u001b[36m5.0173\u001b[0m       0.0053        5.0173  4.7707\n",
      "      5        \u001b[36m5.0173\u001b[0m       0.0053        5.0173  4.7731\n",
      "      6        5.0173       0.0053        5.0173  4.7489\n",
      "      7        \u001b[36m5.0173\u001b[0m       0.0053        5.0173  4.7793\n",
      "      8        \u001b[36m5.0173\u001b[0m       0.0053        5.0173  4.7433\n",
      "      9        5.0173       0.0053        5.0173  4.7369\n",
      "     10        5.0173       0.0053        5.0173  4.7625\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391, 1: 0.00728476821192053, 0.1: 0.006754966887417219, 0.01: 0.005629139072847682, 0.001: 0.005430463576158941}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667, 1: 0.007333333333333333, 0.1: 0.005666666666666667, 0.01: 0.005333333333333333, 0.001: 0.004}\n",
      "pred time\n",
      "{10: 0.35844969749450684, 1: 0.3615422248840332, 0.1: 0.3389120101928711, 0.01: 0.3617289066314697, 0.001: 0.3524658679962158}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 1: 0.0, 0.1: 0.0, 0.01: 0.0, 0.001: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.012405633926391602, 1: 0.010332822799682617, 0.1: 0.010457992553710938, 0.01: 0.010313034057617188, 0.001: 0.012807846069335938}\n",
      "0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0050\u001b[0m        \u001b[35m5.0173\u001b[0m  4.8004\n",
      "      2        5.0173       0.0050        5.0173  4.9192\n",
      "      3        5.0173       0.0050        5.0173  5.0085\n",
      "      4        \u001b[36m5.0173\u001b[0m       0.0050        5.0173  5.0333\n",
      "      5        5.0173       0.0050        5.0173  4.8705\n",
      "      6        \u001b[36m5.0173\u001b[0m       0.0050        5.0173  4.9327\n",
      "      7        \u001b[36m5.0173\u001b[0m       0.0050        5.0173  4.9220\n",
      "      8        5.0173       0.0050        5.0173  4.9346\n",
      "      9        5.0173       0.0050        5.0173  4.8638\n",
      "     10        5.0173       0.0050        \u001b[35m5.0173\u001b[0m  4.7841\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{10: 0.006622516556291391, 1: 0.00728476821192053, 0.1: 0.006754966887417219, 0.01: 0.005629139072847682, 0.001: 0.005430463576158941, 0.0001: 0.0054966887417218545}\n",
      "Val accuracy\n",
      "{10: 0.006666666666666667, 1: 0.007333333333333333, 0.1: 0.005666666666666667, 0.01: 0.005333333333333333, 0.001: 0.004, 0.0001: 0.006333333333333333}\n",
      "pred time\n",
      "{10: 0.35844969749450684, 1: 0.3615422248840332, 0.1: 0.3389120101928711, 0.01: 0.3617289066314697, 0.001: 0.3524658679962158, 0.0001: 0.36675310134887695}\n",
      "OOS Val Accuracy\n",
      "{10: 0.0, 1: 0.0, 0.1: 0.0, 0.01: 0.0, 0.001: 0.0, 0.0001: 0.0}\n",
      "OOS pred time\n",
      "{10: 0.012405633926391602, 1: 0.010332822799682617, 0.1: 0.010457992553710938, 0.01: 0.010313034057617188, 0.001: 0.012807846069335938, 0.0001: 0.011964082717895508}\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "hidden_dim = 800\n",
    "dropout = 0.75\n",
    "momentum_list = [10, 1, 0.1, 0.01, 0.001, 0.0001] #assorted momentums for this learning rate\n",
    "for p in momentum_list:    \n",
    "    print(lr)\n",
    "    class CLINCModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                input_dim=vocab_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim,\n",
    "                dropout=dropout\n",
    "        ):\n",
    "            super(CLINCModule, self).__init__()\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "            self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = F.relu(self.hidden(X))\n",
    "            X = self.dropout(X)\n",
    "            X = F.softmax(self.output(X), dim=-1)\n",
    "            return X\n",
    "   \n",
    "    net = NeuralNetClassifier(\n",
    "    module=CLINCModule,\n",
    "    lr=lr,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    max_epochs=1000,\n",
    "    optimizer=torch.optim.SGD, #using SGD as optimizer\n",
    "    optimizer__momentum = p, #looping through momentums\n",
    "    callbacks=[EarlyStopping(patience=10)],\n",
    "    )\n",
    "    \n",
    "    net.fit(train_x, train_y)\n",
    "    tlabels = net.predict(train_x)\n",
    "    tacc[p] = accuracy_score(tlabels, train_y)\n",
    "    print('training accuracy')\n",
    "    print(tacc)\n",
    "    time0 = time.time()\n",
    "    labels = net.predict(val_x)\n",
    "    vacc[p] = accuracy_score(labels, val_y)\n",
    "    time1 = time.time()\n",
    "    vtime[p] = time1-time0\n",
    "    print('Val accuracy')\n",
    "    print(vacc)\n",
    "    print('pred time')\n",
    "    print(vtime)\n",
    "    time2 = time.time()\n",
    "    olabels = net.predict(val_oos_x)\n",
    "    oacc[p] = accuracy_score(olabels, val_oos_y)\n",
    "    time3 = time.time()\n",
    "    otime[p]=time3-time2\n",
    "    print('OOS Val Accuracy')\n",
    "    print(oacc)\n",
    "    print('OOS pred time')\n",
    "    print(otime)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not converging. Adam retained. Investigating hidden layer size again to confirm 800 optimal, including much larger hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0171\u001b[0m       \u001b[32m0.1003\u001b[0m        \u001b[35m5.0168\u001b[0m  1.2308\n",
      "      2        \u001b[36m5.0161\u001b[0m       \u001b[32m0.3182\u001b[0m        \u001b[35m5.0151\u001b[0m  1.1453\n",
      "      3        \u001b[36m5.0126\u001b[0m       0.2010        \u001b[35m5.0086\u001b[0m  1.1499\n",
      "      4        \u001b[36m4.9988\u001b[0m       0.2308        \u001b[35m4.9795\u001b[0m  1.1425\n",
      "      5        \u001b[36m4.9725\u001b[0m       0.2950        \u001b[35m4.9310\u001b[0m  1.1498\n",
      "      6        \u001b[36m4.9466\u001b[0m       \u001b[32m0.3500\u001b[0m        \u001b[35m4.8811\u001b[0m  1.2321\n",
      "      7        \u001b[36m4.9217\u001b[0m       \u001b[32m0.3828\u001b[0m        \u001b[35m4.8349\u001b[0m  1.1786\n",
      "      8        \u001b[36m4.8983\u001b[0m       \u001b[32m0.4262\u001b[0m        \u001b[35m4.7910\u001b[0m  1.2794\n",
      "      9        \u001b[36m4.8830\u001b[0m       \u001b[32m0.4583\u001b[0m        \u001b[35m4.7538\u001b[0m  1.3499\n",
      "     10        \u001b[36m4.8646\u001b[0m       \u001b[32m0.4917\u001b[0m        \u001b[35m4.7219\u001b[0m  1.1764\n",
      "     11        \u001b[36m4.8473\u001b[0m       \u001b[32m0.5169\u001b[0m        \u001b[35m4.6907\u001b[0m  1.2365\n",
      "     12        \u001b[36m4.8351\u001b[0m       \u001b[32m0.5424\u001b[0m        \u001b[35m4.6624\u001b[0m  1.2033\n",
      "     13        \u001b[36m4.8219\u001b[0m       \u001b[32m0.5540\u001b[0m        \u001b[35m4.6364\u001b[0m  1.2312\n",
      "     14        \u001b[36m4.8108\u001b[0m       \u001b[32m0.5649\u001b[0m        \u001b[35m4.6119\u001b[0m  1.3854\n",
      "     15        \u001b[36m4.8028\u001b[0m       \u001b[32m0.5791\u001b[0m        \u001b[35m4.5886\u001b[0m  1.4049\n",
      "     16        \u001b[36m4.7873\u001b[0m       \u001b[32m0.5960\u001b[0m        \u001b[35m4.5690\u001b[0m  1.2272\n",
      "     17        \u001b[36m4.7773\u001b[0m       \u001b[32m0.6060\u001b[0m        \u001b[35m4.5499\u001b[0m  1.2191\n",
      "     18        \u001b[36m4.7694\u001b[0m       \u001b[32m0.6149\u001b[0m        \u001b[35m4.5331\u001b[0m  1.2050\n",
      "     19        \u001b[36m4.7663\u001b[0m       \u001b[32m0.6228\u001b[0m        \u001b[35m4.5185\u001b[0m  1.2258\n",
      "     20        \u001b[36m4.7498\u001b[0m       \u001b[32m0.6305\u001b[0m        \u001b[35m4.5042\u001b[0m  1.2476\n",
      "     21        \u001b[36m4.7442\u001b[0m       \u001b[32m0.6354\u001b[0m        \u001b[35m4.4926\u001b[0m  1.4016\n",
      "     22        \u001b[36m4.7368\u001b[0m       \u001b[32m0.6381\u001b[0m        \u001b[35m4.4822\u001b[0m  1.3998\n",
      "     23        \u001b[36m4.7336\u001b[0m       \u001b[32m0.6444\u001b[0m        \u001b[35m4.4727\u001b[0m  1.2490\n",
      "     24        \u001b[36m4.7277\u001b[0m       \u001b[32m0.6507\u001b[0m        \u001b[35m4.4649\u001b[0m  1.2572\n",
      "     25        \u001b[36m4.7238\u001b[0m       \u001b[32m0.6546\u001b[0m        \u001b[35m4.4559\u001b[0m  1.2860\n",
      "     26        \u001b[36m4.7156\u001b[0m       \u001b[32m0.6603\u001b[0m        \u001b[35m4.4488\u001b[0m  1.3386\n",
      "     27        \u001b[36m4.7098\u001b[0m       \u001b[32m0.6652\u001b[0m        \u001b[35m4.4413\u001b[0m  1.3825\n",
      "     28        \u001b[36m4.7054\u001b[0m       \u001b[32m0.6745\u001b[0m        \u001b[35m4.4340\u001b[0m  1.4063\n",
      "     29        \u001b[36m4.6974\u001b[0m       \u001b[32m0.6778\u001b[0m        \u001b[35m4.4274\u001b[0m  1.3641\n",
      "     30        4.6996       \u001b[32m0.6871\u001b[0m        \u001b[35m4.4202\u001b[0m  1.2522\n",
      "     31        \u001b[36m4.6923\u001b[0m       \u001b[32m0.6947\u001b[0m        \u001b[35m4.4134\u001b[0m  1.1944\n",
      "     32        \u001b[36m4.6801\u001b[0m       \u001b[32m0.7033\u001b[0m        \u001b[35m4.4054\u001b[0m  1.2389\n",
      "     33        \u001b[36m4.6779\u001b[0m       \u001b[32m0.7073\u001b[0m        \u001b[35m4.3996\u001b[0m  1.2213\n",
      "     34        \u001b[36m4.6747\u001b[0m       \u001b[32m0.7129\u001b[0m        \u001b[35m4.3933\u001b[0m  1.2189\n",
      "     35        \u001b[36m4.6714\u001b[0m       \u001b[32m0.7209\u001b[0m        \u001b[35m4.3875\u001b[0m  1.2388\n",
      "     36        \u001b[36m4.6646\u001b[0m       \u001b[32m0.7281\u001b[0m        \u001b[35m4.3821\u001b[0m  1.2379\n",
      "     37        \u001b[36m4.6615\u001b[0m       \u001b[32m0.7321\u001b[0m        \u001b[35m4.3767\u001b[0m  1.2165\n",
      "     38        \u001b[36m4.6579\u001b[0m       \u001b[32m0.7364\u001b[0m        \u001b[35m4.3718\u001b[0m  1.2021\n",
      "     39        \u001b[36m4.6481\u001b[0m       \u001b[32m0.7444\u001b[0m        \u001b[35m4.3663\u001b[0m  1.2058\n",
      "     40        \u001b[36m4.6478\u001b[0m       \u001b[32m0.7467\u001b[0m        \u001b[35m4.3613\u001b[0m  1.2074\n",
      "     41        4.6524       \u001b[32m0.7543\u001b[0m        \u001b[35m4.3562\u001b[0m  1.2038\n",
      "     42        \u001b[36m4.6440\u001b[0m       \u001b[32m0.7579\u001b[0m        \u001b[35m4.3510\u001b[0m  1.1999\n",
      "     43        \u001b[36m4.6425\u001b[0m       \u001b[32m0.7603\u001b[0m        \u001b[35m4.3468\u001b[0m  1.2056\n",
      "     44        \u001b[36m4.6403\u001b[0m       \u001b[32m0.7616\u001b[0m        \u001b[35m4.3427\u001b[0m  1.2023\n",
      "     45        \u001b[36m4.6367\u001b[0m       \u001b[32m0.7639\u001b[0m        \u001b[35m4.3381\u001b[0m  1.2035\n",
      "     46        \u001b[36m4.6311\u001b[0m       0.7626        \u001b[35m4.3344\u001b[0m  1.1993\n",
      "     47        \u001b[36m4.6253\u001b[0m       0.7632        \u001b[35m4.3305\u001b[0m  1.1995\n",
      "     48        4.6267       \u001b[32m0.7666\u001b[0m        \u001b[35m4.3262\u001b[0m  1.2034\n",
      "     49        4.6260       \u001b[32m0.7709\u001b[0m        \u001b[35m4.3234\u001b[0m  1.2043\n",
      "     50        \u001b[36m4.6209\u001b[0m       \u001b[32m0.7719\u001b[0m        \u001b[35m4.3199\u001b[0m  1.2127\n",
      "     51        \u001b[36m4.6185\u001b[0m       \u001b[32m0.7762\u001b[0m        \u001b[35m4.3169\u001b[0m  1.2052\n",
      "     52        \u001b[36m4.6148\u001b[0m       \u001b[32m0.7768\u001b[0m        \u001b[35m4.3136\u001b[0m  1.2051\n",
      "     53        \u001b[36m4.6099\u001b[0m       \u001b[32m0.7795\u001b[0m        \u001b[35m4.3103\u001b[0m  1.2062\n",
      "     54        \u001b[36m4.6089\u001b[0m       \u001b[32m0.7844\u001b[0m        \u001b[35m4.3067\u001b[0m  1.1990\n",
      "     55        \u001b[36m4.6065\u001b[0m       \u001b[32m0.7901\u001b[0m        \u001b[35m4.3037\u001b[0m  1.2040\n",
      "     56        4.6070       \u001b[32m0.7904\u001b[0m        \u001b[35m4.3004\u001b[0m  1.2005\n",
      "     57        \u001b[36m4.6007\u001b[0m       \u001b[32m0.7934\u001b[0m        \u001b[35m4.2972\u001b[0m  1.3177\n",
      "     58        \u001b[36m4.5970\u001b[0m       \u001b[32m0.7937\u001b[0m        \u001b[35m4.2943\u001b[0m  1.2491\n",
      "     59        4.5973       \u001b[32m0.7947\u001b[0m        \u001b[35m4.2907\u001b[0m  1.2067\n",
      "     60        \u001b[36m4.5953\u001b[0m       \u001b[32m0.7954\u001b[0m        \u001b[35m4.2886\u001b[0m  1.2625\n",
      "     61        \u001b[36m4.5905\u001b[0m       0.7950        \u001b[35m4.2859\u001b[0m  1.1995\n",
      "     62        4.5915       \u001b[32m0.7980\u001b[0m        \u001b[35m4.2829\u001b[0m  1.1994\n",
      "     63        \u001b[36m4.5840\u001b[0m       \u001b[32m0.8003\u001b[0m        \u001b[35m4.2807\u001b[0m  1.2165\n",
      "     64        4.5848       0.8003        \u001b[35m4.2782\u001b[0m  1.2114\n",
      "     65        \u001b[36m4.5773\u001b[0m       \u001b[32m0.8026\u001b[0m        \u001b[35m4.2761\u001b[0m  1.1872\n",
      "     66        4.5785       \u001b[32m0.8060\u001b[0m        \u001b[35m4.2738\u001b[0m  1.2102\n",
      "     67        4.5822       0.8050        \u001b[35m4.2725\u001b[0m  1.1860\n",
      "     68        \u001b[36m4.5717\u001b[0m       \u001b[32m0.8079\u001b[0m        \u001b[35m4.2702\u001b[0m  1.1929\n",
      "     69        4.5728       \u001b[32m0.8083\u001b[0m        \u001b[35m4.2685\u001b[0m  1.2056\n",
      "     70        \u001b[36m4.5675\u001b[0m       \u001b[32m0.8099\u001b[0m        \u001b[35m4.2666\u001b[0m  1.1873\n",
      "     71        \u001b[36m4.5637\u001b[0m       0.8083        \u001b[35m4.2647\u001b[0m  1.2008\n",
      "     72        4.5639       0.8079        \u001b[35m4.2623\u001b[0m  1.2689\n",
      "     73        4.5709       \u001b[32m0.8106\u001b[0m        \u001b[35m4.2605\u001b[0m  1.2410\n",
      "     74        \u001b[36m4.5627\u001b[0m       \u001b[32m0.8113\u001b[0m        \u001b[35m4.2586\u001b[0m  1.2422\n",
      "     75        \u001b[36m4.5554\u001b[0m       \u001b[32m0.8116\u001b[0m        \u001b[35m4.2566\u001b[0m  1.2142\n",
      "     76        4.5566       \u001b[32m0.8149\u001b[0m        \u001b[35m4.2547\u001b[0m  1.1991\n",
      "     77        4.5587       \u001b[32m0.8185\u001b[0m        \u001b[35m4.2525\u001b[0m  1.2510\n",
      "     78        \u001b[36m4.5543\u001b[0m       \u001b[32m0.8195\u001b[0m        \u001b[35m4.2501\u001b[0m  1.2149\n",
      "     79        \u001b[36m4.5500\u001b[0m       \u001b[32m0.8202\u001b[0m        \u001b[35m4.2487\u001b[0m  1.2192\n",
      "     80        4.5562       \u001b[32m0.8212\u001b[0m        \u001b[35m4.2469\u001b[0m  1.2732\n",
      "     81        \u001b[36m4.5467\u001b[0m       \u001b[32m0.8222\u001b[0m        \u001b[35m4.2447\u001b[0m  1.2145\n",
      "     82        4.5478       \u001b[32m0.8248\u001b[0m        \u001b[35m4.2429\u001b[0m  1.2211\n",
      "     83        \u001b[36m4.5456\u001b[0m       \u001b[32m0.8258\u001b[0m        \u001b[35m4.2410\u001b[0m  1.2192\n",
      "     84        \u001b[36m4.5418\u001b[0m       \u001b[32m0.8281\u001b[0m        \u001b[35m4.2390\u001b[0m  1.2521\n",
      "     85        4.5421       \u001b[32m0.8285\u001b[0m        \u001b[35m4.2369\u001b[0m  1.2116\n",
      "     86        4.5443       \u001b[32m0.8311\u001b[0m        \u001b[35m4.2352\u001b[0m  1.2130\n",
      "     87        4.5442       0.8311        \u001b[35m4.2338\u001b[0m  1.2569\n",
      "     88        \u001b[36m4.5408\u001b[0m       \u001b[32m0.8315\u001b[0m        \u001b[35m4.2329\u001b[0m  1.2095\n",
      "     89        \u001b[36m4.5319\u001b[0m       0.8315        \u001b[35m4.2318\u001b[0m  1.2353\n",
      "     90        \u001b[36m4.5282\u001b[0m       \u001b[32m0.8318\u001b[0m        \u001b[35m4.2304\u001b[0m  1.2134\n",
      "     91        4.5333       \u001b[32m0.8351\u001b[0m        \u001b[35m4.2290\u001b[0m  1.2172\n",
      "     92        \u001b[36m4.5261\u001b[0m       \u001b[32m0.8358\u001b[0m        \u001b[35m4.2275\u001b[0m  1.2090\n",
      "     93        4.5306       \u001b[32m0.8361\u001b[0m        \u001b[35m4.2263\u001b[0m  1.2117\n",
      "     94        \u001b[36m4.5235\u001b[0m       \u001b[32m0.8368\u001b[0m        \u001b[35m4.2254\u001b[0m  1.2249\n",
      "     95        4.5300       \u001b[32m0.8377\u001b[0m        \u001b[35m4.2241\u001b[0m  1.2444\n",
      "     96        4.5251       \u001b[32m0.8384\u001b[0m        \u001b[35m4.2229\u001b[0m  1.2418\n",
      "     97        4.5244       \u001b[32m0.8391\u001b[0m        \u001b[35m4.2216\u001b[0m  1.2207\n",
      "     98        \u001b[36m4.5194\u001b[0m       0.8384        \u001b[35m4.2205\u001b[0m  1.2169\n",
      "     99        4.5238       0.8391        \u001b[35m4.2200\u001b[0m  1.2431\n",
      "    100        4.5194       \u001b[32m0.8397\u001b[0m        \u001b[35m4.2192\u001b[0m  1.2189\n",
      "    101        4.5208       \u001b[32m0.8414\u001b[0m        \u001b[35m4.2180\u001b[0m  1.2243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    102        \u001b[36m4.5083\u001b[0m       0.8411        \u001b[35m4.2172\u001b[0m  1.2439\n",
      "    103        4.5121       \u001b[32m0.8421\u001b[0m        \u001b[35m4.2159\u001b[0m  1.2251\n",
      "    104        4.5134       0.8417        \u001b[35m4.2147\u001b[0m  1.2163\n",
      "    105        4.5107       \u001b[32m0.8424\u001b[0m        \u001b[35m4.2137\u001b[0m  1.2485\n",
      "    106        4.5149       \u001b[32m0.8430\u001b[0m        \u001b[35m4.2122\u001b[0m  1.2390\n",
      "    107        4.5093       \u001b[32m0.8434\u001b[0m        \u001b[35m4.2115\u001b[0m  1.2381\n",
      "    108        4.5112       \u001b[32m0.8437\u001b[0m        \u001b[35m4.2107\u001b[0m  1.2478\n",
      "    109        \u001b[36m4.5036\u001b[0m       0.8427        \u001b[35m4.2100\u001b[0m  1.3385\n",
      "    110        4.5125       0.8434        \u001b[35m4.2099\u001b[0m  1.3001\n",
      "    111        \u001b[36m4.5014\u001b[0m       \u001b[32m0.8440\u001b[0m        \u001b[35m4.2091\u001b[0m  1.2332\n",
      "    112        4.5058       0.8437        \u001b[35m4.2084\u001b[0m  1.2357\n",
      "    113        \u001b[36m4.4964\u001b[0m       \u001b[32m0.8467\u001b[0m        \u001b[35m4.2074\u001b[0m  1.2409\n",
      "    114        4.5010       0.8457        \u001b[35m4.2069\u001b[0m  1.2552\n",
      "    115        4.4974       0.8467        4.2069  1.2314\n",
      "    116        \u001b[36m4.4939\u001b[0m       \u001b[32m0.8470\u001b[0m        \u001b[35m4.2060\u001b[0m  1.2482\n",
      "    117        \u001b[36m4.4905\u001b[0m       \u001b[32m0.8487\u001b[0m        \u001b[35m4.2050\u001b[0m  1.2414\n",
      "    118        4.5001       0.8487        \u001b[35m4.2043\u001b[0m  1.2749\n",
      "    119        4.5014       \u001b[32m0.8493\u001b[0m        \u001b[35m4.2038\u001b[0m  1.2219\n",
      "    120        4.4981       \u001b[32m0.8507\u001b[0m        \u001b[35m4.2031\u001b[0m  1.2557\n",
      "    121        4.4949       \u001b[32m0.8513\u001b[0m        \u001b[35m4.2025\u001b[0m  1.2365\n",
      "    122        4.4980       0.8507        \u001b[35m4.2022\u001b[0m  1.2444\n",
      "    123        \u001b[36m4.4901\u001b[0m       0.8497        \u001b[35m4.2019\u001b[0m  1.2330\n",
      "    124        4.4910       0.8500        \u001b[35m4.2017\u001b[0m  1.2375\n",
      "    125        4.4921       0.8500        \u001b[35m4.2009\u001b[0m  1.2313\n",
      "    126        \u001b[36m4.4895\u001b[0m       0.8507        \u001b[35m4.2005\u001b[0m  1.2330\n",
      "    127        \u001b[36m4.4835\u001b[0m       0.8487        \u001b[35m4.1999\u001b[0m  1.2351\n",
      "    128        \u001b[36m4.4828\u001b[0m       0.8510        \u001b[35m4.1993\u001b[0m  1.2383\n",
      "    129        \u001b[36m4.4792\u001b[0m       \u001b[32m0.8517\u001b[0m        \u001b[35m4.1988\u001b[0m  1.2487\n",
      "    130        \u001b[36m4.4782\u001b[0m       0.8507        \u001b[35m4.1986\u001b[0m  1.2571\n",
      "    131        4.4838       0.8513        \u001b[35m4.1979\u001b[0m  1.2341\n",
      "    132        \u001b[36m4.4738\u001b[0m       \u001b[32m0.8520\u001b[0m        4.1981  1.2965\n",
      "    133        4.4778       \u001b[32m0.8526\u001b[0m        \u001b[35m4.1979\u001b[0m  1.2341\n",
      "    134        4.4853       0.8510        \u001b[35m4.1974\u001b[0m  1.2319\n",
      "    135        4.4817       \u001b[32m0.8536\u001b[0m        \u001b[35m4.1966\u001b[0m  1.2449\n",
      "    136        \u001b[36m4.4717\u001b[0m       0.8517        \u001b[35m4.1964\u001b[0m  1.2378\n",
      "    137        4.4738       0.8526        \u001b[35m4.1962\u001b[0m  1.2473\n",
      "    138        4.4763       0.8533        \u001b[35m4.1959\u001b[0m  1.2326\n",
      "    139        \u001b[36m4.4714\u001b[0m       0.8517        \u001b[35m4.1958\u001b[0m  1.2622\n",
      "    140        \u001b[36m4.4700\u001b[0m       0.8533        \u001b[35m4.1951\u001b[0m  1.2410\n",
      "    141        4.4719       0.8523        4.1952  1.2530\n",
      "    142        \u001b[36m4.4675\u001b[0m       0.8523        \u001b[35m4.1949\u001b[0m  1.2355\n",
      "    143        4.4739       0.8523        \u001b[35m4.1943\u001b[0m  1.2515\n",
      "    144        \u001b[36m4.4657\u001b[0m       \u001b[32m0.8546\u001b[0m        \u001b[35m4.1939\u001b[0m  1.2490\n",
      "    145        4.4717       0.8530        \u001b[35m4.1936\u001b[0m  1.2687\n",
      "    146        \u001b[36m4.4630\u001b[0m       \u001b[32m0.8550\u001b[0m        \u001b[35m4.1933\u001b[0m  1.2513\n",
      "    147        4.4662       0.8543        \u001b[35m4.1931\u001b[0m  1.2694\n",
      "    148        4.4646       0.8543        \u001b[35m4.1926\u001b[0m  1.4105\n",
      "    149        4.4665       0.8546        \u001b[35m4.1924\u001b[0m  1.7525\n",
      "    150        \u001b[36m4.4604\u001b[0m       0.8540        4.1926  1.2905\n",
      "    151        4.4612       0.8543        \u001b[35m4.1922\u001b[0m  1.3369\n",
      "    152        \u001b[36m4.4604\u001b[0m       \u001b[32m0.8563\u001b[0m        \u001b[35m4.1917\u001b[0m  1.3201\n",
      "    153        \u001b[36m4.4529\u001b[0m       0.8563        \u001b[35m4.1916\u001b[0m  1.2607\n",
      "    154        4.4665       0.8553        \u001b[35m4.1913\u001b[0m  1.2431\n",
      "    155        4.4532       0.8553        \u001b[35m4.1911\u001b[0m  1.2841\n",
      "    156        4.4559       \u001b[32m0.8566\u001b[0m        \u001b[35m4.1908\u001b[0m  1.3241\n",
      "    157        4.4572       0.8566        \u001b[35m4.1905\u001b[0m  1.3072\n",
      "    158        4.4560       0.8563        \u001b[35m4.1904\u001b[0m  1.2482\n",
      "    159        4.4600       0.8556        \u001b[35m4.1901\u001b[0m  1.2871\n",
      "    160        4.4542       0.8566        \u001b[35m4.1898\u001b[0m  1.2630\n",
      "    161        4.4558       0.8566        4.1898  1.2491\n",
      "    162        4.4542       0.8566        \u001b[35m4.1894\u001b[0m  1.2219\n",
      "    163        \u001b[36m4.4461\u001b[0m       \u001b[32m0.8583\u001b[0m        \u001b[35m4.1892\u001b[0m  1.2529\n",
      "    164        4.4556       0.8563        \u001b[35m4.1891\u001b[0m  1.2513\n",
      "    165        4.4516       0.8583        \u001b[35m4.1888\u001b[0m  1.2456\n",
      "    166        4.4554       0.8583        4.1890  1.2422\n",
      "    167        4.4516       0.8579        4.1890  1.2513\n",
      "    168        \u001b[36m4.4437\u001b[0m       0.8563        \u001b[35m4.1887\u001b[0m  1.2400\n",
      "    169        4.4520       0.8553        \u001b[35m4.1884\u001b[0m  1.2423\n",
      "    170        \u001b[36m4.4416\u001b[0m       0.8546        \u001b[35m4.1883\u001b[0m  1.2447\n",
      "    171        4.4491       0.8563        \u001b[35m4.1879\u001b[0m  1.2424\n",
      "    172        4.4465       0.8566        \u001b[35m4.1877\u001b[0m  1.2491\n",
      "    173        4.4450       0.8573        \u001b[35m4.1871\u001b[0m  1.2454\n",
      "    174        4.4438       0.8579        \u001b[35m4.1865\u001b[0m  1.2663\n",
      "    175        4.4477       0.8579        \u001b[35m4.1863\u001b[0m  1.2550\n",
      "    176        \u001b[36m4.4409\u001b[0m       0.8573        4.1865  1.2508\n",
      "    177        4.4448       \u001b[32m0.8593\u001b[0m        \u001b[35m4.1861\u001b[0m  1.2535\n",
      "    178        4.4432       0.8583        \u001b[35m4.1861\u001b[0m  1.2488\n",
      "    179        \u001b[36m4.4400\u001b[0m       0.8576        \u001b[35m4.1859\u001b[0m  1.2481\n",
      "    180        4.4421       0.8579        4.1861  1.2507\n",
      "    181        \u001b[36m4.4400\u001b[0m       0.8573        \u001b[35m4.1859\u001b[0m  1.2568\n",
      "    182        4.4477       0.8579        \u001b[35m4.1855\u001b[0m  1.2429\n",
      "    183        4.4414       \u001b[32m0.8603\u001b[0m        \u001b[35m4.1850\u001b[0m  1.2580\n",
      "    184        \u001b[36m4.4327\u001b[0m       0.8589        4.1851  1.2496\n",
      "    185        \u001b[36m4.4312\u001b[0m       0.8589        \u001b[35m4.1847\u001b[0m  1.2460\n",
      "    186        4.4343       0.8573        4.1850  1.2514\n",
      "    187        4.4317       0.8586        \u001b[35m4.1841\u001b[0m  1.2506\n",
      "    188        \u001b[36m4.4288\u001b[0m       0.8573        \u001b[35m4.1841\u001b[0m  1.2533\n",
      "    189        4.4375       0.8570        \u001b[35m4.1837\u001b[0m  1.2455\n",
      "    190        4.4309       0.8593        \u001b[35m4.1832\u001b[0m  1.2532\n",
      "    191        4.4289       \u001b[32m0.8606\u001b[0m        \u001b[35m4.1826\u001b[0m  1.2534\n",
      "    192        4.4292       \u001b[32m0.8609\u001b[0m        \u001b[35m4.1823\u001b[0m  1.2536\n",
      "    193        4.4330       \u001b[32m0.8616\u001b[0m        \u001b[35m4.1819\u001b[0m  1.2540\n",
      "    194        4.4312       \u001b[32m0.8619\u001b[0m        4.1820  1.2883\n",
      "    195        4.4339       \u001b[32m0.8629\u001b[0m        \u001b[35m4.1819\u001b[0m  1.2592\n",
      "    196        4.4319       0.8623        \u001b[35m4.1816\u001b[0m  1.2768\n",
      "    197        4.4321       0.8623        \u001b[35m4.1814\u001b[0m  1.2793\n",
      "    198        4.4316       0.8629        \u001b[35m4.1813\u001b[0m  1.2504\n",
      "    199        \u001b[36m4.4274\u001b[0m       0.8629        \u001b[35m4.1809\u001b[0m  1.2576\n",
      "    200        4.4328       0.8629        4.1812  1.2655\n",
      "    201        \u001b[36m4.4220\u001b[0m       \u001b[32m0.8632\u001b[0m        4.1809  1.2746\n",
      "    202        4.4280       \u001b[32m0.8636\u001b[0m        \u001b[35m4.1806\u001b[0m  1.2507\n",
      "    203        4.4323       0.8636        \u001b[35m4.1802\u001b[0m  1.2569\n",
      "    204        4.4270       0.8629        4.1804  1.2616\n",
      "    205        4.4237       0.8623        4.1802  1.2575\n",
      "    206        4.4256       \u001b[32m0.8646\u001b[0m        \u001b[35m4.1798\u001b[0m  1.2568\n",
      "    207        4.4229       0.8616        4.1801  1.2586\n",
      "    208        \u001b[36m4.4208\u001b[0m       0.8629        \u001b[35m4.1797\u001b[0m  1.2570\n",
      "    209        \u001b[36m4.4207\u001b[0m       0.8632        4.1798  1.2674\n",
      "    210        \u001b[36m4.4202\u001b[0m       0.8629        \u001b[35m4.1797\u001b[0m  1.2689\n",
      "    211        4.4232       0.8626        \u001b[35m4.1796\u001b[0m  1.2645\n",
      "    212        4.4251       0.8616        4.1797  1.2669\n",
      "    213        \u001b[36m4.4148\u001b[0m       0.8623        \u001b[35m4.1794\u001b[0m  1.3147\n",
      "    214        4.4169       0.8629        \u001b[35m4.1792\u001b[0m  1.2918\n",
      "    215        4.4175       0.8636        \u001b[35m4.1788\u001b[0m  1.2586\n",
      "    216        4.4172       0.8629        4.1792  1.2669\n",
      "    217        4.4156       0.8626        4.1789  1.2586\n",
      "    218        4.4182       0.8626        4.1789  1.2935\n",
      "    219        \u001b[36m4.4081\u001b[0m       0.8646        \u001b[35m4.1785\u001b[0m  1.2608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    220        4.4140       0.8629        4.1789  1.2701\n",
      "    221        4.4147       0.8632        4.1789  1.2620\n",
      "    222        4.4166       0.8613        4.1791  1.2601\n",
      "    223        4.4100       0.8619        4.1793  1.2705\n",
      "    224        4.4191       0.8609        4.1795  1.2652\n",
      "    225        4.4098       0.8609        4.1793  1.2639\n",
      "    226        4.4099       0.8623        4.1793  1.2722\n",
      "    227        4.4113       0.8619        4.1794  1.2683\n",
      "    228        4.4084       0.8606        4.1791  1.2691\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{50: 0.9144370860927152}\n",
      "Val accuracy\n",
      "{50: 0.8266666666666667}\n",
      "pred time\n",
      "{50: 0.1441209316253662}\n",
      "OOS Val Accuracy\n",
      "{50: 0.04}\n",
      "OOS pred time\n",
      "{50: 0.0038161277770996094}\n",
      "100\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0170\u001b[0m       \u001b[32m0.2689\u001b[0m        \u001b[35m5.0165\u001b[0m  1.4337\n",
      "      2        \u001b[36m5.0149\u001b[0m       \u001b[32m0.4285\u001b[0m        \u001b[35m5.0122\u001b[0m  1.4186\n",
      "      3        \u001b[36m4.9994\u001b[0m       0.2834        \u001b[35m4.9696\u001b[0m  1.4135\n",
      "      4        \u001b[36m4.9371\u001b[0m       0.3526        \u001b[35m4.8655\u001b[0m  1.4124\n",
      "      5        \u001b[36m4.8688\u001b[0m       0.4225        \u001b[35m4.7735\u001b[0m  1.4083\n",
      "      6        \u001b[36m4.8132\u001b[0m       \u001b[32m0.4864\u001b[0m        \u001b[35m4.6993\u001b[0m  1.4294\n",
      "      7        \u001b[36m4.7614\u001b[0m       \u001b[32m0.5387\u001b[0m        \u001b[35m4.6328\u001b[0m  1.3936\n",
      "      8        \u001b[36m4.7136\u001b[0m       \u001b[32m0.5745\u001b[0m        \u001b[35m4.5754\u001b[0m  1.4132\n",
      "      9        \u001b[36m4.6732\u001b[0m       \u001b[32m0.6030\u001b[0m        \u001b[35m4.5298\u001b[0m  1.4200\n",
      "     10        \u001b[36m4.6374\u001b[0m       \u001b[32m0.6205\u001b[0m        \u001b[35m4.4929\u001b[0m  1.4487\n",
      "     11        \u001b[36m4.6086\u001b[0m       \u001b[32m0.6464\u001b[0m        \u001b[35m4.4653\u001b[0m  1.4409\n",
      "     12        \u001b[36m4.5816\u001b[0m       \u001b[32m0.6573\u001b[0m        \u001b[35m4.4451\u001b[0m  1.4319\n",
      "     13        \u001b[36m4.5672\u001b[0m       \u001b[32m0.6712\u001b[0m        \u001b[35m4.4268\u001b[0m  1.4486\n",
      "     14        \u001b[36m4.5451\u001b[0m       \u001b[32m0.6811\u001b[0m        \u001b[35m4.4112\u001b[0m  1.5355\n",
      "     15        \u001b[36m4.5313\u001b[0m       \u001b[32m0.6927\u001b[0m        \u001b[35m4.3970\u001b[0m  1.4552\n",
      "     16        \u001b[36m4.5140\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m4.3845\u001b[0m  1.4607\n",
      "     17        \u001b[36m4.4987\u001b[0m       \u001b[32m0.7152\u001b[0m        \u001b[35m4.3722\u001b[0m  1.4722\n",
      "     18        \u001b[36m4.4878\u001b[0m       \u001b[32m0.7209\u001b[0m        \u001b[35m4.3617\u001b[0m  1.4568\n",
      "     19        \u001b[36m4.4727\u001b[0m       \u001b[32m0.7298\u001b[0m        \u001b[35m4.3494\u001b[0m  1.4678\n",
      "     20        \u001b[36m4.4650\u001b[0m       \u001b[32m0.7377\u001b[0m        \u001b[35m4.3382\u001b[0m  1.4627\n",
      "     21        \u001b[36m4.4523\u001b[0m       \u001b[32m0.7427\u001b[0m        \u001b[35m4.3292\u001b[0m  1.5305\n",
      "     22        \u001b[36m4.4422\u001b[0m       \u001b[32m0.7477\u001b[0m        \u001b[35m4.3217\u001b[0m  1.4702\n",
      "     23        \u001b[36m4.4323\u001b[0m       \u001b[32m0.7520\u001b[0m        \u001b[35m4.3143\u001b[0m  1.4749\n",
      "     24        \u001b[36m4.4240\u001b[0m       \u001b[32m0.7619\u001b[0m        \u001b[35m4.3070\u001b[0m  1.4606\n",
      "     25        \u001b[36m4.4154\u001b[0m       \u001b[32m0.7632\u001b[0m        \u001b[35m4.3023\u001b[0m  1.4674\n",
      "     26        \u001b[36m4.4065\u001b[0m       \u001b[32m0.7666\u001b[0m        \u001b[35m4.2976\u001b[0m  1.4600\n",
      "     27        \u001b[36m4.4019\u001b[0m       \u001b[32m0.7705\u001b[0m        \u001b[35m4.2928\u001b[0m  1.4705\n",
      "     28        \u001b[36m4.3952\u001b[0m       \u001b[32m0.7765\u001b[0m        \u001b[35m4.2879\u001b[0m  1.5227\n",
      "     29        \u001b[36m4.3881\u001b[0m       \u001b[32m0.7791\u001b[0m        \u001b[35m4.2825\u001b[0m  1.4663\n",
      "     30        \u001b[36m4.3797\u001b[0m       \u001b[32m0.7874\u001b[0m        \u001b[35m4.2758\u001b[0m  1.4831\n",
      "     31        \u001b[36m4.3748\u001b[0m       \u001b[32m0.7957\u001b[0m        \u001b[35m4.2699\u001b[0m  1.4646\n",
      "     32        \u001b[36m4.3669\u001b[0m       \u001b[32m0.8007\u001b[0m        \u001b[35m4.2635\u001b[0m  1.4697\n",
      "     33        \u001b[36m4.3564\u001b[0m       \u001b[32m0.8083\u001b[0m        \u001b[35m4.2582\u001b[0m  1.4644\n",
      "     34        \u001b[36m4.3522\u001b[0m       \u001b[32m0.8172\u001b[0m        \u001b[35m4.2522\u001b[0m  1.4810\n",
      "     35        \u001b[36m4.3481\u001b[0m       \u001b[32m0.8225\u001b[0m        \u001b[35m4.2468\u001b[0m  1.4706\n",
      "     36        \u001b[36m4.3416\u001b[0m       \u001b[32m0.8291\u001b[0m        \u001b[35m4.2416\u001b[0m  1.4741\n",
      "     37        \u001b[36m4.3374\u001b[0m       \u001b[32m0.8325\u001b[0m        \u001b[35m4.2354\u001b[0m  1.4790\n",
      "     38        \u001b[36m4.3280\u001b[0m       \u001b[32m0.8344\u001b[0m        \u001b[35m4.2296\u001b[0m  1.4715\n",
      "     39        \u001b[36m4.3265\u001b[0m       \u001b[32m0.8381\u001b[0m        \u001b[35m4.2244\u001b[0m  1.4789\n",
      "     40        \u001b[36m4.3179\u001b[0m       \u001b[32m0.8407\u001b[0m        \u001b[35m4.2200\u001b[0m  1.4679\n",
      "     41        \u001b[36m4.3120\u001b[0m       \u001b[32m0.8440\u001b[0m        \u001b[35m4.2153\u001b[0m  1.4813\n",
      "     42        \u001b[36m4.3046\u001b[0m       0.8434        \u001b[35m4.2124\u001b[0m  1.4816\n",
      "     43        \u001b[36m4.3025\u001b[0m       \u001b[32m0.8454\u001b[0m        \u001b[35m4.2095\u001b[0m  1.4800\n",
      "     44        \u001b[36m4.2983\u001b[0m       \u001b[32m0.8487\u001b[0m        \u001b[35m4.2064\u001b[0m  1.4653\n",
      "     45        \u001b[36m4.2955\u001b[0m       \u001b[32m0.8520\u001b[0m        \u001b[35m4.2033\u001b[0m  1.4730\n",
      "     46        \u001b[36m4.2920\u001b[0m       \u001b[32m0.8530\u001b[0m        \u001b[35m4.2005\u001b[0m  1.4806\n",
      "     47        \u001b[36m4.2853\u001b[0m       \u001b[32m0.8536\u001b[0m        \u001b[35m4.1981\u001b[0m  1.4691\n",
      "     48        \u001b[36m4.2824\u001b[0m       \u001b[32m0.8573\u001b[0m        \u001b[35m4.1959\u001b[0m  1.5250\n",
      "     49        \u001b[36m4.2780\u001b[0m       \u001b[32m0.8586\u001b[0m        \u001b[35m4.1938\u001b[0m  1.5225\n",
      "     50        \u001b[36m4.2716\u001b[0m       \u001b[32m0.8629\u001b[0m        \u001b[35m4.1910\u001b[0m  1.5036\n",
      "     51        \u001b[36m4.2696\u001b[0m       \u001b[32m0.8632\u001b[0m        \u001b[35m4.1890\u001b[0m  1.4858\n",
      "     52        4.2708       \u001b[32m0.8652\u001b[0m        \u001b[35m4.1871\u001b[0m  1.4711\n",
      "     53        \u001b[36m4.2627\u001b[0m       \u001b[32m0.8662\u001b[0m        \u001b[35m4.1856\u001b[0m  1.4754\n",
      "     54        \u001b[36m4.2595\u001b[0m       \u001b[32m0.8675\u001b[0m        \u001b[35m4.1846\u001b[0m  1.5098\n",
      "     55        4.2634       \u001b[32m0.8682\u001b[0m        \u001b[35m4.1831\u001b[0m  1.4700\n",
      "     56        \u001b[36m4.2560\u001b[0m       0.8682        \u001b[35m4.1822\u001b[0m  1.4811\n",
      "     57        \u001b[36m4.2547\u001b[0m       0.8682        \u001b[35m4.1808\u001b[0m  1.4922\n",
      "     58        \u001b[36m4.2527\u001b[0m       \u001b[32m0.8689\u001b[0m        \u001b[35m4.1798\u001b[0m  1.4780\n",
      "     59        \u001b[36m4.2478\u001b[0m       0.8682        \u001b[35m4.1789\u001b[0m  1.4734\n",
      "     60        \u001b[36m4.2449\u001b[0m       \u001b[32m0.8705\u001b[0m        \u001b[35m4.1780\u001b[0m  1.4752\n",
      "     61        4.2454       0.8702        \u001b[35m4.1767\u001b[0m  1.4862\n",
      "     62        \u001b[36m4.2391\u001b[0m       0.8699        \u001b[35m4.1757\u001b[0m  1.4775\n",
      "     63        4.2402       \u001b[32m0.8715\u001b[0m        \u001b[35m4.1748\u001b[0m  1.4757\n",
      "     64        \u001b[36m4.2388\u001b[0m       0.8715        \u001b[35m4.1741\u001b[0m  1.4709\n",
      "     65        \u001b[36m4.2329\u001b[0m       \u001b[32m0.8728\u001b[0m        \u001b[35m4.1732\u001b[0m  1.4830\n",
      "     66        4.2346       0.8725        \u001b[35m4.1726\u001b[0m  1.4858\n",
      "     67        \u001b[36m4.2265\u001b[0m       0.8725        \u001b[35m4.1717\u001b[0m  1.4733\n",
      "     68        \u001b[36m4.2250\u001b[0m       0.8728        \u001b[35m4.1709\u001b[0m  1.4826\n",
      "     69        4.2286       \u001b[32m0.8752\u001b[0m        \u001b[35m4.1702\u001b[0m  1.4733\n",
      "     70        4.2286       0.8735        \u001b[35m4.1698\u001b[0m  1.5066\n",
      "     71        4.2250       \u001b[32m0.8755\u001b[0m        \u001b[35m4.1695\u001b[0m  1.4826\n",
      "     72        \u001b[36m4.2242\u001b[0m       0.8755        \u001b[35m4.1689\u001b[0m  1.4787\n",
      "     73        \u001b[36m4.2207\u001b[0m       \u001b[32m0.8768\u001b[0m        \u001b[35m4.1681\u001b[0m  1.4958\n",
      "     74        \u001b[36m4.2179\u001b[0m       0.8755        \u001b[35m4.1675\u001b[0m  1.4798\n",
      "     75        4.2183       \u001b[32m0.8772\u001b[0m        \u001b[35m4.1668\u001b[0m  1.4898\n",
      "     76        \u001b[36m4.2158\u001b[0m       \u001b[32m0.8781\u001b[0m        \u001b[35m4.1665\u001b[0m  1.4832\n",
      "     77        \u001b[36m4.2141\u001b[0m       0.8755        \u001b[35m4.1662\u001b[0m  1.4728\n",
      "     78        \u001b[36m4.2123\u001b[0m       0.8778        \u001b[35m4.1653\u001b[0m  1.4827\n",
      "     79        \u001b[36m4.2122\u001b[0m       \u001b[32m0.8795\u001b[0m        \u001b[35m4.1648\u001b[0m  1.4932\n",
      "     80        \u001b[36m4.2104\u001b[0m       0.8778        \u001b[35m4.1644\u001b[0m  1.4804\n",
      "     81        \u001b[36m4.2067\u001b[0m       0.8772        \u001b[35m4.1640\u001b[0m  1.4910\n",
      "     82        4.2097       0.8788        \u001b[35m4.1631\u001b[0m  1.4725\n",
      "     83        4.2079       0.8781        \u001b[35m4.1629\u001b[0m  1.4846\n",
      "     84        \u001b[36m4.2048\u001b[0m       0.8765        \u001b[35m4.1627\u001b[0m  1.4886\n",
      "     85        \u001b[36m4.2008\u001b[0m       0.8795        \u001b[35m4.1620\u001b[0m  1.4787\n",
      "     86        4.2038       0.8791        \u001b[35m4.1618\u001b[0m  1.4850\n",
      "     87        4.2021       0.8791        \u001b[35m4.1617\u001b[0m  1.5190\n",
      "     88        \u001b[36m4.1963\u001b[0m       \u001b[32m0.8798\u001b[0m        \u001b[35m4.1610\u001b[0m  1.5082\n",
      "     89        4.1979       0.8795        \u001b[35m4.1604\u001b[0m  1.5118\n",
      "     90        4.1965       0.8795        \u001b[35m4.1602\u001b[0m  1.4912\n",
      "     91        4.1986       0.8795        \u001b[35m4.1599\u001b[0m  1.4789\n",
      "     92        \u001b[36m4.1940\u001b[0m       \u001b[32m0.8805\u001b[0m        \u001b[35m4.1591\u001b[0m  1.4868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     93        \u001b[36m4.1908\u001b[0m       \u001b[32m0.8834\u001b[0m        \u001b[35m4.1580\u001b[0m  1.5022\n",
      "     94        4.1923       \u001b[32m0.8848\u001b[0m        \u001b[35m4.1573\u001b[0m  1.4859\n",
      "     95        4.1918       0.8848        \u001b[35m4.1567\u001b[0m  1.4935\n",
      "     96        \u001b[36m4.1887\u001b[0m       0.8834        \u001b[35m4.1564\u001b[0m  1.4932\n",
      "     97        \u001b[36m4.1886\u001b[0m       0.8848        \u001b[35m4.1557\u001b[0m  1.4913\n",
      "     98        4.1898       0.8838        4.1558  1.4883\n",
      "     99        \u001b[36m4.1853\u001b[0m       0.8828        \u001b[35m4.1551\u001b[0m  1.4912\n",
      "    100        \u001b[36m4.1853\u001b[0m       0.8821        \u001b[35m4.1550\u001b[0m  1.5107\n",
      "    101        \u001b[36m4.1830\u001b[0m       0.8828        \u001b[35m4.1544\u001b[0m  1.4851\n",
      "    102        \u001b[36m4.1819\u001b[0m       0.8844        \u001b[35m4.1538\u001b[0m  1.6649\n",
      "    103        \u001b[36m4.1819\u001b[0m       0.8848        \u001b[35m4.1537\u001b[0m  1.5060\n",
      "    104        \u001b[36m4.1774\u001b[0m       0.8844        \u001b[35m4.1529\u001b[0m  1.5476\n",
      "    105        \u001b[36m4.1771\u001b[0m       \u001b[32m0.8861\u001b[0m        \u001b[35m4.1510\u001b[0m  1.4912\n",
      "    106        4.1784       \u001b[32m0.8911\u001b[0m        \u001b[35m4.1467\u001b[0m  1.4934\n",
      "    107        \u001b[36m4.1747\u001b[0m       \u001b[32m0.8930\u001b[0m        \u001b[35m4.1447\u001b[0m  1.4998\n",
      "    108        \u001b[36m4.1721\u001b[0m       0.8921        4.1448  1.4959\n",
      "    109        4.1724       0.8921        4.1448  1.5948\n",
      "    110        4.1723       \u001b[32m0.8937\u001b[0m        \u001b[35m4.1440\u001b[0m  1.5581\n",
      "    111        4.1725       0.8937        \u001b[35m4.1432\u001b[0m  1.5534\n",
      "    112        \u001b[36m4.1696\u001b[0m       0.8930        4.1433  1.5612\n",
      "    113        \u001b[36m4.1673\u001b[0m       0.8930        \u001b[35m4.1431\u001b[0m  1.7012\n",
      "    114        \u001b[36m4.1670\u001b[0m       0.8930        \u001b[35m4.1429\u001b[0m  1.7194\n",
      "    115        \u001b[36m4.1655\u001b[0m       0.8924        4.1429  1.6401\n",
      "    116        4.1680       \u001b[32m0.8940\u001b[0m        \u001b[35m4.1425\u001b[0m  1.6320\n",
      "    117        4.1672       \u001b[32m0.8944\u001b[0m        \u001b[35m4.1420\u001b[0m  1.5768\n",
      "    118        \u001b[36m4.1629\u001b[0m       0.8934        \u001b[35m4.1420\u001b[0m  1.5652\n",
      "    119        \u001b[36m4.1628\u001b[0m       0.8944        \u001b[35m4.1416\u001b[0m  1.6433\n",
      "    120        \u001b[36m4.1600\u001b[0m       0.8934        4.1416  1.5908\n",
      "    121        4.1634       0.8921        \u001b[35m4.1415\u001b[0m  1.5413\n",
      "    122        \u001b[36m4.1596\u001b[0m       0.8930        \u001b[35m4.1415\u001b[0m  1.5908\n",
      "    123        4.1619       \u001b[32m0.8950\u001b[0m        \u001b[35m4.1409\u001b[0m  1.5812\n",
      "    124        \u001b[36m4.1586\u001b[0m       0.8944        4.1414  1.9182\n",
      "    125        4.1601       0.8930        4.1411  1.7385\n",
      "    126        4.1597       0.8934        4.1411  1.6985\n",
      "    127        \u001b[36m4.1575\u001b[0m       0.8924        4.1414  1.5336\n",
      "    128        4.1577       0.8927        4.1410  1.5782\n",
      "    129        \u001b[36m4.1573\u001b[0m       0.8937        4.1410  1.5580\n",
      "    130        \u001b[36m4.1552\u001b[0m       0.8934        \u001b[35m4.1403\u001b[0m  1.5491\n",
      "    131        \u001b[36m4.1551\u001b[0m       0.8921        4.1406  1.5362\n",
      "    132        \u001b[36m4.1531\u001b[0m       0.8950        \u001b[35m4.1403\u001b[0m  1.5717\n",
      "    133        4.1538       0.8950        4.1405  1.5965\n",
      "    134        \u001b[36m4.1527\u001b[0m       0.8940        4.1410  1.7489\n",
      "    135        4.1543       0.8950        4.1403  1.7154\n",
      "    136        \u001b[36m4.1526\u001b[0m       0.8944        \u001b[35m4.1402\u001b[0m  1.6810\n",
      "    137        \u001b[36m4.1515\u001b[0m       \u001b[32m0.8954\u001b[0m        \u001b[35m4.1390\u001b[0m  1.6500\n",
      "    138        \u001b[36m4.1485\u001b[0m       \u001b[32m0.8967\u001b[0m        \u001b[35m4.1376\u001b[0m  1.6334\n",
      "    139        \u001b[36m4.1484\u001b[0m       \u001b[32m0.8977\u001b[0m        \u001b[35m4.1374\u001b[0m  1.5914\n",
      "    140        \u001b[36m4.1480\u001b[0m       0.8964        \u001b[35m4.1373\u001b[0m  1.8665\n",
      "    141        4.1500       \u001b[32m0.8980\u001b[0m        \u001b[35m4.1371\u001b[0m  1.7240\n",
      "    142        \u001b[36m4.1463\u001b[0m       0.8964        4.1372  1.6300\n",
      "    143        4.1469       0.8974        \u001b[35m4.1368\u001b[0m  1.6093\n",
      "    144        \u001b[36m4.1445\u001b[0m       0.8964        \u001b[35m4.1362\u001b[0m  1.5520\n",
      "    145        \u001b[36m4.1441\u001b[0m       0.8967        4.1364  1.5200\n",
      "    146        4.1444       0.8970        4.1365  1.5217\n",
      "    147        4.1466       0.8974        4.1366  1.6132\n",
      "    148        4.1446       0.8970        4.1365  1.6688\n",
      "    149        \u001b[36m4.1419\u001b[0m       0.8970        4.1364  1.8371\n",
      "    150        4.1425       0.8980        4.1365  1.9066\n",
      "    151        4.1422       \u001b[32m0.8983\u001b[0m        \u001b[35m4.1361\u001b[0m  1.7801\n",
      "    152        4.1435       0.8974        4.1365  1.5944\n",
      "    153        \u001b[36m4.1417\u001b[0m       0.8974        4.1363  1.5713\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{50: 0.9144370860927152, 100: 0.9525165562913908}\n",
      "Val accuracy\n",
      "{50: 0.8266666666666667, 100: 0.868}\n",
      "pred time\n",
      "{50: 0.1441209316253662, 100: 0.19157671928405762}\n",
      "OOS Val Accuracy\n",
      "{50: 0.04, 100: 0.09}\n",
      "OOS pred time\n",
      "{50: 0.0038161277770996094, 100: 0.005321979522705078}\n",
      "200\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0169\u001b[0m       \u001b[32m0.5917\u001b[0m        \u001b[35m5.0159\u001b[0m  2.4881\n",
      "      2        \u001b[36m5.0113\u001b[0m       0.3841        \u001b[35m4.9985\u001b[0m  2.0815\n",
      "      3        \u001b[36m4.9371\u001b[0m       0.3775        \u001b[35m4.8355\u001b[0m  2.0541\n",
      "      4        \u001b[36m4.7921\u001b[0m       0.5070        \u001b[35m4.6799\u001b[0m  2.1587\n",
      "      5        \u001b[36m4.6789\u001b[0m       \u001b[32m0.5970\u001b[0m        \u001b[35m4.5666\u001b[0m  2.4001\n",
      "      6        \u001b[36m4.5867\u001b[0m       \u001b[32m0.6401\u001b[0m        \u001b[35m4.4853\u001b[0m  2.4398\n",
      "      7        \u001b[36m4.5195\u001b[0m       \u001b[32m0.6752\u001b[0m        \u001b[35m4.4363\u001b[0m  2.1579\n",
      "      8        \u001b[36m4.4748\u001b[0m       \u001b[32m0.6980\u001b[0m        \u001b[35m4.4010\u001b[0m  2.3640\n",
      "      9        \u001b[36m4.4393\u001b[0m       \u001b[32m0.7189\u001b[0m        \u001b[35m4.3739\u001b[0m  2.2209\n",
      "     10        \u001b[36m4.4099\u001b[0m       \u001b[32m0.7553\u001b[0m        \u001b[35m4.3436\u001b[0m  2.4528\n",
      "     11        \u001b[36m4.3781\u001b[0m       \u001b[32m0.7801\u001b[0m        \u001b[35m4.3157\u001b[0m  2.4979\n",
      "     12        \u001b[36m4.3493\u001b[0m       \u001b[32m0.8010\u001b[0m        \u001b[35m4.2934\u001b[0m  2.5662\n",
      "     13        \u001b[36m4.3279\u001b[0m       \u001b[32m0.8169\u001b[0m        \u001b[35m4.2700\u001b[0m  2.2935\n",
      "     14        \u001b[36m4.3021\u001b[0m       \u001b[32m0.8262\u001b[0m        \u001b[35m4.2545\u001b[0m  2.2902\n",
      "     15        \u001b[36m4.2887\u001b[0m       \u001b[32m0.8325\u001b[0m        \u001b[35m4.2423\u001b[0m  2.3681\n",
      "     16        \u001b[36m4.2718\u001b[0m       \u001b[32m0.8397\u001b[0m        \u001b[35m4.2322\u001b[0m  2.3872\n",
      "     17        \u001b[36m4.2588\u001b[0m       \u001b[32m0.8460\u001b[0m        \u001b[35m4.2240\u001b[0m  2.3307\n",
      "     18        \u001b[36m4.2484\u001b[0m       \u001b[32m0.8500\u001b[0m        \u001b[35m4.2163\u001b[0m  2.1595\n",
      "     19        \u001b[36m4.2380\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m4.2097\u001b[0m  2.0975\n",
      "     20        \u001b[36m4.2280\u001b[0m       \u001b[32m0.8603\u001b[0m        \u001b[35m4.2023\u001b[0m  2.2996\n",
      "     21        \u001b[36m4.2162\u001b[0m       \u001b[32m0.8616\u001b[0m        \u001b[35m4.1971\u001b[0m  2.1787\n",
      "     22        \u001b[36m4.2073\u001b[0m       \u001b[32m0.8692\u001b[0m        \u001b[35m4.1918\u001b[0m  2.2109\n",
      "     23        \u001b[36m4.2026\u001b[0m       \u001b[32m0.8699\u001b[0m        \u001b[35m4.1876\u001b[0m  2.1475\n",
      "     24        \u001b[36m4.1949\u001b[0m       \u001b[32m0.8815\u001b[0m        \u001b[35m4.1819\u001b[0m  2.3880\n",
      "     25        \u001b[36m4.1889\u001b[0m       0.8811        \u001b[35m4.1772\u001b[0m  2.3392\n",
      "     26        \u001b[36m4.1827\u001b[0m       \u001b[32m0.8887\u001b[0m        \u001b[35m4.1707\u001b[0m  2.6510\n",
      "     27        \u001b[36m4.1737\u001b[0m       \u001b[32m0.8924\u001b[0m        \u001b[35m4.1660\u001b[0m  2.2879\n",
      "     28        \u001b[36m4.1683\u001b[0m       \u001b[32m0.8960\u001b[0m        \u001b[35m4.1618\u001b[0m  2.2960\n",
      "     29        \u001b[36m4.1635\u001b[0m       0.8957        \u001b[35m4.1589\u001b[0m  2.2583\n",
      "     30        \u001b[36m4.1589\u001b[0m       0.8947        \u001b[35m4.1572\u001b[0m  2.2062\n",
      "     31        \u001b[36m4.1543\u001b[0m       \u001b[32m0.8983\u001b[0m        \u001b[35m4.1547\u001b[0m  2.3048\n",
      "     32        \u001b[36m4.1491\u001b[0m       \u001b[32m0.9017\u001b[0m        \u001b[35m4.1520\u001b[0m  2.1916\n",
      "     33        \u001b[36m4.1460\u001b[0m       \u001b[32m0.9040\u001b[0m        \u001b[35m4.1490\u001b[0m  2.1923\n",
      "     34        \u001b[36m4.1417\u001b[0m       \u001b[32m0.9070\u001b[0m        \u001b[35m4.1459\u001b[0m  2.1521\n",
      "     35        \u001b[36m4.1369\u001b[0m       0.9066        \u001b[35m4.1437\u001b[0m  2.1497\n",
      "     36        \u001b[36m4.1341\u001b[0m       \u001b[32m0.9086\u001b[0m        \u001b[35m4.1420\u001b[0m  2.1770\n",
      "     37        \u001b[36m4.1283\u001b[0m       0.9079        \u001b[35m4.1406\u001b[0m  2.1362\n",
      "     38        \u001b[36m4.1245\u001b[0m       0.9086        \u001b[35m4.1393\u001b[0m  2.1453\n",
      "     39        \u001b[36m4.1218\u001b[0m       \u001b[32m0.9096\u001b[0m        \u001b[35m4.1378\u001b[0m  2.1284\n",
      "     40        \u001b[36m4.1208\u001b[0m       0.9096        \u001b[35m4.1367\u001b[0m  2.1570\n",
      "     41        \u001b[36m4.1188\u001b[0m       0.9079        \u001b[35m4.1362\u001b[0m  2.1233\n",
      "     42        \u001b[36m4.1167\u001b[0m       \u001b[32m0.9099\u001b[0m        \u001b[35m4.1351\u001b[0m  2.2979\n",
      "     43        \u001b[36m4.1150\u001b[0m       0.9099        \u001b[35m4.1345\u001b[0m  2.1822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     44        \u001b[36m4.1112\u001b[0m       \u001b[32m0.9113\u001b[0m        \u001b[35m4.1337\u001b[0m  2.2582\n",
      "     45        \u001b[36m4.1104\u001b[0m       0.9113        \u001b[35m4.1329\u001b[0m  2.1436\n",
      "     46        \u001b[36m4.1095\u001b[0m       \u001b[32m0.9139\u001b[0m        \u001b[35m4.1322\u001b[0m  2.1699\n",
      "     47        \u001b[36m4.1066\u001b[0m       0.9139        \u001b[35m4.1319\u001b[0m  2.2201\n",
      "     48        \u001b[36m4.1041\u001b[0m       \u001b[32m0.9159\u001b[0m        \u001b[35m4.1303\u001b[0m  2.2653\n",
      "     49        \u001b[36m4.1006\u001b[0m       0.9139        \u001b[35m4.1296\u001b[0m  2.2250\n",
      "     50        \u001b[36m4.0974\u001b[0m       0.9129        \u001b[35m4.1283\u001b[0m  2.1840\n",
      "     51        4.0977       \u001b[32m0.9162\u001b[0m        \u001b[35m4.1273\u001b[0m  2.2352\n",
      "     52        \u001b[36m4.0953\u001b[0m       \u001b[32m0.9189\u001b[0m        \u001b[35m4.1247\u001b[0m  2.3422\n",
      "     53        \u001b[36m4.0921\u001b[0m       \u001b[32m0.9209\u001b[0m        \u001b[35m4.1226\u001b[0m  2.5611\n",
      "     54        \u001b[36m4.0895\u001b[0m       \u001b[32m0.9222\u001b[0m        \u001b[35m4.1217\u001b[0m  2.3258\n",
      "     55        \u001b[36m4.0878\u001b[0m       0.9209        \u001b[35m4.1214\u001b[0m  2.2840\n",
      "     56        4.0884       0.9205        \u001b[35m4.1210\u001b[0m  2.4763\n",
      "     57        \u001b[36m4.0846\u001b[0m       \u001b[32m0.9232\u001b[0m        \u001b[35m4.1198\u001b[0m  2.4433\n",
      "     58        \u001b[36m4.0837\u001b[0m       0.9209        \u001b[35m4.1197\u001b[0m  2.2998\n",
      "     59        \u001b[36m4.0822\u001b[0m       0.9215        \u001b[35m4.1189\u001b[0m  2.3312\n",
      "     60        \u001b[36m4.0820\u001b[0m       \u001b[32m0.9262\u001b[0m        \u001b[35m4.1164\u001b[0m  2.2978\n",
      "     61        \u001b[36m4.0779\u001b[0m       0.9248        \u001b[35m4.1154\u001b[0m  2.2130\n",
      "     62        \u001b[36m4.0766\u001b[0m       \u001b[32m0.9285\u001b[0m        \u001b[35m4.1149\u001b[0m  2.2990\n",
      "     63        \u001b[36m4.0747\u001b[0m       0.9285        \u001b[35m4.1139\u001b[0m  2.2121\n",
      "     64        4.0748       0.9285        \u001b[35m4.1135\u001b[0m  2.3125\n",
      "     65        \u001b[36m4.0741\u001b[0m       \u001b[32m0.9288\u001b[0m        \u001b[35m4.1131\u001b[0m  2.3105\n",
      "     66        \u001b[36m4.0729\u001b[0m       \u001b[32m0.9298\u001b[0m        \u001b[35m4.1128\u001b[0m  2.7343\n",
      "     67        \u001b[36m4.0714\u001b[0m       0.9298        \u001b[35m4.1123\u001b[0m  2.3530\n",
      "     68        \u001b[36m4.0700\u001b[0m       0.9298        4.1123  2.6296\n",
      "     69        \u001b[36m4.0697\u001b[0m       0.9288        \u001b[35m4.1116\u001b[0m  2.6940\n",
      "     70        4.0709       0.9272        \u001b[35m4.1116\u001b[0m  2.6457\n",
      "     71        \u001b[36m4.0684\u001b[0m       0.9285        \u001b[35m4.1110\u001b[0m  2.4113\n",
      "     72        4.0687       0.9288        \u001b[35m4.1107\u001b[0m  2.4404\n",
      "     73        \u001b[36m4.0672\u001b[0m       0.9278        4.1110  2.4302\n",
      "     74        4.0679       0.9285        \u001b[35m4.1103\u001b[0m  2.4687\n",
      "     75        \u001b[36m4.0655\u001b[0m       \u001b[32m0.9301\u001b[0m        \u001b[35m4.1101\u001b[0m  2.4330\n",
      "     76        \u001b[36m4.0647\u001b[0m       0.9298        \u001b[35m4.1093\u001b[0m  2.4267\n",
      "     77        \u001b[36m4.0634\u001b[0m       0.9281        \u001b[35m4.1092\u001b[0m  2.4203\n",
      "     78        \u001b[36m4.0632\u001b[0m       0.9275        4.1093  2.4438\n",
      "     79        \u001b[36m4.0629\u001b[0m       0.9285        \u001b[35m4.1088\u001b[0m  2.4321\n",
      "     80        \u001b[36m4.0614\u001b[0m       0.9295        \u001b[35m4.1085\u001b[0m  2.4281\n",
      "     81        \u001b[36m4.0606\u001b[0m       \u001b[32m0.9318\u001b[0m        \u001b[35m4.1078\u001b[0m  2.3670\n",
      "     82        \u001b[36m4.0594\u001b[0m       \u001b[32m0.9321\u001b[0m        \u001b[35m4.1075\u001b[0m  2.4588\n",
      "     83        \u001b[36m4.0581\u001b[0m       0.9315        \u001b[35m4.1071\u001b[0m  2.3747\n",
      "     84        4.0586       0.9311        \u001b[35m4.1067\u001b[0m  2.6850\n",
      "     85        \u001b[36m4.0561\u001b[0m       0.9318        \u001b[35m4.1064\u001b[0m  2.6133\n",
      "     86        4.0566       \u001b[32m0.9325\u001b[0m        \u001b[35m4.1061\u001b[0m  2.5501\n",
      "     87        4.0568       0.9325        4.1063  2.4473\n",
      "     88        \u001b[36m4.0543\u001b[0m       \u001b[32m0.9328\u001b[0m        4.1062  2.3844\n",
      "     89        4.0544       0.9315        4.1063  2.3695\n",
      "     90        4.0571       \u001b[32m0.9331\u001b[0m        \u001b[35m4.1053\u001b[0m  2.4017\n",
      "     91        \u001b[36m4.0541\u001b[0m       \u001b[32m0.9344\u001b[0m        \u001b[35m4.1049\u001b[0m  2.4046\n",
      "     92        4.0547       0.9311        4.1055  2.4509\n",
      "     93        \u001b[36m4.0533\u001b[0m       0.9321        4.1053  2.4029\n",
      "     94        4.0538       0.9331        4.1049  2.4127\n",
      "     95        \u001b[36m4.0529\u001b[0m       0.9338        \u001b[35m4.1048\u001b[0m  2.4202\n",
      "     96        \u001b[36m4.0523\u001b[0m       0.9331        \u001b[35m4.1042\u001b[0m  2.3366\n",
      "     97        4.0526       0.9328        4.1044  2.2780\n",
      "     98        \u001b[36m4.0522\u001b[0m       0.9341        \u001b[35m4.1039\u001b[0m  2.4273\n",
      "     99        \u001b[36m4.0504\u001b[0m       0.9331        \u001b[35m4.1039\u001b[0m  2.3040\n",
      "    100        \u001b[36m4.0500\u001b[0m       0.9325        \u001b[35m4.1036\u001b[0m  2.4397\n",
      "    101        4.0507       0.9321        4.1039  2.2775\n",
      "    102        4.0502       0.9325        4.1040  2.4250\n",
      "    103        \u001b[36m4.0499\u001b[0m       0.9315        4.1038  2.2457\n",
      "    104        \u001b[36m4.0486\u001b[0m       0.9328        \u001b[35m4.1035\u001b[0m  2.4978\n",
      "    105        4.0503       0.9331        \u001b[35m4.1033\u001b[0m  2.2540\n",
      "    106        4.0487       0.9328        \u001b[35m4.1031\u001b[0m  2.4699\n",
      "    107        \u001b[36m4.0479\u001b[0m       0.9315        \u001b[35m4.1031\u001b[0m  2.2066\n",
      "    108        4.0482       0.9315        4.1031  2.5250\n",
      "    109        4.0481       0.9318        4.1031  2.2029\n",
      "    110        4.0486       0.9318        4.1031  2.5265\n",
      "    111        \u001b[36m4.0474\u001b[0m       0.9315        4.1034  2.2076\n",
      "    112        \u001b[36m4.0469\u001b[0m       0.9318        \u001b[35m4.1027\u001b[0m  2.5451\n",
      "    113        4.0469       0.9295        4.1032  2.4160\n",
      "    114        \u001b[36m4.0464\u001b[0m       0.9305        4.1032  2.4190\n",
      "    115        4.0468       0.9298        \u001b[35m4.1025\u001b[0m  2.1871\n",
      "    116        4.0466       0.9305        4.1026  2.2652\n",
      "    117        4.0468       0.9315        \u001b[35m4.1025\u001b[0m  2.1749\n",
      "    118        \u001b[36m4.0458\u001b[0m       0.9298        4.1025  2.1934\n",
      "    119        \u001b[36m4.0446\u001b[0m       0.9308        4.1027  2.1769\n",
      "    120        4.0452       0.9301        4.1028  2.1959\n",
      "    121        4.0454       0.9295        \u001b[35m4.1025\u001b[0m  2.1941\n",
      "    122        4.0457       0.9308        \u001b[35m4.1023\u001b[0m  2.1714\n",
      "    123        4.0447       0.9318        \u001b[35m4.1018\u001b[0m  2.2222\n",
      "    124        4.0454       0.9308        4.1018  2.3451\n",
      "    125        \u001b[36m4.0445\u001b[0m       0.9298        4.1019  2.3391\n",
      "    126        \u001b[36m4.0438\u001b[0m       0.9298        4.1022  2.2253\n",
      "    127        4.0440       0.9301        4.1020  2.4604\n",
      "    128        4.0445       0.9308        4.1023  2.2579\n",
      "    129        4.0444       0.9305        4.1018  2.5334\n",
      "    130        \u001b[36m4.0433\u001b[0m       0.9305        4.1018  2.4023\n",
      "    131        4.0438       0.9301        \u001b[35m4.1014\u001b[0m  2.3860\n",
      "    132        \u001b[36m4.0432\u001b[0m       0.9305        \u001b[35m4.1014\u001b[0m  2.1829\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{50: 0.9144370860927152, 100: 0.9525165562913908, 200: 0.9829801324503311}\n",
      "Val accuracy\n",
      "{50: 0.8266666666666667, 100: 0.868, 200: 0.902}\n",
      "pred time\n",
      "{50: 0.1441209316253662, 100: 0.19157671928405762, 200: 0.19345808029174805}\n",
      "OOS Val Accuracy\n",
      "{50: 0.04, 100: 0.09, 200: 0.13}\n",
      "OOS pred time\n",
      "{50: 0.0038161277770996094, 100: 0.005321979522705078, 200: 0.005211830139160156}\n",
      "400\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0165\u001b[0m       \u001b[32m0.6258\u001b[0m        \u001b[35m5.0144\u001b[0m  3.9755\n",
      "      2        \u001b[36m4.9877\u001b[0m       0.3566        \u001b[35m4.9023\u001b[0m  3.8207\n",
      "      3        \u001b[36m4.7884\u001b[0m       0.5195        \u001b[35m4.6581\u001b[0m  3.8443\n",
      "      4        \u001b[36m4.5997\u001b[0m       \u001b[32m0.6662\u001b[0m        \u001b[35m4.4932\u001b[0m  3.7832\n",
      "      5        \u001b[36m4.4695\u001b[0m       \u001b[32m0.7291\u001b[0m        \u001b[35m4.4011\u001b[0m  3.6260\n",
      "      6        \u001b[36m4.3946\u001b[0m       \u001b[32m0.7629\u001b[0m        \u001b[35m4.3497\u001b[0m  3.8267\n",
      "      7        \u001b[36m4.3394\u001b[0m       \u001b[32m0.7911\u001b[0m        \u001b[35m4.3080\u001b[0m  3.6330\n",
      "      8        \u001b[36m4.2993\u001b[0m       \u001b[32m0.8156\u001b[0m        \u001b[35m4.2769\u001b[0m  3.5300\n",
      "      9        \u001b[36m4.2704\u001b[0m       \u001b[32m0.8298\u001b[0m        \u001b[35m4.2529\u001b[0m  3.5164\n",
      "     10        \u001b[36m4.2450\u001b[0m       \u001b[32m0.8440\u001b[0m        \u001b[35m4.2354\u001b[0m  3.4781\n",
      "     11        \u001b[36m4.2248\u001b[0m       \u001b[32m0.8566\u001b[0m        \u001b[35m4.2210\u001b[0m  3.4719\n",
      "     12        \u001b[36m4.2063\u001b[0m       \u001b[32m0.8626\u001b[0m        \u001b[35m4.2093\u001b[0m  3.4986\n",
      "     13        \u001b[36m4.1926\u001b[0m       \u001b[32m0.8758\u001b[0m        \u001b[35m4.1962\u001b[0m  3.5097\n",
      "     14        \u001b[36m4.1765\u001b[0m       \u001b[32m0.8871\u001b[0m        \u001b[35m4.1861\u001b[0m  3.4995\n",
      "     15        \u001b[36m4.1620\u001b[0m       \u001b[32m0.8947\u001b[0m        \u001b[35m4.1764\u001b[0m  3.5283\n",
      "     16        \u001b[36m4.1508\u001b[0m       \u001b[32m0.9020\u001b[0m        \u001b[35m4.1647\u001b[0m  3.5191\n",
      "     17        \u001b[36m4.1370\u001b[0m       \u001b[32m0.9050\u001b[0m        \u001b[35m4.1566\u001b[0m  3.5366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18        \u001b[36m4.1284\u001b[0m       \u001b[32m0.9109\u001b[0m        \u001b[35m4.1496\u001b[0m  3.5247\n",
      "     19        \u001b[36m4.1203\u001b[0m       \u001b[32m0.9129\u001b[0m        \u001b[35m4.1448\u001b[0m  3.5568\n",
      "     20        \u001b[36m4.1127\u001b[0m       \u001b[32m0.9136\u001b[0m        \u001b[35m4.1421\u001b[0m  3.5397\n",
      "     21        \u001b[36m4.1086\u001b[0m       0.9136        \u001b[35m4.1397\u001b[0m  3.5517\n",
      "     22        \u001b[36m4.1033\u001b[0m       \u001b[32m0.9199\u001b[0m        \u001b[35m4.1355\u001b[0m  3.5539\n",
      "     23        \u001b[36m4.0992\u001b[0m       \u001b[32m0.9222\u001b[0m        \u001b[35m4.1330\u001b[0m  3.5776\n",
      "     24        \u001b[36m4.0933\u001b[0m       0.9205        \u001b[35m4.1318\u001b[0m  3.5672\n",
      "     25        \u001b[36m4.0897\u001b[0m       0.9212        \u001b[35m4.1299\u001b[0m  3.5515\n",
      "     26        \u001b[36m4.0876\u001b[0m       \u001b[32m0.9235\u001b[0m        \u001b[35m4.1279\u001b[0m  3.6154\n",
      "     27        \u001b[36m4.0837\u001b[0m       0.9232        \u001b[35m4.1272\u001b[0m  3.7022\n",
      "     28        \u001b[36m4.0824\u001b[0m       0.9212        \u001b[35m4.1265\u001b[0m  3.8041\n",
      "     29        \u001b[36m4.0798\u001b[0m       0.9219        \u001b[35m4.1250\u001b[0m  3.8737\n",
      "     30        \u001b[36m4.0753\u001b[0m       \u001b[32m0.9285\u001b[0m        \u001b[35m4.1230\u001b[0m  3.6562\n",
      "     31        \u001b[36m4.0720\u001b[0m       \u001b[32m0.9305\u001b[0m        \u001b[35m4.1202\u001b[0m  3.5309\n",
      "     32        \u001b[36m4.0689\u001b[0m       0.9301        \u001b[35m4.1181\u001b[0m  3.6022\n",
      "     33        \u001b[36m4.0667\u001b[0m       0.9305        \u001b[35m4.1177\u001b[0m  3.5796\n",
      "     34        \u001b[36m4.0642\u001b[0m       \u001b[32m0.9311\u001b[0m        \u001b[35m4.1148\u001b[0m  3.5962\n",
      "     35        \u001b[36m4.0616\u001b[0m       \u001b[32m0.9358\u001b[0m        \u001b[35m4.1115\u001b[0m  3.6275\n",
      "     36        \u001b[36m4.0584\u001b[0m       \u001b[32m0.9384\u001b[0m        \u001b[35m4.1092\u001b[0m  3.5659\n",
      "     37        \u001b[36m4.0562\u001b[0m       \u001b[32m0.9394\u001b[0m        \u001b[35m4.1072\u001b[0m  3.5475\n",
      "     38        \u001b[36m4.0550\u001b[0m       0.9394        \u001b[35m4.1072\u001b[0m  3.3543\n",
      "     39        \u001b[36m4.0544\u001b[0m       \u001b[32m0.9407\u001b[0m        \u001b[35m4.1062\u001b[0m  3.5658\n",
      "     40        \u001b[36m4.0515\u001b[0m       0.9387        \u001b[35m4.1059\u001b[0m  3.6835\n",
      "     41        \u001b[36m4.0513\u001b[0m       0.9387        \u001b[35m4.1055\u001b[0m  3.5658\n",
      "     42        \u001b[36m4.0497\u001b[0m       0.9387        \u001b[35m4.1050\u001b[0m  3.5609\n",
      "     43        \u001b[36m4.0490\u001b[0m       \u001b[32m0.9414\u001b[0m        \u001b[35m4.1040\u001b[0m  3.5722\n",
      "     44        \u001b[36m4.0482\u001b[0m       0.9404        \u001b[35m4.1034\u001b[0m  3.5542\n",
      "     45        \u001b[36m4.0463\u001b[0m       0.9407        \u001b[35m4.1031\u001b[0m  3.5528\n",
      "     46        4.0467       \u001b[32m0.9421\u001b[0m        \u001b[35m4.1024\u001b[0m  3.5662\n",
      "     47        \u001b[36m4.0451\u001b[0m       0.9421        4.1024  3.5579\n",
      "     48        \u001b[36m4.0445\u001b[0m       0.9414        \u001b[35m4.1018\u001b[0m  3.5765\n",
      "     49        \u001b[36m4.0435\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m4.1007\u001b[0m  3.5540\n",
      "     50        4.0438       0.9407        4.1012  3.6074\n",
      "     51        \u001b[36m4.0433\u001b[0m       0.9424        4.1008  3.5819\n",
      "     52        \u001b[36m4.0424\u001b[0m       0.9424        \u001b[35m4.1004\u001b[0m  3.5724\n",
      "     53        \u001b[36m4.0421\u001b[0m       0.9417        \u001b[35m4.0998\u001b[0m  3.5617\n",
      "     54        \u001b[36m4.0415\u001b[0m       0.9404        4.1001  3.5562\n",
      "     55        \u001b[36m4.0415\u001b[0m       0.9417        \u001b[35m4.0997\u001b[0m  3.5600\n",
      "     56        \u001b[36m4.0403\u001b[0m       0.9407        \u001b[35m4.0992\u001b[0m  3.5915\n",
      "     57        4.0405       0.9391        \u001b[35m4.0989\u001b[0m  3.5587\n",
      "     58        \u001b[36m4.0390\u001b[0m       0.9417        \u001b[35m4.0978\u001b[0m  3.5667\n",
      "     59        4.0395       0.9407        4.0980  3.5750\n",
      "     60        4.0393       0.9404        4.0986  3.5612\n",
      "     61        \u001b[36m4.0389\u001b[0m       0.9411        4.0978  3.5558\n",
      "     62        \u001b[36m4.0385\u001b[0m       0.9414        \u001b[35m4.0973\u001b[0m  3.5573\n",
      "     63        4.0387       0.9404        4.0979  3.5517\n",
      "     64        4.0385       0.9417        \u001b[35m4.0971\u001b[0m  3.6201\n",
      "     65        \u001b[36m4.0381\u001b[0m       0.9414        \u001b[35m4.0969\u001b[0m  3.5640\n",
      "     66        \u001b[36m4.0381\u001b[0m       \u001b[32m0.9430\u001b[0m        \u001b[35m4.0965\u001b[0m  3.5721\n",
      "     67        \u001b[36m4.0373\u001b[0m       0.9414        4.0967  3.5459\n",
      "     68        4.0376       0.9414        4.0969  3.5686\n",
      "     69        \u001b[36m4.0372\u001b[0m       \u001b[32m0.9434\u001b[0m        \u001b[35m4.0961\u001b[0m  3.6055\n",
      "     70        \u001b[36m4.0371\u001b[0m       0.9414        \u001b[35m4.0957\u001b[0m  3.5731\n",
      "     71        \u001b[36m4.0367\u001b[0m       0.9414        4.0961  3.5593\n",
      "     72        4.0370       0.9411        4.0962  3.5913\n",
      "     73        4.0369       0.9407        4.0959  3.7833\n",
      "     74        \u001b[36m4.0361\u001b[0m       0.9421        \u001b[35m4.0957\u001b[0m  3.5853\n",
      "     75        \u001b[36m4.0359\u001b[0m       0.9414        \u001b[35m4.0952\u001b[0m  3.5683\n",
      "     76        4.0360       \u001b[32m0.9440\u001b[0m        \u001b[35m4.0947\u001b[0m  3.6001\n",
      "     77        \u001b[36m4.0356\u001b[0m       0.9430        4.0948  3.7025\n",
      "     78        4.0360       0.9424        4.0955  3.5805\n",
      "     79        \u001b[36m4.0355\u001b[0m       0.9414        4.0952  3.6998\n",
      "     80        \u001b[36m4.0353\u001b[0m       0.9434        \u001b[35m4.0946\u001b[0m  3.5797\n",
      "     81        4.0355       0.9414        4.0948  3.5832\n",
      "     82        \u001b[36m4.0353\u001b[0m       0.9421        4.0949  3.6424\n",
      "     83        4.0353       0.9424        \u001b[35m4.0945\u001b[0m  3.5469\n",
      "     84        \u001b[36m4.0350\u001b[0m       0.9417        4.0950  3.5667\n",
      "     85        \u001b[36m4.0348\u001b[0m       0.9414        4.0951  3.5652\n",
      "     86        \u001b[36m4.0346\u001b[0m       0.9434        \u001b[35m4.0942\u001b[0m  3.5576\n",
      "     87        \u001b[36m4.0343\u001b[0m       0.9430        4.0943  3.6094\n",
      "     88        4.0349       0.9434        \u001b[35m4.0941\u001b[0m  3.5671\n",
      "     89        4.0348       0.9427        \u001b[35m4.0939\u001b[0m  3.5897\n",
      "     90        4.0346       0.9414        \u001b[35m4.0938\u001b[0m  3.5553\n",
      "     91        \u001b[36m4.0342\u001b[0m       0.9434        4.0941  3.5705\n",
      "     92        \u001b[36m4.0341\u001b[0m       \u001b[32m0.9450\u001b[0m        \u001b[35m4.0934\u001b[0m  3.5637\n",
      "     93        \u001b[36m4.0338\u001b[0m       0.9437        4.0936  3.5587\n",
      "     94        4.0342       0.9430        4.0942  3.5909\n",
      "     95        4.0341       \u001b[32m0.9457\u001b[0m        \u001b[35m4.0932\u001b[0m  3.5633\n",
      "     96        4.0339       0.9434        4.0937  3.5700\n",
      "     97        4.0339       0.9411        4.0946  3.6274\n",
      "     98        \u001b[36m4.0336\u001b[0m       0.9414        4.0943  3.6105\n",
      "     99        \u001b[36m4.0335\u001b[0m       0.9424        4.0936  3.5721\n",
      "    100        \u001b[36m4.0330\u001b[0m       0.9417        4.0940  3.6813\n",
      "    101        4.0331       0.9421        4.0937  3.5765\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{50: 0.9144370860927152, 100: 0.9525165562913908, 200: 0.9829801324503311, 400: 0.9866225165562914}\n",
      "Val accuracy\n",
      "{50: 0.8266666666666667, 100: 0.868, 200: 0.902, 400: 0.9043333333333333}\n",
      "pred time\n",
      "{50: 0.1441209316253662, 100: 0.19157671928405762, 200: 0.19345808029174805, 400: 0.2257852554321289}\n",
      "OOS Val Accuracy\n",
      "{50: 0.04, 100: 0.09, 200: 0.13, 400: 0.21}\n",
      "OOS pred time\n",
      "{50: 0.0038161277770996094, 100: 0.005321979522705078, 200: 0.005211830139160156, 400: 0.007739067077636719}\n",
      "800\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0158\u001b[0m       \u001b[32m0.5609\u001b[0m        \u001b[35m5.0103\u001b[0m  6.4512\n",
      "      2        \u001b[36m4.9118\u001b[0m       0.4682        \u001b[35m4.7297\u001b[0m  6.3145\n",
      "      3        \u001b[36m4.6015\u001b[0m       \u001b[32m0.6728\u001b[0m        \u001b[35m4.4803\u001b[0m  6.2827\n",
      "      4        \u001b[36m4.4225\u001b[0m       \u001b[32m0.7626\u001b[0m        \u001b[35m4.3653\u001b[0m  6.3828\n",
      "      5        \u001b[36m4.3227\u001b[0m       \u001b[32m0.8123\u001b[0m        \u001b[35m4.2935\u001b[0m  6.5509\n",
      "      6        \u001b[36m4.2632\u001b[0m       \u001b[32m0.8321\u001b[0m        \u001b[35m4.2558\u001b[0m  6.3906\n",
      "      7        \u001b[36m4.2265\u001b[0m       \u001b[32m0.8517\u001b[0m        \u001b[35m4.2301\u001b[0m  6.3737\n",
      "      8        \u001b[36m4.1987\u001b[0m       \u001b[32m0.8632\u001b[0m        \u001b[35m4.2135\u001b[0m  6.2483\n",
      "      9        \u001b[36m4.1778\u001b[0m       \u001b[32m0.8775\u001b[0m        \u001b[35m4.1954\u001b[0m  6.1583\n",
      "     10        \u001b[36m4.1556\u001b[0m       \u001b[32m0.8993\u001b[0m        \u001b[35m4.1742\u001b[0m  6.3879\n",
      "     11        \u001b[36m4.1341\u001b[0m       \u001b[32m0.9017\u001b[0m        \u001b[35m4.1622\u001b[0m  6.2357\n",
      "     12        \u001b[36m4.1212\u001b[0m       \u001b[32m0.9063\u001b[0m        \u001b[35m4.1536\u001b[0m  6.2389\n",
      "     13        \u001b[36m4.1103\u001b[0m       \u001b[32m0.9132\u001b[0m        \u001b[35m4.1470\u001b[0m  6.1758\n",
      "     14        \u001b[36m4.1014\u001b[0m       \u001b[32m0.9199\u001b[0m        \u001b[35m4.1392\u001b[0m  6.1721\n",
      "     15        \u001b[36m4.0938\u001b[0m       \u001b[32m0.9219\u001b[0m        \u001b[35m4.1363\u001b[0m  6.1716\n",
      "     16        \u001b[36m4.0879\u001b[0m       \u001b[32m0.9228\u001b[0m        \u001b[35m4.1326\u001b[0m  6.3132\n",
      "     17        \u001b[36m4.0819\u001b[0m       \u001b[32m0.9285\u001b[0m        \u001b[35m4.1296\u001b[0m  6.3239\n",
      "     18        \u001b[36m4.0724\u001b[0m       \u001b[32m0.9291\u001b[0m        \u001b[35m4.1248\u001b[0m  6.2952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     19        \u001b[36m4.0673\u001b[0m       \u001b[32m0.9311\u001b[0m        \u001b[35m4.1209\u001b[0m  6.3732\n",
      "     20        \u001b[36m4.0629\u001b[0m       \u001b[32m0.9351\u001b[0m        \u001b[35m4.1187\u001b[0m  6.2594\n",
      "     21        \u001b[36m4.0581\u001b[0m       0.9348        \u001b[35m4.1159\u001b[0m  6.2065\n",
      "     22        \u001b[36m4.0552\u001b[0m       \u001b[32m0.9391\u001b[0m        \u001b[35m4.1132\u001b[0m  6.2833\n",
      "     23        \u001b[36m4.0514\u001b[0m       \u001b[32m0.9397\u001b[0m        \u001b[35m4.1109\u001b[0m  6.2887\n",
      "     24        \u001b[36m4.0489\u001b[0m       \u001b[32m0.9427\u001b[0m        \u001b[35m4.1089\u001b[0m  6.4198\n",
      "     25        \u001b[36m4.0472\u001b[0m       0.9421        \u001b[35m4.1084\u001b[0m  6.4481\n",
      "     26        \u001b[36m4.0460\u001b[0m       0.9427        \u001b[35m4.1067\u001b[0m  6.3913\n",
      "     27        \u001b[36m4.0442\u001b[0m       0.9421        \u001b[35m4.1063\u001b[0m  6.2536\n",
      "     28        \u001b[36m4.0434\u001b[0m       \u001b[32m0.9447\u001b[0m        \u001b[35m4.1044\u001b[0m  6.3409\n",
      "     29        \u001b[36m4.0422\u001b[0m       0.9437        \u001b[35m4.1039\u001b[0m  6.3926\n",
      "     30        \u001b[36m4.0407\u001b[0m       0.9417        \u001b[35m4.1034\u001b[0m  6.3065\n",
      "     31        4.0407       0.9427        \u001b[35m4.1027\u001b[0m  6.2962\n",
      "     32        \u001b[36m4.0404\u001b[0m       0.9437        \u001b[35m4.1024\u001b[0m  6.3609\n",
      "     33        \u001b[36m4.0393\u001b[0m       \u001b[32m0.9450\u001b[0m        \u001b[35m4.1014\u001b[0m  6.3610\n",
      "     34        \u001b[36m4.0386\u001b[0m       0.9444        \u001b[35m4.0999\u001b[0m  6.4921\n",
      "     35        \u001b[36m4.0382\u001b[0m       0.9444        \u001b[35m4.0998\u001b[0m  6.5013\n",
      "     36        \u001b[36m4.0375\u001b[0m       0.9437        \u001b[35m4.0997\u001b[0m  6.3093\n",
      "     37        \u001b[36m4.0373\u001b[0m       0.9444        \u001b[35m4.0995\u001b[0m  6.4109\n",
      "     38        \u001b[36m4.0366\u001b[0m       0.9430        \u001b[35m4.0994\u001b[0m  6.4949\n",
      "     39        \u001b[36m4.0360\u001b[0m       0.9437        \u001b[35m4.0986\u001b[0m  6.4309\n",
      "     40        \u001b[36m4.0360\u001b[0m       0.9437        4.0986  6.3863\n",
      "     41        \u001b[36m4.0359\u001b[0m       0.9447        \u001b[35m4.0980\u001b[0m  6.3541\n",
      "     42        \u001b[36m4.0351\u001b[0m       0.9444        \u001b[35m4.0980\u001b[0m  6.4189\n",
      "     43        4.0354       0.9427        \u001b[35m4.0975\u001b[0m  6.5629\n",
      "     44        \u001b[36m4.0349\u001b[0m       0.9447        \u001b[35m4.0974\u001b[0m  6.5450\n",
      "     45        \u001b[36m4.0348\u001b[0m       0.9430        \u001b[35m4.0972\u001b[0m  6.4078\n",
      "     46        \u001b[36m4.0347\u001b[0m       0.9440        \u001b[35m4.0971\u001b[0m  6.3312\n",
      "     47        \u001b[36m4.0344\u001b[0m       0.9430        4.0974  6.3918\n",
      "     48        \u001b[36m4.0340\u001b[0m       0.9417        4.0973  6.3424\n",
      "     49        4.0340       0.9407        4.0973  6.4151\n",
      "     50        4.0342       0.9427        \u001b[35m4.0957\u001b[0m  6.3464\n",
      "     51        \u001b[36m4.0334\u001b[0m       0.9434        4.0961  6.4744\n",
      "     52        4.0337       0.9444        4.0959  6.4069\n",
      "     53        4.0335       \u001b[32m0.9460\u001b[0m        \u001b[35m4.0949\u001b[0m  6.5259\n",
      "     54        4.0337       0.9414        4.0954  6.5092\n",
      "     55        \u001b[36m4.0334\u001b[0m       0.9437        4.0954  6.3734\n",
      "     56        \u001b[36m4.0332\u001b[0m       0.9450        4.0954  6.3469\n",
      "     57        4.0332       0.9457        \u001b[35m4.0943\u001b[0m  6.0833\n",
      "     58        4.0333       0.9447        4.0949  6.3804\n",
      "     59        4.0332       0.9447        4.0945  6.7000\n",
      "     60        \u001b[36m4.0330\u001b[0m       0.9421        4.0950  6.6820\n",
      "     61        \u001b[36m4.0327\u001b[0m       0.9434        \u001b[35m4.0941\u001b[0m  6.5448\n",
      "     62        \u001b[36m4.0325\u001b[0m       0.9447        \u001b[35m4.0938\u001b[0m  6.5435\n",
      "     63        4.0326       0.9440        4.0941  6.5504\n",
      "     64        4.0327       0.9447        \u001b[35m4.0930\u001b[0m  6.5176\n",
      "     65        \u001b[36m4.0325\u001b[0m       0.9427        4.0939  6.3928\n",
      "     66        \u001b[36m4.0324\u001b[0m       0.9434        4.0933  6.2857\n",
      "     67        \u001b[36m4.0323\u001b[0m       0.9427        4.0936  6.2974\n",
      "     68        \u001b[36m4.0321\u001b[0m       0.9444        \u001b[35m4.0928\u001b[0m  6.2894\n",
      "     69        4.0327       0.9450        \u001b[35m4.0925\u001b[0m  6.4704\n",
      "     70        4.0326       0.9454        4.0928  6.7827\n",
      "     71        \u001b[36m4.0321\u001b[0m       0.9457        \u001b[35m4.0921\u001b[0m  6.7218\n",
      "     72        4.0321       0.9430        4.0927  6.6144\n",
      "     73        4.0322       0.9440        4.0926  6.6079\n",
      "     74        \u001b[36m4.0319\u001b[0m       0.9440        4.0927  6.6458\n",
      "     75        \u001b[36m4.0319\u001b[0m       0.9447        4.0931  6.8059\n",
      "     76        4.0321       0.9444        4.0932  6.6485\n",
      "     77        4.0320       0.9440        4.0930  6.7450\n",
      "     78        \u001b[36m4.0318\u001b[0m       0.9414        4.0933  6.6947\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{50: 0.9144370860927152, 100: 0.9525165562913908, 200: 0.9829801324503311, 400: 0.9866225165562914, 800: 0.9868211920529801}\n",
      "Val accuracy\n",
      "{50: 0.8266666666666667, 100: 0.868, 200: 0.902, 400: 0.9043333333333333, 800: 0.9053333333333333}\n",
      "pred time\n",
      "{50: 0.1441209316253662, 100: 0.19157671928405762, 200: 0.19345808029174805, 400: 0.2257852554321289, 800: 0.3612978458404541}\n",
      "OOS Val Accuracy\n",
      "{50: 0.04, 100: 0.09, 200: 0.13, 400: 0.21, 800: 0.18}\n",
      "OOS pred time\n",
      "{50: 0.0038161277770996094, 100: 0.005321979522705078, 200: 0.005211830139160156, 400: 0.007739067077636719, 800: 0.010519027709960938}\n",
      "1600\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m5.0132\u001b[0m       \u001b[32m0.2662\u001b[0m        \u001b[35m4.9873\u001b[0m  11.1502\n",
      "      2        \u001b[36m4.7732\u001b[0m       \u001b[32m0.6232\u001b[0m        \u001b[35m4.5488\u001b[0m  11.0536\n",
      "      3        \u001b[36m4.4305\u001b[0m       \u001b[32m0.7825\u001b[0m        \u001b[35m4.3451\u001b[0m  11.0131\n",
      "      4        \u001b[36m4.2870\u001b[0m       \u001b[32m0.8328\u001b[0m        \u001b[35m4.2654\u001b[0m  11.1005\n",
      "      5        \u001b[36m4.2223\u001b[0m       \u001b[32m0.8639\u001b[0m        \u001b[35m4.2212\u001b[0m  11.5850\n",
      "      6        \u001b[36m4.1763\u001b[0m       \u001b[32m0.8894\u001b[0m        \u001b[35m4.1930\u001b[0m  11.6858\n",
      "      7        \u001b[36m4.1413\u001b[0m       \u001b[32m0.9119\u001b[0m        \u001b[35m4.1653\u001b[0m  11.4651\n",
      "      8        \u001b[36m4.1146\u001b[0m       \u001b[32m0.9156\u001b[0m        \u001b[35m4.1511\u001b[0m  11.4684\n",
      "      9        \u001b[36m4.0992\u001b[0m       \u001b[32m0.9192\u001b[0m        \u001b[35m4.1425\u001b[0m  11.4050\n",
      "     10        \u001b[36m4.0855\u001b[0m       \u001b[32m0.9298\u001b[0m        \u001b[35m4.1320\u001b[0m  11.4852\n",
      "     11        \u001b[36m4.0744\u001b[0m       0.9298        \u001b[35m4.1268\u001b[0m  11.6506\n",
      "     12        \u001b[36m4.0680\u001b[0m       \u001b[32m0.9338\u001b[0m        \u001b[35m4.1234\u001b[0m  11.3127\n",
      "     13        \u001b[36m4.0628\u001b[0m       \u001b[32m0.9344\u001b[0m        \u001b[35m4.1205\u001b[0m  11.7441\n",
      "     14        \u001b[36m4.0549\u001b[0m       \u001b[32m0.9384\u001b[0m        \u001b[35m4.1154\u001b[0m  11.5806\n",
      "     15        \u001b[36m4.0495\u001b[0m       \u001b[32m0.9391\u001b[0m        \u001b[35m4.1120\u001b[0m  11.6020\n",
      "     16        \u001b[36m4.0459\u001b[0m       \u001b[32m0.9404\u001b[0m        \u001b[35m4.1101\u001b[0m  11.6152\n",
      "     17        \u001b[36m4.0433\u001b[0m       \u001b[32m0.9421\u001b[0m        \u001b[35m4.1083\u001b[0m  11.6202\n",
      "     18        \u001b[36m4.0415\u001b[0m       \u001b[32m0.9427\u001b[0m        \u001b[35m4.1060\u001b[0m  11.7633\n",
      "     19        \u001b[36m4.0414\u001b[0m       0.9421        \u001b[35m4.1056\u001b[0m  11.3239\n",
      "     20        \u001b[36m4.0388\u001b[0m       \u001b[32m0.9434\u001b[0m        \u001b[35m4.1037\u001b[0m  11.5830\n",
      "     21        \u001b[36m4.0380\u001b[0m       \u001b[32m0.9440\u001b[0m        \u001b[35m4.1033\u001b[0m  11.6918\n",
      "     22        4.0380       \u001b[32m0.9454\u001b[0m        \u001b[35m4.1026\u001b[0m  11.5485\n",
      "     23        \u001b[36m4.0369\u001b[0m       \u001b[32m0.9464\u001b[0m        \u001b[35m4.1012\u001b[0m  11.1791\n",
      "     24        \u001b[36m4.0368\u001b[0m       0.9427        4.1017  11.1568\n",
      "     25        \u001b[36m4.0360\u001b[0m       0.9434        \u001b[35m4.1006\u001b[0m  10.9439\n",
      "     26        \u001b[36m4.0352\u001b[0m       0.9464        \u001b[35m4.0995\u001b[0m  11.0213\n",
      "     27        \u001b[36m4.0350\u001b[0m       0.9454        \u001b[35m4.0988\u001b[0m  11.1496\n",
      "     28        \u001b[36m4.0344\u001b[0m       0.9454        4.0989  11.1243\n",
      "     29        4.0348       0.9427        4.0993  11.4444\n",
      "     30        \u001b[36m4.0342\u001b[0m       0.9444        \u001b[35m4.0982\u001b[0m  11.3678\n",
      "     31        \u001b[36m4.0340\u001b[0m       0.9457        \u001b[35m4.0974\u001b[0m  11.0936\n",
      "     32        \u001b[36m4.0337\u001b[0m       \u001b[32m0.9467\u001b[0m        4.0978  11.0901\n",
      "     33        \u001b[36m4.0337\u001b[0m       \u001b[32m0.9470\u001b[0m        \u001b[35m4.0972\u001b[0m  11.0902\n",
      "     34        \u001b[36m4.0336\u001b[0m       0.9457        \u001b[35m4.0964\u001b[0m  11.1050\n",
      "     35        \u001b[36m4.0332\u001b[0m       0.9470        \u001b[35m4.0962\u001b[0m  11.5457\n",
      "     36        \u001b[36m4.0327\u001b[0m       0.9464        \u001b[35m4.0951\u001b[0m  11.5614\n",
      "     37        4.0329       0.9467        4.0961  11.2876\n",
      "     38        4.0330       0.9437        4.0967  11.2210\n",
      "     39        \u001b[36m4.0326\u001b[0m       0.9464        4.0954  11.1138\n",
      "     40        \u001b[36m4.0325\u001b[0m       0.9460        4.0958  11.0869\n",
      "     41        \u001b[36m4.0323\u001b[0m       0.9460        4.0956  11.1020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     42        4.0324       0.9470        \u001b[35m4.0943\u001b[0m  11.1228\n",
      "     43        \u001b[36m4.0320\u001b[0m       0.9464        4.0947  11.3458\n",
      "     44        4.0323       0.9444        4.0948  11.1179\n",
      "     45        4.0321       0.9450        4.0948  11.1263\n",
      "     46        \u001b[36m4.0320\u001b[0m       0.9454        \u001b[35m4.0941\u001b[0m  11.1258\n",
      "     47        4.0320       0.9440        4.0942  11.1458\n",
      "     48        \u001b[36m4.0320\u001b[0m       0.9467        \u001b[35m4.0931\u001b[0m  11.2284\n",
      "     49        \u001b[36m4.0318\u001b[0m       \u001b[32m0.9480\u001b[0m        \u001b[35m4.0929\u001b[0m  11.1924\n",
      "     50        \u001b[36m4.0318\u001b[0m       0.9457        4.0934  11.1937\n",
      "     51        \u001b[36m4.0316\u001b[0m       0.9460        4.0933  11.0919\n",
      "     52        4.0317       0.9457        4.0935  11.1520\n",
      "     53        4.0319       0.9460        4.0937  11.1545\n",
      "     54        \u001b[36m4.0315\u001b[0m       0.9454        4.0938  11.1866\n",
      "     55        4.0317       0.9450        4.0943  11.2692\n",
      "     56        4.0315       0.9470        4.0938  11.3958\n",
      "     57        \u001b[36m4.0314\u001b[0m       0.9460        4.0930  11.2342\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{50: 0.9144370860927152, 100: 0.9525165562913908, 200: 0.9829801324503311, 400: 0.9866225165562914, 800: 0.9868211920529801, 1600: 0.9870860927152317}\n",
      "Val accuracy\n",
      "{50: 0.8266666666666667, 100: 0.868, 200: 0.902, 400: 0.9043333333333333, 800: 0.9053333333333333, 1600: 0.903}\n",
      "pred time\n",
      "{50: 0.1441209316253662, 100: 0.19157671928405762, 200: 0.19345808029174805, 400: 0.2257852554321289, 800: 0.3612978458404541, 1600: 0.6009829044342041}\n",
      "OOS Val Accuracy\n",
      "{50: 0.04, 100: 0.09, 200: 0.13, 400: 0.21, 800: 0.18, 1600: 0.19}\n",
      "OOS pred time\n",
      "{50: 0.0038161277770996094, 100: 0.005321979522705078, 200: 0.005211830139160156, 400: 0.007739067077636719, 800: 0.010519027709960938, 1600: 0.02101612091064453}\n",
      "3200\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m5.0011\u001b[0m       \u001b[32m0.3609\u001b[0m        \u001b[35m4.8839\u001b[0m  20.0473\n",
      "      2        \u001b[36m4.6013\u001b[0m       \u001b[32m0.7430\u001b[0m        \u001b[35m4.3996\u001b[0m  20.4394\n",
      "      3        \u001b[36m4.2990\u001b[0m       \u001b[32m0.8440\u001b[0m        \u001b[35m4.2562\u001b[0m  20.5510\n",
      "      4        \u001b[36m4.1973\u001b[0m       \u001b[32m0.8758\u001b[0m        \u001b[35m4.2033\u001b[0m  21.1168\n",
      "      5        \u001b[36m4.1441\u001b[0m       \u001b[32m0.9152\u001b[0m        \u001b[35m4.1618\u001b[0m  20.7230\n",
      "      6        \u001b[36m4.1006\u001b[0m       \u001b[32m0.9252\u001b[0m        \u001b[35m4.1411\u001b[0m  20.4889\n",
      "      7        \u001b[36m4.0801\u001b[0m       \u001b[32m0.9268\u001b[0m        \u001b[35m4.1318\u001b[0m  20.3839\n",
      "      8        \u001b[36m4.0701\u001b[0m       \u001b[32m0.9305\u001b[0m        \u001b[35m4.1253\u001b[0m  19.7918\n",
      "      9        \u001b[36m4.0606\u001b[0m       \u001b[32m0.9354\u001b[0m        \u001b[35m4.1218\u001b[0m  19.6982\n",
      "     10        \u001b[36m4.0518\u001b[0m       \u001b[32m0.9414\u001b[0m        \u001b[35m4.1152\u001b[0m  19.4615\n",
      "     11        \u001b[36m4.0456\u001b[0m       0.9407        \u001b[35m4.1116\u001b[0m  19.3614\n",
      "     12        \u001b[36m4.0417\u001b[0m       0.9414        \u001b[35m4.1094\u001b[0m  19.5958\n",
      "     13        \u001b[36m4.0394\u001b[0m       0.9414        \u001b[35m4.1075\u001b[0m  19.9018\n",
      "     14        \u001b[36m4.0381\u001b[0m       \u001b[32m0.9427\u001b[0m        \u001b[35m4.1060\u001b[0m  19.7426\n",
      "     15        \u001b[36m4.0365\u001b[0m       \u001b[32m0.9450\u001b[0m        \u001b[35m4.1051\u001b[0m  20.0145\n",
      "     16        \u001b[36m4.0359\u001b[0m       0.9427        \u001b[35m4.1043\u001b[0m  20.1286\n",
      "     17        \u001b[36m4.0351\u001b[0m       \u001b[32m0.9457\u001b[0m        \u001b[35m4.1028\u001b[0m  19.6842\n",
      "     18        4.0352       0.9424        4.1033  19.9118\n",
      "     19        \u001b[36m4.0346\u001b[0m       \u001b[32m0.9460\u001b[0m        \u001b[35m4.1012\u001b[0m  20.8329\n",
      "     20        \u001b[36m4.0339\u001b[0m       \u001b[32m0.9464\u001b[0m        \u001b[35m4.1003\u001b[0m  19.4296\n",
      "     21        \u001b[36m4.0337\u001b[0m       0.9434        4.1006  19.3612\n",
      "     22        \u001b[36m4.0336\u001b[0m       0.9444        \u001b[35m4.1000\u001b[0m  19.7962\n",
      "     23        \u001b[36m4.0333\u001b[0m       0.9444        4.1000  19.4954\n",
      "     24        \u001b[36m4.0331\u001b[0m       0.9427        4.1001  19.9387\n",
      "     25        \u001b[36m4.0329\u001b[0m       0.9424        \u001b[35m4.0998\u001b[0m  20.3638\n",
      "     26        \u001b[36m4.0328\u001b[0m       0.9444        \u001b[35m4.0989\u001b[0m  19.7444\n",
      "     27        \u001b[36m4.0324\u001b[0m       0.9444        \u001b[35m4.0985\u001b[0m  19.5180\n",
      "     28        4.0325       0.9444        \u001b[35m4.0981\u001b[0m  19.6589\n",
      "     29        \u001b[36m4.0323\u001b[0m       0.9450        \u001b[35m4.0973\u001b[0m  19.7623\n",
      "     30        \u001b[36m4.0321\u001b[0m       0.9444        4.0977  19.8256\n",
      "     31        4.0321       0.9464        \u001b[35m4.0971\u001b[0m  20.6186\n",
      "     32        \u001b[36m4.0320\u001b[0m       0.9447        4.0973  20.8358\n",
      "     33        \u001b[36m4.0318\u001b[0m       0.9430        4.0982  20.3257\n",
      "     34        \u001b[36m4.0315\u001b[0m       0.9440        4.0971  19.6447\n",
      "     35        \u001b[36m4.0312\u001b[0m       0.9440        \u001b[35m4.0964\u001b[0m  19.4586\n",
      "     36        4.0316       0.9424        \u001b[35m4.0964\u001b[0m  19.4200\n",
      "     37        4.0314       0.9447        \u001b[35m4.0963\u001b[0m  20.0058\n",
      "     38        4.0314       0.9417        4.0972  19.7994\n",
      "     39        4.0312       0.9440        \u001b[35m4.0954\u001b[0m  20.4831\n",
      "     40        \u001b[36m4.0310\u001b[0m       0.9424        4.0968  19.5400\n",
      "     41        4.0312       0.9424        4.0961  19.5567\n",
      "     42        4.0311       0.9424        4.0962  19.3689\n",
      "     43        4.0311       0.9427        4.0957  19.8943\n",
      "     44        \u001b[36m4.0310\u001b[0m       0.9427        \u001b[35m4.0953\u001b[0m  19.8677\n",
      "     45        \u001b[36m4.0309\u001b[0m       0.9457        \u001b[35m4.0946\u001b[0m  19.7998\n",
      "     46        \u001b[36m4.0309\u001b[0m       0.9437        4.0956  19.7889\n",
      "     47        4.0310       0.9444        \u001b[35m4.0946\u001b[0m  19.5550\n",
      "     48        4.0309       0.9450        4.0951  19.5607\n",
      "     49        4.0309       0.9440        4.0950  19.8255\n",
      "     50        \u001b[36m4.0308\u001b[0m       0.9437        4.0950  19.5383\n",
      "     51        4.0308       0.9427        4.0953  19.5850\n",
      "     52        4.0309       0.9424        4.0952  19.5109\n",
      "     53        4.0309       0.9434        \u001b[35m4.0942\u001b[0m  19.6137\n",
      "     54        4.0309       0.9427        4.0947  19.7096\n",
      "     55        \u001b[36m4.0307\u001b[0m       0.9427        4.0943  19.6868\n",
      "     56        4.0309       0.9427        4.0954  19.7448\n",
      "     57        4.0307       0.9424        4.0949  19.5925\n",
      "     58        4.0308       0.9440        \u001b[35m4.0935\u001b[0m  19.5397\n",
      "     59        4.0308       0.9450        4.0943  19.5501\n",
      "     60        \u001b[36m4.0307\u001b[0m       0.9434        4.0941  19.5837\n",
      "     61        4.0308       0.9440        4.0938  19.7044\n",
      "     62        4.0307       0.9427        4.0939  19.6445\n",
      "     63        4.0307       0.9424        4.0945  19.5699\n",
      "     64        4.0307       0.9427        4.0939  19.6381\n",
      "     65        4.0308       0.9434        4.0940  19.7152\n",
      "     66        4.0307       0.9430        4.0942  19.7652\n",
      "     67        \u001b[36m4.0306\u001b[0m       0.9424        4.0939  19.6915\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{50: 0.9144370860927152, 100: 0.9525165562913908, 200: 0.9829801324503311, 400: 0.9866225165562914, 800: 0.9868211920529801, 1600: 0.9870860927152317, 3200: 0.9870860927152317}\n",
      "Val accuracy\n",
      "{50: 0.8266666666666667, 100: 0.868, 200: 0.902, 400: 0.9043333333333333, 800: 0.9053333333333333, 1600: 0.903, 3200: 0.903}\n",
      "pred time\n",
      "{50: 0.1441209316253662, 100: 0.19157671928405762, 200: 0.19345808029174805, 400: 0.2257852554321289, 800: 0.3612978458404541, 1600: 0.6009829044342041, 3200: 0.9811649322509766}\n",
      "OOS Val Accuracy\n",
      "{50: 0.04, 100: 0.09, 200: 0.13, 400: 0.21, 800: 0.18, 1600: 0.19, 3200: 0.17}\n",
      "OOS pred time\n",
      "{50: 0.0038161277770996094, 100: 0.005321979522705078, 200: 0.005211830139160156, 400: 0.007739067077636719, 800: 0.010519027709960938, 1600: 0.02101612091064453, 3200: 0.03236198425292969}\n",
      "6400\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m4.9628\u001b[0m       \u001b[32m0.4762\u001b[0m        \u001b[35m4.7052\u001b[0m  38.6443\n",
      "      2        \u001b[36m4.4340\u001b[0m       \u001b[32m0.8146\u001b[0m        \u001b[35m4.2854\u001b[0m  39.0900\n",
      "      3        \u001b[36m4.2107\u001b[0m       \u001b[32m0.8838\u001b[0m        \u001b[35m4.1933\u001b[0m  38.0508\n",
      "      4        \u001b[36m4.1264\u001b[0m       \u001b[32m0.9172\u001b[0m        \u001b[35m4.1504\u001b[0m  38.1155\n",
      "      5        \u001b[36m4.0891\u001b[0m       \u001b[32m0.9275\u001b[0m        \u001b[35m4.1340\u001b[0m  37.1076\n",
      "      6        \u001b[36m4.0671\u001b[0m       \u001b[32m0.9331\u001b[0m        \u001b[35m4.1237\u001b[0m  38.9828\n",
      "      7        \u001b[36m4.0550\u001b[0m       \u001b[32m0.9338\u001b[0m        \u001b[35m4.1184\u001b[0m  42.4910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8        \u001b[36m4.0458\u001b[0m       \u001b[32m0.9381\u001b[0m        \u001b[35m4.1128\u001b[0m  38.6286\n",
      "      9        \u001b[36m4.0406\u001b[0m       \u001b[32m0.9397\u001b[0m        \u001b[35m4.1117\u001b[0m  36.8542\n",
      "     10        \u001b[36m4.0383\u001b[0m       \u001b[32m0.9401\u001b[0m        \u001b[35m4.1078\u001b[0m  36.0486\n",
      "     11        \u001b[36m4.0364\u001b[0m       \u001b[32m0.9421\u001b[0m        \u001b[35m4.1055\u001b[0m  36.7903\n",
      "     12        \u001b[36m4.0356\u001b[0m       0.9417        \u001b[35m4.1045\u001b[0m  39.0225\n",
      "     13        \u001b[36m4.0348\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m4.1027\u001b[0m  39.1421\n",
      "     14        \u001b[36m4.0341\u001b[0m       \u001b[32m0.9437\u001b[0m        \u001b[35m4.1021\u001b[0m  39.2116\n",
      "     15        \u001b[36m4.0338\u001b[0m       \u001b[32m0.9447\u001b[0m        \u001b[35m4.1012\u001b[0m  40.0323\n",
      "     16        \u001b[36m4.0336\u001b[0m       0.9440        4.1015  40.0047\n",
      "     17        \u001b[36m4.0331\u001b[0m       0.9414        4.1028  39.6398\n",
      "     18        \u001b[36m4.0330\u001b[0m       0.9424        \u001b[35m4.1004\u001b[0m  39.2430\n",
      "     19        \u001b[36m4.0327\u001b[0m       0.9444        \u001b[35m4.0996\u001b[0m  37.7536\n",
      "     20        \u001b[36m4.0325\u001b[0m       0.9421        4.0998  37.4436\n",
      "     21        \u001b[36m4.0322\u001b[0m       0.9447        \u001b[35m4.0987\u001b[0m  37.4940\n",
      "     22        4.0323       0.9430        4.0995  37.7521\n",
      "     23        \u001b[36m4.0320\u001b[0m       0.9434        4.0989  37.5587\n",
      "     24        4.0321       0.9440        \u001b[35m4.0976\u001b[0m  37.5614\n",
      "     25        \u001b[36m4.0317\u001b[0m       0.9424        4.0981  37.9145\n",
      "     26        \u001b[36m4.0317\u001b[0m       0.9417        4.0983  37.8999\n",
      "     27        4.0317       0.9430        4.0985  38.3118\n",
      "     28        \u001b[36m4.0316\u001b[0m       0.9444        \u001b[35m4.0967\u001b[0m  38.2824\n",
      "     29        \u001b[36m4.0315\u001b[0m       0.9440        4.0970  40.2189\n",
      "     30        \u001b[36m4.0313\u001b[0m       0.9421        4.0972  39.1928\n",
      "     31        \u001b[36m4.0313\u001b[0m       0.9424        \u001b[35m4.0966\u001b[0m  40.0496\n",
      "     32        4.0313       0.9407        4.0972  41.5619\n",
      "     33        \u001b[36m4.0311\u001b[0m       0.9424        \u001b[35m4.0964\u001b[0m  37.7462\n",
      "     34        4.0312       0.9417        4.0974  37.5749\n",
      "     35        \u001b[36m4.0310\u001b[0m       0.9437        4.0967  37.9228\n",
      "     36        4.0311       0.9424        4.0965  38.2791\n",
      "     37        4.0311       0.9417        4.0972  37.9361\n",
      "     38        4.0311       0.9430        \u001b[35m4.0955\u001b[0m  37.9638\n",
      "     39        4.0310       0.9440        \u001b[35m4.0955\u001b[0m  38.1592\n",
      "     40        \u001b[36m4.0309\u001b[0m       0.9427        4.0965  37.3725\n",
      "     41        \u001b[36m4.0309\u001b[0m       0.9411        4.0972  37.5680\n",
      "     42        4.0311       0.9407        4.0968  37.2124\n",
      "     43        \u001b[36m4.0308\u001b[0m       0.9434        4.0959  39.7836\n",
      "     44        \u001b[36m4.0307\u001b[0m       0.9411        4.0960  37.7916\n",
      "     45        \u001b[36m4.0306\u001b[0m       0.9417        4.0957  37.4018\n",
      "     46        4.0308       0.9411        4.0961  37.3676\n",
      "     47        4.0308       0.9417        4.0960  37.2931\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{50: 0.9144370860927152, 100: 0.9525165562913908, 200: 0.9829801324503311, 400: 0.9866225165562914, 800: 0.9868211920529801, 1600: 0.9870860927152317, 3200: 0.9870860927152317, 6400: 0.9865562913907284}\n",
      "Val accuracy\n",
      "{50: 0.8266666666666667, 100: 0.868, 200: 0.902, 400: 0.9043333333333333, 800: 0.9053333333333333, 1600: 0.903, 3200: 0.903, 6400: 0.9}\n",
      "pred time\n",
      "{50: 0.1441209316253662, 100: 0.19157671928405762, 200: 0.19345808029174805, 400: 0.2257852554321289, 800: 0.3612978458404541, 1600: 0.6009829044342041, 3200: 0.9811649322509766, 6400: 1.8936481475830078}\n",
      "OOS Val Accuracy\n",
      "{50: 0.04, 100: 0.09, 200: 0.13, 400: 0.21, 800: 0.18, 1600: 0.19, 3200: 0.17, 6400: 0.16}\n",
      "OOS pred time\n",
      "{50: 0.0038161277770996094, 100: 0.005321979522705078, 200: 0.005211830139160156, 400: 0.007739067077636719, 800: 0.010519027709960938, 1600: 0.02101612091064453, 3200: 0.03236198425292969, 6400: 0.06450796127319336}\n",
      "12800\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m4.8996\u001b[0m       \u001b[32m0.6043\u001b[0m        \u001b[35m4.5365\u001b[0m  84.5235\n",
      "      2        \u001b[36m4.3176\u001b[0m       \u001b[32m0.8513\u001b[0m        \u001b[35m4.2249\u001b[0m  84.2700\n",
      "      3        \u001b[36m4.1525\u001b[0m       \u001b[32m0.9020\u001b[0m        \u001b[35m4.1575\u001b[0m  85.4591\n",
      "      4        \u001b[36m4.0965\u001b[0m       \u001b[32m0.9248\u001b[0m        \u001b[35m4.1346\u001b[0m  84.1607\n",
      "      5        \u001b[36m4.0663\u001b[0m       \u001b[32m0.9318\u001b[0m        \u001b[35m4.1208\u001b[0m  84.0402\n",
      "      6        \u001b[36m4.0480\u001b[0m       \u001b[32m0.9368\u001b[0m        \u001b[35m4.1125\u001b[0m  84.3073\n",
      "      7        \u001b[36m4.0400\u001b[0m       \u001b[32m0.9414\u001b[0m        \u001b[35m4.1077\u001b[0m  83.8903\n",
      "      8        \u001b[36m4.0374\u001b[0m       0.9404        \u001b[35m4.1067\u001b[0m  82.4372\n",
      "      9        \u001b[36m4.0360\u001b[0m       0.9407        \u001b[35m4.1041\u001b[0m  81.3954\n",
      "     10        \u001b[36m4.0346\u001b[0m       \u001b[32m0.9430\u001b[0m        \u001b[35m4.1037\u001b[0m  83.1473\n",
      "     11        \u001b[36m4.0339\u001b[0m       0.9397        4.1039  86.9152\n",
      "     12        \u001b[36m4.0332\u001b[0m       0.9417        \u001b[35m4.1015\u001b[0m  83.6878\n",
      "     13        \u001b[36m4.0332\u001b[0m       0.9404        \u001b[35m4.1014\u001b[0m  86.9907\n",
      "     14        \u001b[36m4.0330\u001b[0m       0.9401        4.1021  86.1312\n",
      "     15        \u001b[36m4.0327\u001b[0m       0.9411        \u001b[35m4.1012\u001b[0m  86.9917\n",
      "     16        \u001b[36m4.0325\u001b[0m       0.9411        \u001b[35m4.1011\u001b[0m  86.1698\n",
      "     17        \u001b[36m4.0324\u001b[0m       0.9391        4.1019  85.5949\n",
      "     18        \u001b[36m4.0321\u001b[0m       0.9411        \u001b[35m4.0996\u001b[0m  83.9699\n",
      "     19        \u001b[36m4.0318\u001b[0m       0.9391        4.1015  83.0976\n",
      "     20        \u001b[36m4.0318\u001b[0m       0.9391        4.1020  83.1922\n",
      "     21        \u001b[36m4.0318\u001b[0m       0.9387        4.1009  83.0212\n",
      "     22        \u001b[36m4.0318\u001b[0m       0.9368        4.1014  82.8258\n",
      "     23        \u001b[36m4.0317\u001b[0m       0.9364        4.1012  83.6185\n",
      "     24        \u001b[36m4.0315\u001b[0m       0.9394        4.0997  88.1616\n",
      "     25        \u001b[36m4.0315\u001b[0m       0.9404        4.1002  83.0365\n",
      "     26        \u001b[36m4.0314\u001b[0m       0.9394        4.1004  83.2265\n",
      "     27        4.0316       0.9411        \u001b[35m4.0986\u001b[0m  83.5263\n",
      "     28        \u001b[36m4.0313\u001b[0m       0.9397        4.0996  83.0887\n",
      "     29        \u001b[36m4.0312\u001b[0m       0.9397        \u001b[35m4.0981\u001b[0m  83.4358\n",
      "     30        4.0314       0.9414        4.0989  83.9919\n",
      "     31        \u001b[36m4.0311\u001b[0m       0.9397        4.0988  84.4381\n",
      "     32        4.0312       0.9394        4.0992  84.0557\n",
      "     33        4.0313       0.9401        4.0989  84.0872\n",
      "     34        4.0314       0.9414        4.0986  84.1004\n",
      "     35        \u001b[36m4.0311\u001b[0m       0.9391        4.0989  83.6818\n",
      "     36        4.0311       0.9411        \u001b[35m4.0981\u001b[0m  84.1197\n",
      "     37        4.0312       0.9407        \u001b[35m4.0980\u001b[0m  84.0095\n",
      "     38        \u001b[36m4.0311\u001b[0m       0.9368        4.1001  83.7786\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{50: 0.9144370860927152, 100: 0.9525165562913908, 200: 0.9829801324503311, 400: 0.9866225165562914, 800: 0.9868211920529801, 1600: 0.9870860927152317, 3200: 0.9870860927152317, 6400: 0.9865562913907284, 12800: 0.9864238410596027}\n",
      "Val accuracy\n",
      "{50: 0.8266666666666667, 100: 0.868, 200: 0.902, 400: 0.9043333333333333, 800: 0.9053333333333333, 1600: 0.903, 3200: 0.903, 6400: 0.9, 12800: 0.899}\n",
      "pred time\n",
      "{50: 0.1441209316253662, 100: 0.19157671928405762, 200: 0.19345808029174805, 400: 0.2257852554321289, 800: 0.3612978458404541, 1600: 0.6009829044342041, 3200: 0.9811649322509766, 6400: 1.8936481475830078, 12800: 4.0066680908203125}\n",
      "OOS Val Accuracy\n",
      "{50: 0.04, 100: 0.09, 200: 0.13, 400: 0.21, 800: 0.18, 1600: 0.19, 3200: 0.17, 6400: 0.16, 12800: 0.15}\n",
      "OOS pred time\n",
      "{50: 0.0038161277770996094, 100: 0.005321979522705078, 200: 0.005211830139160156, 400: 0.007739067077636719, 800: 0.010519027709960938, 1600: 0.02101612091064453, 3200: 0.03236198425292969, 6400: 0.06450796127319336, 12800: 0.13319897651672363}\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "hidden_dim_list = [50, 100, 200, 400, 800, 1600, 3200, 6400, 12800] #hidden layer size\n",
    "dropout = 0.75\n",
    "for hidden_dim in hidden_dim_list:    #looping for hidden layer size\n",
    "    print(hidden_dim)\n",
    "    class CLINCModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                input_dim=vocab_dim,\n",
    "                hidden_dim=hidden_dim, #setting hidden layer size\n",
    "                output_dim=output_dim,\n",
    "                dropout=dropout\n",
    "        ):\n",
    "            super(CLINCModule, self).__init__()\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "            self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = F.relu(self.hidden(X))\n",
    "            X = self.dropout(X)\n",
    "            X = F.softmax(self.output(X), dim=-1)\n",
    "            return X\n",
    "   \n",
    "    net = NeuralNetClassifier(\n",
    "    module=CLINCModule,\n",
    "    lr=lr,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    max_epochs=1000,\n",
    "    optimizer=torch.optim.Adam, #Adam again - momentum has been removed accordingly.\n",
    "    callbacks=[EarlyStopping(patience=10)],\n",
    "    )\n",
    "    \n",
    "    net.fit(train_x, train_y)\n",
    "    tlabels = net.predict(train_x)\n",
    "    tacc[hidden_dim] = accuracy_score(tlabels, train_y)\n",
    "    print('training accuracy')\n",
    "    print(tacc)\n",
    "    time0 = time.time()\n",
    "    labels = net.predict(val_x)\n",
    "    vacc[hidden_dim] = accuracy_score(labels, val_y)\n",
    "    time1 = time.time()\n",
    "    vtime[hidden_dim] = time1-time0\n",
    "    print('Val accuracy')\n",
    "    print(vacc)\n",
    "    print('pred time')\n",
    "    print(vtime)\n",
    "    time2 = time.time()\n",
    "    olabels = net.predict(val_oos_x)\n",
    "    oacc[hidden_dim] = accuracy_score(olabels, val_oos_y)\n",
    "    time3 = time.time()\n",
    "    otime[hidden_dim]=time3-time2\n",
    "    print('OOS Val Accuracy')\n",
    "    print(oacc)\n",
    "    print('OOS pred time')\n",
    "    print(otime)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decrease in performance after 800. Experimenting with additional hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0173\u001b[0m       \u001b[32m0.0325\u001b[0m        \u001b[35m5.0172\u001b[0m  1.5052\n",
      "      2        \u001b[36m5.0170\u001b[0m       \u001b[32m0.0500\u001b[0m        \u001b[35m5.0165\u001b[0m  1.4924\n",
      "      3        \u001b[36m5.0140\u001b[0m       0.0301        \u001b[35m5.0076\u001b[0m  1.5714\n",
      "      4        \u001b[36m5.0031\u001b[0m       \u001b[32m0.0788\u001b[0m        \u001b[35m4.9890\u001b[0m  1.5027\n",
      "      5        \u001b[36m4.9908\u001b[0m       \u001b[32m0.1093\u001b[0m        \u001b[35m4.9624\u001b[0m  1.5579\n",
      "      6        \u001b[36m4.9788\u001b[0m       \u001b[32m0.1215\u001b[0m        \u001b[35m4.9366\u001b[0m  1.5185\n",
      "      7        \u001b[36m4.9692\u001b[0m       \u001b[32m0.1401\u001b[0m        \u001b[35m4.9184\u001b[0m  1.4710\n",
      "      8        \u001b[36m4.9601\u001b[0m       \u001b[32m0.1629\u001b[0m        \u001b[35m4.9013\u001b[0m  1.5335\n",
      "      9        \u001b[36m4.9523\u001b[0m       \u001b[32m0.1904\u001b[0m        \u001b[35m4.8836\u001b[0m  1.5409\n",
      "     10        \u001b[36m4.9459\u001b[0m       \u001b[32m0.2175\u001b[0m        \u001b[35m4.8679\u001b[0m  1.5013\n",
      "     11        \u001b[36m4.9371\u001b[0m       \u001b[32m0.2401\u001b[0m        \u001b[35m4.8478\u001b[0m  1.5600\n",
      "     12        \u001b[36m4.9334\u001b[0m       \u001b[32m0.2666\u001b[0m        \u001b[35m4.8286\u001b[0m  1.6302\n",
      "     13        \u001b[36m4.9212\u001b[0m       \u001b[32m0.2821\u001b[0m        \u001b[35m4.8067\u001b[0m  1.6952\n",
      "     14        \u001b[36m4.9133\u001b[0m       \u001b[32m0.2993\u001b[0m        \u001b[35m4.7890\u001b[0m  1.6660\n",
      "     15        \u001b[36m4.9056\u001b[0m       \u001b[32m0.3215\u001b[0m        \u001b[35m4.7693\u001b[0m  1.6879\n",
      "     16        \u001b[36m4.9029\u001b[0m       \u001b[32m0.3457\u001b[0m        \u001b[35m4.7530\u001b[0m  1.5765\n",
      "     17        \u001b[36m4.8974\u001b[0m       \u001b[32m0.3752\u001b[0m        \u001b[35m4.7355\u001b[0m  1.5645\n",
      "     18        \u001b[36m4.8882\u001b[0m       \u001b[32m0.3967\u001b[0m        \u001b[35m4.7232\u001b[0m  1.6691\n",
      "     19        \u001b[36m4.8810\u001b[0m       \u001b[32m0.4103\u001b[0m        \u001b[35m4.7076\u001b[0m  1.7583\n",
      "     20        \u001b[36m4.8748\u001b[0m       \u001b[32m0.4328\u001b[0m        \u001b[35m4.6922\u001b[0m  1.5996\n",
      "     21        \u001b[36m4.8693\u001b[0m       \u001b[32m0.4533\u001b[0m        \u001b[35m4.6751\u001b[0m  1.5969\n",
      "     22        \u001b[36m4.8642\u001b[0m       \u001b[32m0.4682\u001b[0m        \u001b[35m4.6596\u001b[0m  1.5941\n",
      "     23        \u001b[36m4.8622\u001b[0m       \u001b[32m0.4805\u001b[0m        \u001b[35m4.6479\u001b[0m  1.5619\n",
      "     24        \u001b[36m4.8568\u001b[0m       \u001b[32m0.5013\u001b[0m        \u001b[35m4.6314\u001b[0m  1.6454\n",
      "     25        \u001b[36m4.8487\u001b[0m       \u001b[32m0.5116\u001b[0m        \u001b[35m4.6193\u001b[0m  1.6060\n",
      "     26        \u001b[36m4.8431\u001b[0m       \u001b[32m0.5202\u001b[0m        \u001b[35m4.6046\u001b[0m  1.5536\n",
      "     27        \u001b[36m4.8392\u001b[0m       \u001b[32m0.5374\u001b[0m        \u001b[35m4.5898\u001b[0m  1.6609\n",
      "     28        \u001b[36m4.8355\u001b[0m       \u001b[32m0.5454\u001b[0m        \u001b[35m4.5778\u001b[0m  1.6417\n",
      "     29        \u001b[36m4.8318\u001b[0m       \u001b[32m0.5526\u001b[0m        \u001b[35m4.5674\u001b[0m  1.6653\n",
      "     30        \u001b[36m4.8280\u001b[0m       \u001b[32m0.5606\u001b[0m        \u001b[35m4.5575\u001b[0m  1.7360\n",
      "     31        \u001b[36m4.8196\u001b[0m       \u001b[32m0.5735\u001b[0m        \u001b[35m4.5453\u001b[0m  1.6540\n",
      "     32        4.8211       \u001b[32m0.5805\u001b[0m        \u001b[35m4.5355\u001b[0m  1.5960\n",
      "     33        \u001b[36m4.8157\u001b[0m       \u001b[32m0.5811\u001b[0m        \u001b[35m4.5251\u001b[0m  1.7122\n",
      "     34        \u001b[36m4.8107\u001b[0m       \u001b[32m0.5897\u001b[0m        \u001b[35m4.5175\u001b[0m  1.5984\n",
      "     35        \u001b[36m4.8042\u001b[0m       \u001b[32m0.5977\u001b[0m        \u001b[35m4.5107\u001b[0m  1.6185\n",
      "     36        4.8052       0.5944        \u001b[35m4.5036\u001b[0m  1.6701\n",
      "     37        \u001b[36m4.7996\u001b[0m       \u001b[32m0.6023\u001b[0m        \u001b[35m4.4945\u001b[0m  1.6926\n",
      "     38        \u001b[36m4.7943\u001b[0m       \u001b[32m0.6079\u001b[0m        \u001b[35m4.4868\u001b[0m  1.8355\n",
      "     39        4.7947       \u001b[32m0.6215\u001b[0m        \u001b[35m4.4775\u001b[0m  1.8332\n",
      "     40        \u001b[36m4.7909\u001b[0m       \u001b[32m0.6219\u001b[0m        \u001b[35m4.4721\u001b[0m  1.8783\n",
      "     41        4.7938       \u001b[32m0.6268\u001b[0m        \u001b[35m4.4643\u001b[0m  1.6385\n",
      "     42        \u001b[36m4.7848\u001b[0m       \u001b[32m0.6311\u001b[0m        \u001b[35m4.4576\u001b[0m  1.6154\n",
      "     43        \u001b[36m4.7807\u001b[0m       \u001b[32m0.6351\u001b[0m        \u001b[35m4.4524\u001b[0m  1.9166\n",
      "     44        \u001b[36m4.7741\u001b[0m       \u001b[32m0.6434\u001b[0m        \u001b[35m4.4442\u001b[0m  1.7900\n",
      "     45        \u001b[36m4.7737\u001b[0m       \u001b[32m0.6503\u001b[0m        \u001b[35m4.4372\u001b[0m  1.6700\n",
      "     46        4.7761       0.6497        \u001b[35m4.4327\u001b[0m  1.7274\n",
      "     47        \u001b[36m4.7638\u001b[0m       0.6457        \u001b[35m4.4307\u001b[0m  1.7477\n",
      "     48        4.7700       \u001b[32m0.6546\u001b[0m        \u001b[35m4.4230\u001b[0m  1.7467\n",
      "     49        4.7672       \u001b[32m0.6632\u001b[0m        \u001b[35m4.4171\u001b[0m  1.6986\n",
      "     50        \u001b[36m4.7611\u001b[0m       \u001b[32m0.6639\u001b[0m        \u001b[35m4.4131\u001b[0m  1.5913\n",
      "     51        \u001b[36m4.7543\u001b[0m       0.6623        \u001b[35m4.4093\u001b[0m  1.5716\n",
      "     52        4.7583       \u001b[32m0.6682\u001b[0m        \u001b[35m4.4044\u001b[0m  1.5643\n",
      "     53        \u001b[36m4.7534\u001b[0m       \u001b[32m0.6705\u001b[0m        \u001b[35m4.4008\u001b[0m  1.7184\n",
      "     54        \u001b[36m4.7500\u001b[0m       \u001b[32m0.6735\u001b[0m        \u001b[35m4.3960\u001b[0m  1.6484\n",
      "     55        \u001b[36m4.7499\u001b[0m       \u001b[32m0.6801\u001b[0m        \u001b[35m4.3905\u001b[0m  1.6177\n",
      "     56        4.7500       0.6798        \u001b[35m4.3892\u001b[0m  1.6809\n",
      "     57        \u001b[36m4.7463\u001b[0m       0.6772        \u001b[35m4.3875\u001b[0m  1.6490\n",
      "     58        \u001b[36m4.7420\u001b[0m       0.6785        \u001b[35m4.3865\u001b[0m  1.6314\n",
      "     59        4.7434       0.6762        \u001b[35m4.3855\u001b[0m  1.7038\n",
      "     60        \u001b[36m4.7339\u001b[0m       0.6778        \u001b[35m4.3814\u001b[0m  1.6035\n",
      "     61        \u001b[36m4.7335\u001b[0m       \u001b[32m0.6834\u001b[0m        \u001b[35m4.3768\u001b[0m  1.7518\n",
      "     62        4.7339       0.6821        \u001b[35m4.3739\u001b[0m  1.8071\n",
      "     63        \u001b[36m4.7308\u001b[0m       \u001b[32m0.6848\u001b[0m        \u001b[35m4.3731\u001b[0m  1.7130\n",
      "     64        \u001b[36m4.7301\u001b[0m       \u001b[32m0.6894\u001b[0m        \u001b[35m4.3691\u001b[0m  1.6718\n",
      "     65        \u001b[36m4.7268\u001b[0m       0.6868        \u001b[35m4.3673\u001b[0m  1.7578\n",
      "     66        \u001b[36m4.7256\u001b[0m       \u001b[32m0.6901\u001b[0m        \u001b[35m4.3644\u001b[0m  1.7120\n",
      "     67        4.7276       \u001b[32m0.6927\u001b[0m        \u001b[35m4.3634\u001b[0m  1.6396\n",
      "     68        \u001b[36m4.7201\u001b[0m       0.6924        \u001b[35m4.3613\u001b[0m  1.7635\n",
      "     69        4.7202       \u001b[32m0.6930\u001b[0m        \u001b[35m4.3577\u001b[0m  1.7999\n",
      "     70        \u001b[36m4.7194\u001b[0m       \u001b[32m0.6964\u001b[0m        \u001b[35m4.3551\u001b[0m  1.6055\n",
      "     71        \u001b[36m4.7188\u001b[0m       \u001b[32m0.7000\u001b[0m        \u001b[35m4.3526\u001b[0m  1.6089\n",
      "     72        \u001b[36m4.7136\u001b[0m       0.7000        \u001b[35m4.3524\u001b[0m  1.6096\n",
      "     73        4.7167       \u001b[32m0.7017\u001b[0m        \u001b[35m4.3506\u001b[0m  1.7311\n",
      "     74        \u001b[36m4.7117\u001b[0m       0.7003        \u001b[35m4.3501\u001b[0m  1.5835\n",
      "     75        4.7118       \u001b[32m0.7030\u001b[0m        \u001b[35m4.3470\u001b[0m  1.6811\n",
      "     76        4.7118       \u001b[32m0.7046\u001b[0m        \u001b[35m4.3461\u001b[0m  1.6117\n",
      "     77        \u001b[36m4.7111\u001b[0m       \u001b[32m0.7063\u001b[0m        \u001b[35m4.3445\u001b[0m  1.5873\n",
      "     78        \u001b[36m4.7071\u001b[0m       0.7060        \u001b[35m4.3434\u001b[0m  1.5906\n",
      "     79        4.7083       \u001b[32m0.7073\u001b[0m        \u001b[35m4.3413\u001b[0m  1.6236\n",
      "     80        \u001b[36m4.7068\u001b[0m       \u001b[32m0.7076\u001b[0m        \u001b[35m4.3404\u001b[0m  1.6278\n",
      "     81        \u001b[36m4.7004\u001b[0m       0.7066        \u001b[35m4.3401\u001b[0m  1.5970\n",
      "     82        4.7069       \u001b[32m0.7083\u001b[0m        \u001b[35m4.3389\u001b[0m  1.6193\n",
      "     83        \u001b[36m4.6994\u001b[0m       \u001b[32m0.7093\u001b[0m        \u001b[35m4.3379\u001b[0m  1.6552\n",
      "     84        \u001b[36m4.6975\u001b[0m       0.7093        \u001b[35m4.3375\u001b[0m  1.6330\n",
      "     85        4.7009       0.7093        \u001b[35m4.3367\u001b[0m  1.6242\n",
      "     86        4.6986       \u001b[32m0.7113\u001b[0m        \u001b[35m4.3356\u001b[0m  1.6408\n",
      "     87        \u001b[36m4.6952\u001b[0m       \u001b[32m0.7119\u001b[0m        4.3357  1.6450\n",
      "     88        \u001b[36m4.6898\u001b[0m       0.7113        \u001b[35m4.3342\u001b[0m  1.6352\n",
      "     89        4.6918       \u001b[32m0.7152\u001b[0m        \u001b[35m4.3325\u001b[0m  1.8623\n",
      "     90        4.6904       0.7142        4.3330  1.8294\n",
      "     91        4.6909       0.7123        \u001b[35m4.3323\u001b[0m  1.8948\n",
      "     92        \u001b[36m4.6886\u001b[0m       0.7126        \u001b[35m4.3316\u001b[0m  1.6701\n",
      "     93        \u001b[36m4.6844\u001b[0m       0.7099        4.3322  1.6473\n",
      "     94        4.6891       0.7103        4.3318  1.6795\n",
      "     95        4.6853       0.7116        \u001b[35m4.3307\u001b[0m  1.6968\n",
      "     96        4.6856       0.7119        \u001b[35m4.3286\u001b[0m  1.6427\n",
      "     97        4.6848       0.7129        \u001b[35m4.3284\u001b[0m  1.6485\n",
      "     98        \u001b[36m4.6835\u001b[0m       0.7123        \u001b[35m4.3281\u001b[0m  1.6467\n",
      "     99        4.6847       0.7136        \u001b[35m4.3255\u001b[0m  1.6560\n",
      "    100        \u001b[36m4.6816\u001b[0m       0.7126        4.3264  1.9276\n",
      "    101        \u001b[36m4.6760\u001b[0m       \u001b[32m0.7156\u001b[0m        4.3257  1.6835\n",
      "    102        \u001b[36m4.6738\u001b[0m       \u001b[32m0.7162\u001b[0m        \u001b[35m4.3236\u001b[0m  1.6426\n",
      "    103        4.6780       \u001b[32m0.7166\u001b[0m        4.3238  1.9457\n",
      "    104        4.6752       0.7146        4.3238  1.6656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    105        4.6772       0.7139        \u001b[35m4.3236\u001b[0m  1.7308\n",
      "    106        \u001b[36m4.6695\u001b[0m       \u001b[32m0.7179\u001b[0m        \u001b[35m4.3224\u001b[0m  1.9601\n",
      "    107        4.6753       0.7169        \u001b[35m4.3221\u001b[0m  1.6860\n",
      "    108        4.6763       0.7169        \u001b[35m4.3213\u001b[0m  1.6749\n",
      "    109        4.6738       \u001b[32m0.7192\u001b[0m        \u001b[35m4.3196\u001b[0m  1.6412\n",
      "    110        4.6723       \u001b[32m0.7202\u001b[0m        \u001b[35m4.3196\u001b[0m  1.6298\n",
      "    111        \u001b[36m4.6664\u001b[0m       \u001b[32m0.7205\u001b[0m        \u001b[35m4.3185\u001b[0m  1.6467\n",
      "    112        4.6708       \u001b[32m0.7209\u001b[0m        \u001b[35m4.3181\u001b[0m  1.6816\n",
      "    113        4.6725       \u001b[32m0.7222\u001b[0m        \u001b[35m4.3176\u001b[0m  1.6435\n",
      "    114        \u001b[36m4.6575\u001b[0m       0.7209        \u001b[35m4.3176\u001b[0m  1.6305\n",
      "    115        4.6641       0.7205        \u001b[35m4.3168\u001b[0m  1.6281\n",
      "    116        4.6676       0.7219        \u001b[35m4.3160\u001b[0m  1.6121\n",
      "    117        4.6675       \u001b[32m0.7225\u001b[0m        \u001b[35m4.3157\u001b[0m  1.6401\n",
      "    118        \u001b[36m4.6572\u001b[0m       0.7225        \u001b[35m4.3155\u001b[0m  1.6463\n",
      "    119        \u001b[36m4.6559\u001b[0m       0.7209        4.3160  1.6372\n",
      "    120        4.6652       \u001b[32m0.7228\u001b[0m        \u001b[35m4.3150\u001b[0m  1.6174\n",
      "    121        4.6605       \u001b[32m0.7238\u001b[0m        \u001b[35m4.3136\u001b[0m  1.6142\n",
      "    122        4.6560       0.7192        4.3162  1.6052\n",
      "    123        4.6586       0.7179        4.3160  1.6306\n",
      "    124        4.6576       0.7209        \u001b[35m4.3135\u001b[0m  1.6449\n",
      "    125        4.6579       0.7235        \u001b[35m4.3131\u001b[0m  1.6440\n",
      "    126        4.6566       \u001b[32m0.7245\u001b[0m        \u001b[35m4.3122\u001b[0m  1.6334\n",
      "    127        4.6592       0.7238        4.3123  1.6268\n",
      "    128        4.6589       0.7232        4.3125  1.6277\n",
      "    129        4.6563       0.7225        4.3125  1.6154\n",
      "    130        \u001b[36m4.6527\u001b[0m       0.7245        \u001b[35m4.3112\u001b[0m  1.6466\n",
      "    131        4.6531       \u001b[32m0.7255\u001b[0m        \u001b[35m4.3105\u001b[0m  1.6161\n",
      "    132        \u001b[36m4.6492\u001b[0m       0.7232        \u001b[35m4.3104\u001b[0m  1.6244\n",
      "    133        4.6509       \u001b[32m0.7262\u001b[0m        \u001b[35m4.3096\u001b[0m  1.6226\n",
      "    134        4.6526       0.7228        4.3108  1.6619\n",
      "    135        \u001b[36m4.6486\u001b[0m       0.7245        \u001b[35m4.3094\u001b[0m  1.6922\n",
      "    136        4.6544       \u001b[32m0.7272\u001b[0m        \u001b[35m4.3081\u001b[0m  1.6244\n",
      "    137        4.6488       0.7258        \u001b[35m4.3077\u001b[0m  1.6350\n",
      "    138        4.6522       0.7258        4.3083  1.6299\n",
      "    139        \u001b[36m4.6448\u001b[0m       \u001b[32m0.7285\u001b[0m        \u001b[35m4.3076\u001b[0m  1.6154\n",
      "    140        4.6474       0.7278        4.3080  1.6296\n",
      "    141        4.6479       0.7281        \u001b[35m4.3072\u001b[0m  1.6273\n",
      "    142        4.6460       \u001b[32m0.7305\u001b[0m        \u001b[35m4.3054\u001b[0m  1.7595\n",
      "    143        \u001b[36m4.6421\u001b[0m       0.7301        4.3058  1.7236\n",
      "    144        \u001b[36m4.6368\u001b[0m       0.7288        \u001b[35m4.3052\u001b[0m  1.6677\n",
      "    145        4.6434       0.7288        \u001b[35m4.3047\u001b[0m  1.6420\n",
      "    146        \u001b[36m4.6348\u001b[0m       0.7291        4.3050  1.6396\n",
      "    147        4.6384       0.7301        4.3048  1.6254\n",
      "    148        4.6409       \u001b[32m0.7308\u001b[0m        \u001b[35m4.3035\u001b[0m  1.6485\n",
      "    149        4.6384       \u001b[32m0.7328\u001b[0m        \u001b[35m4.3031\u001b[0m  1.6935\n",
      "    150        \u001b[36m4.6318\u001b[0m       \u001b[32m0.7338\u001b[0m        \u001b[35m4.3030\u001b[0m  1.6511\n",
      "    151        4.6334       \u001b[32m0.7344\u001b[0m        \u001b[35m4.3023\u001b[0m  1.6574\n",
      "    152        4.6402       0.7288        4.3039  1.6525\n",
      "    153        4.6329       0.7315        4.3036  1.6351\n",
      "    154        4.6386       0.7311        4.3040  1.6305\n",
      "    155        4.6368       0.7318        4.3036  1.6327\n",
      "    156        4.6367       0.7328        4.3025  1.6271\n",
      "    157        4.6346       0.7344        \u001b[35m4.3014\u001b[0m  1.6391\n",
      "    158        \u001b[36m4.6296\u001b[0m       \u001b[32m0.7354\u001b[0m        \u001b[35m4.3007\u001b[0m  1.6649\n",
      "    159        \u001b[36m4.6278\u001b[0m       0.7348        \u001b[35m4.2998\u001b[0m  1.6770\n",
      "    160        4.6299       0.7341        4.3008  1.6542\n",
      "    161        4.6326       \u001b[32m0.7371\u001b[0m        \u001b[35m4.2998\u001b[0m  1.6411\n",
      "    162        \u001b[36m4.6246\u001b[0m       0.7334        4.3000  1.6370\n",
      "    163        4.6303       0.7361        \u001b[35m4.2984\u001b[0m  1.6420\n",
      "    164        4.6298       0.7358        4.2994  1.6293\n",
      "    165        4.6290       0.7368        4.2985  1.6523\n",
      "    166        4.6284       0.7364        4.2987  1.6421\n",
      "    167        4.6249       0.7371        \u001b[35m4.2977\u001b[0m  1.6606\n",
      "    168        4.6260       \u001b[32m0.7374\u001b[0m        4.2979  1.6682\n",
      "    169        4.6258       0.7371        4.2980  1.6888\n",
      "    170        \u001b[36m4.6234\u001b[0m       0.7361        4.2991  1.6357\n",
      "    171        4.6257       0.7361        4.2985  1.6406\n",
      "    172        4.6279       0.7374        \u001b[35m4.2973\u001b[0m  1.6494\n",
      "    173        4.6247       \u001b[32m0.7387\u001b[0m        \u001b[35m4.2965\u001b[0m  1.6404\n",
      "    174        \u001b[36m4.6190\u001b[0m       0.7384        4.2974  1.6298\n",
      "    175        4.6270       0.7387        \u001b[35m4.2963\u001b[0m  1.6411\n",
      "    176        4.6221       0.7354        4.2980  1.6429\n",
      "    177        4.6202       0.7358        4.2969  1.6381\n",
      "    178        4.6194       0.7381        \u001b[35m4.2957\u001b[0m  1.6563\n",
      "    179        4.6196       0.7374        4.2963  1.6402\n",
      "    180        4.6191       \u001b[32m0.7391\u001b[0m        \u001b[35m4.2953\u001b[0m  1.6412\n",
      "    181        4.6229       0.7387        4.2956  1.6483\n",
      "    182        \u001b[36m4.6181\u001b[0m       0.7368        4.2961  1.6399\n",
      "    183        4.6195       0.7358        4.2965  1.6252\n",
      "    184        4.6181       0.7377        4.2962  1.6403\n",
      "    185        \u001b[36m4.6154\u001b[0m       \u001b[32m0.7397\u001b[0m        \u001b[35m4.2950\u001b[0m  1.6450\n",
      "    186        4.6164       0.7384        4.2957  1.6600\n",
      "    187        \u001b[36m4.6140\u001b[0m       0.7377        4.2955  1.6493\n",
      "    188        4.6210       0.7397        \u001b[35m4.2946\u001b[0m  1.6481\n",
      "    189        4.6141       \u001b[32m0.7407\u001b[0m        \u001b[35m4.2941\u001b[0m  1.6445\n",
      "    190        \u001b[36m4.6094\u001b[0m       0.7407        \u001b[35m4.2937\u001b[0m  1.6517\n",
      "    191        4.6152       \u001b[32m0.7414\u001b[0m        \u001b[35m4.2929\u001b[0m  1.6386\n",
      "    192        4.6174       \u001b[32m0.7417\u001b[0m        \u001b[35m4.2927\u001b[0m  1.6593\n",
      "    193        4.6120       \u001b[32m0.7424\u001b[0m        \u001b[35m4.2925\u001b[0m  1.6472\n",
      "    194        4.6135       0.7401        4.2929  1.7177\n",
      "    195        4.6102       0.7417        4.2927  1.6477\n",
      "    196        \u001b[36m4.6079\u001b[0m       0.7407        4.2931  1.6429\n",
      "    197        \u001b[36m4.6052\u001b[0m       0.7411        4.2926  1.6679\n",
      "    198        4.6067       0.7424        \u001b[35m4.2920\u001b[0m  1.6567\n",
      "    199        4.6058       0.7424        4.2920  1.6581\n",
      "    200        4.6060       \u001b[32m0.7440\u001b[0m        \u001b[35m4.2904\u001b[0m  1.6654\n",
      "    201        \u001b[36m4.6036\u001b[0m       0.7424        4.2906  1.6705\n",
      "    202        4.6079       0.7440        \u001b[35m4.2900\u001b[0m  1.6577\n",
      "    203        \u001b[36m4.6034\u001b[0m       0.7437        4.2906  1.6915\n",
      "    204        \u001b[36m4.6031\u001b[0m       0.7407        4.2919  1.6784\n",
      "    205        4.6049       0.7411        4.2922  1.6538\n",
      "    206        4.6070       0.7417        4.2920  1.6716\n",
      "    207        4.6058       0.7411        4.2923  1.6539\n",
      "    208        4.6054       0.7424        4.2917  1.6643\n",
      "    209        \u001b[36m4.6021\u001b[0m       0.7417        4.2912  1.6499\n",
      "    210        \u001b[36m4.6008\u001b[0m       \u001b[32m0.7450\u001b[0m        4.2903  1.6438\n",
      "    211        4.6025       0.7440        4.2902  1.6499\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{100: 0.7872847682119205}\n",
      "Val accuracy\n",
      "{100: 0.7203333333333334}\n",
      "pred time\n",
      "{100: 0.1648869514465332}\n",
      "OOS Val Accuracy\n",
      "{100: 0.0}\n",
      "OOS pred time\n",
      "{100: 0.0043487548828125}\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0255\u001b[0m        \u001b[35m5.0171\u001b[0m  2.1624\n",
      "      2        \u001b[36m5.0164\u001b[0m       \u001b[32m0.0629\u001b[0m        \u001b[35m5.0138\u001b[0m  2.1721\n",
      "      3        \u001b[36m5.0021\u001b[0m       \u001b[32m0.0854\u001b[0m        \u001b[35m4.9714\u001b[0m  2.1810\n",
      "      4        \u001b[36m4.9678\u001b[0m       \u001b[32m0.1417\u001b[0m        \u001b[35m4.9158\u001b[0m  2.2076\n",
      "      5        \u001b[36m4.9357\u001b[0m       \u001b[32m0.2159\u001b[0m        \u001b[35m4.8702\u001b[0m  2.1619\n",
      "      6        \u001b[36m4.9054\u001b[0m       \u001b[32m0.2781\u001b[0m        \u001b[35m4.8142\u001b[0m  2.1732\n",
      "      7        \u001b[36m4.8824\u001b[0m       \u001b[32m0.3182\u001b[0m        \u001b[35m4.7678\u001b[0m  2.1647\n",
      "      8        \u001b[36m4.8494\u001b[0m       \u001b[32m0.3735\u001b[0m        \u001b[35m4.7207\u001b[0m  2.1616\n",
      "      9        \u001b[36m4.8262\u001b[0m       \u001b[32m0.4132\u001b[0m        \u001b[35m4.6781\u001b[0m  2.1788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10        \u001b[36m4.7947\u001b[0m       \u001b[32m0.4666\u001b[0m        \u001b[35m4.6304\u001b[0m  2.1802\n",
      "     11        \u001b[36m4.7689\u001b[0m       \u001b[32m0.5089\u001b[0m        \u001b[35m4.5895\u001b[0m  2.1720\n",
      "     12        \u001b[36m4.7459\u001b[0m       \u001b[32m0.5477\u001b[0m        \u001b[35m4.5494\u001b[0m  2.1667\n",
      "     13        \u001b[36m4.7224\u001b[0m       \u001b[32m0.5636\u001b[0m        \u001b[35m4.5180\u001b[0m  2.1509\n",
      "     14        \u001b[36m4.7036\u001b[0m       \u001b[32m0.5851\u001b[0m        \u001b[35m4.4930\u001b[0m  2.1955\n",
      "     15        \u001b[36m4.6820\u001b[0m       \u001b[32m0.5911\u001b[0m        \u001b[35m4.4761\u001b[0m  2.2031\n",
      "     16        \u001b[36m4.6670\u001b[0m       \u001b[32m0.6020\u001b[0m        \u001b[35m4.4577\u001b[0m  2.1542\n",
      "     17        \u001b[36m4.6522\u001b[0m       \u001b[32m0.6162\u001b[0m        \u001b[35m4.4432\u001b[0m  2.1363\n",
      "     18        \u001b[36m4.6326\u001b[0m       \u001b[32m0.6225\u001b[0m        \u001b[35m4.4326\u001b[0m  2.1456\n",
      "     19        \u001b[36m4.6232\u001b[0m       \u001b[32m0.6301\u001b[0m        \u001b[35m4.4216\u001b[0m  2.1372\n",
      "     20        \u001b[36m4.6095\u001b[0m       \u001b[32m0.6447\u001b[0m        \u001b[35m4.4095\u001b[0m  2.1892\n",
      "     21        \u001b[36m4.6032\u001b[0m       \u001b[32m0.6510\u001b[0m        \u001b[35m4.4026\u001b[0m  2.1374\n",
      "     22        \u001b[36m4.5921\u001b[0m       \u001b[32m0.6533\u001b[0m        \u001b[35m4.3960\u001b[0m  2.1981\n",
      "     23        \u001b[36m4.5835\u001b[0m       \u001b[32m0.6606\u001b[0m        \u001b[35m4.3883\u001b[0m  2.1991\n",
      "     24        \u001b[36m4.5743\u001b[0m       \u001b[32m0.6666\u001b[0m        \u001b[35m4.3805\u001b[0m  2.2145\n",
      "     25        \u001b[36m4.5658\u001b[0m       \u001b[32m0.6738\u001b[0m        \u001b[35m4.3742\u001b[0m  2.1633\n",
      "     26        \u001b[36m4.5563\u001b[0m       \u001b[32m0.6781\u001b[0m        \u001b[35m4.3688\u001b[0m  2.1547\n",
      "     27        \u001b[36m4.5457\u001b[0m       \u001b[32m0.6887\u001b[0m        \u001b[35m4.3575\u001b[0m  2.1968\n",
      "     28        \u001b[36m4.5380\u001b[0m       \u001b[32m0.6954\u001b[0m        \u001b[35m4.3512\u001b[0m  2.2089\n",
      "     29        \u001b[36m4.5329\u001b[0m       \u001b[32m0.6974\u001b[0m        \u001b[35m4.3474\u001b[0m  2.3455\n",
      "     30        \u001b[36m4.5267\u001b[0m       \u001b[32m0.7017\u001b[0m        \u001b[35m4.3425\u001b[0m  2.3203\n",
      "     31        \u001b[36m4.5253\u001b[0m       \u001b[32m0.7063\u001b[0m        \u001b[35m4.3380\u001b[0m  2.2880\n",
      "     32        \u001b[36m4.5138\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m4.3343\u001b[0m  2.4205\n",
      "     33        \u001b[36m4.5054\u001b[0m       \u001b[32m0.7185\u001b[0m        \u001b[35m4.3261\u001b[0m  2.4472\n",
      "     34        \u001b[36m4.5006\u001b[0m       0.7152        4.3263  2.3027\n",
      "     35        \u001b[36m4.4943\u001b[0m       \u001b[32m0.7219\u001b[0m        \u001b[35m4.3207\u001b[0m  2.2784\n",
      "     36        \u001b[36m4.4922\u001b[0m       \u001b[32m0.7228\u001b[0m        \u001b[35m4.3175\u001b[0m  2.3833\n",
      "     37        \u001b[36m4.4839\u001b[0m       \u001b[32m0.7291\u001b[0m        \u001b[35m4.3129\u001b[0m  2.3639\n",
      "     38        \u001b[36m4.4828\u001b[0m       \u001b[32m0.7301\u001b[0m        \u001b[35m4.3107\u001b[0m  2.2359\n",
      "     39        \u001b[36m4.4744\u001b[0m       \u001b[32m0.7308\u001b[0m        \u001b[35m4.3071\u001b[0m  2.0844\n",
      "     40        \u001b[36m4.4744\u001b[0m       0.7308        \u001b[35m4.3049\u001b[0m  2.0265\n",
      "     41        \u001b[36m4.4682\u001b[0m       \u001b[32m0.7331\u001b[0m        \u001b[35m4.3029\u001b[0m  2.0120\n",
      "     42        \u001b[36m4.4615\u001b[0m       \u001b[32m0.7377\u001b[0m        \u001b[35m4.2994\u001b[0m  2.2132\n",
      "     43        \u001b[36m4.4604\u001b[0m       0.7368        \u001b[35m4.2987\u001b[0m  2.2519\n",
      "     44        \u001b[36m4.4561\u001b[0m       \u001b[32m0.7384\u001b[0m        \u001b[35m4.2974\u001b[0m  2.1156\n",
      "     45        \u001b[36m4.4537\u001b[0m       \u001b[32m0.7387\u001b[0m        \u001b[35m4.2966\u001b[0m  2.1642\n",
      "     46        \u001b[36m4.4444\u001b[0m       \u001b[32m0.7414\u001b[0m        \u001b[35m4.2932\u001b[0m  2.3902\n",
      "     47        \u001b[36m4.4422\u001b[0m       \u001b[32m0.7457\u001b[0m        \u001b[35m4.2919\u001b[0m  2.3060\n",
      "     48        \u001b[36m4.4379\u001b[0m       0.7450        \u001b[35m4.2899\u001b[0m  2.2876\n",
      "     49        4.4382       \u001b[32m0.7493\u001b[0m        \u001b[35m4.2864\u001b[0m  2.3503\n",
      "     50        \u001b[36m4.4365\u001b[0m       \u001b[32m0.7517\u001b[0m        \u001b[35m4.2839\u001b[0m  2.3119\n",
      "     51        \u001b[36m4.4298\u001b[0m       0.7497        4.2839  2.3486\n",
      "     52        \u001b[36m4.4288\u001b[0m       \u001b[32m0.7560\u001b[0m        \u001b[35m4.2812\u001b[0m  2.3398\n",
      "     53        \u001b[36m4.4223\u001b[0m       0.7533        \u001b[35m4.2808\u001b[0m  2.3318\n",
      "     54        \u001b[36m4.4204\u001b[0m       \u001b[32m0.7623\u001b[0m        \u001b[35m4.2741\u001b[0m  2.3260\n",
      "     55        \u001b[36m4.4191\u001b[0m       0.7623        \u001b[35m4.2726\u001b[0m  2.3489\n",
      "     56        \u001b[36m4.4188\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m4.2696\u001b[0m  2.3154\n",
      "     57        \u001b[36m4.4142\u001b[0m       \u001b[32m0.7692\u001b[0m        \u001b[35m4.2659\u001b[0m  2.3948\n",
      "     58        \u001b[36m4.4114\u001b[0m       \u001b[32m0.7702\u001b[0m        \u001b[35m4.2641\u001b[0m  2.3571\n",
      "     59        \u001b[36m4.4068\u001b[0m       \u001b[32m0.7738\u001b[0m        \u001b[35m4.2633\u001b[0m  2.3967\n",
      "     60        4.4093       0.7702        \u001b[35m4.2630\u001b[0m  2.3154\n",
      "     61        \u001b[36m4.4012\u001b[0m       \u001b[32m0.7758\u001b[0m        \u001b[35m4.2600\u001b[0m  2.2909\n",
      "     62        \u001b[36m4.3991\u001b[0m       \u001b[32m0.7798\u001b[0m        \u001b[35m4.2566\u001b[0m  2.3574\n",
      "     63        \u001b[36m4.3968\u001b[0m       0.7785        4.2570  2.3419\n",
      "     64        4.3988       \u001b[32m0.7828\u001b[0m        \u001b[35m4.2546\u001b[0m  2.3670\n",
      "     65        \u001b[36m4.3936\u001b[0m       0.7825        \u001b[35m4.2535\u001b[0m  2.3403\n",
      "     66        \u001b[36m4.3868\u001b[0m       0.7805        \u001b[35m4.2529\u001b[0m  2.3487\n",
      "     67        4.3919       0.7821        \u001b[35m4.2513\u001b[0m  2.3363\n",
      "     68        4.3878       \u001b[32m0.7841\u001b[0m        \u001b[35m4.2500\u001b[0m  2.3617\n",
      "     69        \u001b[36m4.3825\u001b[0m       0.7834        \u001b[35m4.2499\u001b[0m  2.3376\n",
      "     70        \u001b[36m4.3803\u001b[0m       \u001b[32m0.7868\u001b[0m        \u001b[35m4.2479\u001b[0m  2.3630\n",
      "     71        \u001b[36m4.3790\u001b[0m       0.7858        \u001b[35m4.2470\u001b[0m  2.3560\n",
      "     72        \u001b[36m4.3788\u001b[0m       \u001b[32m0.7901\u001b[0m        \u001b[35m4.2454\u001b[0m  2.3679\n",
      "     73        4.3818       0.7884        4.2456  2.3186\n",
      "     74        \u001b[36m4.3740\u001b[0m       \u001b[32m0.7930\u001b[0m        \u001b[35m4.2440\u001b[0m  2.3732\n",
      "     75        \u001b[36m4.3701\u001b[0m       0.7904        \u001b[35m4.2436\u001b[0m  2.3360\n",
      "     76        4.3719       0.7911        \u001b[35m4.2430\u001b[0m  2.3885\n",
      "     77        \u001b[36m4.3681\u001b[0m       \u001b[32m0.7940\u001b[0m        \u001b[35m4.2414\u001b[0m  2.3402\n",
      "     78        \u001b[36m4.3658\u001b[0m       0.7934        \u001b[35m4.2414\u001b[0m  2.3754\n",
      "     79        \u001b[36m4.3635\u001b[0m       0.7930        \u001b[35m4.2399\u001b[0m  2.3777\n",
      "     80        \u001b[36m4.3627\u001b[0m       0.7937        4.2406  2.3654\n",
      "     81        4.3645       \u001b[32m0.7960\u001b[0m        \u001b[35m4.2393\u001b[0m  2.3447\n",
      "     82        \u001b[36m4.3609\u001b[0m       0.7960        \u001b[35m4.2380\u001b[0m  2.3354\n",
      "     83        4.3620       0.7950        4.2387  2.4071\n",
      "     84        4.3622       0.7960        4.2384  2.3793\n",
      "     85        \u001b[36m4.3569\u001b[0m       \u001b[32m0.7970\u001b[0m        \u001b[35m4.2360\u001b[0m  2.4191\n",
      "     86        \u001b[36m4.3503\u001b[0m       \u001b[32m0.7987\u001b[0m        \u001b[35m4.2337\u001b[0m  2.3885\n",
      "     87        4.3544       \u001b[32m0.8020\u001b[0m        \u001b[35m4.2322\u001b[0m  2.3617\n",
      "     88        \u001b[36m4.3484\u001b[0m       0.8020        \u001b[35m4.2309\u001b[0m  2.4011\n",
      "     89        \u001b[36m4.3470\u001b[0m       0.8007        \u001b[35m4.2307\u001b[0m  2.3636\n",
      "     90        4.3502       \u001b[32m0.8030\u001b[0m        \u001b[35m4.2285\u001b[0m  2.3530\n",
      "     91        4.3503       0.8013        4.2294  2.4096\n",
      "     92        \u001b[36m4.3442\u001b[0m       \u001b[32m0.8036\u001b[0m        \u001b[35m4.2285\u001b[0m  2.3747\n",
      "     93        4.3458       0.8033        \u001b[35m4.2267\u001b[0m  2.4083\n",
      "     94        \u001b[36m4.3378\u001b[0m       \u001b[32m0.8053\u001b[0m        4.2277  2.3526\n",
      "     95        4.3439       \u001b[32m0.8070\u001b[0m        \u001b[35m4.2253\u001b[0m  2.4329\n",
      "     96        4.3407       \u001b[32m0.8076\u001b[0m        \u001b[35m4.2252\u001b[0m  2.4665\n",
      "     97        4.3404       0.8066        \u001b[35m4.2244\u001b[0m  2.4256\n",
      "     98        4.3412       0.8073        4.2251  2.3893\n",
      "     99        \u001b[36m4.3351\u001b[0m       \u001b[32m0.8079\u001b[0m        4.2248  2.4162\n",
      "    100        4.3355       \u001b[32m0.8089\u001b[0m        \u001b[35m4.2238\u001b[0m  2.3859\n",
      "    101        \u001b[36m4.3344\u001b[0m       \u001b[32m0.8099\u001b[0m        \u001b[35m4.2218\u001b[0m  2.4391\n",
      "    102        \u001b[36m4.3317\u001b[0m       0.8093        4.2222  2.3656\n",
      "    103        4.3326       \u001b[32m0.8109\u001b[0m        \u001b[35m4.2214\u001b[0m  2.4616\n",
      "    104        4.3351       0.8099        4.2227  2.3766\n",
      "    105        4.3336       0.8103        \u001b[35m4.2214\u001b[0m  2.4349\n",
      "    106        \u001b[36m4.3247\u001b[0m       0.8086        4.2230  2.4614\n",
      "    107        4.3304       0.8106        \u001b[35m4.2210\u001b[0m  2.5005\n",
      "    108        4.3278       0.8089        4.2225  2.5007\n",
      "    109        \u001b[36m4.3209\u001b[0m       0.8076        4.2227  2.4459\n",
      "    110        4.3256       0.8103        4.2216  2.4545\n",
      "    111        4.3252       0.8089        4.2215  2.4630\n",
      "    112        4.3214       \u001b[32m0.8116\u001b[0m        \u001b[35m4.2207\u001b[0m  2.4104\n",
      "    113        4.3279       \u001b[32m0.8119\u001b[0m        \u001b[35m4.2202\u001b[0m  2.4866\n",
      "    114        4.3214       \u001b[32m0.8136\u001b[0m        4.2202  2.4394\n",
      "    115        \u001b[36m4.3174\u001b[0m       0.8126        \u001b[35m4.2197\u001b[0m  2.4671\n",
      "    116        4.3195       0.8132        \u001b[35m4.2194\u001b[0m  2.4331\n",
      "    117        \u001b[36m4.3163\u001b[0m       0.8109        4.2195  2.4481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    118        4.3206       0.8126        4.2198  2.3738\n",
      "    119        \u001b[36m4.3150\u001b[0m       0.8132        \u001b[35m4.2187\u001b[0m  2.4346\n",
      "    120        \u001b[36m4.3137\u001b[0m       0.8132        4.2190  2.4416\n",
      "    121        \u001b[36m4.3123\u001b[0m       \u001b[32m0.8142\u001b[0m        \u001b[35m4.2181\u001b[0m  2.4259\n",
      "    122        4.3136       0.8126        4.2186  2.4349\n",
      "    123        4.3180       0.8136        \u001b[35m4.2176\u001b[0m  2.4401\n",
      "    124        4.3161       \u001b[32m0.8146\u001b[0m        \u001b[35m4.2174\u001b[0m  2.4586\n",
      "    125        \u001b[36m4.3119\u001b[0m       0.8142        4.2178  2.4255\n",
      "    126        \u001b[36m4.3087\u001b[0m       0.8129        4.2183  2.4132\n",
      "    127        4.3109       0.8132        4.2182  2.4471\n",
      "    128        4.3115       \u001b[32m0.8152\u001b[0m        \u001b[35m4.2170\u001b[0m  2.3804\n",
      "    129        4.3088       0.8146        \u001b[35m4.2162\u001b[0m  2.4103\n",
      "    130        4.3095       0.8152        \u001b[35m4.2162\u001b[0m  2.3767\n",
      "    131        \u001b[36m4.3065\u001b[0m       0.8139        4.2170  2.4148\n",
      "    132        \u001b[36m4.3048\u001b[0m       \u001b[32m0.8162\u001b[0m        \u001b[35m4.2161\u001b[0m  2.4213\n",
      "    133        4.3073       0.8159        \u001b[35m4.2158\u001b[0m  2.4569\n",
      "    134        \u001b[36m4.2991\u001b[0m       0.8149        \u001b[35m4.2154\u001b[0m  2.4312\n",
      "    135        4.3053       0.8142        \u001b[35m4.2153\u001b[0m  2.4874\n",
      "    136        4.3068       0.8156        4.2158  2.4258\n",
      "    137        4.3010       \u001b[32m0.8166\u001b[0m        \u001b[35m4.2150\u001b[0m  2.3754\n",
      "    138        4.3042       0.8166        \u001b[35m4.2148\u001b[0m  2.3846\n",
      "    139        \u001b[36m4.2985\u001b[0m       0.8156        \u001b[35m4.2146\u001b[0m  2.4560\n",
      "    140        4.2996       0.8166        \u001b[35m4.2145\u001b[0m  2.3805\n",
      "    141        \u001b[36m4.2968\u001b[0m       0.8149        4.2152  2.4096\n",
      "    142        \u001b[36m4.2966\u001b[0m       \u001b[32m0.8169\u001b[0m        4.2146  2.4168\n",
      "    143        4.2986       0.8166        \u001b[35m4.2135\u001b[0m  2.4654\n",
      "    144        4.3013       \u001b[32m0.8179\u001b[0m        \u001b[35m4.2133\u001b[0m  2.5144\n",
      "    145        \u001b[36m4.2949\u001b[0m       \u001b[32m0.8182\u001b[0m        4.2134  2.4163\n",
      "    146        4.2975       0.8172        \u001b[35m4.2130\u001b[0m  2.3784\n",
      "    147        \u001b[36m4.2937\u001b[0m       0.8172        4.2137  2.4593\n",
      "    148        4.2942       0.8182        \u001b[35m4.2129\u001b[0m  2.4006\n",
      "    149        \u001b[36m4.2908\u001b[0m       0.8179        4.2130  2.5801\n",
      "    150        4.2926       0.8175        4.2133  2.8840\n",
      "    151        4.2942       0.8172        \u001b[35m4.2127\u001b[0m  2.4610\n",
      "    152        4.2954       0.8166        4.2133  2.5731\n",
      "    153        4.2989       0.8169        4.2136  2.5362\n",
      "    154        4.2913       0.8162        4.2132  2.5749\n",
      "    155        4.2920       0.8182        4.2136  2.4801\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{100: 0.7872847682119205, 200: 0.8627152317880795}\n",
      "Val accuracy\n",
      "{100: 0.7203333333333334, 200: 0.7883333333333333}\n",
      "pred time\n",
      "{100: 0.1648869514465332, 200: 0.17763805389404297}\n",
      "OOS Val Accuracy\n",
      "{100: 0.0, 200: 0.05}\n",
      "OOS pred time\n",
      "{100: 0.0043487548828125, 200: 0.004634857177734375}\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0172\u001b[0m       \u001b[32m0.0656\u001b[0m        \u001b[35m5.0168\u001b[0m  4.0863\n",
      "      2        \u001b[36m5.0100\u001b[0m       \u001b[32m0.0685\u001b[0m        \u001b[35m4.9861\u001b[0m  4.1030\n",
      "      3        \u001b[36m4.9549\u001b[0m       \u001b[32m0.1772\u001b[0m        \u001b[35m4.8879\u001b[0m  4.1528\n",
      "      4        \u001b[36m4.8753\u001b[0m       \u001b[32m0.3301\u001b[0m        \u001b[35m4.7667\u001b[0m  4.1231\n",
      "      5        \u001b[36m4.7862\u001b[0m       \u001b[32m0.4308\u001b[0m        \u001b[35m4.6539\u001b[0m  4.1388\n",
      "      6        \u001b[36m4.7073\u001b[0m       \u001b[32m0.5285\u001b[0m        \u001b[35m4.5580\u001b[0m  4.1361\n",
      "      7        \u001b[36m4.6392\u001b[0m       \u001b[32m0.5877\u001b[0m        \u001b[35m4.4856\u001b[0m  4.2036\n",
      "      8        \u001b[36m4.5780\u001b[0m       \u001b[32m0.6305\u001b[0m        \u001b[35m4.4322\u001b[0m  4.0690\n",
      "      9        \u001b[36m4.5294\u001b[0m       \u001b[32m0.6778\u001b[0m        \u001b[35m4.3847\u001b[0m  4.0623\n",
      "     10        \u001b[36m4.4858\u001b[0m       \u001b[32m0.7215\u001b[0m        \u001b[35m4.3444\u001b[0m  4.0091\n",
      "     11        \u001b[36m4.4476\u001b[0m       \u001b[32m0.7334\u001b[0m        \u001b[35m4.3196\u001b[0m  4.0179\n",
      "     12        \u001b[36m4.4154\u001b[0m       \u001b[32m0.7490\u001b[0m        \u001b[35m4.2990\u001b[0m  4.0755\n",
      "     13        \u001b[36m4.3933\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m4.2901\u001b[0m  4.0617\n",
      "     14        \u001b[36m4.3737\u001b[0m       \u001b[32m0.7560\u001b[0m        \u001b[35m4.2846\u001b[0m  4.1154\n",
      "     15        \u001b[36m4.3620\u001b[0m       \u001b[32m0.7613\u001b[0m        \u001b[35m4.2801\u001b[0m  4.1894\n",
      "     16        \u001b[36m4.3476\u001b[0m       \u001b[32m0.7682\u001b[0m        \u001b[35m4.2730\u001b[0m  4.2080\n",
      "     17        \u001b[36m4.3339\u001b[0m       \u001b[32m0.7728\u001b[0m        \u001b[35m4.2668\u001b[0m  4.1571\n",
      "     18        \u001b[36m4.3255\u001b[0m       0.7719        \u001b[35m4.2652\u001b[0m  4.2130\n",
      "     19        \u001b[36m4.3177\u001b[0m       \u001b[32m0.7772\u001b[0m        \u001b[35m4.2593\u001b[0m  4.1925\n",
      "     20        \u001b[36m4.3078\u001b[0m       \u001b[32m0.7778\u001b[0m        \u001b[35m4.2577\u001b[0m  4.1880\n",
      "     21        \u001b[36m4.3016\u001b[0m       0.7778        \u001b[35m4.2553\u001b[0m  4.2127\n",
      "     22        \u001b[36m4.2950\u001b[0m       \u001b[32m0.7831\u001b[0m        \u001b[35m4.2522\u001b[0m  4.1113\n",
      "     23        \u001b[36m4.2923\u001b[0m       \u001b[32m0.7858\u001b[0m        \u001b[35m4.2505\u001b[0m  3.8794\n",
      "     24        \u001b[36m4.2875\u001b[0m       \u001b[32m0.7881\u001b[0m        \u001b[35m4.2468\u001b[0m  4.1871\n",
      "     25        \u001b[36m4.2814\u001b[0m       0.7854        4.2470  4.1787\n",
      "     26        \u001b[36m4.2738\u001b[0m       \u001b[32m0.7901\u001b[0m        \u001b[35m4.2445\u001b[0m  4.2021\n",
      "     27        \u001b[36m4.2682\u001b[0m       \u001b[32m0.7934\u001b[0m        \u001b[35m4.2406\u001b[0m  4.2545\n",
      "     28        \u001b[36m4.2672\u001b[0m       0.7934        \u001b[35m4.2390\u001b[0m  4.3012\n",
      "     29        \u001b[36m4.2616\u001b[0m       \u001b[32m0.8010\u001b[0m        \u001b[35m4.2345\u001b[0m  4.2291\n",
      "     30        \u001b[36m4.2570\u001b[0m       \u001b[32m0.8036\u001b[0m        \u001b[35m4.2311\u001b[0m  4.2314\n",
      "     31        \u001b[36m4.2529\u001b[0m       \u001b[32m0.8149\u001b[0m        \u001b[35m4.2201\u001b[0m  4.2654\n",
      "     32        \u001b[36m4.2440\u001b[0m       \u001b[32m0.8219\u001b[0m        \u001b[35m4.2130\u001b[0m  4.2374\n",
      "     33        \u001b[36m4.2385\u001b[0m       \u001b[32m0.8262\u001b[0m        \u001b[35m4.2092\u001b[0m  4.2479\n",
      "     34        \u001b[36m4.2319\u001b[0m       \u001b[32m0.8285\u001b[0m        \u001b[35m4.2053\u001b[0m  4.2474\n",
      "     35        \u001b[36m4.2295\u001b[0m       \u001b[32m0.8308\u001b[0m        \u001b[35m4.2026\u001b[0m  4.2780\n",
      "     36        \u001b[36m4.2237\u001b[0m       \u001b[32m0.8321\u001b[0m        \u001b[35m4.2003\u001b[0m  4.2919\n",
      "     37        \u001b[36m4.2169\u001b[0m       \u001b[32m0.8477\u001b[0m        \u001b[35m4.1863\u001b[0m  4.3365\n",
      "     38        \u001b[36m4.2119\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m4.1788\u001b[0m  4.3102\n",
      "     39        \u001b[36m4.2080\u001b[0m       \u001b[32m0.8632\u001b[0m        \u001b[35m4.1739\u001b[0m  4.3108\n",
      "     40        \u001b[36m4.1946\u001b[0m       \u001b[32m0.8675\u001b[0m        \u001b[35m4.1667\u001b[0m  4.3226\n",
      "     41        \u001b[36m4.1903\u001b[0m       \u001b[32m0.8702\u001b[0m        \u001b[35m4.1645\u001b[0m  4.3004\n",
      "     42        \u001b[36m4.1857\u001b[0m       0.8692        \u001b[35m4.1632\u001b[0m  4.3283\n",
      "     43        \u001b[36m4.1811\u001b[0m       \u001b[32m0.8722\u001b[0m        \u001b[35m4.1622\u001b[0m  4.3689\n",
      "     44        \u001b[36m4.1775\u001b[0m       0.8712        \u001b[35m4.1610\u001b[0m  4.3474\n",
      "     45        4.1777       \u001b[32m0.8748\u001b[0m        \u001b[35m4.1587\u001b[0m  4.3441\n",
      "     46        \u001b[36m4.1688\u001b[0m       0.8738        \u001b[35m4.1576\u001b[0m  4.3752\n",
      "     47        4.1702       \u001b[32m0.8765\u001b[0m        \u001b[35m4.1546\u001b[0m  4.3604\n",
      "     48        \u001b[36m4.1642\u001b[0m       \u001b[32m0.8801\u001b[0m        \u001b[35m4.1538\u001b[0m  4.3598\n",
      "     49        \u001b[36m4.1619\u001b[0m       0.8768        \u001b[35m4.1536\u001b[0m  4.3684\n",
      "     50        \u001b[36m4.1588\u001b[0m       \u001b[32m0.8808\u001b[0m        \u001b[35m4.1520\u001b[0m  4.3640\n",
      "     51        \u001b[36m4.1545\u001b[0m       \u001b[32m0.8815\u001b[0m        \u001b[35m4.1510\u001b[0m  4.3874\n",
      "     52        \u001b[36m4.1532\u001b[0m       0.8795        4.1518  4.3848\n",
      "     53        4.1542       0.8801        4.1510  4.3969\n",
      "     54        \u001b[36m4.1494\u001b[0m       0.8801        \u001b[35m4.1495\u001b[0m  4.3859\n",
      "     55        \u001b[36m4.1438\u001b[0m       \u001b[32m0.8825\u001b[0m        \u001b[35m4.1483\u001b[0m  4.4325\n",
      "     56        4.1454       \u001b[32m0.8828\u001b[0m        4.1488  4.4381\n",
      "     57        4.1443       0.8821        4.1491  4.4317\n",
      "     58        4.1439       \u001b[32m0.8841\u001b[0m        4.1486  4.4507\n",
      "     59        \u001b[36m4.1414\u001b[0m       0.8838        \u001b[35m4.1474\u001b[0m  4.4202\n",
      "     60        \u001b[36m4.1379\u001b[0m       \u001b[32m0.8844\u001b[0m        \u001b[35m4.1470\u001b[0m  4.4731\n",
      "     61        \u001b[36m4.1364\u001b[0m       \u001b[32m0.8851\u001b[0m        \u001b[35m4.1458\u001b[0m  4.4618\n",
      "     62        4.1376       \u001b[32m0.8874\u001b[0m        \u001b[35m4.1432\u001b[0m  4.4639\n",
      "     63        \u001b[36m4.1330\u001b[0m       \u001b[32m0.8894\u001b[0m        \u001b[35m4.1421\u001b[0m  4.5092\n",
      "     64        \u001b[36m4.1321\u001b[0m       \u001b[32m0.8897\u001b[0m        4.1422  4.4706\n",
      "     65        4.1321       0.8884        4.1427  4.4869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     66        \u001b[36m4.1296\u001b[0m       0.8874        4.1427  4.4876\n",
      "     67        \u001b[36m4.1291\u001b[0m       0.8897        \u001b[35m4.1420\u001b[0m  4.4988\n",
      "     68        4.1309       \u001b[32m0.8907\u001b[0m        \u001b[35m4.1407\u001b[0m  4.4705\n",
      "     69        \u001b[36m4.1260\u001b[0m       \u001b[32m0.8914\u001b[0m        \u001b[35m4.1406\u001b[0m  4.5457\n",
      "     70        \u001b[36m4.1257\u001b[0m       \u001b[32m0.8921\u001b[0m        \u001b[35m4.1404\u001b[0m  4.5151\n",
      "     71        \u001b[36m4.1220\u001b[0m       0.8914        \u001b[35m4.1399\u001b[0m  4.5490\n",
      "     72        4.1228       0.8897        4.1410  4.5413\n",
      "     73        4.1224       0.8921        4.1406  4.5797\n",
      "     74        \u001b[36m4.1203\u001b[0m       0.8921        \u001b[35m4.1393\u001b[0m  4.5253\n",
      "     75        \u001b[36m4.1178\u001b[0m       \u001b[32m0.8924\u001b[0m        \u001b[35m4.1390\u001b[0m  4.4683\n",
      "     76        4.1205       0.8914        4.1402  4.5429\n",
      "     77        4.1192       \u001b[32m0.8930\u001b[0m        \u001b[35m4.1389\u001b[0m  4.5854\n",
      "     78        4.1185       0.8911        4.1397  4.5606\n",
      "     79        \u001b[36m4.1174\u001b[0m       0.8927        \u001b[35m4.1385\u001b[0m  4.5744\n",
      "     80        \u001b[36m4.1156\u001b[0m       \u001b[32m0.8947\u001b[0m        \u001b[35m4.1366\u001b[0m  4.5704\n",
      "     81        \u001b[36m4.1143\u001b[0m       \u001b[32m0.8960\u001b[0m        \u001b[35m4.1350\u001b[0m  4.6004\n",
      "     82        \u001b[36m4.1137\u001b[0m       \u001b[32m0.8987\u001b[0m        \u001b[35m4.1328\u001b[0m  4.6301\n",
      "     83        \u001b[36m4.1118\u001b[0m       \u001b[32m0.8990\u001b[0m        \u001b[35m4.1324\u001b[0m  4.6035\n",
      "     84        \u001b[36m4.1103\u001b[0m       \u001b[32m0.9003\u001b[0m        \u001b[35m4.1320\u001b[0m  4.6394\n",
      "     85        \u001b[36m4.1076\u001b[0m       0.9003        \u001b[35m4.1314\u001b[0m  4.6176\n",
      "     86        \u001b[36m4.1055\u001b[0m       \u001b[32m0.9017\u001b[0m        \u001b[35m4.1294\u001b[0m  4.6333\n",
      "     87        \u001b[36m4.1040\u001b[0m       0.9000        4.1305  4.6326\n",
      "     88        \u001b[36m4.1028\u001b[0m       0.9003        4.1303  4.6275\n",
      "     89        4.1067       \u001b[32m0.9036\u001b[0m        \u001b[35m4.1278\u001b[0m  4.6477\n",
      "     90        \u001b[36m4.1025\u001b[0m       0.9033        4.1278  4.6888\n",
      "     91        \u001b[36m4.1003\u001b[0m       0.9023        4.1282  4.6629\n",
      "     92        4.1018       0.9026        \u001b[35m4.1277\u001b[0m  4.6864\n",
      "     93        4.1013       \u001b[32m0.9063\u001b[0m        \u001b[35m4.1262\u001b[0m  4.6559\n",
      "     94        \u001b[36m4.0988\u001b[0m       \u001b[32m0.9070\u001b[0m        \u001b[35m4.1247\u001b[0m  4.6750\n",
      "     95        \u001b[36m4.0983\u001b[0m       0.9070        \u001b[35m4.1240\u001b[0m  4.6972\n",
      "     96        \u001b[36m4.0977\u001b[0m       \u001b[32m0.9086\u001b[0m        \u001b[35m4.1218\u001b[0m  4.6590\n",
      "     97        4.0979       0.9073        4.1231  4.6944\n",
      "     98        \u001b[36m4.0970\u001b[0m       0.9073        4.1220  4.6680\n",
      "     99        \u001b[36m4.0938\u001b[0m       \u001b[32m0.9089\u001b[0m        \u001b[35m4.1217\u001b[0m  4.6838\n",
      "    100        \u001b[36m4.0919\u001b[0m       \u001b[32m0.9106\u001b[0m        \u001b[35m4.1213\u001b[0m  4.7221\n",
      "    101        4.0932       0.9096        4.1214  4.7378\n",
      "    102        \u001b[36m4.0919\u001b[0m       0.9096        \u001b[35m4.1212\u001b[0m  4.6885\n",
      "    103        \u001b[36m4.0907\u001b[0m       0.9076        4.1212  4.6899\n",
      "    104        \u001b[36m4.0900\u001b[0m       0.9103        \u001b[35m4.1196\u001b[0m  4.7114\n",
      "    105        4.0912       0.9099        4.1199  4.7274\n",
      "    106        \u001b[36m4.0890\u001b[0m       0.9096        4.1197  4.7940\n",
      "    107        4.0902       0.9093        4.1204  4.9051\n",
      "    108        \u001b[36m4.0875\u001b[0m       0.9096        4.1201  4.8556\n",
      "    109        4.0886       0.9089        4.1203  4.8136\n",
      "    110        \u001b[36m4.0857\u001b[0m       \u001b[32m0.9136\u001b[0m        \u001b[35m4.1183\u001b[0m  4.9085\n",
      "    111        4.0860       0.9113        4.1188  4.9372\n",
      "    112        4.0869       0.9099        4.1196  4.7967\n",
      "    113        4.0862       0.9089        4.1201  4.8650\n",
      "    114        4.0885       0.9093        4.1203  4.7991\n",
      "    115        \u001b[36m4.0828\u001b[0m       0.9093        4.1197  4.8442\n",
      "    116        4.0835       0.9113        4.1194  4.9576\n",
      "    117        4.0832       0.9093        4.1207  4.8206\n",
      "    118        4.0852       0.9103        4.1191  4.8727\n",
      "    119        \u001b[36m4.0815\u001b[0m       0.9132        \u001b[35m4.1181\u001b[0m  4.8468\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{100: 0.7872847682119205, 200: 0.8627152317880795, 400: 0.9660927152317881}\n",
      "Val accuracy\n",
      "{100: 0.7203333333333334, 200: 0.7883333333333333, 400: 0.893}\n",
      "pred time\n",
      "{100: 0.1648869514465332, 200: 0.17763805389404297, 400: 0.23238801956176758}\n",
      "OOS Val Accuracy\n",
      "{100: 0.0, 200: 0.05, 400: 0.1}\n",
      "OOS pred time\n",
      "{100: 0.0043487548828125, 200: 0.004634857177734375, 400: 0.008620262145996094}\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0170\u001b[0m       \u001b[32m0.0348\u001b[0m        \u001b[35m5.0152\u001b[0m  7.2414\n",
      "      2        \u001b[36m4.9873\u001b[0m       \u001b[32m0.1692\u001b[0m        \u001b[35m4.9081\u001b[0m  7.6678\n",
      "      3        \u001b[36m4.8413\u001b[0m       \u001b[32m0.3758\u001b[0m        \u001b[35m4.7022\u001b[0m  7.5955\n",
      "      4        \u001b[36m4.6748\u001b[0m       \u001b[32m0.5636\u001b[0m        \u001b[35m4.5308\u001b[0m  7.5731\n",
      "      5        \u001b[36m4.5371\u001b[0m       \u001b[32m0.6636\u001b[0m        \u001b[35m4.3996\u001b[0m  7.5689\n",
      "      6        \u001b[36m4.4394\u001b[0m       \u001b[32m0.7209\u001b[0m        \u001b[35m4.3364\u001b[0m  7.5737\n",
      "      7        \u001b[36m4.3724\u001b[0m       \u001b[32m0.7507\u001b[0m        \u001b[35m4.2995\u001b[0m  7.5742\n",
      "      8        \u001b[36m4.3293\u001b[0m       \u001b[32m0.7738\u001b[0m        \u001b[35m4.2729\u001b[0m  7.4462\n",
      "      9        \u001b[36m4.3007\u001b[0m       \u001b[32m0.7748\u001b[0m        \u001b[35m4.2632\u001b[0m  7.4021\n",
      "     10        \u001b[36m4.2811\u001b[0m       \u001b[32m0.7818\u001b[0m        \u001b[35m4.2559\u001b[0m  7.4608\n",
      "     11        \u001b[36m4.2644\u001b[0m       \u001b[32m0.7858\u001b[0m        \u001b[35m4.2491\u001b[0m  7.4426\n",
      "     12        \u001b[36m4.2564\u001b[0m       \u001b[32m0.7894\u001b[0m        \u001b[35m4.2441\u001b[0m  7.4794\n",
      "     13        \u001b[36m4.2435\u001b[0m       \u001b[32m0.8036\u001b[0m        \u001b[35m4.2332\u001b[0m  7.4640\n",
      "     14        \u001b[36m4.2304\u001b[0m       \u001b[32m0.8149\u001b[0m        \u001b[35m4.2216\u001b[0m  7.4984\n",
      "     15        \u001b[36m4.2146\u001b[0m       \u001b[32m0.8278\u001b[0m        \u001b[35m4.2096\u001b[0m  7.5248\n",
      "     16        \u001b[36m4.2023\u001b[0m       \u001b[32m0.8318\u001b[0m        \u001b[35m4.2025\u001b[0m  7.6012\n",
      "     17        \u001b[36m4.1922\u001b[0m       \u001b[32m0.8387\u001b[0m        \u001b[35m4.1954\u001b[0m  7.6011\n",
      "     18        \u001b[36m4.1836\u001b[0m       \u001b[32m0.8430\u001b[0m        \u001b[35m4.1912\u001b[0m  7.5501\n",
      "     19        \u001b[36m4.1776\u001b[0m       \u001b[32m0.8460\u001b[0m        \u001b[35m4.1873\u001b[0m  7.5743\n",
      "     20        \u001b[36m4.1720\u001b[0m       \u001b[32m0.8500\u001b[0m        \u001b[35m4.1845\u001b[0m  7.6122\n",
      "     21        \u001b[36m4.1655\u001b[0m       \u001b[32m0.8632\u001b[0m        \u001b[35m4.1703\u001b[0m  7.6176\n",
      "     22        \u001b[36m4.1522\u001b[0m       \u001b[32m0.8728\u001b[0m        \u001b[35m4.1615\u001b[0m  7.6803\n",
      "     23        \u001b[36m4.1429\u001b[0m       \u001b[32m0.8791\u001b[0m        \u001b[35m4.1561\u001b[0m  7.6305\n",
      "     24        \u001b[36m4.1389\u001b[0m       \u001b[32m0.8821\u001b[0m        \u001b[35m4.1529\u001b[0m  7.6670\n",
      "     25        \u001b[36m4.1328\u001b[0m       0.8821        \u001b[35m4.1511\u001b[0m  7.6373\n",
      "     26        \u001b[36m4.1267\u001b[0m       \u001b[32m0.8861\u001b[0m        \u001b[35m4.1466\u001b[0m  7.7301\n",
      "     27        \u001b[36m4.1238\u001b[0m       \u001b[32m0.8917\u001b[0m        \u001b[35m4.1433\u001b[0m  7.7316\n",
      "     28        \u001b[36m4.1158\u001b[0m       \u001b[32m0.8960\u001b[0m        \u001b[35m4.1372\u001b[0m  8.0507\n",
      "     29        \u001b[36m4.1103\u001b[0m       \u001b[32m0.8997\u001b[0m        \u001b[35m4.1333\u001b[0m  7.7722\n",
      "     30        \u001b[36m4.1061\u001b[0m       \u001b[32m0.9040\u001b[0m        \u001b[35m4.1287\u001b[0m  7.7705\n",
      "     31        \u001b[36m4.0981\u001b[0m       \u001b[32m0.9089\u001b[0m        \u001b[35m4.1255\u001b[0m  7.7548\n",
      "     32        \u001b[36m4.0937\u001b[0m       \u001b[32m0.9093\u001b[0m        \u001b[35m4.1238\u001b[0m  7.7643\n",
      "     33        \u001b[36m4.0902\u001b[0m       \u001b[32m0.9129\u001b[0m        \u001b[35m4.1195\u001b[0m  7.7775\n",
      "     34        \u001b[36m4.0875\u001b[0m       \u001b[32m0.9166\u001b[0m        \u001b[35m4.1179\u001b[0m  7.7217\n",
      "     35        \u001b[36m4.0829\u001b[0m       0.9142        \u001b[35m4.1175\u001b[0m  7.7787\n",
      "     36        \u001b[36m4.0810\u001b[0m       0.9159        \u001b[35m4.1157\u001b[0m  7.7628\n",
      "     37        \u001b[36m4.0798\u001b[0m       0.9152        4.1179  7.7328\n",
      "     38        \u001b[36m4.0765\u001b[0m       0.9159        4.1158  7.8139\n",
      "     39        \u001b[36m4.0744\u001b[0m       \u001b[32m0.9202\u001b[0m        \u001b[35m4.1123\u001b[0m  7.7642\n",
      "     40        \u001b[36m4.0732\u001b[0m       \u001b[32m0.9205\u001b[0m        \u001b[35m4.1109\u001b[0m  7.7881\n",
      "     41        \u001b[36m4.0730\u001b[0m       0.9195        4.1112  7.8345\n",
      "     42        \u001b[36m4.0688\u001b[0m       0.9192        4.1113  7.8047\n",
      "     43        \u001b[36m4.0672\u001b[0m       0.9202        4.1109  7.8894\n",
      "     44        4.0679       \u001b[32m0.9215\u001b[0m        4.1118  7.8274\n",
      "     45        \u001b[36m4.0661\u001b[0m       \u001b[32m0.9245\u001b[0m        \u001b[35m4.1086\u001b[0m  7.8120\n",
      "     46        \u001b[36m4.0617\u001b[0m       \u001b[32m0.9252\u001b[0m        \u001b[35m4.1072\u001b[0m  7.8817\n",
      "     47        \u001b[36m4.0601\u001b[0m       0.9245        \u001b[35m4.1062\u001b[0m  7.8793\n",
      "     48        4.0603       \u001b[32m0.9268\u001b[0m        \u001b[35m4.1048\u001b[0m  7.8657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     49        \u001b[36m4.0585\u001b[0m       0.9252        4.1062  7.9090\n",
      "     50        \u001b[36m4.0574\u001b[0m       0.9262        \u001b[35m4.1043\u001b[0m  7.7395\n",
      "     51        \u001b[36m4.0565\u001b[0m       \u001b[32m0.9275\u001b[0m        \u001b[35m4.1028\u001b[0m  7.8799\n",
      "     52        4.0567       \u001b[32m0.9288\u001b[0m        4.1033  7.9706\n",
      "     53        \u001b[36m4.0553\u001b[0m       0.9275        4.1035  7.9312\n",
      "     54        4.0570       0.9281        4.1033  8.0179\n",
      "     55        \u001b[36m4.0540\u001b[0m       0.9288        \u001b[35m4.1016\u001b[0m  7.9543\n",
      "     56        4.0542       0.9275        4.1037  7.9625\n",
      "     57        4.0544       0.9272        4.1043  8.0101\n",
      "     58        \u001b[36m4.0521\u001b[0m       0.9281        4.1027  7.9799\n",
      "     59        \u001b[36m4.0519\u001b[0m       \u001b[32m0.9315\u001b[0m        \u001b[35m4.0996\u001b[0m  7.9870\n",
      "     60        \u001b[36m4.0517\u001b[0m       0.9311        \u001b[35m4.0996\u001b[0m  8.0527\n",
      "     61        \u001b[36m4.0503\u001b[0m       \u001b[32m0.9318\u001b[0m        \u001b[35m4.0978\u001b[0m  8.0677\n",
      "     62        \u001b[36m4.0497\u001b[0m       0.9301        4.0993  8.0485\n",
      "     63        \u001b[36m4.0493\u001b[0m       \u001b[32m0.9341\u001b[0m        \u001b[35m4.0977\u001b[0m  8.0651\n",
      "     64        \u001b[36m4.0472\u001b[0m       0.9325        4.0987  8.1628\n",
      "     65        4.0474       0.9321        4.0992  8.0849\n",
      "     66        4.0483       0.9298        4.1000  8.0606\n",
      "     67        \u001b[36m4.0468\u001b[0m       0.9328        4.0979  8.2347\n",
      "     68        \u001b[36m4.0451\u001b[0m       0.9321        4.0979  8.0441\n",
      "     69        4.0458       0.9334        4.0978  8.3489\n",
      "     70        4.0453       0.9331        \u001b[35m4.0977\u001b[0m  8.1449\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{100: 0.7872847682119205, 200: 0.8627152317880795, 400: 0.9660927152317881, 800: 0.9821854304635762}\n",
      "Val accuracy\n",
      "{100: 0.7203333333333334, 200: 0.7883333333333333, 400: 0.893, 800: 0.9023333333333333}\n",
      "pred time\n",
      "{100: 0.1648869514465332, 200: 0.17763805389404297, 400: 0.23238801956176758, 800: 0.4028737545013428}\n",
      "OOS Val Accuracy\n",
      "{100: 0.0, 200: 0.05, 400: 0.1, 800: 0.17}\n",
      "OOS pred time\n",
      "{100: 0.0043487548828125, 200: 0.004634857177734375, 400: 0.008620262145996094, 800: 0.012100934982299805}\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m5.0145\u001b[0m       \u001b[32m0.0384\u001b[0m        \u001b[35m4.9920\u001b[0m  16.0904\n",
      "      2        \u001b[36m4.9164\u001b[0m       \u001b[32m0.3076\u001b[0m        \u001b[35m4.7555\u001b[0m  15.7859\n",
      "      3        \u001b[36m4.6626\u001b[0m       \u001b[32m0.5808\u001b[0m        \u001b[35m4.4969\u001b[0m  16.3929\n",
      "      4        \u001b[36m4.4529\u001b[0m       \u001b[32m0.7007\u001b[0m        \u001b[35m4.3541\u001b[0m  16.2927\n",
      "      5        \u001b[36m4.3492\u001b[0m       \u001b[32m0.7381\u001b[0m        \u001b[35m4.3081\u001b[0m  16.2035\n",
      "      6        \u001b[36m4.2929\u001b[0m       \u001b[32m0.7808\u001b[0m        \u001b[35m4.2633\u001b[0m  16.3368\n",
      "      7        \u001b[36m4.2473\u001b[0m       \u001b[32m0.8036\u001b[0m        \u001b[35m4.2351\u001b[0m  16.1753\n",
      "      8        \u001b[36m4.2157\u001b[0m       \u001b[32m0.8325\u001b[0m        \u001b[35m4.2060\u001b[0m  16.2253\n",
      "      9        \u001b[36m4.1850\u001b[0m       \u001b[32m0.8526\u001b[0m        \u001b[35m4.1874\u001b[0m  16.0784\n",
      "     10        \u001b[36m4.1662\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m4.1752\u001b[0m  16.1338\n",
      "     11        \u001b[36m4.1476\u001b[0m       \u001b[32m0.8728\u001b[0m        \u001b[35m4.1645\u001b[0m  16.3418\n",
      "     12        \u001b[36m4.1350\u001b[0m       \u001b[32m0.8785\u001b[0m        \u001b[35m4.1580\u001b[0m  16.2815\n",
      "     13        \u001b[36m4.1224\u001b[0m       \u001b[32m0.8914\u001b[0m        \u001b[35m4.1459\u001b[0m  16.3832\n",
      "     14        \u001b[36m4.1142\u001b[0m       \u001b[32m0.8944\u001b[0m        \u001b[35m4.1408\u001b[0m  16.4840\n",
      "     15        \u001b[36m4.1050\u001b[0m       \u001b[32m0.8970\u001b[0m        \u001b[35m4.1382\u001b[0m  16.4577\n",
      "     16        \u001b[36m4.0981\u001b[0m       \u001b[32m0.9036\u001b[0m        \u001b[35m4.1323\u001b[0m  16.6784\n",
      "     17        \u001b[36m4.0908\u001b[0m       \u001b[32m0.9119\u001b[0m        \u001b[35m4.1253\u001b[0m  16.5947\n",
      "     18        \u001b[36m4.0812\u001b[0m       \u001b[32m0.9156\u001b[0m        \u001b[35m4.1216\u001b[0m  16.7677\n",
      "     19        \u001b[36m4.0729\u001b[0m       \u001b[32m0.9265\u001b[0m        \u001b[35m4.1104\u001b[0m  16.7965\n",
      "     20        \u001b[36m4.0645\u001b[0m       \u001b[32m0.9311\u001b[0m        \u001b[35m4.1049\u001b[0m  16.6789\n",
      "     21        \u001b[36m4.0606\u001b[0m       0.9285        4.1058  17.1544\n",
      "     22        \u001b[36m4.0577\u001b[0m       0.9305        \u001b[35m4.1033\u001b[0m  17.0350\n",
      "     23        \u001b[36m4.0565\u001b[0m       \u001b[32m0.9315\u001b[0m        4.1034  16.9326\n",
      "     24        \u001b[36m4.0540\u001b[0m       0.9285        4.1050  16.8503\n",
      "     25        \u001b[36m4.0529\u001b[0m       0.9272        4.1053  16.8703\n",
      "     26        \u001b[36m4.0516\u001b[0m       0.9281        4.1047  17.1718\n",
      "     27        \u001b[36m4.0512\u001b[0m       0.9295        4.1051  16.9056\n",
      "     28        \u001b[36m4.0499\u001b[0m       0.9308        \u001b[35m4.1028\u001b[0m  16.9796\n",
      "     29        \u001b[36m4.0481\u001b[0m       0.9272        4.1039  16.9552\n",
      "     30        4.0486       0.9295        4.1028  16.9790\n",
      "     31        \u001b[36m4.0454\u001b[0m       0.9315        \u001b[35m4.1013\u001b[0m  17.0894\n",
      "     32        \u001b[36m4.0452\u001b[0m       \u001b[32m0.9321\u001b[0m        \u001b[35m4.1006\u001b[0m  16.9500\n",
      "     33        \u001b[36m4.0427\u001b[0m       \u001b[32m0.9348\u001b[0m        \u001b[35m4.0981\u001b[0m  17.1874\n",
      "     34        \u001b[36m4.0419\u001b[0m       \u001b[32m0.9361\u001b[0m        \u001b[35m4.0970\u001b[0m  17.0101\n",
      "     35        \u001b[36m4.0410\u001b[0m       0.9338        4.0996  17.5716\n",
      "     36        \u001b[36m4.0407\u001b[0m       0.9318        4.0998  17.4345\n",
      "     37        \u001b[36m4.0407\u001b[0m       0.9318        4.0992  16.9798\n",
      "     38        \u001b[36m4.0397\u001b[0m       0.9301        4.1020  16.7225\n",
      "     39        \u001b[36m4.0385\u001b[0m       0.9321        4.0989  16.7285\n",
      "     40        4.0394       0.9341        4.0973  16.8220\n",
      "     41        4.0390       0.9325        4.0986  16.7673\n",
      "     42        4.0386       0.9341        4.0979  16.7984\n",
      "     43        \u001b[36m4.0378\u001b[0m       \u001b[32m0.9368\u001b[0m        \u001b[35m4.0960\u001b[0m  16.9043\n",
      "     44        4.0381       0.9291        4.0997  16.7800\n",
      "     45        4.0379       0.9354        4.0968  16.8006\n",
      "     46        4.0383       0.9331        4.0984  17.0979\n",
      "     47        4.0382       0.9351        4.0964  16.9907\n",
      "     48        \u001b[36m4.0373\u001b[0m       0.9344        \u001b[35m4.0959\u001b[0m  16.8664\n",
      "     49        4.0377       0.9358        4.0961  17.2362\n",
      "     50        \u001b[36m4.0372\u001b[0m       0.9321        4.0980  17.2540\n",
      "     51        \u001b[36m4.0367\u001b[0m       0.9351        4.0969  17.3087\n",
      "     52        4.0373       0.9328        4.0966  17.0990\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{100: 0.7872847682119205, 200: 0.8627152317880795, 400: 0.9660927152317881, 800: 0.9821854304635762, 1600: 0.9834437086092715}\n",
      "Val accuracy\n",
      "{100: 0.7203333333333334, 200: 0.7883333333333333, 400: 0.893, 800: 0.9023333333333333, 1600: 0.9026666666666666}\n",
      "pred time\n",
      "{100: 0.1648869514465332, 200: 0.17763805389404297, 400: 0.23238801956176758, 800: 0.4028737545013428, 1600: 0.813187837600708}\n",
      "OOS Val Accuracy\n",
      "{100: 0.0, 200: 0.05, 400: 0.1, 800: 0.17, 1600: 0.12}\n",
      "OOS pred time\n",
      "{100: 0.0043487548828125, 200: 0.004634857177734375, 400: 0.008620262145996094, 800: 0.012100934982299805, 1600: 0.02760481834411621}\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "hidden_dim_list = [100,200,400,800,1600] #size for both hidden layers\n",
    "dropout = 0.75\n",
    "for hidden_dim in hidden_dim_list:        \n",
    "    class CLINCModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                input_dim=vocab_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim,\n",
    "                dropout=dropout\n",
    "        ):\n",
    "            super(CLINCModule, self).__init__()\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            self.hidden = nn.Linear(input_dim, hidden_dim) \n",
    "            self.hidden2 = nn.Linear(hidden_dim, hidden_dim) #hidden layer 2\n",
    "\n",
    "\n",
    "            self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = F.relu(self.hidden(X))\n",
    "            X = self.dropout(X)\n",
    "            X = F.relu(self.hidden2(X)) #hidden layer 2\n",
    "            X = self.dropout(X) #dropout 2\n",
    "            X = F.softmax(self.output(X), dim=-1)\n",
    "            return X\n",
    "\n",
    "    net = NeuralNetClassifier(\n",
    "    module=CLINCModule,\n",
    "    lr=lr,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    max_epochs=1000,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    callbacks=[EarlyStopping(patience=10)],\n",
    "    )\n",
    "\n",
    "    net.fit(train_x, train_y)\n",
    "    tlabels = net.predict(train_x)\n",
    "    tacc[hidden_dim] = accuracy_score(tlabels, train_y)\n",
    "    print('training accuracy')\n",
    "    print(tacc)\n",
    "    time0 = time.time()\n",
    "    labels = net.predict(val_x)\n",
    "    vacc[hidden_dim] = accuracy_score(labels, val_y)\n",
    "    time1 = time.time()\n",
    "    vtime[hidden_dim] = time1-time0\n",
    "    print('Val accuracy')\n",
    "    print(vacc)\n",
    "    print('pred time')\n",
    "    print(vtime)\n",
    "    time2 = time.time()\n",
    "    olabels = net.predict(val_oos_x)\n",
    "    oacc[hidden_dim] = accuracy_score(olabels, val_oos_y)\n",
    "    time3 = time.time()\n",
    "    otime[hidden_dim]=time3-time2\n",
    "    print('OOS Val Accuracy')\n",
    "    print(oacc)\n",
    "    print('OOS pred time')\n",
    "    print(otime)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With no hidden layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0170\u001b[0m       \u001b[32m0.6474\u001b[0m        \u001b[35m5.0167\u001b[0m  1.9125\n",
      "      2        \u001b[36m5.0163\u001b[0m       \u001b[32m0.7811\u001b[0m        \u001b[35m5.0160\u001b[0m  2.0325\n",
      "      3        \u001b[36m5.0153\u001b[0m       \u001b[32m0.8086\u001b[0m        \u001b[35m5.0151\u001b[0m  2.0285\n",
      "      4        \u001b[36m5.0140\u001b[0m       \u001b[32m0.8209\u001b[0m        \u001b[35m5.0140\u001b[0m  1.9413\n",
      "      5        \u001b[36m5.0122\u001b[0m       0.8132        \u001b[35m5.0127\u001b[0m  1.9885\n",
      "      6        \u001b[36m5.0097\u001b[0m       0.8017        \u001b[35m5.0111\u001b[0m  1.9310\n",
      "      7        \u001b[36m5.0061\u001b[0m       0.7884        \u001b[35m5.0092\u001b[0m  2.0014\n",
      "      8        \u001b[36m5.0019\u001b[0m       0.7709        \u001b[35m5.0070\u001b[0m  1.9692\n",
      "      9        \u001b[36m4.9966\u001b[0m       0.7623        \u001b[35m5.0045\u001b[0m  1.9227\n",
      "     10        \u001b[36m4.9915\u001b[0m       0.7487        \u001b[35m5.0018\u001b[0m  1.9665\n",
      "     11        \u001b[36m4.9847\u001b[0m       0.7377        \u001b[35m4.9988\u001b[0m  1.9575\n",
      "     12        \u001b[36m4.9763\u001b[0m       0.7295        \u001b[35m4.9954\u001b[0m  1.9626\n",
      "     13        \u001b[36m4.9668\u001b[0m       0.7278        \u001b[35m4.9918\u001b[0m  2.0229\n",
      "     14        \u001b[36m4.9604\u001b[0m       0.7288        \u001b[35m4.9879\u001b[0m  1.9227\n",
      "     15        \u001b[36m4.9515\u001b[0m       0.7288        \u001b[35m4.9839\u001b[0m  2.0014\n",
      "     16        \u001b[36m4.9407\u001b[0m       0.7331        \u001b[35m4.9797\u001b[0m  1.9834\n",
      "     17        \u001b[36m4.9349\u001b[0m       0.7364        \u001b[35m4.9753\u001b[0m  2.0091\n",
      "     18        \u001b[36m4.9269\u001b[0m       0.7430        \u001b[35m4.9708\u001b[0m  2.0021\n",
      "     19        \u001b[36m4.9193\u001b[0m       0.7497        \u001b[35m4.9663\u001b[0m  1.9593\n",
      "     20        \u001b[36m4.9104\u001b[0m       0.7543        \u001b[35m4.9615\u001b[0m  2.0183\n",
      "     21        \u001b[36m4.9062\u001b[0m       0.7563        \u001b[35m4.9567\u001b[0m  1.9671\n",
      "     22        \u001b[36m4.8963\u001b[0m       0.7623        \u001b[35m4.9518\u001b[0m  1.9882\n",
      "     23        \u001b[36m4.8865\u001b[0m       0.7666        \u001b[35m4.9466\u001b[0m  2.0116\n",
      "     24        \u001b[36m4.8856\u001b[0m       0.7715        \u001b[35m4.9417\u001b[0m  1.9917\n",
      "     25        \u001b[36m4.8708\u001b[0m       0.7755        \u001b[35m4.9366\u001b[0m  2.0095\n",
      "     26        \u001b[36m4.8681\u001b[0m       0.7775        \u001b[35m4.9314\u001b[0m  1.9554\n",
      "     27        \u001b[36m4.8616\u001b[0m       0.7834        \u001b[35m4.9261\u001b[0m  1.9795\n",
      "     28        \u001b[36m4.8552\u001b[0m       0.7907        \u001b[35m4.9208\u001b[0m  2.0043\n",
      "     29        \u001b[36m4.8542\u001b[0m       0.7944        \u001b[35m4.9157\u001b[0m  1.9588\n",
      "     30        \u001b[36m4.8439\u001b[0m       0.7993        \u001b[35m4.9104\u001b[0m  2.0077\n",
      "     31        \u001b[36m4.8420\u001b[0m       0.8043        \u001b[35m4.9051\u001b[0m  2.0004\n",
      "     32        \u001b[36m4.8405\u001b[0m       0.8066        \u001b[35m4.8998\u001b[0m  1.9912\n",
      "     33        \u001b[36m4.8315\u001b[0m       0.8103        \u001b[35m4.8945\u001b[0m  1.9852\n",
      "     34        \u001b[36m4.8256\u001b[0m       0.8123        \u001b[35m4.8892\u001b[0m  2.0226\n",
      "     35        \u001b[36m4.8203\u001b[0m       0.8132        \u001b[35m4.8839\u001b[0m  2.0096\n",
      "     36        \u001b[36m4.8180\u001b[0m       0.8182        \u001b[35m4.8785\u001b[0m  1.9509\n",
      "     37        \u001b[36m4.8163\u001b[0m       \u001b[32m0.8225\u001b[0m        \u001b[35m4.8733\u001b[0m  2.0360\n",
      "     38        \u001b[36m4.8069\u001b[0m       \u001b[32m0.8248\u001b[0m        \u001b[35m4.8680\u001b[0m  2.0067\n",
      "     39        \u001b[36m4.7966\u001b[0m       \u001b[32m0.8285\u001b[0m        \u001b[35m4.8626\u001b[0m  1.9432\n",
      "     40        4.7999       \u001b[32m0.8301\u001b[0m        \u001b[35m4.8573\u001b[0m  2.0120\n",
      "     41        4.7980       \u001b[32m0.8331\u001b[0m        \u001b[35m4.8521\u001b[0m  1.9544\n",
      "     42        \u001b[36m4.7957\u001b[0m       \u001b[32m0.8348\u001b[0m        \u001b[35m4.8468\u001b[0m  2.0127\n",
      "     43        \u001b[36m4.7853\u001b[0m       \u001b[32m0.8394\u001b[0m        \u001b[35m4.8415\u001b[0m  1.9662\n",
      "     44        \u001b[36m4.7826\u001b[0m       \u001b[32m0.8417\u001b[0m        \u001b[35m4.8361\u001b[0m  1.9298\n",
      "     45        4.7856       \u001b[32m0.8447\u001b[0m        \u001b[35m4.8310\u001b[0m  2.0289\n",
      "     46        \u001b[36m4.7778\u001b[0m       \u001b[32m0.8450\u001b[0m        \u001b[35m4.8258\u001b[0m  1.9466\n",
      "     47        \u001b[36m4.7748\u001b[0m       \u001b[32m0.8480\u001b[0m        \u001b[35m4.8207\u001b[0m  2.0031\n",
      "     48        \u001b[36m4.7734\u001b[0m       \u001b[32m0.8487\u001b[0m        \u001b[35m4.8155\u001b[0m  1.9910\n",
      "     49        \u001b[36m4.7717\u001b[0m       \u001b[32m0.8517\u001b[0m        \u001b[35m4.8104\u001b[0m  1.9403\n",
      "     50        \u001b[36m4.7696\u001b[0m       \u001b[32m0.8543\u001b[0m        \u001b[35m4.8054\u001b[0m  2.0406\n",
      "     51        \u001b[36m4.7619\u001b[0m       \u001b[32m0.8553\u001b[0m        \u001b[35m4.8004\u001b[0m  1.9131\n",
      "     52        4.7627       \u001b[32m0.8560\u001b[0m        \u001b[35m4.7954\u001b[0m  2.0135\n",
      "     53        \u001b[36m4.7591\u001b[0m       \u001b[32m0.8583\u001b[0m        \u001b[35m4.7904\u001b[0m  1.9856\n",
      "     54        \u001b[36m4.7589\u001b[0m       \u001b[32m0.8613\u001b[0m        \u001b[35m4.7855\u001b[0m  1.9409\n",
      "     55        \u001b[36m4.7501\u001b[0m       \u001b[32m0.8632\u001b[0m        \u001b[35m4.7805\u001b[0m  2.1800\n",
      "     56        \u001b[36m4.7469\u001b[0m       \u001b[32m0.8646\u001b[0m        \u001b[35m4.7756\u001b[0m  1.9666\n",
      "     57        4.7519       \u001b[32m0.8666\u001b[0m        \u001b[35m4.7708\u001b[0m  1.9979\n",
      "     58        \u001b[36m4.7454\u001b[0m       \u001b[32m0.8692\u001b[0m        \u001b[35m4.7659\u001b[0m  1.9734\n",
      "     59        \u001b[36m4.7422\u001b[0m       \u001b[32m0.8709\u001b[0m        \u001b[35m4.7610\u001b[0m  1.9265\n",
      "     60        \u001b[36m4.7395\u001b[0m       \u001b[32m0.8719\u001b[0m        \u001b[35m4.7562\u001b[0m  2.0634\n",
      "     61        \u001b[36m4.7380\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m4.7515\u001b[0m  2.0535\n",
      "     62        \u001b[36m4.7373\u001b[0m       \u001b[32m0.8745\u001b[0m        \u001b[35m4.7469\u001b[0m  2.0166\n",
      "     63        \u001b[36m4.7364\u001b[0m       \u001b[32m0.8772\u001b[0m        \u001b[35m4.7421\u001b[0m  2.0321\n",
      "     64        \u001b[36m4.7303\u001b[0m       \u001b[32m0.8798\u001b[0m        \u001b[35m4.7374\u001b[0m  2.0564\n",
      "     65        \u001b[36m4.7269\u001b[0m       \u001b[32m0.8828\u001b[0m        \u001b[35m4.7328\u001b[0m  1.9626\n",
      "     66        \u001b[36m4.7254\u001b[0m       0.8828        \u001b[35m4.7283\u001b[0m  1.9760\n",
      "     67        4.7287       \u001b[32m0.8851\u001b[0m        \u001b[35m4.7239\u001b[0m  2.0735\n",
      "     68        \u001b[36m4.7209\u001b[0m       \u001b[32m0.8858\u001b[0m        \u001b[35m4.7195\u001b[0m  1.9178\n",
      "     69        \u001b[36m4.7200\u001b[0m       \u001b[32m0.8861\u001b[0m        \u001b[35m4.7151\u001b[0m  2.0795\n",
      "     70        4.7217       \u001b[32m0.8887\u001b[0m        \u001b[35m4.7108\u001b[0m  1.9996\n",
      "     71        \u001b[36m4.7148\u001b[0m       \u001b[32m0.8897\u001b[0m        \u001b[35m4.7063\u001b[0m  1.9454\n",
      "     72        \u001b[36m4.7140\u001b[0m       \u001b[32m0.8911\u001b[0m        \u001b[35m4.7020\u001b[0m  2.0377\n",
      "     73        4.7150       \u001b[32m0.8944\u001b[0m        \u001b[35m4.6978\u001b[0m  1.9182\n",
      "     74        4.7155       0.8944        \u001b[35m4.6937\u001b[0m  1.9832\n",
      "     75        \u001b[36m4.7055\u001b[0m       \u001b[32m0.8954\u001b[0m        \u001b[35m4.6895\u001b[0m  1.9893\n",
      "     76        4.7121       \u001b[32m0.8970\u001b[0m        \u001b[35m4.6853\u001b[0m  1.9193\n",
      "     77        4.7094       \u001b[32m0.8974\u001b[0m        \u001b[35m4.6813\u001b[0m  2.0400\n",
      "     78        4.7116       0.8970        \u001b[35m4.6773\u001b[0m  1.9464\n",
      "     79        4.7072       \u001b[32m0.8987\u001b[0m        \u001b[35m4.6733\u001b[0m  2.0293\n",
      "     80        4.7096       \u001b[32m0.8997\u001b[0m        \u001b[35m4.6694\u001b[0m  1.9817\n",
      "     81        \u001b[36m4.7025\u001b[0m       \u001b[32m0.9007\u001b[0m        \u001b[35m4.6655\u001b[0m  1.9507\n",
      "     82        4.7032       \u001b[32m0.9010\u001b[0m        \u001b[35m4.6616\u001b[0m  2.0354\n",
      "     83        \u001b[36m4.6988\u001b[0m       \u001b[32m0.9020\u001b[0m        \u001b[35m4.6578\u001b[0m  1.9379\n",
      "     84        4.6996       0.9010        \u001b[35m4.6540\u001b[0m  2.0091\n",
      "     85        \u001b[36m4.6927\u001b[0m       0.9020        \u001b[35m4.6501\u001b[0m  1.9562\n",
      "     86        4.6956       \u001b[32m0.9033\u001b[0m        \u001b[35m4.6464\u001b[0m  1.9305\n",
      "     87        4.6960       \u001b[32m0.9040\u001b[0m        \u001b[35m4.6426\u001b[0m  1.9982\n",
      "     88        4.7004       \u001b[32m0.9046\u001b[0m        \u001b[35m4.6390\u001b[0m  1.9306\n",
      "     89        \u001b[36m4.6906\u001b[0m       \u001b[32m0.9056\u001b[0m        \u001b[35m4.6354\u001b[0m  2.0043\n",
      "     90        4.6913       \u001b[32m0.9073\u001b[0m        \u001b[35m4.6318\u001b[0m  1.9438\n",
      "     91        4.6919       \u001b[32m0.9076\u001b[0m        \u001b[35m4.6282\u001b[0m  1.9466\n",
      "     92        \u001b[36m4.6893\u001b[0m       \u001b[32m0.9079\u001b[0m        \u001b[35m4.6246\u001b[0m  1.9985\n",
      "     93        \u001b[36m4.6835\u001b[0m       \u001b[32m0.9086\u001b[0m        \u001b[35m4.6211\u001b[0m  1.9211\n",
      "     94        4.6857       0.9086        \u001b[35m4.6177\u001b[0m  2.0012\n",
      "     95        4.6905       0.9086        \u001b[35m4.6143\u001b[0m  1.9630\n",
      "     96        \u001b[36m4.6813\u001b[0m       \u001b[32m0.9089\u001b[0m        \u001b[35m4.6110\u001b[0m  1.9824\n",
      "     97        \u001b[36m4.6803\u001b[0m       0.9089        \u001b[35m4.6077\u001b[0m  1.9779\n",
      "     98        4.6815       \u001b[32m0.9103\u001b[0m        \u001b[35m4.6043\u001b[0m  1.9054\n",
      "     99        4.6865       \u001b[32m0.9106\u001b[0m        \u001b[35m4.6011\u001b[0m  2.0074\n",
      "    100        \u001b[36m4.6787\u001b[0m       \u001b[32m0.9126\u001b[0m        \u001b[35m4.5979\u001b[0m  1.9509\n",
      "    101        \u001b[36m4.6771\u001b[0m       0.9116        \u001b[35m4.5947\u001b[0m  1.9698\n",
      "    102        4.6773       0.9113        \u001b[35m4.5916\u001b[0m  1.9456\n",
      "    103        4.6897       0.9119        \u001b[35m4.5886\u001b[0m  1.9163\n",
      "    104        \u001b[36m4.6715\u001b[0m       0.9119        \u001b[35m4.5855\u001b[0m  2.0057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    105        4.6747       0.9119        \u001b[35m4.5822\u001b[0m  1.9365\n",
      "    106        \u001b[36m4.6713\u001b[0m       0.9123        \u001b[35m4.5792\u001b[0m  1.9616\n",
      "    107        4.6737       0.9119        \u001b[35m4.5762\u001b[0m  1.9758\n",
      "    108        \u001b[36m4.6696\u001b[0m       \u001b[32m0.9129\u001b[0m        \u001b[35m4.5732\u001b[0m  1.9211\n",
      "    109        \u001b[36m4.6639\u001b[0m       \u001b[32m0.9132\u001b[0m        \u001b[35m4.5702\u001b[0m  2.0008\n",
      "    110        4.6680       0.9119        \u001b[35m4.5672\u001b[0m  1.9327\n",
      "    111        4.6708       \u001b[32m0.9139\u001b[0m        \u001b[35m4.5643\u001b[0m  2.0023\n",
      "    112        4.6641       \u001b[32m0.9152\u001b[0m        \u001b[35m4.5614\u001b[0m  1.9845\n",
      "    113        4.6700       \u001b[32m0.9159\u001b[0m        \u001b[35m4.5586\u001b[0m  1.9386\n",
      "    114        4.6723       0.9159        \u001b[35m4.5559\u001b[0m  2.0182\n",
      "    115        4.6693       \u001b[32m0.9166\u001b[0m        \u001b[35m4.5530\u001b[0m  1.8936\n",
      "    116        \u001b[36m4.6619\u001b[0m       \u001b[32m0.9172\u001b[0m        \u001b[35m4.5503\u001b[0m  1.9841\n",
      "    117        4.6667       \u001b[32m0.9175\u001b[0m        \u001b[35m4.5476\u001b[0m  1.9503\n",
      "    118        4.6642       \u001b[32m0.9179\u001b[0m        \u001b[35m4.5448\u001b[0m  1.9137\n",
      "    119        4.6679       \u001b[32m0.9182\u001b[0m        \u001b[35m4.5420\u001b[0m  2.0155\n",
      "    120        \u001b[36m4.6600\u001b[0m       0.9172        \u001b[35m4.5393\u001b[0m  1.9281\n",
      "    121        4.6625       \u001b[32m0.9185\u001b[0m        \u001b[35m4.5367\u001b[0m  1.9686\n",
      "    122        \u001b[36m4.6565\u001b[0m       0.9182        \u001b[35m4.5341\u001b[0m  1.9234\n",
      "    123        4.6619       0.9185        \u001b[35m4.5315\u001b[0m  1.9098\n",
      "    124        4.6583       \u001b[32m0.9192\u001b[0m        \u001b[35m4.5290\u001b[0m  2.0153\n",
      "    125        \u001b[36m4.6556\u001b[0m       0.9189        \u001b[35m4.5265\u001b[0m  1.9643\n",
      "    126        4.6598       0.9192        \u001b[35m4.5241\u001b[0m  1.9898\n",
      "    127        4.6573       0.9189        \u001b[35m4.5216\u001b[0m  1.9526\n",
      "    128        4.6623       \u001b[32m0.9195\u001b[0m        \u001b[35m4.5191\u001b[0m  1.9314\n",
      "    129        4.6576       0.9189        \u001b[35m4.5168\u001b[0m  2.0199\n",
      "    130        4.6564       0.9182        \u001b[35m4.5145\u001b[0m  1.8892\n",
      "    131        \u001b[36m4.6513\u001b[0m       0.9182        \u001b[35m4.5121\u001b[0m  1.9952\n",
      "    132        4.6585       0.9182        \u001b[35m4.5097\u001b[0m  1.9193\n",
      "    133        \u001b[36m4.6505\u001b[0m       0.9185        \u001b[35m4.5074\u001b[0m  1.9064\n",
      "    134        \u001b[36m4.6468\u001b[0m       0.9185        \u001b[35m4.5051\u001b[0m  2.1437\n",
      "    135        4.6507       0.9192        \u001b[35m4.5029\u001b[0m  1.7986\n",
      "    136        4.6548       0.9195        \u001b[35m4.5006\u001b[0m  2.0527\n",
      "    137        \u001b[36m4.6443\u001b[0m       \u001b[32m0.9199\u001b[0m        \u001b[35m4.4984\u001b[0m  1.9628\n",
      "    138        4.6579       \u001b[32m0.9205\u001b[0m        \u001b[35m4.4961\u001b[0m  2.0313\n",
      "    139        4.6478       0.9199        \u001b[35m4.4940\u001b[0m  1.9678\n",
      "    140        4.6453       0.9192        \u001b[35m4.4918\u001b[0m  1.9454\n",
      "    141        4.6448       0.9199        \u001b[35m4.4896\u001b[0m  2.0263\n",
      "    142        4.6444       0.9192        \u001b[35m4.4874\u001b[0m  1.9601\n",
      "    143        \u001b[36m4.6412\u001b[0m       0.9205        \u001b[35m4.4854\u001b[0m  1.9387\n",
      "    144        4.6446       0.9192        \u001b[35m4.4832\u001b[0m  1.8999\n",
      "    145        4.6449       0.9199        \u001b[35m4.4811\u001b[0m  1.9151\n",
      "    146        4.6436       0.9192        \u001b[35m4.4791\u001b[0m  1.9881\n",
      "    147        \u001b[36m4.6400\u001b[0m       0.9199        \u001b[35m4.4769\u001b[0m  1.9327\n",
      "    148        4.6434       0.9205        \u001b[35m4.4749\u001b[0m  1.9918\n",
      "    149        4.6433       0.9199        \u001b[35m4.4730\u001b[0m  1.9213\n",
      "    150        4.6498       0.9202        \u001b[35m4.4711\u001b[0m  1.9188\n",
      "    151        4.6412       0.9199        \u001b[35m4.4692\u001b[0m  2.0064\n",
      "    152        4.6426       0.9202        \u001b[35m4.4672\u001b[0m  1.9202\n",
      "    153        4.6427       0.9195        \u001b[35m4.4654\u001b[0m  2.0036\n",
      "    154        \u001b[36m4.6385\u001b[0m       0.9189        \u001b[35m4.4635\u001b[0m  1.9079\n",
      "    155        \u001b[36m4.6367\u001b[0m       0.9199        \u001b[35m4.4616\u001b[0m  1.9251\n",
      "    156        4.6400       0.9202        \u001b[35m4.4598\u001b[0m  1.9802\n",
      "    157        4.6380       0.9202        \u001b[35m4.4580\u001b[0m  1.9351\n",
      "    158        \u001b[36m4.6342\u001b[0m       \u001b[32m0.9209\u001b[0m        \u001b[35m4.4563\u001b[0m  1.9990\n",
      "    159        \u001b[36m4.6321\u001b[0m       0.9205        \u001b[35m4.4545\u001b[0m  1.9283\n",
      "    160        4.6331       \u001b[32m0.9219\u001b[0m        \u001b[35m4.4526\u001b[0m  1.9199\n",
      "    161        4.6324       0.9212        \u001b[35m4.4508\u001b[0m  1.9419\n",
      "    162        4.6404       \u001b[32m0.9222\u001b[0m        \u001b[35m4.4491\u001b[0m  1.9168\n",
      "    163        \u001b[36m4.6294\u001b[0m       \u001b[32m0.9225\u001b[0m        \u001b[35m4.4473\u001b[0m  1.9940\n",
      "    164        4.6350       0.9222        \u001b[35m4.4456\u001b[0m  1.9077\n",
      "    165        4.6294       0.9222        \u001b[35m4.4438\u001b[0m  1.9577\n",
      "    166        4.6356       0.9215        \u001b[35m4.4422\u001b[0m  1.9333\n",
      "    167        4.6398       0.9219        \u001b[35m4.4406\u001b[0m  1.9168\n",
      "    168        4.6301       0.9219        \u001b[35m4.4390\u001b[0m  1.9903\n",
      "    169        4.6348       0.9219        \u001b[35m4.4375\u001b[0m  1.8933\n",
      "    170        \u001b[36m4.6285\u001b[0m       0.9219        \u001b[35m4.4358\u001b[0m  1.9811\n",
      "    171        4.6316       0.9215        \u001b[35m4.4342\u001b[0m  1.9339\n",
      "    172        4.6329       0.9215        \u001b[35m4.4328\u001b[0m  1.9149\n",
      "    173        4.6332       0.9222        \u001b[35m4.4311\u001b[0m  2.0002\n",
      "    174        4.6289       0.9215        \u001b[35m4.4296\u001b[0m  1.8944\n",
      "    175        \u001b[36m4.6271\u001b[0m       0.9209        \u001b[35m4.4279\u001b[0m  1.9672\n",
      "    176        \u001b[36m4.6263\u001b[0m       0.9199        \u001b[35m4.4264\u001b[0m  1.9297\n",
      "    177        4.6314       0.9205        \u001b[35m4.4249\u001b[0m  1.9162\n",
      "    178        4.6313       0.9209        \u001b[35m4.4234\u001b[0m  1.9753\n",
      "    179        4.6275       0.9202        \u001b[35m4.4219\u001b[0m  1.8967\n",
      "    180        4.6266       0.9222        \u001b[35m4.4204\u001b[0m  1.9810\n",
      "    181        4.6266       0.9215        \u001b[35m4.4190\u001b[0m  1.9366\n",
      "    182        4.6272       0.9219        \u001b[35m4.4176\u001b[0m  1.9108\n",
      "    183        4.6298       0.9225        \u001b[35m4.4162\u001b[0m  1.9647\n",
      "    184        \u001b[36m4.6214\u001b[0m       0.9225        \u001b[35m4.4146\u001b[0m  1.9546\n",
      "    185        4.6234       \u001b[32m0.9228\u001b[0m        \u001b[35m4.4132\u001b[0m  1.9172\n",
      "    186        4.6240       0.9228        \u001b[35m4.4118\u001b[0m  1.9391\n",
      "    187        4.6310       0.9219        \u001b[35m4.4105\u001b[0m  1.9111\n",
      "    188        4.6299       0.9225        \u001b[35m4.4092\u001b[0m  2.0214\n",
      "    189        4.6242       0.9225        \u001b[35m4.4078\u001b[0m  1.9211\n",
      "    190        \u001b[36m4.6194\u001b[0m       0.9215        \u001b[35m4.4064\u001b[0m  2.0022\n",
      "    191        4.6246       0.9219        \u001b[35m4.4051\u001b[0m  1.8956\n",
      "    192        4.6279       0.9228        \u001b[35m4.4037\u001b[0m  1.9598\n",
      "    193        4.6230       \u001b[32m0.9232\u001b[0m        \u001b[35m4.4023\u001b[0m  1.9324\n",
      "    194        4.6237       0.9225        \u001b[35m4.4011\u001b[0m  1.9129\n",
      "    195        \u001b[36m4.6179\u001b[0m       0.9228        \u001b[35m4.3997\u001b[0m  1.9794\n",
      "    196        4.6216       0.9219        \u001b[35m4.3984\u001b[0m  1.9363\n",
      "    197        4.6199       \u001b[32m0.9242\u001b[0m        \u001b[35m4.3972\u001b[0m  1.9889\n",
      "    198        4.6233       \u001b[32m0.9248\u001b[0m        \u001b[35m4.3960\u001b[0m  1.9081\n",
      "    199        4.6245       0.9242        \u001b[35m4.3947\u001b[0m  1.9178\n",
      "    200        4.6192       0.9228        \u001b[35m4.3936\u001b[0m  1.9703\n",
      "    201        \u001b[36m4.6155\u001b[0m       0.9232        \u001b[35m4.3924\u001b[0m  1.9154\n",
      "    202        4.6231       0.9222        \u001b[35m4.3912\u001b[0m  1.9947\n",
      "    203        4.6256       0.9222        \u001b[35m4.3901\u001b[0m  1.9278\n",
      "    204        4.6220       0.9222        \u001b[35m4.3889\u001b[0m  1.9468\n",
      "    205        4.6184       0.9222        \u001b[35m4.3877\u001b[0m  1.9319\n",
      "    206        4.6181       0.9228        \u001b[35m4.3866\u001b[0m  1.9100\n",
      "    207        4.6182       0.9222        \u001b[35m4.3854\u001b[0m  1.9616\n",
      "    208        4.6186       0.9219        \u001b[35m4.3843\u001b[0m  1.9966\n",
      "    209        4.6221       0.9219        \u001b[35m4.3831\u001b[0m  1.9521\n",
      "    210        4.6182       0.9222        \u001b[35m4.3820\u001b[0m  1.9447\n",
      "    211        \u001b[36m4.6115\u001b[0m       0.9212        \u001b[35m4.3808\u001b[0m  1.9181\n",
      "    212        4.6165       0.9212        \u001b[35m4.3796\u001b[0m  2.0257\n",
      "    213        4.6123       0.9219        \u001b[35m4.3785\u001b[0m  1.9275\n",
      "    214        4.6126       0.9219        \u001b[35m4.3773\u001b[0m  1.9419\n",
      "    215        4.6212       0.9215        \u001b[35m4.3762\u001b[0m  1.9241\n",
      "    216        4.6120       0.9212        \u001b[35m4.3753\u001b[0m  1.9188\n",
      "    217        \u001b[36m4.6105\u001b[0m       0.9209        \u001b[35m4.3742\u001b[0m  1.9916\n",
      "    218        4.6199       0.9222        \u001b[35m4.3731\u001b[0m  1.9040\n",
      "    219        4.6173       0.9215        \u001b[35m4.3721\u001b[0m  2.0032\n",
      "    220        4.6165       0.9219        \u001b[35m4.3711\u001b[0m  1.9396\n",
      "    221        4.6148       0.9219        \u001b[35m4.3700\u001b[0m  1.9478\n",
      "    222        4.6112       0.9232        \u001b[35m4.3690\u001b[0m  1.9303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    223        4.6185       0.9232        \u001b[35m4.3681\u001b[0m  1.9079\n",
      "    224        4.6150       0.9232        \u001b[35m4.3671\u001b[0m  1.9789\n",
      "    225        \u001b[36m4.6104\u001b[0m       0.9228        \u001b[35m4.3660\u001b[0m  1.8879\n",
      "    226        4.6162       0.9225        \u001b[35m4.3651\u001b[0m  1.9451\n",
      "    227        4.6165       0.9228        \u001b[35m4.3641\u001b[0m  1.9179\n",
      "    228        4.6155       0.9225        \u001b[35m4.3631\u001b[0m  1.8972\n",
      "    229        4.6110       0.9219        \u001b[35m4.3621\u001b[0m  1.9866\n",
      "    230        \u001b[36m4.6103\u001b[0m       0.9232        \u001b[35m4.3610\u001b[0m  1.8940\n",
      "    231        \u001b[36m4.6074\u001b[0m       0.9228        \u001b[35m4.3600\u001b[0m  1.9889\n",
      "    232        4.6135       0.9225        \u001b[35m4.3591\u001b[0m  1.9388\n",
      "    233        4.6092       0.9232        \u001b[35m4.3581\u001b[0m  1.9166\n",
      "    234        4.6081       0.9222        \u001b[35m4.3573\u001b[0m  1.9517\n",
      "    235        4.6082       0.9222        \u001b[35m4.3564\u001b[0m  1.9081\n",
      "    236        4.6099       0.9209        \u001b[35m4.3555\u001b[0m  1.9884\n",
      "    237        4.6119       0.9215        \u001b[35m4.3547\u001b[0m  1.9124\n",
      "    238        4.6111       0.9215        \u001b[35m4.3538\u001b[0m  1.9046\n",
      "    239        4.6120       0.9225        \u001b[35m4.3529\u001b[0m  1.9184\n",
      "    240        4.6083       0.9225        \u001b[35m4.3520\u001b[0m  1.8997\n",
      "    241        4.6149       0.9225        \u001b[35m4.3511\u001b[0m  1.9901\n",
      "    242        4.6078       0.9228        \u001b[35m4.3502\u001b[0m  1.9217\n",
      "    243        \u001b[36m4.6043\u001b[0m       0.9228        \u001b[35m4.3493\u001b[0m  1.9744\n",
      "    244        4.6070       0.9225        \u001b[35m4.3485\u001b[0m  1.9207\n",
      "    245        4.6075       0.9222        \u001b[35m4.3477\u001b[0m  1.9087\n",
      "    246        4.6046       0.9219        \u001b[35m4.3468\u001b[0m  1.9967\n",
      "    247        4.6088       0.9222        \u001b[35m4.3459\u001b[0m  1.8951\n",
      "    248        \u001b[36m4.6015\u001b[0m       0.9225        \u001b[35m4.3451\u001b[0m  1.9462\n",
      "    249        4.6081       0.9225        \u001b[35m4.3443\u001b[0m  1.9196\n",
      "    250        4.6048       0.9222        \u001b[35m4.3435\u001b[0m  1.9148\n",
      "    251        4.6098       0.9215        \u001b[35m4.3428\u001b[0m  1.9918\n",
      "    252        4.6038       0.9215        \u001b[35m4.3420\u001b[0m  1.8995\n",
      "    253        4.6106       0.9209        \u001b[35m4.3411\u001b[0m  1.9746\n",
      "    254        4.6096       0.9215        \u001b[35m4.3403\u001b[0m  1.9424\n",
      "    255        4.6024       0.9228        \u001b[35m4.3394\u001b[0m  1.9780\n",
      "    256        4.6114       0.9232        \u001b[35m4.3387\u001b[0m  1.8769\n",
      "    257        4.6055       0.9232        \u001b[35m4.3379\u001b[0m  1.7636\n",
      "    258        4.6091       0.9228        \u001b[35m4.3371\u001b[0m  1.9224\n",
      "    259        \u001b[36m4.6013\u001b[0m       0.9228        \u001b[35m4.3364\u001b[0m  1.8668\n",
      "    260        4.6015       0.9225        \u001b[35m4.3356\u001b[0m  1.9722\n",
      "    261        \u001b[36m4.5987\u001b[0m       0.9225        \u001b[35m4.3348\u001b[0m  1.9260\n",
      "    262        4.6055       0.9228        \u001b[35m4.3340\u001b[0m  1.9111\n",
      "    263        4.6065       0.9232        \u001b[35m4.3333\u001b[0m  1.9796\n",
      "    264        4.6017       0.9235        \u001b[35m4.3327\u001b[0m  1.9247\n",
      "    265        4.6054       0.9235        \u001b[35m4.3320\u001b[0m  1.9832\n",
      "    266        4.6049       0.9235        \u001b[35m4.3313\u001b[0m  1.9160\n",
      "    267        4.6114       0.9228        \u001b[35m4.3307\u001b[0m  1.9345\n",
      "    268        4.6056       0.9232        \u001b[35m4.3300\u001b[0m  1.9482\n",
      "    269        \u001b[36m4.5979\u001b[0m       0.9232        \u001b[35m4.3292\u001b[0m  1.9055\n",
      "    270        4.6023       0.9228        \u001b[35m4.3286\u001b[0m  1.9841\n",
      "    271        4.6040       0.9228        \u001b[35m4.3279\u001b[0m  1.9338\n",
      "    272        4.5981       0.9232        \u001b[35m4.3271\u001b[0m  1.9889\n",
      "    273        \u001b[36m4.5960\u001b[0m       0.9228        \u001b[35m4.3265\u001b[0m  1.9142\n",
      "    274        4.6005       0.9232        \u001b[35m4.3258\u001b[0m  1.8829\n",
      "    275        4.6058       0.9232        \u001b[35m4.3251\u001b[0m  1.9958\n",
      "    276        4.5966       0.9228        \u001b[35m4.3245\u001b[0m  1.8891\n",
      "    277        4.5992       0.9232        \u001b[35m4.3238\u001b[0m  1.9659\n",
      "    278        4.5976       0.9232        \u001b[35m4.3231\u001b[0m  1.9060\n",
      "    279        4.6015       0.9228        \u001b[35m4.3225\u001b[0m  1.9113\n",
      "    280        4.5968       0.9232        \u001b[35m4.3218\u001b[0m  1.9745\n",
      "    281        4.5981       0.9238        \u001b[35m4.3211\u001b[0m  1.9206\n",
      "    282        4.6060       0.9242        \u001b[35m4.3205\u001b[0m  2.0053\n",
      "    283        4.5977       \u001b[32m0.9252\u001b[0m        \u001b[35m4.3199\u001b[0m  2.0254\n",
      "    284        \u001b[36m4.5959\u001b[0m       0.9245        \u001b[35m4.3192\u001b[0m  1.9513\n",
      "    285        4.6063       0.9245        \u001b[35m4.3187\u001b[0m  1.9118\n",
      "    286        \u001b[36m4.5943\u001b[0m       0.9252        \u001b[35m4.3181\u001b[0m  1.9248\n",
      "    287        4.5984       0.9245        \u001b[35m4.3175\u001b[0m  1.9981\n",
      "    288        4.5985       0.9248        \u001b[35m4.3168\u001b[0m  1.9167\n",
      "    289        4.5952       0.9252        \u001b[35m4.3162\u001b[0m  1.9686\n",
      "    290        4.5956       \u001b[32m0.9255\u001b[0m        \u001b[35m4.3156\u001b[0m  1.9486\n",
      "    291        4.6012       0.9248        \u001b[35m4.3149\u001b[0m  1.9312\n",
      "    292        \u001b[36m4.5943\u001b[0m       0.9245        \u001b[35m4.3143\u001b[0m  1.9510\n",
      "    293        4.5999       0.9252        \u001b[35m4.3137\u001b[0m  1.9101\n",
      "    294        4.5964       0.9255        \u001b[35m4.3131\u001b[0m  1.9918\n",
      "    295        \u001b[36m4.5940\u001b[0m       0.9235        \u001b[35m4.3124\u001b[0m  1.9779\n",
      "    296        \u001b[36m4.5933\u001b[0m       0.9238        \u001b[35m4.3119\u001b[0m  2.0473\n",
      "    297        4.5980       0.9245        \u001b[35m4.3112\u001b[0m  1.9700\n",
      "    298        4.5951       0.9242        \u001b[35m4.3106\u001b[0m  2.0040\n",
      "    299        4.5977       0.9245        \u001b[35m4.3101\u001b[0m  1.9297\n",
      "    300        4.5951       0.9255        \u001b[35m4.3094\u001b[0m  1.8755\n",
      "    301        4.5939       0.9252        \u001b[35m4.3088\u001b[0m  1.9839\n",
      "    302        \u001b[36m4.5916\u001b[0m       0.9255        \u001b[35m4.3083\u001b[0m  1.8941\n",
      "    303        4.5965       0.9238        \u001b[35m4.3077\u001b[0m  1.9672\n",
      "    304        4.5995       0.9235        \u001b[35m4.3072\u001b[0m  1.9195\n",
      "    305        4.5975       0.9235        \u001b[35m4.3066\u001b[0m  1.9630\n",
      "    306        \u001b[36m4.5916\u001b[0m       0.9238        \u001b[35m4.3061\u001b[0m  1.9647\n",
      "    307        4.5923       0.9242        \u001b[35m4.3055\u001b[0m  1.9085\n",
      "    308        4.5966       0.9245        \u001b[35m4.3050\u001b[0m  2.0179\n",
      "    309        4.5966       0.9245        \u001b[35m4.3045\u001b[0m  1.9072\n",
      "    310        4.5939       0.9245        \u001b[35m4.3040\u001b[0m  2.0497\n",
      "    311        \u001b[36m4.5864\u001b[0m       0.9245        \u001b[35m4.3035\u001b[0m  1.8902\n",
      "    312        4.5943       0.9245        \u001b[35m4.3029\u001b[0m  1.9460\n",
      "    313        4.5911       0.9238        \u001b[35m4.3023\u001b[0m  2.1087\n",
      "    314        4.5915       0.9242        \u001b[35m4.3018\u001b[0m  1.9454\n",
      "    315        4.5871       0.9242        \u001b[35m4.3012\u001b[0m  2.0693\n",
      "    316        4.5944       0.9235        \u001b[35m4.3007\u001b[0m  1.9252\n",
      "    317        4.5944       0.9222        \u001b[35m4.3001\u001b[0m  1.9763\n",
      "    318        4.5887       0.9232        \u001b[35m4.2996\u001b[0m  1.9341\n",
      "    319        4.5912       0.9222        \u001b[35m4.2989\u001b[0m  1.8884\n",
      "    320        4.5902       0.9225        \u001b[35m4.2984\u001b[0m  2.0103\n",
      "    321        4.5960       0.9235        \u001b[35m4.2979\u001b[0m  1.9138\n",
      "    322        4.5939       0.9232        \u001b[35m4.2974\u001b[0m  2.0072\n",
      "    323        4.5926       0.9235        \u001b[35m4.2970\u001b[0m  1.9178\n",
      "    324        4.5923       0.9232        \u001b[35m4.2964\u001b[0m  1.9176\n",
      "    325        4.5972       0.9235        \u001b[35m4.2959\u001b[0m  1.9364\n",
      "    326        4.5902       0.9232        \u001b[35m4.2954\u001b[0m  1.9883\n",
      "    327        4.5920       0.9235        \u001b[35m4.2949\u001b[0m  1.9609\n",
      "    328        4.5910       0.9242        \u001b[35m4.2944\u001b[0m  1.9570\n",
      "    329        4.5915       0.9248        \u001b[35m4.2940\u001b[0m  2.0085\n",
      "    330        4.5979       0.9248        \u001b[35m4.2935\u001b[0m  1.9179\n",
      "    331        4.5931       0.9252        \u001b[35m4.2930\u001b[0m  1.9476\n",
      "    332        4.5901       0.9245        \u001b[35m4.2925\u001b[0m  2.0213\n",
      "    333        4.5901       0.9245        \u001b[35m4.2920\u001b[0m  1.8831\n",
      "    334        4.5958       0.9245        \u001b[35m4.2916\u001b[0m  2.0674\n",
      "    335        4.5919       0.9242        \u001b[35m4.2912\u001b[0m  1.9095\n",
      "    336        4.5959       0.9248        \u001b[35m4.2908\u001b[0m  2.0540\n",
      "    337        4.5931       0.9252        \u001b[35m4.2904\u001b[0m  1.9135\n",
      "    338        \u001b[36m4.5856\u001b[0m       0.9242        \u001b[35m4.2899\u001b[0m  1.9141\n",
      "    339        \u001b[36m4.5847\u001b[0m       0.9232        \u001b[35m4.2894\u001b[0m  1.9816\n",
      "    340        4.5896       0.9238        \u001b[35m4.2891\u001b[0m  1.9139\n",
      "    341        4.5936       0.9235        \u001b[35m4.2886\u001b[0m  1.9916\n",
      "    342        \u001b[36m4.5829\u001b[0m       0.9242        \u001b[35m4.2881\u001b[0m  1.9234\n",
      "    343        4.5922       0.9238        \u001b[35m4.2877\u001b[0m  1.9867\n",
      "    344        4.5901       0.9242        \u001b[35m4.2871\u001b[0m  1.9402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    345        4.5854       0.9238        \u001b[35m4.2866\u001b[0m  1.9363\n",
      "    346        4.5838       0.9238        \u001b[35m4.2862\u001b[0m  1.9697\n",
      "    347        4.5884       0.9235        \u001b[35m4.2856\u001b[0m  1.9723\n",
      "    348        4.5909       0.9238        \u001b[35m4.2852\u001b[0m  1.9383\n",
      "    349        4.5937       0.9235        \u001b[35m4.2847\u001b[0m  1.9347\n",
      "    350        4.5853       0.9238        \u001b[35m4.2844\u001b[0m  1.9175\n",
      "    351        4.5903       0.9235        \u001b[35m4.2840\u001b[0m  1.9637\n",
      "    352        4.5903       0.9238        \u001b[35m4.2836\u001b[0m  1.9461\n",
      "    353        4.5904       0.9235        \u001b[35m4.2832\u001b[0m  1.9950\n",
      "    354        \u001b[36m4.5827\u001b[0m       0.9238        \u001b[35m4.2828\u001b[0m  2.0293\n",
      "    355        \u001b[36m4.5806\u001b[0m       0.9248        \u001b[35m4.2824\u001b[0m  2.0513\n",
      "    356        4.5840       0.9225        \u001b[35m4.2820\u001b[0m  2.0689\n",
      "    357        4.5809       0.9235        \u001b[35m4.2815\u001b[0m  1.9933\n",
      "    358        4.5831       0.9235        \u001b[35m4.2812\u001b[0m  1.9473\n",
      "    359        4.5836       0.9235        \u001b[35m4.2808\u001b[0m  1.9251\n",
      "    360        4.5927       0.9235        \u001b[35m4.2805\u001b[0m  1.9586\n",
      "    361        4.5851       0.9235        \u001b[35m4.2801\u001b[0m  1.9263\n",
      "    362        \u001b[36m4.5802\u001b[0m       0.9242        \u001b[35m4.2797\u001b[0m  1.9475\n",
      "    363        4.5872       0.9238        \u001b[35m4.2793\u001b[0m  1.9098\n",
      "    364        4.5907       0.9232        \u001b[35m4.2790\u001b[0m  1.9199\n",
      "    365        4.5885       0.9232        \u001b[35m4.2786\u001b[0m  1.9932\n",
      "    366        4.5898       0.9232        \u001b[35m4.2783\u001b[0m  2.0100\n",
      "    367        4.5854       0.9242        \u001b[35m4.2778\u001b[0m  1.9616\n",
      "    368        \u001b[36m4.5787\u001b[0m       0.9245        \u001b[35m4.2774\u001b[0m  1.9627\n",
      "    369        4.5876       0.9242        \u001b[35m4.2770\u001b[0m  2.0551\n",
      "    370        4.5798       0.9232        \u001b[35m4.2767\u001b[0m  1.9365\n",
      "    371        4.5830       0.9225        \u001b[35m4.2763\u001b[0m  2.0665\n",
      "    372        4.5868       0.9225        \u001b[35m4.2760\u001b[0m  1.9016\n",
      "    373        4.5865       0.9215        \u001b[35m4.2756\u001b[0m  1.9578\n",
      "    374        4.5851       0.9209        \u001b[35m4.2752\u001b[0m  1.9639\n",
      "    375        4.5863       0.9212        \u001b[35m4.2749\u001b[0m  1.9140\n",
      "    376        4.5900       0.9212        \u001b[35m4.2745\u001b[0m  2.0066\n",
      "    377        4.5863       0.9222        \u001b[35m4.2741\u001b[0m  1.9295\n",
      "    378        4.5854       0.9219        \u001b[35m4.2737\u001b[0m  2.0030\n",
      "    379        4.5794       0.9219        \u001b[35m4.2733\u001b[0m  1.9365\n",
      "    380        4.5843       0.9209        \u001b[35m4.2729\u001b[0m  1.9517\n",
      "    381        4.5808       0.9209        \u001b[35m4.2726\u001b[0m  1.9380\n",
      "    382        4.5797       0.9215        \u001b[35m4.2722\u001b[0m  1.9345\n",
      "    383        4.5865       0.9215        \u001b[35m4.2719\u001b[0m  2.0145\n",
      "    384        4.5874       0.9225        \u001b[35m4.2715\u001b[0m  1.9291\n",
      "    385        4.5815       0.9222        \u001b[35m4.2713\u001b[0m  2.0193\n",
      "    386        4.5876       0.9219        \u001b[35m4.2709\u001b[0m  1.9001\n",
      "    387        4.5833       0.9225        \u001b[35m4.2705\u001b[0m  1.9373\n",
      "    388        4.5820       0.9235        \u001b[35m4.2701\u001b[0m  1.9305\n",
      "    389        4.5816       0.9235        \u001b[35m4.2697\u001b[0m  1.9058\n",
      "    390        4.5869       0.9232        \u001b[35m4.2694\u001b[0m  1.9848\n",
      "    391        4.5814       0.9232        \u001b[35m4.2691\u001b[0m  1.9266\n",
      "    392        4.5882       0.9225        \u001b[35m4.2686\u001b[0m  1.9343\n",
      "    393        4.5802       0.9232        \u001b[35m4.2684\u001b[0m  1.9308\n",
      "    394        4.5823       0.9228        \u001b[35m4.2680\u001b[0m  1.9299\n",
      "    395        4.5847       0.9225        \u001b[35m4.2677\u001b[0m  1.9842\n",
      "    396        \u001b[36m4.5698\u001b[0m       0.9225        \u001b[35m4.2674\u001b[0m  1.9273\n",
      "    397        4.5813       0.9228        \u001b[35m4.2671\u001b[0m  1.9949\n",
      "    398        4.5841       0.9225        \u001b[35m4.2667\u001b[0m  1.9058\n",
      "    399        4.5797       0.9225        \u001b[35m4.2664\u001b[0m  2.0092\n",
      "    400        4.5823       0.9232        \u001b[35m4.2661\u001b[0m  1.9181\n",
      "    401        4.5873       0.9228        \u001b[35m4.2658\u001b[0m  1.9629\n",
      "    402        4.5795       0.9232        \u001b[35m4.2655\u001b[0m  1.9175\n",
      "    403        4.5847       0.9235        \u001b[35m4.2651\u001b[0m  1.9093\n",
      "    404        4.5807       0.9232        \u001b[35m4.2648\u001b[0m  1.9757\n",
      "    405        4.5845       0.9228        \u001b[35m4.2644\u001b[0m  1.8943\n",
      "    406        4.5893       0.9232        \u001b[35m4.2641\u001b[0m  1.9231\n",
      "    407        4.5773       0.9228        \u001b[35m4.2638\u001b[0m  1.8943\n",
      "    408        4.5733       0.9222        \u001b[35m4.2634\u001b[0m  1.8994\n",
      "    409        4.5775       0.9219        \u001b[35m4.2632\u001b[0m  1.9225\n",
      "    410        4.5843       0.9222        \u001b[35m4.2630\u001b[0m  1.8985\n",
      "    411        4.5853       0.9225        \u001b[35m4.2628\u001b[0m  1.9891\n",
      "    412        4.5783       0.9228        \u001b[35m4.2623\u001b[0m  1.9268\n",
      "    413        4.5754       0.9225        \u001b[35m4.2621\u001b[0m  1.9357\n",
      "    414        4.5838       0.9222        \u001b[35m4.2617\u001b[0m  1.9277\n",
      "    415        4.5792       0.9222        \u001b[35m4.2614\u001b[0m  1.8970\n",
      "    416        4.5815       0.9215        \u001b[35m4.2612\u001b[0m  1.9755\n",
      "    417        4.5806       0.9219        \u001b[35m4.2608\u001b[0m  1.9258\n",
      "    418        4.5802       0.9215        \u001b[35m4.2605\u001b[0m  1.9785\n",
      "    419        4.5863       0.9219        \u001b[35m4.2602\u001b[0m  1.9187\n",
      "    420        4.5846       0.9225        \u001b[35m4.2599\u001b[0m  1.9864\n",
      "    421        4.5784       0.9222        \u001b[35m4.2596\u001b[0m  1.8269\n",
      "    422        4.5775       0.9215        \u001b[35m4.2592\u001b[0m  1.9394\n",
      "    423        4.5768       0.9215        \u001b[35m4.2590\u001b[0m  1.9405\n",
      "    424        4.5841       0.9209        \u001b[35m4.2588\u001b[0m  1.9425\n",
      "    425        4.5796       0.9222        \u001b[35m4.2585\u001b[0m  2.0560\n",
      "    426        4.5767       0.9215        \u001b[35m4.2580\u001b[0m  1.9390\n",
      "    427        4.5770       0.9212        \u001b[35m4.2578\u001b[0m  1.9924\n",
      "    428        4.5822       0.9215        \u001b[35m4.2575\u001b[0m  1.9007\n",
      "    429        4.5836       0.9222        \u001b[35m4.2573\u001b[0m  1.9646\n",
      "    430        4.5805       0.9219        \u001b[35m4.2569\u001b[0m  1.9976\n",
      "    431        4.5810       0.9222        \u001b[35m4.2566\u001b[0m  1.8979\n",
      "    432        4.5827       0.9219        \u001b[35m4.2564\u001b[0m  1.9518\n",
      "    433        4.5818       0.9215        \u001b[35m4.2562\u001b[0m  1.9335\n",
      "    434        4.5815       0.9215        \u001b[35m4.2559\u001b[0m  1.9929\n",
      "    435        4.5775       0.9219        \u001b[35m4.2557\u001b[0m  1.9214\n",
      "    436        4.5740       0.9219        \u001b[35m4.2554\u001b[0m  1.9665\n",
      "    437        4.5791       0.9212        \u001b[35m4.2550\u001b[0m  1.9382\n",
      "    438        4.5760       0.9215        \u001b[35m4.2547\u001b[0m  1.9453\n",
      "    439        4.5810       0.9209        \u001b[35m4.2545\u001b[0m  1.9491\n",
      "    440        4.5817       0.9209        \u001b[35m4.2543\u001b[0m  1.9636\n",
      "    441        4.5750       0.9205        \u001b[35m4.2540\u001b[0m  1.9364\n",
      "    442        4.5859       0.9202        \u001b[35m4.2538\u001b[0m  1.9252\n",
      "    443        4.5816       0.9209        \u001b[35m4.2535\u001b[0m  1.9591\n",
      "    444        4.5852       0.9219        \u001b[35m4.2533\u001b[0m  1.9314\n",
      "    445        4.5772       0.9219        \u001b[35m4.2529\u001b[0m  1.9495\n",
      "    446        4.5706       0.9219        \u001b[35m4.2526\u001b[0m  1.9489\n",
      "    447        4.5710       0.9219        \u001b[35m4.2523\u001b[0m  1.9242\n",
      "    448        4.5739       0.9215        \u001b[35m4.2521\u001b[0m  1.9994\n",
      "    449        \u001b[36m4.5678\u001b[0m       0.9219        \u001b[35m4.2518\u001b[0m  1.9133\n",
      "    450        4.5816       0.9222        \u001b[35m4.2515\u001b[0m  1.9856\n",
      "    451        4.5747       0.9219        \u001b[35m4.2513\u001b[0m  1.9151\n",
      "    452        4.5765       0.9219        \u001b[35m4.2511\u001b[0m  1.9416\n",
      "    453        4.5758       0.9225        \u001b[35m4.2509\u001b[0m  1.9398\n",
      "    454        4.5835       0.9228        \u001b[35m4.2506\u001b[0m  1.9208\n",
      "    455        4.5752       0.9225        \u001b[35m4.2503\u001b[0m  1.9962\n",
      "    456        4.5876       0.9225        \u001b[35m4.2500\u001b[0m  1.9321\n",
      "    457        4.5728       0.9232        \u001b[35m4.2497\u001b[0m  2.0156\n",
      "    458        4.5680       0.9222        \u001b[35m4.2494\u001b[0m  1.9225\n",
      "    459        4.5716       0.9219        \u001b[35m4.2491\u001b[0m  1.9508\n",
      "    460        4.5846       0.9219        \u001b[35m4.2488\u001b[0m  1.9356\n",
      "    461        4.5808       0.9219        \u001b[35m4.2486\u001b[0m  1.9328\n",
      "    462        4.5811       0.9212        \u001b[35m4.2485\u001b[0m  1.9476\n",
      "    463        4.5730       0.9205        \u001b[35m4.2483\u001b[0m  1.9074\n",
      "    464        4.5791       0.9209        \u001b[35m4.2480\u001b[0m  1.9843\n",
      "    465        4.5754       0.9215        \u001b[35m4.2478\u001b[0m  1.8855\n",
      "    466        4.5771       0.9212        \u001b[35m4.2476\u001b[0m  2.0405\n",
      "    467        4.5798       0.9209        \u001b[35m4.2474\u001b[0m  1.9379\n",
      "    468        4.5782       0.9212        \u001b[35m4.2471\u001b[0m  2.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    469        4.5709       0.9209        \u001b[35m4.2469\u001b[0m  1.9316\n",
      "    470        4.5750       0.9215        \u001b[35m4.2466\u001b[0m  1.9224\n",
      "    471        4.5736       0.9222        \u001b[35m4.2462\u001b[0m  1.9296\n",
      "    472        4.5755       0.9222        \u001b[35m4.2460\u001b[0m  1.8886\n",
      "    473        4.5749       0.9219        \u001b[35m4.2456\u001b[0m  1.9248\n",
      "    474        4.5776       0.9209        \u001b[35m4.2453\u001b[0m  1.9415\n",
      "    475        4.5702       0.9209        \u001b[35m4.2451\u001b[0m  2.0847\n",
      "    476        4.5767       0.9209        \u001b[35m4.2448\u001b[0m  2.0191\n",
      "    477        4.5789       0.9212        \u001b[35m4.2445\u001b[0m  1.9355\n",
      "    478        4.5743       0.9205        \u001b[35m4.2442\u001b[0m  1.9756\n",
      "    479        4.5747       0.9195        \u001b[35m4.2441\u001b[0m  1.9774\n",
      "    480        4.5710       0.9199        \u001b[35m4.2439\u001b[0m  2.0626\n",
      "    481        4.5778       0.9202        \u001b[35m4.2438\u001b[0m  1.9492\n",
      "    482        4.5738       0.9195        \u001b[35m4.2436\u001b[0m  2.0930\n",
      "    483        4.5783       0.9205        \u001b[35m4.2434\u001b[0m  1.9277\n",
      "    484        4.5724       0.9205        \u001b[35m4.2432\u001b[0m  1.9513\n",
      "    485        4.5774       0.9205        \u001b[35m4.2429\u001b[0m  1.9081\n",
      "    486        \u001b[36m4.5674\u001b[0m       0.9215        \u001b[35m4.2427\u001b[0m  1.8864\n",
      "    487        4.5749       0.9215        \u001b[35m4.2424\u001b[0m  1.9459\n",
      "    488        4.5712       0.9212        \u001b[35m4.2420\u001b[0m  1.9301\n",
      "    489        4.5748       0.9215        \u001b[35m4.2419\u001b[0m  2.0002\n",
      "    490        4.5802       0.9215        \u001b[35m4.2416\u001b[0m  1.9218\n",
      "    491        4.5807       0.9215        \u001b[35m4.2415\u001b[0m  1.9767\n",
      "    492        4.5793       0.9209        \u001b[35m4.2412\u001b[0m  1.9201\n",
      "    493        4.5787       0.9212        \u001b[35m4.2410\u001b[0m  1.9406\n",
      "    494        4.5730       0.9215        \u001b[35m4.2407\u001b[0m  1.9383\n",
      "    495        4.5757       0.9212        \u001b[35m4.2405\u001b[0m  1.9503\n",
      "    496        4.5791       0.9205        \u001b[35m4.2404\u001b[0m  2.0387\n",
      "    497        4.5754       0.9209        \u001b[35m4.2402\u001b[0m  1.9318\n",
      "    498        4.5712       0.9205        \u001b[35m4.2399\u001b[0m  2.0441\n",
      "    499        \u001b[36m4.5659\u001b[0m       0.9205        \u001b[35m4.2397\u001b[0m  1.7659\n",
      "    500        4.5713       0.9202        \u001b[35m4.2394\u001b[0m  1.9867\n",
      "    501        4.5695       0.9199        \u001b[35m4.2393\u001b[0m  1.9408\n",
      "    502        4.5723       0.9199        \u001b[35m4.2390\u001b[0m  1.9514\n",
      "    503        4.5792       0.9202        \u001b[35m4.2389\u001b[0m  1.9136\n",
      "    504        4.5708       0.9202        \u001b[35m4.2386\u001b[0m  1.9030\n",
      "    505        4.5671       0.9205        \u001b[35m4.2384\u001b[0m  1.9288\n",
      "    506        4.5754       0.9195        \u001b[35m4.2383\u001b[0m  1.9070\n",
      "    507        4.5751       0.9192        \u001b[35m4.2381\u001b[0m  1.9650\n",
      "    508        4.5743       0.9192        \u001b[35m4.2380\u001b[0m  1.9442\n",
      "    509        4.5754       0.9199        \u001b[35m4.2378\u001b[0m  1.9661\n",
      "    510        4.5779       0.9199        \u001b[35m4.2375\u001b[0m  1.9427\n",
      "    511        4.5768       0.9189        \u001b[35m4.2374\u001b[0m  1.9380\n",
      "    512        4.5705       0.9195        \u001b[35m4.2372\u001b[0m  2.0373\n",
      "    513        4.5726       0.9199        \u001b[35m4.2370\u001b[0m  1.9269\n",
      "    514        4.5732       0.9195        \u001b[35m4.2368\u001b[0m  1.9859\n",
      "    515        4.5744       0.9195        \u001b[35m4.2365\u001b[0m  1.9038\n",
      "    516        4.5695       0.9192        \u001b[35m4.2364\u001b[0m  1.9843\n",
      "    517        4.5710       0.9195        \u001b[35m4.2362\u001b[0m  1.9260\n",
      "    518        4.5727       0.9195        \u001b[35m4.2360\u001b[0m  1.9513\n",
      "    519        4.5681       0.9192        \u001b[35m4.2357\u001b[0m  1.9340\n",
      "    520        4.5710       0.9192        \u001b[35m4.2356\u001b[0m  1.8947\n",
      "    521        4.5699       0.9185        \u001b[35m4.2354\u001b[0m  2.0046\n",
      "    522        4.5726       0.9195        \u001b[35m4.2352\u001b[0m  1.9498\n",
      "    523        \u001b[36m4.5659\u001b[0m       0.9199        \u001b[35m4.2351\u001b[0m  1.9859\n",
      "    524        4.5707       0.9195        \u001b[35m4.2349\u001b[0m  1.9230\n",
      "    525        4.5732       0.9192        \u001b[35m4.2348\u001b[0m  1.9427\n",
      "    526        4.5804       0.9195        \u001b[35m4.2346\u001b[0m  1.9326\n",
      "    527        4.5720       0.9192        \u001b[35m4.2344\u001b[0m  1.8943\n",
      "    528        4.5751       0.9195        \u001b[35m4.2343\u001b[0m  2.0838\n",
      "    529        4.5765       0.9195        \u001b[35m4.2342\u001b[0m  1.9273\n",
      "    530        4.5701       0.9192        \u001b[35m4.2340\u001b[0m  1.8997\n",
      "    531        \u001b[36m4.5651\u001b[0m       0.9192        \u001b[35m4.2338\u001b[0m  1.9022\n",
      "    532        4.5770       0.9189        \u001b[35m4.2336\u001b[0m  1.9072\n",
      "    533        4.5695       0.9185        \u001b[35m4.2334\u001b[0m  1.9245\n",
      "    534        4.5735       0.9179        \u001b[35m4.2332\u001b[0m  2.0285\n",
      "    535        4.5660       0.9175        \u001b[35m4.2330\u001b[0m  1.9575\n",
      "    536        4.5727       0.9179        \u001b[35m4.2328\u001b[0m  1.9548\n",
      "    537        4.5696       0.9172        \u001b[35m4.2327\u001b[0m  1.9383\n",
      "    538        4.5706       0.9179        \u001b[35m4.2325\u001b[0m  1.9087\n",
      "    539        4.5704       0.9179        \u001b[35m4.2323\u001b[0m  1.9971\n",
      "    540        4.5696       0.9182        \u001b[35m4.2321\u001b[0m  1.8960\n",
      "    541        4.5691       0.9189        \u001b[35m4.2320\u001b[0m  2.0097\n",
      "    542        4.5658       0.9179        \u001b[35m4.2317\u001b[0m  1.9446\n",
      "    543        4.5693       0.9189        \u001b[35m4.2315\u001b[0m  1.9591\n",
      "    544        4.5729       0.9179        \u001b[35m4.2313\u001b[0m  1.9307\n",
      "    545        4.5708       0.9185        \u001b[35m4.2311\u001b[0m  1.9313\n",
      "    546        4.5746       0.9189        \u001b[35m4.2309\u001b[0m  1.9598\n",
      "    547        4.5717       0.9179        \u001b[35m4.2307\u001b[0m  1.9250\n",
      "    548        4.5738       0.9185        \u001b[35m4.2305\u001b[0m  2.0111\n",
      "    549        4.5694       0.9179        \u001b[35m4.2302\u001b[0m  1.9794\n",
      "    550        4.5671       0.9182        \u001b[35m4.2300\u001b[0m  1.9965\n",
      "    551        4.5666       0.9182        \u001b[35m4.2298\u001b[0m  1.9447\n",
      "    552        4.5716       0.9182        \u001b[35m4.2296\u001b[0m  1.9799\n",
      "    553        4.5734       0.9189        \u001b[35m4.2294\u001b[0m  1.9383\n",
      "    554        4.5660       0.9182        \u001b[35m4.2292\u001b[0m  1.9328\n",
      "    555        4.5681       0.9182        \u001b[35m4.2290\u001b[0m  1.9241\n",
      "    556        4.5736       0.9185        \u001b[35m4.2288\u001b[0m  1.9621\n",
      "    557        4.5761       0.9175        \u001b[35m4.2287\u001b[0m  2.0215\n",
      "    558        4.5710       0.9182        \u001b[35m4.2287\u001b[0m  1.9340\n",
      "    559        4.5675       0.9175        \u001b[35m4.2285\u001b[0m  1.9951\n",
      "    560        4.5702       0.9175        \u001b[35m4.2283\u001b[0m  1.9144\n",
      "    561        4.5742       0.9182        \u001b[35m4.2280\u001b[0m  1.9945\n",
      "    562        4.5671       0.9189        \u001b[35m4.2278\u001b[0m  1.9337\n",
      "    563        4.5728       0.9189        \u001b[35m4.2277\u001b[0m  1.9456\n",
      "    564        4.5699       0.9189        \u001b[35m4.2275\u001b[0m  1.9600\n",
      "    565        4.5769       0.9189        \u001b[35m4.2273\u001b[0m  1.8998\n",
      "    566        4.5739       0.9185        \u001b[35m4.2271\u001b[0m  2.0230\n",
      "    567        4.5677       0.9185        \u001b[35m4.2270\u001b[0m  1.9316\n",
      "    568        4.5703       0.9182        \u001b[35m4.2269\u001b[0m  2.0020\n",
      "    569        4.5730       0.9192        \u001b[35m4.2267\u001b[0m  1.8991\n",
      "    570        4.5661       0.9192        \u001b[35m4.2266\u001b[0m  1.9971\n",
      "    571        4.5721       0.9185        \u001b[35m4.2265\u001b[0m  1.9442\n",
      "    572        4.5700       0.9192        \u001b[35m4.2264\u001b[0m  1.9395\n",
      "    573        4.5752       0.9189        \u001b[35m4.2262\u001b[0m  1.9218\n",
      "    574        4.5688       0.9189        \u001b[35m4.2261\u001b[0m  1.9071\n",
      "    575        4.5726       0.9185        \u001b[35m4.2259\u001b[0m  2.0057\n",
      "    576        4.5737       0.9185        \u001b[35m4.2258\u001b[0m  1.9924\n",
      "    577        4.5687       0.9182        \u001b[35m4.2257\u001b[0m  1.9552\n",
      "    578        4.5703       0.9182        \u001b[35m4.2256\u001b[0m  1.9758\n",
      "    579        4.5670       0.9175        \u001b[35m4.2254\u001b[0m  2.0143\n",
      "    580        4.5712       0.9182        \u001b[35m4.2253\u001b[0m  1.9513\n",
      "    581        4.5736       0.9182        \u001b[35m4.2251\u001b[0m  1.9986\n",
      "    582        4.5690       0.9179        \u001b[35m4.2251\u001b[0m  1.9327\n",
      "    583        \u001b[36m4.5626\u001b[0m       0.9175        \u001b[35m4.2249\u001b[0m  1.9307\n",
      "    584        4.5643       0.9172        \u001b[35m4.2247\u001b[0m  1.9355\n",
      "    585        4.5681       0.9179        \u001b[35m4.2245\u001b[0m  1.9634\n",
      "    586        4.5626       0.9185        \u001b[35m4.2244\u001b[0m  2.0190\n",
      "    587        4.5692       0.9185        \u001b[35m4.2243\u001b[0m  1.9462\n",
      "    588        4.5690       0.9189        \u001b[35m4.2241\u001b[0m  2.0721\n",
      "    589        4.5727       0.9195        \u001b[35m4.2240\u001b[0m  1.9292\n",
      "    590        4.5685       0.9199        \u001b[35m4.2238\u001b[0m  1.9912\n",
      "    591        4.5683       0.9192        \u001b[35m4.2238\u001b[0m  1.9108\n",
      "    592        4.5704       0.9192        \u001b[35m4.2236\u001b[0m  1.9463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    593        4.5689       0.9189        \u001b[35m4.2234\u001b[0m  1.9511\n",
      "    594        4.5673       0.9189        \u001b[35m4.2233\u001b[0m  1.9108\n",
      "    595        4.5769       0.9195        \u001b[35m4.2231\u001b[0m  2.0045\n",
      "    596        4.5762       0.9189        \u001b[35m4.2230\u001b[0m  1.9334\n",
      "    597        4.5674       0.9185        \u001b[35m4.2228\u001b[0m  2.0055\n",
      "    598        4.5733       0.9185        \u001b[35m4.2225\u001b[0m  1.9529\n",
      "    599        \u001b[36m4.5585\u001b[0m       0.9179        \u001b[35m4.2223\u001b[0m  2.0073\n",
      "    600        4.5653       0.9166        \u001b[35m4.2221\u001b[0m  1.9913\n",
      "    601        4.5687       0.9169        \u001b[35m4.2220\u001b[0m  2.0223\n",
      "    602        4.5665       0.9175        \u001b[35m4.2218\u001b[0m  1.9056\n",
      "    603        4.5732       0.9172        \u001b[35m4.2216\u001b[0m  1.9439\n",
      "    604        4.5699       0.9175        \u001b[35m4.2216\u001b[0m  1.9438\n",
      "    605        4.5672       0.9166        \u001b[35m4.2215\u001b[0m  1.9547\n",
      "    606        4.5715       0.9172        \u001b[35m4.2213\u001b[0m  1.9337\n",
      "    607        4.5672       0.9179        \u001b[35m4.2212\u001b[0m  1.9276\n",
      "    608        4.5664       0.9172        \u001b[35m4.2212\u001b[0m  1.9540\n",
      "    609        4.5686       0.9179        \u001b[35m4.2209\u001b[0m  1.9410\n",
      "    610        4.5704       0.9179        \u001b[35m4.2207\u001b[0m  1.9701\n",
      "    611        4.5608       0.9182        \u001b[35m4.2206\u001b[0m  1.9113\n",
      "    612        4.5641       0.9179        \u001b[35m4.2204\u001b[0m  1.9580\n",
      "    613        4.5651       0.9182        \u001b[35m4.2202\u001b[0m  1.9495\n",
      "    614        4.5723       0.9175        \u001b[35m4.2202\u001b[0m  1.9541\n",
      "    615        4.5655       0.9179        \u001b[35m4.2200\u001b[0m  1.9540\n",
      "    616        4.5703       0.9179        \u001b[35m4.2199\u001b[0m  1.9274\n",
      "    617        4.5713       0.9179        \u001b[35m4.2197\u001b[0m  2.0179\n",
      "    618        4.5681       0.9175        \u001b[35m4.2196\u001b[0m  1.9313\n",
      "    619        4.5653       0.9185        \u001b[35m4.2196\u001b[0m  2.0006\n",
      "    620        4.5678       0.9182        \u001b[35m4.2193\u001b[0m  1.9082\n",
      "    621        4.5660       0.9175        \u001b[35m4.2191\u001b[0m  1.9964\n",
      "    622        4.5647       0.9175        \u001b[35m4.2191\u001b[0m  1.9379\n",
      "    623        4.5642       0.9172        \u001b[35m4.2190\u001b[0m  1.9909\n",
      "    624        4.5693       0.9172        \u001b[35m4.2189\u001b[0m  1.9527\n",
      "    625        4.5687       0.9175        \u001b[35m4.2188\u001b[0m  1.9928\n",
      "    626        4.5650       0.9175        \u001b[35m4.2185\u001b[0m  1.9528\n",
      "    627        4.5672       0.9179        \u001b[35m4.2184\u001b[0m  1.9700\n",
      "    628        4.5604       0.9182        \u001b[35m4.2183\u001b[0m  1.9892\n",
      "    629        4.5722       0.9182        \u001b[35m4.2181\u001b[0m  1.9879\n",
      "    630        4.5780       0.9182        \u001b[35m4.2179\u001b[0m  1.9427\n",
      "    631        4.5672       0.9182        \u001b[35m4.2178\u001b[0m  1.9857\n",
      "    632        4.5702       0.9185        \u001b[35m4.2176\u001b[0m  2.0165\n",
      "    633        4.5656       0.9182        \u001b[35m4.2175\u001b[0m  1.9339\n",
      "    634        4.5602       0.9185        \u001b[35m4.2173\u001b[0m  1.9200\n",
      "    635        4.5655       0.9192        \u001b[35m4.2171\u001b[0m  1.9290\n",
      "    636        4.5666       0.9182        \u001b[35m4.2169\u001b[0m  1.9059\n",
      "    637        4.5713       0.9189        \u001b[35m4.2168\u001b[0m  1.9388\n",
      "    638        4.5701       0.9192        \u001b[35m4.2167\u001b[0m  2.0269\n",
      "    639        4.5706       0.9192        \u001b[35m4.2166\u001b[0m  2.0182\n",
      "    640        4.5749       0.9189        \u001b[35m4.2165\u001b[0m  1.9224\n",
      "    641        4.5677       0.9189        \u001b[35m4.2165\u001b[0m  2.0308\n",
      "    642        4.5636       0.9189        \u001b[35m4.2164\u001b[0m  1.9597\n",
      "    643        4.5668       0.9185        \u001b[35m4.2163\u001b[0m  2.0262\n",
      "    644        4.5663       0.9185        \u001b[35m4.2162\u001b[0m  1.9267\n",
      "    645        4.5715       0.9189        \u001b[35m4.2160\u001b[0m  2.0027\n",
      "    646        4.5799       0.9192        \u001b[35m4.2160\u001b[0m  1.9116\n",
      "    647        4.5622       0.9179        \u001b[35m4.2158\u001b[0m  1.9891\n",
      "    648        4.5711       0.9179        \u001b[35m4.2157\u001b[0m  1.9265\n",
      "    649        4.5622       0.9179        \u001b[35m4.2156\u001b[0m  1.9271\n",
      "    650        4.5686       0.9179        \u001b[35m4.2155\u001b[0m  1.9354\n",
      "    651        4.5664       0.9189        \u001b[35m4.2153\u001b[0m  1.9224\n",
      "    652        4.5666       0.9185        \u001b[35m4.2152\u001b[0m  1.9933\n",
      "    653        4.5709       0.9185        \u001b[35m4.2150\u001b[0m  1.9136\n",
      "    654        4.5615       0.9185        \u001b[35m4.2149\u001b[0m  2.0238\n",
      "    655        \u001b[36m4.5576\u001b[0m       0.9185        \u001b[35m4.2147\u001b[0m  1.9709\n",
      "    656        4.5632       0.9182        \u001b[35m4.2145\u001b[0m  1.9273\n",
      "    657        4.5678       0.9182        \u001b[35m4.2145\u001b[0m  1.9115\n",
      "    658        4.5628       0.9182        \u001b[35m4.2144\u001b[0m  1.9570\n",
      "    659        \u001b[36m4.5546\u001b[0m       0.9185        \u001b[35m4.2142\u001b[0m  1.9586\n",
      "    660        4.5696       0.9189        \u001b[35m4.2141\u001b[0m  1.9672\n",
      "    661        4.5658       0.9179        \u001b[35m4.2139\u001b[0m  1.9448\n",
      "    662        4.5632       0.9179        \u001b[35m4.2138\u001b[0m  1.9163\n",
      "    663        4.5610       0.9182        \u001b[35m4.2137\u001b[0m  2.2361\n",
      "    664        4.5720       0.9182        \u001b[35m4.2135\u001b[0m  2.1958\n",
      "    665        4.5584       0.9185        \u001b[35m4.2134\u001b[0m  2.0125\n",
      "    666        4.5636       0.9182        \u001b[35m4.2133\u001b[0m  1.9580\n",
      "    667        4.5666       0.9185        \u001b[35m4.2133\u001b[0m  1.9149\n",
      "    668        4.5602       0.9182        \u001b[35m4.2131\u001b[0m  2.0018\n",
      "    669        4.5643       0.9175        \u001b[35m4.2130\u001b[0m  2.0272\n",
      "    670        4.5712       0.9185        \u001b[35m4.2129\u001b[0m  1.9748\n",
      "    671        4.5587       0.9185        \u001b[35m4.2128\u001b[0m  1.9518\n",
      "    672        4.5694       0.9185        \u001b[35m4.2127\u001b[0m  1.9316\n",
      "    673        4.5663       0.9189        \u001b[35m4.2125\u001b[0m  1.9809\n",
      "    674        4.5654       0.9189        \u001b[35m4.2123\u001b[0m  1.9440\n",
      "    675        4.5714       0.9192        \u001b[35m4.2123\u001b[0m  1.9454\n",
      "    676        4.5690       0.9185        \u001b[35m4.2121\u001b[0m  1.9550\n",
      "    677        4.5657       0.9179        \u001b[35m4.2120\u001b[0m  1.9262\n",
      "    678        4.5746       0.9182        \u001b[35m4.2119\u001b[0m  2.0786\n",
      "    679        4.5652       0.9182        \u001b[35m4.2117\u001b[0m  1.9729\n",
      "    680        4.5683       0.9179        \u001b[35m4.2116\u001b[0m  1.9865\n",
      "    681        4.5616       0.9182        \u001b[35m4.2114\u001b[0m  1.9196\n",
      "    682        4.5648       0.9182        \u001b[35m4.2114\u001b[0m  1.9396\n",
      "    683        4.5612       0.9179        \u001b[35m4.2113\u001b[0m  1.9345\n",
      "    684        4.5659       0.9179        \u001b[35m4.2112\u001b[0m  1.9633\n",
      "    685        4.5669       0.9185        \u001b[35m4.2112\u001b[0m  1.9399\n",
      "    686        4.5706       0.9185        \u001b[35m4.2110\u001b[0m  2.0304\n",
      "    687        4.5680       0.9189        \u001b[35m4.2109\u001b[0m  1.9672\n",
      "    688        4.5604       0.9182        \u001b[35m4.2108\u001b[0m  2.0433\n",
      "    689        4.5647       0.9182        \u001b[35m4.2107\u001b[0m  1.9710\n",
      "    690        4.5614       0.9179        \u001b[35m4.2106\u001b[0m  1.9853\n",
      "    691        4.5645       0.9179        \u001b[35m4.2104\u001b[0m  1.9254\n",
      "    692        4.5638       0.9182        \u001b[35m4.2103\u001b[0m  1.9984\n",
      "    693        4.5729       0.9182        \u001b[35m4.2101\u001b[0m  2.0881\n",
      "    694        4.5668       0.9179        \u001b[35m4.2100\u001b[0m  2.0467\n",
      "    695        4.5678       0.9179        \u001b[35m4.2099\u001b[0m  2.1087\n",
      "    696        4.5642       0.9179        \u001b[35m4.2098\u001b[0m  1.9320\n",
      "    697        4.5652       0.9175        \u001b[35m4.2098\u001b[0m  2.1215\n",
      "    698        4.5674       0.9172        \u001b[35m4.2097\u001b[0m  1.9578\n",
      "    699        4.5725       0.9175        \u001b[35m4.2095\u001b[0m  2.0750\n",
      "    700        4.5720       0.9179        \u001b[35m4.2094\u001b[0m  1.9812\n",
      "    701        4.5663       0.9175        \u001b[35m4.2093\u001b[0m  2.0949\n",
      "    702        4.5655       0.9185        \u001b[35m4.2093\u001b[0m  1.9804\n",
      "    703        4.5675       0.9185        \u001b[35m4.2091\u001b[0m  2.0103\n",
      "    704        4.5643       0.9172        \u001b[35m4.2090\u001b[0m  1.9284\n",
      "    705        4.5642       0.9185        \u001b[35m4.2089\u001b[0m  1.9557\n",
      "    706        4.5672       0.9182        \u001b[35m4.2087\u001b[0m  1.9099\n",
      "    707        4.5657       0.9175        \u001b[35m4.2085\u001b[0m  1.9624\n",
      "    708        4.5619       0.9179        \u001b[35m4.2085\u001b[0m  1.9072\n",
      "    709        4.5655       0.9179        \u001b[35m4.2084\u001b[0m  1.9358\n",
      "    710        4.5646       0.9185        \u001b[35m4.2083\u001b[0m  1.9641\n",
      "    711        4.5590       0.9185        \u001b[35m4.2082\u001b[0m  1.9434\n",
      "    712        4.5552       0.9182        \u001b[35m4.2081\u001b[0m  1.9731\n",
      "    713        4.5647       0.9185        \u001b[35m4.2079\u001b[0m  1.9236\n",
      "    714        4.5704       0.9199        \u001b[35m4.2078\u001b[0m  1.9461\n",
      "    715        4.5646       0.9199        \u001b[35m4.2077\u001b[0m  1.9194\n",
      "    716        4.5606       0.9199        \u001b[35m4.2075\u001b[0m  1.9409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    717        4.5630       0.9202        \u001b[35m4.2073\u001b[0m  1.9157\n",
      "    718        4.5662       0.9199        \u001b[35m4.2072\u001b[0m  1.9357\n",
      "    719        4.5771       0.9205        \u001b[35m4.2072\u001b[0m  1.9320\n",
      "    720        4.5615       0.9205        \u001b[35m4.2071\u001b[0m  1.9665\n",
      "    721        4.5601       0.9205        \u001b[35m4.2070\u001b[0m  1.9173\n",
      "    722        4.5703       0.9195        \u001b[35m4.2069\u001b[0m  1.9356\n",
      "    723        4.5638       0.9195        \u001b[35m4.2068\u001b[0m  1.9260\n",
      "    724        4.5655       0.9195        \u001b[35m4.2068\u001b[0m  1.9174\n",
      "    725        4.5653       0.9199        \u001b[35m4.2067\u001b[0m  1.9570\n",
      "    726        4.5655       0.9195        \u001b[35m4.2066\u001b[0m  1.9219\n",
      "    727        4.5654       0.9192        \u001b[35m4.2065\u001b[0m  1.9460\n",
      "    728        4.5654       0.9192        \u001b[35m4.2065\u001b[0m  1.9477\n",
      "    729        4.5600       0.9195        \u001b[35m4.2064\u001b[0m  1.9246\n",
      "    730        4.5613       0.9192        \u001b[35m4.2063\u001b[0m  1.9345\n",
      "    731        4.5616       0.9189        \u001b[35m4.2061\u001b[0m  1.9013\n",
      "    732        4.5660       0.9185        \u001b[35m4.2060\u001b[0m  1.9428\n",
      "    733        4.5664       0.9189        \u001b[35m4.2060\u001b[0m  1.9467\n",
      "    734        4.5646       0.9185        \u001b[35m4.2059\u001b[0m  1.9094\n",
      "    735        4.5650       0.9185        \u001b[35m4.2058\u001b[0m  1.9175\n",
      "    736        4.5682       0.9182        \u001b[35m4.2057\u001b[0m  1.9327\n",
      "    737        4.5620       0.9189        \u001b[35m4.2056\u001b[0m  1.9154\n",
      "    738        4.5691       0.9182        4.2056  1.9341\n",
      "    739        4.5653       0.9182        \u001b[35m4.2055\u001b[0m  1.9272\n",
      "    740        4.5588       0.9189        \u001b[35m4.2055\u001b[0m  1.9251\n",
      "    741        4.5669       0.9192        \u001b[35m4.2053\u001b[0m  1.9241\n",
      "    742        4.5677       0.9192        \u001b[35m4.2051\u001b[0m  1.9171\n",
      "    743        4.5605       0.9192        \u001b[35m4.2051\u001b[0m  1.9273\n",
      "    744        4.5608       0.9195        \u001b[35m4.2051\u001b[0m  1.9773\n",
      "    745        4.5634       0.9192        \u001b[35m4.2050\u001b[0m  1.9312\n",
      "    746        4.5675       0.9189        \u001b[35m4.2050\u001b[0m  1.9418\n",
      "    747        4.5587       0.9182        \u001b[35m4.2049\u001b[0m  1.9586\n",
      "    748        4.5641       0.9185        \u001b[35m4.2047\u001b[0m  1.9262\n",
      "    749        4.5679       0.9182        \u001b[35m4.2046\u001b[0m  1.9829\n",
      "    750        4.5612       0.9189        \u001b[35m4.2045\u001b[0m  1.9436\n",
      "    751        4.5653       0.9192        \u001b[35m4.2044\u001b[0m  1.9411\n",
      "    752        4.5624       0.9195        \u001b[35m4.2043\u001b[0m  1.9681\n",
      "    753        4.5670       0.9192        \u001b[35m4.2042\u001b[0m  1.9545\n",
      "    754        4.5601       0.9192        \u001b[35m4.2042\u001b[0m  1.9218\n",
      "    755        4.5576       0.9192        \u001b[35m4.2040\u001b[0m  1.9588\n",
      "    756        4.5579       0.9195        \u001b[35m4.2039\u001b[0m  1.9469\n",
      "    757        4.5634       0.9189        \u001b[35m4.2038\u001b[0m  1.9515\n",
      "    758        4.5623       0.9189        \u001b[35m4.2037\u001b[0m  1.9405\n",
      "    759        4.5673       0.9189        \u001b[35m4.2036\u001b[0m  1.9378\n",
      "    760        4.5639       0.9192        \u001b[35m4.2036\u001b[0m  1.9290\n",
      "    761        4.5602       0.9195        \u001b[35m4.2034\u001b[0m  1.9305\n",
      "    762        4.5675       0.9195        \u001b[35m4.2032\u001b[0m  1.9182\n",
      "    763        4.5664       0.9195        \u001b[35m4.2032\u001b[0m  1.9379\n",
      "    764        4.5574       0.9192        \u001b[35m4.2031\u001b[0m  1.9205\n",
      "    765        4.5679       0.9192        \u001b[35m4.2030\u001b[0m  1.9493\n",
      "    766        4.5623       0.9192        \u001b[35m4.2029\u001b[0m  1.9436\n",
      "    767        4.5608       0.9189        \u001b[35m4.2028\u001b[0m  1.9122\n",
      "    768        4.5604       0.9192        \u001b[35m4.2027\u001b[0m  1.9032\n",
      "    769        4.5614       0.9192        \u001b[35m4.2026\u001b[0m  1.8975\n",
      "    770        4.5621       0.9192        \u001b[35m4.2025\u001b[0m  1.9042\n",
      "    771        4.5581       0.9185        \u001b[35m4.2024\u001b[0m  1.9428\n",
      "    772        4.5616       0.9192        \u001b[35m4.2023\u001b[0m  1.9562\n",
      "    773        4.5598       0.9182        \u001b[35m4.2022\u001b[0m  1.9380\n",
      "    774        4.5595       0.9189        \u001b[35m4.2022\u001b[0m  1.9200\n",
      "    775        4.5620       0.9185        \u001b[35m4.2020\u001b[0m  1.9236\n",
      "    776        4.5595       0.9189        \u001b[35m4.2019\u001b[0m  1.9387\n",
      "    777        4.5617       0.9182        \u001b[35m4.2018\u001b[0m  1.9565\n",
      "    778        4.5673       0.9182        \u001b[35m4.2017\u001b[0m  1.9294\n",
      "    779        4.5581       0.9185        \u001b[35m4.2016\u001b[0m  1.9547\n",
      "    780        4.5613       0.9189        \u001b[35m4.2015\u001b[0m  1.9190\n",
      "    781        4.5618       0.9185        \u001b[35m4.2014\u001b[0m  1.9428\n",
      "    782        4.5633       0.9182        \u001b[35m4.2013\u001b[0m  1.9408\n",
      "    783        4.5621       0.9179        \u001b[35m4.2012\u001b[0m  1.9324\n",
      "    784        4.5645       0.9179        \u001b[35m4.2011\u001b[0m  1.9171\n",
      "    785        4.5721       0.9182        \u001b[35m4.2010\u001b[0m  1.9584\n",
      "    786        4.5625       0.9185        \u001b[35m4.2009\u001b[0m  1.9293\n",
      "    787        4.5583       0.9185        \u001b[35m4.2008\u001b[0m  1.9325\n",
      "    788        4.5591       0.9182        \u001b[35m4.2008\u001b[0m  1.9326\n",
      "    789        4.5670       0.9192        \u001b[35m4.2007\u001b[0m  1.8953\n",
      "    790        4.5595       0.9185        \u001b[35m4.2006\u001b[0m  1.9417\n",
      "    791        4.5630       0.9189        \u001b[35m4.2005\u001b[0m  1.9106\n",
      "    792        4.5568       0.9189        \u001b[35m4.2004\u001b[0m  1.9431\n",
      "    793        4.5595       0.9182        \u001b[35m4.2003\u001b[0m  1.9379\n",
      "    794        \u001b[36m4.5529\u001b[0m       0.9182        4.2003  1.9418\n",
      "    795        4.5572       0.9185        \u001b[35m4.2001\u001b[0m  1.9691\n",
      "    796        4.5579       0.9175        \u001b[35m4.2001\u001b[0m  1.9518\n",
      "    797        4.5660       0.9169        \u001b[35m4.2000\u001b[0m  1.9184\n",
      "    798        4.5668       0.9169        \u001b[35m4.2000\u001b[0m  1.9431\n",
      "    799        4.5580       0.9169        \u001b[35m4.1999\u001b[0m  1.9003\n",
      "    800        4.5611       0.9169        \u001b[35m4.1998\u001b[0m  1.9203\n",
      "    801        4.5586       0.9169        \u001b[35m4.1996\u001b[0m  1.9218\n",
      "    802        4.5607       0.9179        \u001b[35m4.1995\u001b[0m  1.9460\n",
      "    803        4.5612       0.9175        \u001b[35m4.1994\u001b[0m  1.9519\n",
      "    804        4.5715       0.9175        4.1994  1.9481\n",
      "    805        4.5613       0.9175        \u001b[35m4.1994\u001b[0m  2.0035\n",
      "    806        4.5577       0.9169        \u001b[35m4.1994\u001b[0m  1.9609\n",
      "    807        4.5580       0.9172        \u001b[35m4.1992\u001b[0m  1.9805\n",
      "    808        4.5621       0.9172        \u001b[35m4.1992\u001b[0m  1.9283\n",
      "    809        4.5571       0.9179        \u001b[35m4.1991\u001b[0m  1.9714\n",
      "    810        4.5637       0.9182        \u001b[35m4.1990\u001b[0m  1.9779\n",
      "    811        4.5658       0.9189        \u001b[35m4.1990\u001b[0m  1.9821\n",
      "    812        4.5653       0.9179        \u001b[35m4.1989\u001b[0m  1.9590\n",
      "    813        4.5682       0.9175        \u001b[35m4.1988\u001b[0m  1.9370\n",
      "    814        4.5622       0.9179        \u001b[35m4.1988\u001b[0m  1.9423\n",
      "    815        4.5593       0.9172        \u001b[35m4.1988\u001b[0m  1.9695\n",
      "    816        4.5571       0.9172        \u001b[35m4.1986\u001b[0m  1.9437\n",
      "    817        4.5620       0.9172        \u001b[35m4.1985\u001b[0m  1.9405\n",
      "    818        4.5565       0.9185        4.1986  1.9489\n",
      "    819        4.5597       0.9182        \u001b[35m4.1985\u001b[0m  1.9448\n",
      "    820        4.5639       0.9182        \u001b[35m4.1984\u001b[0m  1.9375\n",
      "    821        4.5595       0.9172        \u001b[35m4.1983\u001b[0m  1.9706\n",
      "    822        4.5608       0.9179        \u001b[35m4.1983\u001b[0m  1.9587\n",
      "    823        4.5575       0.9175        \u001b[35m4.1982\u001b[0m  1.9648\n",
      "    824        4.5610       0.9169        \u001b[35m4.1981\u001b[0m  1.9631\n",
      "    825        4.5616       0.9172        \u001b[35m4.1980\u001b[0m  1.9595\n",
      "    826        4.5552       0.9172        \u001b[35m4.1979\u001b[0m  1.9847\n",
      "    827        4.5585       0.9175        \u001b[35m4.1979\u001b[0m  1.9823\n",
      "    828        4.5561       0.9172        \u001b[35m4.1978\u001b[0m  1.9606\n",
      "    829        4.5606       0.9179        \u001b[35m4.1977\u001b[0m  1.9523\n",
      "    830        4.5679       0.9182        \u001b[35m4.1977\u001b[0m  1.9690\n",
      "    831        4.5568       0.9185        \u001b[35m4.1976\u001b[0m  1.9318\n",
      "    832        4.5626       0.9185        \u001b[35m4.1976\u001b[0m  1.9393\n",
      "    833        4.5677       0.9185        \u001b[35m4.1975\u001b[0m  1.9558\n",
      "    834        4.5631       0.9182        \u001b[35m4.1974\u001b[0m  1.9724\n",
      "    835        4.5585       0.9185        \u001b[35m4.1974\u001b[0m  1.9420\n",
      "    836        4.5579       0.9179        \u001b[35m4.1972\u001b[0m  1.9583\n",
      "    837        4.5613       0.9172        \u001b[35m4.1971\u001b[0m  1.9439\n",
      "    838        4.5617       0.9175        \u001b[35m4.1971\u001b[0m  1.9509\n",
      "    839        4.5558       0.9166        \u001b[35m4.1970\u001b[0m  1.9471\n",
      "    840        4.5640       0.9179        \u001b[35m4.1968\u001b[0m  1.9477\n",
      "    841        4.5562       0.9175        \u001b[35m4.1967\u001b[0m  1.9483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    842        4.5644       0.9185        \u001b[35m4.1967\u001b[0m  1.9283\n",
      "    843        4.5698       0.9192        \u001b[35m4.1965\u001b[0m  1.9424\n",
      "    844        4.5634       0.9185        \u001b[35m4.1964\u001b[0m  1.9413\n",
      "    845        4.5605       0.9182        \u001b[35m4.1963\u001b[0m  1.9491\n",
      "    846        4.5558       0.9179        \u001b[35m4.1962\u001b[0m  1.9696\n",
      "    847        4.5581       0.9182        \u001b[35m4.1961\u001b[0m  1.9489\n",
      "    848        4.5578       0.9175        4.1961  1.9454\n",
      "    849        4.5670       0.9172        \u001b[35m4.1961\u001b[0m  1.9902\n",
      "    850        4.5646       0.9182        \u001b[35m4.1961\u001b[0m  1.9548\n",
      "    851        4.5562       0.9185        \u001b[35m4.1959\u001b[0m  1.9737\n",
      "    852        4.5599       0.9192        4.1959  1.9577\n",
      "    853        4.5538       0.9199        \u001b[35m4.1958\u001b[0m  1.9402\n",
      "    854        4.5672       0.9195        \u001b[35m4.1958\u001b[0m  1.9305\n",
      "    855        4.5567       0.9189        \u001b[35m4.1957\u001b[0m  1.9533\n",
      "    856        4.5625       0.9195        \u001b[35m4.1956\u001b[0m  1.9467\n",
      "    857        4.5611       0.9179        \u001b[35m4.1955\u001b[0m  1.9337\n",
      "    858        4.5548       0.9182        \u001b[35m4.1954\u001b[0m  1.9363\n",
      "    859        4.5590       0.9182        \u001b[35m4.1953\u001b[0m  1.9575\n",
      "    860        4.5601       0.9185        \u001b[35m4.1952\u001b[0m  1.9423\n",
      "    861        4.5575       0.9182        \u001b[35m4.1952\u001b[0m  1.9702\n",
      "    862        4.5570       0.9179        \u001b[35m4.1951\u001b[0m  1.9445\n",
      "    863        4.5586       0.9169        \u001b[35m4.1950\u001b[0m  1.9617\n",
      "    864        4.5582       0.9172        \u001b[35m4.1949\u001b[0m  1.9258\n",
      "    865        4.5631       0.9179        \u001b[35m4.1948\u001b[0m  1.9305\n",
      "    866        4.5572       0.9182        \u001b[35m4.1947\u001b[0m  1.9445\n",
      "    867        4.5613       0.9182        \u001b[35m4.1946\u001b[0m  1.9363\n",
      "    868        4.5622       0.9179        \u001b[35m4.1945\u001b[0m  1.9443\n",
      "    869        4.5635       0.9179        \u001b[35m4.1944\u001b[0m  1.9480\n",
      "    870        4.5646       0.9185        4.1944  1.9342\n",
      "    871        \u001b[36m4.5526\u001b[0m       0.9182        \u001b[35m4.1944\u001b[0m  1.9497\n",
      "    872        4.5579       0.9185        \u001b[35m4.1943\u001b[0m  1.9650\n",
      "    873        4.5540       0.9185        \u001b[35m4.1943\u001b[0m  1.9304\n",
      "    874        4.5613       0.9185        \u001b[35m4.1942\u001b[0m  1.9272\n",
      "    875        4.5615       0.9189        \u001b[35m4.1942\u001b[0m  1.9190\n",
      "    876        4.5665       0.9189        \u001b[35m4.1941\u001b[0m  1.9491\n",
      "    877        4.5533       0.9185        \u001b[35m4.1941\u001b[0m  1.9311\n",
      "    878        4.5579       0.9185        \u001b[35m4.1940\u001b[0m  1.9538\n",
      "    879        4.5595       0.9185        \u001b[35m4.1939\u001b[0m  1.9373\n",
      "    880        4.5609       0.9185        \u001b[35m4.1938\u001b[0m  1.9226\n",
      "    881        4.5666       0.9185        \u001b[35m4.1938\u001b[0m  1.9151\n",
      "    882        4.5582       0.9182        \u001b[35m4.1937\u001b[0m  1.9061\n",
      "    883        4.5606       0.9182        \u001b[35m4.1937\u001b[0m  1.9295\n",
      "    884        4.5557       0.9192        \u001b[35m4.1937\u001b[0m  1.8577\n",
      "    885        4.5623       0.9185        \u001b[35m4.1936\u001b[0m  1.9076\n",
      "    886        4.5646       0.9189        \u001b[35m4.1935\u001b[0m  1.8487\n",
      "    887        4.5530       0.9189        \u001b[35m4.1934\u001b[0m  1.8561\n",
      "    888        \u001b[36m4.5521\u001b[0m       0.9185        \u001b[35m4.1933\u001b[0m  1.9223\n",
      "    889        4.5677       0.9179        \u001b[35m4.1931\u001b[0m  1.9593\n",
      "    890        4.5556       0.9182        \u001b[35m4.1931\u001b[0m  1.9555\n",
      "    891        4.5536       0.9175        \u001b[35m4.1930\u001b[0m  1.9692\n",
      "    892        4.5645       0.9182        \u001b[35m4.1929\u001b[0m  1.9485\n",
      "    893        4.5629       0.9182        \u001b[35m4.1928\u001b[0m  1.9526\n",
      "    894        4.5627       0.9185        \u001b[35m4.1927\u001b[0m  1.9329\n",
      "    895        4.5536       0.9179        \u001b[35m4.1926\u001b[0m  1.9587\n",
      "    896        4.5535       0.9185        \u001b[35m4.1925\u001b[0m  1.9663\n",
      "    897        \u001b[36m4.5519\u001b[0m       0.9185        \u001b[35m4.1925\u001b[0m  1.9769\n",
      "    898        \u001b[36m4.5505\u001b[0m       0.9189        \u001b[35m4.1924\u001b[0m  1.9258\n",
      "    899        4.5648       0.9185        \u001b[35m4.1923\u001b[0m  1.9408\n",
      "    900        4.5593       0.9189        \u001b[35m4.1923\u001b[0m  1.9226\n",
      "    901        4.5555       0.9192        \u001b[35m4.1921\u001b[0m  1.9049\n",
      "    902        4.5548       0.9189        \u001b[35m4.1920\u001b[0m  1.9545\n",
      "    903        4.5575       0.9189        \u001b[35m4.1920\u001b[0m  1.9678\n",
      "    904        4.5553       0.9195        \u001b[35m4.1919\u001b[0m  1.9425\n",
      "    905        4.5621       0.9189        \u001b[35m4.1918\u001b[0m  1.9441\n",
      "    906        4.5653       0.9189        \u001b[35m4.1917\u001b[0m  1.9424\n",
      "    907        4.5571       0.9189        \u001b[35m4.1917\u001b[0m  1.9300\n",
      "    908        4.5570       0.9192        \u001b[35m4.1916\u001b[0m  1.9222\n",
      "    909        4.5578       0.9189        \u001b[35m4.1916\u001b[0m  1.9133\n",
      "    910        4.5575       0.9185        \u001b[35m4.1915\u001b[0m  1.9582\n",
      "    911        4.5571       0.9185        \u001b[35m4.1915\u001b[0m  1.9329\n",
      "    912        4.5636       0.9185        \u001b[35m4.1914\u001b[0m  1.9560\n",
      "    913        4.5634       0.9185        \u001b[35m4.1914\u001b[0m  1.9285\n",
      "    914        4.5582       0.9182        \u001b[35m4.1913\u001b[0m  1.9330\n",
      "    915        4.5569       0.9185        \u001b[35m4.1913\u001b[0m  1.9273\n",
      "    916        4.5586       0.9199        \u001b[35m4.1913\u001b[0m  1.9146\n",
      "    917        4.5659       0.9185        \u001b[35m4.1912\u001b[0m  1.8983\n",
      "    918        4.5600       0.9189        \u001b[35m4.1911\u001b[0m  1.9286\n",
      "    919        4.5591       0.9189        \u001b[35m4.1910\u001b[0m  1.9520\n",
      "    920        4.5611       0.9189        \u001b[35m4.1909\u001b[0m  1.9647\n",
      "    921        4.5534       0.9185        \u001b[35m4.1909\u001b[0m  1.9400\n",
      "    922        4.5612       0.9189        \u001b[35m4.1908\u001b[0m  1.9392\n",
      "    923        4.5544       0.9192        \u001b[35m4.1907\u001b[0m  1.9181\n",
      "    924        4.5563       0.9182        \u001b[35m4.1906\u001b[0m  1.9804\n",
      "    925        4.5645       0.9192        \u001b[35m4.1905\u001b[0m  1.9654\n",
      "    926        4.5590       0.9192        \u001b[35m4.1904\u001b[0m  1.9269\n",
      "    927        4.5622       0.9189        \u001b[35m4.1904\u001b[0m  1.9637\n",
      "    928        4.5543       0.9185        \u001b[35m4.1903\u001b[0m  1.9538\n",
      "    929        4.5551       0.9185        \u001b[35m4.1902\u001b[0m  2.0902\n",
      "    930        4.5654       0.9182        \u001b[35m4.1901\u001b[0m  1.9921\n",
      "    931        4.5605       0.9179        \u001b[35m4.1901\u001b[0m  1.9506\n",
      "    932        4.5635       0.9185        \u001b[35m4.1900\u001b[0m  1.9398\n",
      "    933        4.5636       0.9185        \u001b[35m4.1899\u001b[0m  1.9607\n",
      "    934        4.5616       0.9175        \u001b[35m4.1898\u001b[0m  1.9479\n",
      "    935        4.5559       0.9179        \u001b[35m4.1896\u001b[0m  1.9461\n",
      "    936        4.5608       0.9182        \u001b[35m4.1895\u001b[0m  1.9323\n",
      "    937        4.5597       0.9189        \u001b[35m4.1894\u001b[0m  1.9861\n",
      "    938        4.5651       0.9189        \u001b[35m4.1894\u001b[0m  1.9856\n",
      "    939        4.5577       0.9189        \u001b[35m4.1894\u001b[0m  1.9365\n",
      "    940        \u001b[36m4.5479\u001b[0m       0.9182        \u001b[35m4.1892\u001b[0m  1.9565\n",
      "    941        4.5616       0.9182        4.1892  1.9683\n",
      "    942        4.5527       0.9185        \u001b[35m4.1892\u001b[0m  1.9310\n",
      "    943        4.5607       0.9185        \u001b[35m4.1891\u001b[0m  1.9790\n",
      "    944        4.5575       0.9185        \u001b[35m4.1891\u001b[0m  1.9140\n",
      "    945        4.5623       0.9185        4.1891  1.9403\n",
      "    946        4.5601       0.9185        \u001b[35m4.1890\u001b[0m  1.9662\n",
      "    947        4.5597       0.9185        \u001b[35m4.1889\u001b[0m  1.9951\n",
      "    948        4.5579       0.9189        \u001b[35m4.1888\u001b[0m  1.9585\n",
      "    949        4.5601       0.9182        \u001b[35m4.1888\u001b[0m  1.9595\n",
      "    950        4.5636       0.9182        \u001b[35m4.1887\u001b[0m  1.9929\n",
      "    951        4.5573       0.9172        \u001b[35m4.1886\u001b[0m  1.9789\n",
      "    952        4.5624       0.9182        \u001b[35m4.1885\u001b[0m  1.9983\n",
      "    953        4.5585       0.9182        4.1885  1.9694\n",
      "    954        4.5631       0.9182        \u001b[35m4.1885\u001b[0m  1.9638\n",
      "    955        4.5517       0.9185        4.1885  1.9426\n",
      "    956        4.5627       0.9179        4.1885  1.9306\n",
      "    957        4.5550       0.9179        4.1885  1.9512\n",
      "    958        4.5598       0.9175        4.1885  1.9289\n",
      "    959        4.5602       0.9175        \u001b[35m4.1884\u001b[0m  1.9451\n",
      "    960        4.5590       0.9179        \u001b[35m4.1884\u001b[0m  1.9209\n",
      "    961        4.5602       0.9182        4.1885  1.9507\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{1600: 0.9682119205298013}\n",
      "Val accuracy\n",
      "{1600: 0.8613333333333333}\n",
      "pred time\n",
      "{1600: 0.18616509437561035}\n",
      "OOS Val Accuracy\n",
      "{1600: 0.16}\n",
      "OOS pred time\n",
      "{1600: 0.005899906158447266}\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "dropout = 0.75\n",
    "class CLINCModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim=vocab_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_dim=output_dim,\n",
    "            dropout=dropout\n",
    "    ):\n",
    "        super(CLINCModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.output = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = F.relu(X)\n",
    "        X = self.dropout(X) # hidden layer removed\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "module=CLINCModule,\n",
    "lr=lr,\n",
    "criterion=torch.nn.CrossEntropyLoss,\n",
    "max_epochs=1000,\n",
    "optimizer=torch.optim.Adam,\n",
    "callbacks=[EarlyStopping(patience=10)],\n",
    ")\n",
    "\n",
    "net.fit(train_x, train_y)\n",
    "tlabels = net.predict(train_x)\n",
    "tacc[hidden_dim] = accuracy_score(tlabels, train_y)\n",
    "print('training accuracy')\n",
    "print(tacc)\n",
    "time0 = time.time()\n",
    "labels = net.predict(val_x)\n",
    "vacc[hidden_dim] = accuracy_score(labels, val_y)\n",
    "time1 = time.time()\n",
    "vtime[hidden_dim] = time1-time0\n",
    "print('Val accuracy')\n",
    "print(vacc)\n",
    "print('pred time')\n",
    "print(vtime)\n",
    "time2 = time.time()\n",
    "olabels = net.predict(val_oos_x)\n",
    "oacc[hidden_dim] = accuracy_score(olabels, val_oos_y)\n",
    "time3 = time.time()\n",
    "otime[hidden_dim]=time3-time2\n",
    "print('OOS Val Accuracy')\n",
    "print(oacc)\n",
    "print('OOS pred time')\n",
    "print(otime)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting for patience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0158\u001b[0m       \u001b[32m0.5245\u001b[0m        \u001b[35m5.0103\u001b[0m  6.6359\n",
      "      2        \u001b[36m4.9139\u001b[0m       0.4758        \u001b[35m4.7317\u001b[0m  6.6599\n",
      "      3        \u001b[36m4.5996\u001b[0m       \u001b[32m0.6685\u001b[0m        \u001b[35m4.4816\u001b[0m  6.7153\n",
      "      4        \u001b[36m4.4274\u001b[0m       \u001b[32m0.7589\u001b[0m        \u001b[35m4.3687\u001b[0m  6.4396\n",
      "      5        \u001b[36m4.3246\u001b[0m       \u001b[32m0.8063\u001b[0m        \u001b[35m4.2951\u001b[0m  6.4540\n",
      "      6        \u001b[36m4.2656\u001b[0m       \u001b[32m0.8384\u001b[0m        \u001b[35m4.2550\u001b[0m  6.3557\n",
      "      7        \u001b[36m4.2222\u001b[0m       \u001b[32m0.8609\u001b[0m        \u001b[35m4.2262\u001b[0m  6.3473\n",
      "      8        \u001b[36m4.1939\u001b[0m       \u001b[32m0.8685\u001b[0m        \u001b[35m4.2085\u001b[0m  6.4061\n",
      "      9        \u001b[36m4.1745\u001b[0m       \u001b[32m0.8874\u001b[0m        \u001b[35m4.1913\u001b[0m  6.2543\n",
      "     10        \u001b[36m4.1525\u001b[0m       \u001b[32m0.9043\u001b[0m        \u001b[35m4.1731\u001b[0m  6.3500\n",
      "     11        \u001b[36m4.1296\u001b[0m       \u001b[32m0.9156\u001b[0m        \u001b[35m4.1550\u001b[0m  6.3983\n",
      "     12        \u001b[36m4.1146\u001b[0m       \u001b[32m0.9189\u001b[0m        \u001b[35m4.1475\u001b[0m  6.3477\n",
      "     13        \u001b[36m4.1032\u001b[0m       \u001b[32m0.9225\u001b[0m        \u001b[35m4.1394\u001b[0m  6.3434\n",
      "     14        \u001b[36m4.0940\u001b[0m       \u001b[32m0.9232\u001b[0m        \u001b[35m4.1348\u001b[0m  6.2272\n",
      "     15        \u001b[36m4.0873\u001b[0m       \u001b[32m0.9275\u001b[0m        \u001b[35m4.1310\u001b[0m  6.2531\n",
      "     16        \u001b[36m4.0806\u001b[0m       \u001b[32m0.9288\u001b[0m        \u001b[35m4.1272\u001b[0m  6.2285\n",
      "     17        \u001b[36m4.0758\u001b[0m       \u001b[32m0.9348\u001b[0m        \u001b[35m4.1231\u001b[0m  6.1899\n",
      "     18        \u001b[36m4.0705\u001b[0m       \u001b[32m0.9354\u001b[0m        \u001b[35m4.1209\u001b[0m  6.2303\n",
      "     19        \u001b[36m4.0654\u001b[0m       0.9351        \u001b[35m4.1192\u001b[0m  6.2424\n",
      "     20        \u001b[36m4.0608\u001b[0m       \u001b[32m0.9358\u001b[0m        \u001b[35m4.1176\u001b[0m  6.2414\n",
      "     21        \u001b[36m4.0572\u001b[0m       \u001b[32m0.9381\u001b[0m        \u001b[35m4.1132\u001b[0m  6.2414\n",
      "     22        \u001b[36m4.0528\u001b[0m       \u001b[32m0.9394\u001b[0m        \u001b[35m4.1108\u001b[0m  6.2328\n",
      "     23        \u001b[36m4.0506\u001b[0m       \u001b[32m0.9414\u001b[0m        \u001b[35m4.1091\u001b[0m  6.2487\n",
      "     24        \u001b[36m4.0479\u001b[0m       \u001b[32m0.9427\u001b[0m        \u001b[35m4.1077\u001b[0m  6.3593\n",
      "     25        \u001b[36m4.0468\u001b[0m       \u001b[32m0.9430\u001b[0m        \u001b[35m4.1061\u001b[0m  6.3333\n",
      "     26        \u001b[36m4.0453\u001b[0m       \u001b[32m0.9450\u001b[0m        \u001b[35m4.1052\u001b[0m  6.2920\n",
      "     27        \u001b[36m4.0439\u001b[0m       0.9440        \u001b[35m4.1042\u001b[0m  6.3579\n",
      "     28        \u001b[36m4.0426\u001b[0m       0.9444        \u001b[35m4.1039\u001b[0m  6.2957\n",
      "     29        \u001b[36m4.0414\u001b[0m       0.9444        \u001b[35m4.1033\u001b[0m  6.3760\n",
      "     30        4.0416       \u001b[32m0.9457\u001b[0m        \u001b[35m4.1022\u001b[0m  6.3546\n",
      "     31        \u001b[36m4.0410\u001b[0m       0.9444        \u001b[35m4.1012\u001b[0m  6.3572\n",
      "     32        \u001b[36m4.0393\u001b[0m       \u001b[32m0.9467\u001b[0m        \u001b[35m4.1003\u001b[0m  6.3424\n",
      "     33        \u001b[36m4.0390\u001b[0m       0.9450        4.1006  6.3281\n",
      "     34        \u001b[36m4.0386\u001b[0m       0.9444        \u001b[35m4.1000\u001b[0m  6.3047\n",
      "     35        \u001b[36m4.0379\u001b[0m       0.9457        \u001b[35m4.0995\u001b[0m  6.3407\n",
      "     36        \u001b[36m4.0376\u001b[0m       \u001b[32m0.9470\u001b[0m        \u001b[35m4.0986\u001b[0m  6.3477\n",
      "     37        4.0376       0.9460        4.0987  6.3537\n",
      "     38        \u001b[36m4.0368\u001b[0m       0.9450        4.0994  6.3496\n",
      "     39        \u001b[36m4.0367\u001b[0m       0.9454        \u001b[35m4.0985\u001b[0m  6.4148\n",
      "     40        \u001b[36m4.0356\u001b[0m       0.9464        \u001b[35m4.0981\u001b[0m  6.3676\n",
      "     41        4.0363       0.9440        4.0983  6.3486\n",
      "     42        4.0357       0.9434        4.0982  6.3904\n",
      "     43        \u001b[36m4.0354\u001b[0m       0.9444        \u001b[35m4.0969\u001b[0m  6.3301\n",
      "     44        \u001b[36m4.0348\u001b[0m       0.9457        \u001b[35m4.0965\u001b[0m  6.3723\n",
      "     45        \u001b[36m4.0348\u001b[0m       0.9457        \u001b[35m4.0959\u001b[0m  6.3913\n",
      "     46        \u001b[36m4.0346\u001b[0m       0.9447        4.0961  6.3370\n",
      "     47        \u001b[36m4.0345\u001b[0m       0.9464        \u001b[35m4.0953\u001b[0m  6.4364\n",
      "     48        \u001b[36m4.0339\u001b[0m       0.9454        4.0959  6.4266\n",
      "     49        4.0343       0.9460        4.0955  6.3814\n",
      "     50        \u001b[36m4.0338\u001b[0m       0.9460        \u001b[35m4.0951\u001b[0m  6.3567\n",
      "     51        4.0339       0.9447        4.0955  6.3563\n",
      "     52        4.0339       0.9464        \u001b[35m4.0948\u001b[0m  6.3340\n",
      "     53        \u001b[36m4.0334\u001b[0m       0.9460        4.0948  6.3967\n",
      "     54        4.0334       0.9454        \u001b[35m4.0947\u001b[0m  6.3756\n",
      "     55        4.0335       0.9430        4.0952  6.3733\n",
      "     56        \u001b[36m4.0332\u001b[0m       0.9454        4.0953  6.3638\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "training accuracy\n",
      "{5: 0.9870860927152317}\n",
      "Val accuracy\n",
      "{5: 0.9066666666666666}\n",
      "pred time\n",
      "{5: 0.3598189353942871}\n",
      "OOS Val Accuracy\n",
      "{5: 0.3}\n",
      "OOS pred time\n",
      "{5: 0.010627985000610352}\n",
      "800\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0158\u001b[0m       \u001b[32m0.5513\u001b[0m        \u001b[35m5.0104\u001b[0m  6.2957\n",
      "      2        \u001b[36m4.9127\u001b[0m       0.4758        \u001b[35m4.7263\u001b[0m  6.3832\n",
      "      3        \u001b[36m4.5999\u001b[0m       \u001b[32m0.6768\u001b[0m        \u001b[35m4.4786\u001b[0m  6.3396\n",
      "      4        \u001b[36m4.4186\u001b[0m       \u001b[32m0.7646\u001b[0m        \u001b[35m4.3616\u001b[0m  6.3105\n",
      "      5        \u001b[36m4.3197\u001b[0m       \u001b[32m0.8202\u001b[0m        \u001b[35m4.2891\u001b[0m  6.3607\n",
      "      6        \u001b[36m4.2581\u001b[0m       \u001b[32m0.8407\u001b[0m        \u001b[35m4.2505\u001b[0m  6.3755\n",
      "      7        \u001b[36m4.2191\u001b[0m       \u001b[32m0.8596\u001b[0m        \u001b[35m4.2245\u001b[0m  6.3309\n",
      "      8        \u001b[36m4.1905\u001b[0m       \u001b[32m0.8715\u001b[0m        \u001b[35m4.2057\u001b[0m  6.3066\n",
      "      9        \u001b[36m4.1702\u001b[0m       \u001b[32m0.8848\u001b[0m        \u001b[35m4.1884\u001b[0m  6.2373\n",
      "     10        \u001b[36m4.1484\u001b[0m       \u001b[32m0.9000\u001b[0m        \u001b[35m4.1730\u001b[0m  6.2123\n",
      "     11        \u001b[36m4.1312\u001b[0m       \u001b[32m0.9076\u001b[0m        \u001b[35m4.1585\u001b[0m  6.2003\n",
      "     12        \u001b[36m4.1159\u001b[0m       \u001b[32m0.9119\u001b[0m        \u001b[35m4.1497\u001b[0m  6.2278\n",
      "     13        \u001b[36m4.1044\u001b[0m       \u001b[32m0.9146\u001b[0m        \u001b[35m4.1442\u001b[0m  6.2132\n",
      "     14        \u001b[36m4.0977\u001b[0m       \u001b[32m0.9156\u001b[0m        \u001b[35m4.1405\u001b[0m  6.2497\n",
      "     15        \u001b[36m4.0939\u001b[0m       \u001b[32m0.9172\u001b[0m        \u001b[35m4.1368\u001b[0m  6.3021\n",
      "     16        \u001b[36m4.0857\u001b[0m       \u001b[32m0.9235\u001b[0m        \u001b[35m4.1313\u001b[0m  6.3123\n",
      "     17        \u001b[36m4.0769\u001b[0m       \u001b[32m0.9305\u001b[0m        \u001b[35m4.1263\u001b[0m  6.2609\n",
      "     18        \u001b[36m4.0707\u001b[0m       \u001b[32m0.9318\u001b[0m        \u001b[35m4.1231\u001b[0m  6.2465\n",
      "     19        \u001b[36m4.0666\u001b[0m       \u001b[32m0.9325\u001b[0m        \u001b[35m4.1206\u001b[0m  6.3536\n",
      "     20        \u001b[36m4.0618\u001b[0m       \u001b[32m0.9354\u001b[0m        \u001b[35m4.1175\u001b[0m  6.3304\n",
      "     21        \u001b[36m4.0585\u001b[0m       \u001b[32m0.9358\u001b[0m        \u001b[35m4.1153\u001b[0m  6.3199\n",
      "     22        \u001b[36m4.0545\u001b[0m       \u001b[32m0.9391\u001b[0m        \u001b[35m4.1132\u001b[0m  6.3029\n",
      "     23        \u001b[36m4.0504\u001b[0m       \u001b[32m0.9401\u001b[0m        \u001b[35m4.1104\u001b[0m  6.2149\n",
      "     24        \u001b[36m4.0491\u001b[0m       \u001b[32m0.9430\u001b[0m        \u001b[35m4.1085\u001b[0m  6.1923\n",
      "     25        \u001b[36m4.0463\u001b[0m       0.9424        \u001b[35m4.1080\u001b[0m  6.3328\n",
      "     26        \u001b[36m4.0458\u001b[0m       \u001b[32m0.9434\u001b[0m        \u001b[35m4.1060\u001b[0m  6.3439\n",
      "     27        \u001b[36m4.0447\u001b[0m       \u001b[32m0.9437\u001b[0m        \u001b[35m4.1053\u001b[0m  6.3284\n",
      "     28        \u001b[36m4.0430\u001b[0m       \u001b[32m0.9444\u001b[0m        \u001b[35m4.1047\u001b[0m  6.3320\n",
      "     29        \u001b[36m4.0415\u001b[0m       0.9444        \u001b[35m4.1035\u001b[0m  6.3371\n",
      "     30        \u001b[36m4.0413\u001b[0m       0.9437        \u001b[35m4.1033\u001b[0m  6.3519\n",
      "     31        \u001b[36m4.0397\u001b[0m       0.9424        \u001b[35m4.1022\u001b[0m  6.3385\n",
      "     32        4.0398       \u001b[32m0.9457\u001b[0m        \u001b[35m4.1011\u001b[0m  6.3698\n",
      "     33        \u001b[36m4.0393\u001b[0m       0.9421        4.1012  6.3603\n",
      "     34        \u001b[36m4.0387\u001b[0m       0.9450        \u001b[35m4.1002\u001b[0m  6.3590\n",
      "     35        \u001b[36m4.0377\u001b[0m       0.9454        \u001b[35m4.0994\u001b[0m  6.3372\n",
      "     36        4.0380       \u001b[32m0.9460\u001b[0m        \u001b[35m4.0992\u001b[0m  6.3695\n",
      "     37        \u001b[36m4.0369\u001b[0m       0.9444        4.0994  6.3517\n",
      "     38        \u001b[36m4.0368\u001b[0m       0.9450        \u001b[35m4.0990\u001b[0m  6.3638\n",
      "     39        \u001b[36m4.0368\u001b[0m       0.9437        \u001b[35m4.0989\u001b[0m  6.3615\n",
      "     40        \u001b[36m4.0363\u001b[0m       0.9447        \u001b[35m4.0983\u001b[0m  6.3532\n",
      "     41        \u001b[36m4.0357\u001b[0m       \u001b[32m0.9467\u001b[0m        \u001b[35m4.0975\u001b[0m  6.4169\n",
      "     42        4.0361       \u001b[32m0.9470\u001b[0m        \u001b[35m4.0972\u001b[0m  6.3362\n",
      "     43        4.0358       0.9450        \u001b[35m4.0967\u001b[0m  6.3276\n",
      "     44        \u001b[36m4.0351\u001b[0m       \u001b[32m0.9474\u001b[0m        4.0967  6.2819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     45        \u001b[36m4.0349\u001b[0m       0.9434        4.0971  6.3108\n",
      "     46        \u001b[36m4.0348\u001b[0m       0.9447        \u001b[35m4.0961\u001b[0m  6.2760\n",
      "     47        \u001b[36m4.0345\u001b[0m       0.9460        \u001b[35m4.0955\u001b[0m  6.3619\n",
      "     48        \u001b[36m4.0343\u001b[0m       0.9454        \u001b[35m4.0954\u001b[0m  6.3100\n",
      "     49        4.0346       0.9460        4.0955  6.3138\n",
      "     50        \u001b[36m4.0338\u001b[0m       0.9457        \u001b[35m4.0954\u001b[0m  6.3144\n",
      "     51        4.0341       0.9447        4.0955  6.4639\n",
      "     52        \u001b[36m4.0335\u001b[0m       0.9430        \u001b[35m4.0953\u001b[0m  6.4119\n",
      "     53        \u001b[36m4.0335\u001b[0m       0.9464        \u001b[35m4.0941\u001b[0m  6.3548\n",
      "     54        4.0335       0.9454        \u001b[35m4.0940\u001b[0m  6.3701\n",
      "     55        4.0336       0.9460        \u001b[35m4.0937\u001b[0m  6.3463\n",
      "     56        \u001b[36m4.0331\u001b[0m       0.9464        \u001b[35m4.0937\u001b[0m  6.3704\n",
      "     57        4.0333       0.9450        4.0941  6.3888\n",
      "     58        \u001b[36m4.0330\u001b[0m       0.9447        4.0937  6.3430\n",
      "     59        \u001b[36m4.0328\u001b[0m       0.9460        4.0941  6.3557\n",
      "     60        4.0328       0.9454        4.0942  6.3447\n",
      "     61        4.0329       0.9470        4.0938  6.3282\n",
      "     62        \u001b[36m4.0326\u001b[0m       0.9447        4.0944  6.3835\n",
      "     63        4.0327       0.9444        4.0940  6.3357\n",
      "     64        \u001b[36m4.0325\u001b[0m       0.9444        4.0942  6.3469\n",
      "     65        \u001b[36m4.0324\u001b[0m       0.9464        \u001b[35m4.0927\u001b[0m  6.3295\n",
      "     66        \u001b[36m4.0323\u001b[0m       0.9444        4.0929  6.3774\n",
      "     67        4.0325       \u001b[32m0.9480\u001b[0m        \u001b[35m4.0924\u001b[0m  6.3240\n",
      "     68        \u001b[36m4.0323\u001b[0m       0.9437        4.0931  6.3380\n",
      "     69        \u001b[36m4.0320\u001b[0m       0.9437        4.0930  6.3421\n",
      "     70        4.0324       0.9440        4.0929  6.3805\n",
      "     71        4.0321       0.9454        4.0927  6.4392\n",
      "     72        \u001b[36m4.0318\u001b[0m       0.9444        4.0925  6.3734\n",
      "     73        4.0319       0.9434        4.0927  6.3785\n",
      "     74        4.0321       0.9450        4.0929  6.4028\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{5: 0.9870860927152317, 10: 0.9866887417218543}\n",
      "Val accuracy\n",
      "{5: 0.9066666666666666, 10: 0.909}\n",
      "pred time\n",
      "{5: 0.3598189353942871, 10: 0.38475608825683594}\n",
      "OOS Val Accuracy\n",
      "{5: 0.3, 10: 0.2}\n",
      "OOS pred time\n",
      "{5: 0.010627985000610352, 10: 0.01389002799987793}\n",
      "800\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0158\u001b[0m       \u001b[32m0.5589\u001b[0m        \u001b[35m5.0104\u001b[0m  6.3231\n",
      "      2        \u001b[36m4.9116\u001b[0m       0.4712        \u001b[35m4.7265\u001b[0m  6.3317\n",
      "      3        \u001b[36m4.6033\u001b[0m       \u001b[32m0.6808\u001b[0m        \u001b[35m4.4806\u001b[0m  6.3394\n",
      "      4        \u001b[36m4.4194\u001b[0m       \u001b[32m0.7629\u001b[0m        \u001b[35m4.3632\u001b[0m  6.3365\n",
      "      5        \u001b[36m4.3251\u001b[0m       \u001b[32m0.8182\u001b[0m        \u001b[35m4.2949\u001b[0m  6.4311\n",
      "      6        \u001b[36m4.2619\u001b[0m       \u001b[32m0.8401\u001b[0m        \u001b[35m4.2501\u001b[0m  6.3285\n",
      "      7        \u001b[36m4.2217\u001b[0m       \u001b[32m0.8553\u001b[0m        \u001b[35m4.2238\u001b[0m  6.2920\n",
      "      8        \u001b[36m4.1949\u001b[0m       \u001b[32m0.8656\u001b[0m        \u001b[35m4.2077\u001b[0m  6.2333\n",
      "      9        \u001b[36m4.1715\u001b[0m       \u001b[32m0.8927\u001b[0m        \u001b[35m4.1868\u001b[0m  6.2098\n",
      "     10        \u001b[36m4.1434\u001b[0m       \u001b[32m0.9083\u001b[0m        \u001b[35m4.1665\u001b[0m  6.1753\n",
      "     11        \u001b[36m4.1253\u001b[0m       \u001b[32m0.9116\u001b[0m        \u001b[35m4.1537\u001b[0m  6.2231\n",
      "     12        \u001b[36m4.1128\u001b[0m       \u001b[32m0.9132\u001b[0m        \u001b[35m4.1482\u001b[0m  6.2500\n",
      "     13        \u001b[36m4.1037\u001b[0m       \u001b[32m0.9175\u001b[0m        \u001b[35m4.1414\u001b[0m  6.2344\n",
      "     14        \u001b[36m4.0961\u001b[0m       \u001b[32m0.9205\u001b[0m        \u001b[35m4.1372\u001b[0m  6.2465\n",
      "     15        \u001b[36m4.0874\u001b[0m       \u001b[32m0.9291\u001b[0m        \u001b[35m4.1301\u001b[0m  6.2836\n",
      "     16        \u001b[36m4.0793\u001b[0m       0.9291        \u001b[35m4.1264\u001b[0m  6.2499\n",
      "     17        \u001b[36m4.0738\u001b[0m       \u001b[32m0.9341\u001b[0m        \u001b[35m4.1236\u001b[0m  6.2388\n",
      "     18        \u001b[36m4.0693\u001b[0m       0.9334        \u001b[35m4.1216\u001b[0m  6.2503\n",
      "     19        \u001b[36m4.0658\u001b[0m       0.9331        \u001b[35m4.1193\u001b[0m  6.2661\n",
      "     20        \u001b[36m4.0607\u001b[0m       \u001b[32m0.9364\u001b[0m        \u001b[35m4.1169\u001b[0m  6.3000\n",
      "     21        \u001b[36m4.0558\u001b[0m       \u001b[32m0.9377\u001b[0m        \u001b[35m4.1148\u001b[0m  6.2829\n",
      "     22        \u001b[36m4.0527\u001b[0m       \u001b[32m0.9391\u001b[0m        \u001b[35m4.1107\u001b[0m  6.2869\n",
      "     23        \u001b[36m4.0507\u001b[0m       \u001b[32m0.9421\u001b[0m        \u001b[35m4.1089\u001b[0m  6.3277\n",
      "     24        \u001b[36m4.0480\u001b[0m       0.9417        \u001b[35m4.1083\u001b[0m  6.5754\n",
      "     25        \u001b[36m4.0470\u001b[0m       0.9407        \u001b[35m4.1062\u001b[0m  6.5125\n",
      "     26        \u001b[36m4.0459\u001b[0m       0.9411        \u001b[35m4.1059\u001b[0m  6.3580\n",
      "     27        \u001b[36m4.0438\u001b[0m       \u001b[32m0.9434\u001b[0m        \u001b[35m4.1039\u001b[0m  6.3368\n",
      "     28        \u001b[36m4.0436\u001b[0m       0.9427        \u001b[35m4.1036\u001b[0m  6.3676\n",
      "     29        \u001b[36m4.0423\u001b[0m       0.9427        \u001b[35m4.1030\u001b[0m  6.3450\n",
      "     30        \u001b[36m4.0413\u001b[0m       0.9414        \u001b[35m4.1024\u001b[0m  6.3618\n",
      "     31        \u001b[36m4.0405\u001b[0m       \u001b[32m0.9450\u001b[0m        \u001b[35m4.1014\u001b[0m  6.3026\n",
      "     32        \u001b[36m4.0403\u001b[0m       0.9434        \u001b[35m4.1013\u001b[0m  6.3832\n",
      "     33        \u001b[36m4.0394\u001b[0m       0.9437        \u001b[35m4.1009\u001b[0m  6.3643\n",
      "     34        \u001b[36m4.0385\u001b[0m       \u001b[32m0.9460\u001b[0m        \u001b[35m4.1003\u001b[0m  6.3884\n",
      "     35        \u001b[36m4.0381\u001b[0m       \u001b[32m0.9474\u001b[0m        \u001b[35m4.0993\u001b[0m  6.3804\n",
      "     36        \u001b[36m4.0376\u001b[0m       0.9450        4.0994  6.3928\n",
      "     37        \u001b[36m4.0369\u001b[0m       0.9464        \u001b[35m4.0988\u001b[0m  6.3733\n",
      "     38        4.0373       0.9454        \u001b[35m4.0978\u001b[0m  6.4012\n",
      "     39        4.0371       0.9447        4.0980  6.4081\n",
      "     40        \u001b[36m4.0367\u001b[0m       0.9457        4.0985  6.3646\n",
      "     41        \u001b[36m4.0362\u001b[0m       0.9440        4.0982  6.3835\n",
      "     42        \u001b[36m4.0359\u001b[0m       0.9457        \u001b[35m4.0974\u001b[0m  6.3447\n",
      "     43        \u001b[36m4.0355\u001b[0m       0.9434        4.0980  6.2605\n",
      "     44        \u001b[36m4.0351\u001b[0m       0.9454        \u001b[35m4.0967\u001b[0m  6.3454\n",
      "     45        \u001b[36m4.0349\u001b[0m       0.9444        \u001b[35m4.0962\u001b[0m  6.3612\n",
      "     46        \u001b[36m4.0348\u001b[0m       0.9440        \u001b[35m4.0955\u001b[0m  6.3834\n",
      "     47        \u001b[36m4.0346\u001b[0m       0.9447        4.0959  6.3804\n",
      "     48        4.0347       0.9464        \u001b[35m4.0954\u001b[0m  6.3207\n",
      "     49        \u001b[36m4.0346\u001b[0m       0.9450        4.0958  6.3487\n",
      "     50        \u001b[36m4.0341\u001b[0m       0.9457        \u001b[35m4.0946\u001b[0m  6.3374\n",
      "     51        \u001b[36m4.0340\u001b[0m       0.9457        4.0951  6.3317\n",
      "     52        \u001b[36m4.0339\u001b[0m       0.9464        4.0948  6.4243\n",
      "     53        4.0339       0.9467        \u001b[35m4.0942\u001b[0m  6.3536\n",
      "     54        \u001b[36m4.0334\u001b[0m       0.9454        \u001b[35m4.0940\u001b[0m  6.3435\n",
      "     55        \u001b[36m4.0333\u001b[0m       \u001b[32m0.9477\u001b[0m        \u001b[35m4.0940\u001b[0m  6.3499\n",
      "     56        \u001b[36m4.0330\u001b[0m       0.9450        4.0942  6.3646\n",
      "     57        \u001b[36m4.0329\u001b[0m       0.9474        \u001b[35m4.0937\u001b[0m  6.3556\n",
      "     58        \u001b[36m4.0329\u001b[0m       \u001b[32m0.9483\u001b[0m        \u001b[35m4.0935\u001b[0m  6.3894\n",
      "     59        4.0331       0.9477        4.0940  6.4255\n",
      "     60        4.0330       0.9480        \u001b[35m4.0932\u001b[0m  6.3862\n",
      "     61        \u001b[36m4.0327\u001b[0m       0.9457        4.0934  6.3560\n",
      "     62        4.0327       0.9454        \u001b[35m4.0931\u001b[0m  6.3624\n",
      "     63        \u001b[36m4.0326\u001b[0m       0.9440        \u001b[35m4.0927\u001b[0m  6.3432\n",
      "     64        \u001b[36m4.0325\u001b[0m       0.9447        4.0937  6.3938\n",
      "     65        4.0325       0.9444        4.0937  6.3398\n",
      "     66        \u001b[36m4.0322\u001b[0m       0.9457        \u001b[35m4.0926\u001b[0m  6.4417\n",
      "     67        4.0323       0.9477        \u001b[35m4.0919\u001b[0m  6.4735\n",
      "     68        4.0322       0.9450        4.0923  6.4194\n",
      "     69        \u001b[36m4.0322\u001b[0m       0.9460        4.0921  6.3970\n",
      "     70        \u001b[36m4.0321\u001b[0m       0.9444        4.0926  6.5512\n",
      "     71        4.0323       0.9454        \u001b[35m4.0918\u001b[0m  6.4510\n",
      "     72        \u001b[36m4.0319\u001b[0m       0.9467        \u001b[35m4.0915\u001b[0m  6.4172\n",
      "     73        \u001b[36m4.0318\u001b[0m       0.9437        4.0929  6.4253\n",
      "     74        \u001b[36m4.0318\u001b[0m       0.9440        4.0929  6.3985\n",
      "     75        4.0318       0.9447        4.0923  6.3501\n",
      "     76        \u001b[36m4.0317\u001b[0m       0.9434        4.0923  6.3688\n",
      "     77        \u001b[36m4.0316\u001b[0m       0.9437        4.0920  6.4386\n",
      "     78        4.0316       0.9447        4.0918  6.4000\n",
      "     79        \u001b[36m4.0316\u001b[0m       0.9454        4.0919  6.3735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     80        4.0317       0.9444        4.0926  6.3438\n",
      "     81        4.0316       0.9450        4.0922  6.3974\n",
      "     82        \u001b[36m4.0315\u001b[0m       0.9427        4.0926  6.3608\n",
      "     83        \u001b[36m4.0314\u001b[0m       0.9444        4.0922  6.4344\n",
      "     84        4.0315       0.9440        4.0921  6.4697\n",
      "     85        4.0315       0.9440        4.0924  6.4249\n",
      "     86        4.0314       0.9440        4.0920  6.4089\n",
      "     87        \u001b[36m4.0313\u001b[0m       0.9467        4.0917  6.3463\n",
      "     88        \u001b[36m4.0310\u001b[0m       0.9460        \u001b[35m4.0913\u001b[0m  6.4175\n",
      "     89        4.0313       0.9444        4.0920  6.3947\n",
      "     90        4.0311       0.9437        4.0922  6.4943\n",
      "     91        4.0312       0.9444        \u001b[35m4.0913\u001b[0m  6.4630\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "training accuracy\n",
      "{5: 0.9870860927152317, 10: 0.9866887417218543, 20: 0.9874834437086093}\n",
      "Val accuracy\n",
      "{5: 0.9066666666666666, 10: 0.909, 20: 0.9066666666666666}\n",
      "pred time\n",
      "{5: 0.3598189353942871, 10: 0.38475608825683594, 20: 0.3568098545074463}\n",
      "OOS Val Accuracy\n",
      "{5: 0.3, 10: 0.2, 20: 0.2}\n",
      "OOS pred time\n",
      "{5: 0.010627985000610352, 10: 0.01389002799987793, 20: 0.010986089706420898}\n",
      "800\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0158\u001b[0m       \u001b[32m0.4583\u001b[0m        \u001b[35m5.0102\u001b[0m  6.4073\n",
      "      2        \u001b[36m4.9134\u001b[0m       \u001b[32m0.4748\u001b[0m        \u001b[35m4.7340\u001b[0m  6.3823\n",
      "      3        \u001b[36m4.6019\u001b[0m       \u001b[32m0.6669\u001b[0m        \u001b[35m4.4808\u001b[0m  6.3375\n",
      "      4        \u001b[36m4.4244\u001b[0m       \u001b[32m0.7579\u001b[0m        \u001b[35m4.3676\u001b[0m  6.3496\n",
      "      5        \u001b[36m4.3251\u001b[0m       \u001b[32m0.8109\u001b[0m        \u001b[35m4.2935\u001b[0m  6.2934\n",
      "      6        \u001b[36m4.2621\u001b[0m       \u001b[32m0.8364\u001b[0m        \u001b[35m4.2533\u001b[0m  6.7155\n",
      "      7        \u001b[36m4.2248\u001b[0m       \u001b[32m0.8536\u001b[0m        \u001b[35m4.2287\u001b[0m  6.4959\n",
      "      8        \u001b[36m4.1978\u001b[0m       \u001b[32m0.8613\u001b[0m        \u001b[35m4.2118\u001b[0m  6.2673\n",
      "      9        \u001b[36m4.1752\u001b[0m       \u001b[32m0.8808\u001b[0m        \u001b[35m4.1918\u001b[0m  6.2801\n",
      "     10        \u001b[36m4.1525\u001b[0m       \u001b[32m0.9003\u001b[0m        \u001b[35m4.1718\u001b[0m  6.2968\n",
      "     11        \u001b[36m4.1337\u001b[0m       \u001b[32m0.9046\u001b[0m        \u001b[35m4.1610\u001b[0m  6.3523\n",
      "     12        \u001b[36m4.1202\u001b[0m       \u001b[32m0.9093\u001b[0m        \u001b[35m4.1535\u001b[0m  6.2042\n",
      "     13        \u001b[36m4.1100\u001b[0m       \u001b[32m0.9146\u001b[0m        \u001b[35m4.1457\u001b[0m  6.2219\n",
      "     14        \u001b[36m4.1009\u001b[0m       \u001b[32m0.9162\u001b[0m        \u001b[35m4.1412\u001b[0m  6.2461\n",
      "     15        \u001b[36m4.0949\u001b[0m       \u001b[32m0.9175\u001b[0m        \u001b[35m4.1376\u001b[0m  6.2667\n",
      "     16        \u001b[36m4.0909\u001b[0m       \u001b[32m0.9202\u001b[0m        \u001b[35m4.1358\u001b[0m  6.2577\n",
      "     17        \u001b[36m4.0852\u001b[0m       \u001b[32m0.9228\u001b[0m        \u001b[35m4.1334\u001b[0m  6.2659\n",
      "     18        \u001b[36m4.0801\u001b[0m       \u001b[32m0.9245\u001b[0m        \u001b[35m4.1306\u001b[0m  6.2535\n",
      "     19        \u001b[36m4.0742\u001b[0m       \u001b[32m0.9281\u001b[0m        \u001b[35m4.1270\u001b[0m  6.4551\n",
      "     20        \u001b[36m4.0678\u001b[0m       \u001b[32m0.9325\u001b[0m        \u001b[35m4.1217\u001b[0m  6.3069\n",
      "     21        \u001b[36m4.0626\u001b[0m       \u001b[32m0.9338\u001b[0m        \u001b[35m4.1187\u001b[0m  6.2893\n",
      "     22        \u001b[36m4.0597\u001b[0m       \u001b[32m0.9351\u001b[0m        \u001b[35m4.1154\u001b[0m  6.3018\n",
      "     23        \u001b[36m4.0567\u001b[0m       \u001b[32m0.9371\u001b[0m        \u001b[35m4.1138\u001b[0m  6.3141\n",
      "     24        \u001b[36m4.0541\u001b[0m       0.9371        \u001b[35m4.1121\u001b[0m  6.3313\n",
      "     25        \u001b[36m4.0525\u001b[0m       0.9364        \u001b[35m4.1116\u001b[0m  6.3131\n",
      "     26        \u001b[36m4.0515\u001b[0m       \u001b[32m0.9377\u001b[0m        \u001b[35m4.1097\u001b[0m  6.3570\n",
      "     27        \u001b[36m4.0501\u001b[0m       0.9358        4.1099  6.3194\n",
      "     28        \u001b[36m4.0488\u001b[0m       0.9371        \u001b[35m4.1089\u001b[0m  6.3217\n",
      "     29        \u001b[36m4.0485\u001b[0m       \u001b[32m0.9381\u001b[0m        \u001b[35m4.1078\u001b[0m  6.3223\n",
      "     30        \u001b[36m4.0467\u001b[0m       0.9368        \u001b[35m4.1073\u001b[0m  6.3559\n",
      "     31        \u001b[36m4.0463\u001b[0m       0.9374        4.1080  6.3156\n",
      "     32        \u001b[36m4.0436\u001b[0m       \u001b[32m0.9407\u001b[0m        \u001b[35m4.1056\u001b[0m  6.3358\n",
      "     33        \u001b[36m4.0415\u001b[0m       0.9404        \u001b[35m4.1050\u001b[0m  6.3378\n",
      "     34        \u001b[36m4.0406\u001b[0m       0.9394        \u001b[35m4.1046\u001b[0m  6.3282\n",
      "     35        \u001b[36m4.0397\u001b[0m       0.9387        \u001b[35m4.1037\u001b[0m  6.3686\n",
      "     36        \u001b[36m4.0393\u001b[0m       \u001b[32m0.9414\u001b[0m        \u001b[35m4.1025\u001b[0m  6.3234\n",
      "     37        \u001b[36m4.0386\u001b[0m       0.9414        \u001b[35m4.1017\u001b[0m  6.3403\n",
      "     38        \u001b[36m4.0379\u001b[0m       0.9414        \u001b[35m4.1010\u001b[0m  6.3228\n",
      "     39        \u001b[36m4.0376\u001b[0m       0.9407        \u001b[35m4.1009\u001b[0m  6.3541\n",
      "     40        \u001b[36m4.0374\u001b[0m       0.9414        4.1011  6.3650\n",
      "     41        \u001b[36m4.0371\u001b[0m       0.9411        \u001b[35m4.1007\u001b[0m  6.3589\n",
      "     42        \u001b[36m4.0364\u001b[0m       \u001b[32m0.9437\u001b[0m        \u001b[35m4.0996\u001b[0m  6.3553\n",
      "     43        4.0365       0.9407        4.1009  6.3347\n",
      "     44        \u001b[36m4.0360\u001b[0m       0.9421        4.0998  6.2916\n",
      "     45        \u001b[36m4.0357\u001b[0m       0.9434        \u001b[35m4.0988\u001b[0m  6.2931\n",
      "     46        \u001b[36m4.0351\u001b[0m       0.9424        \u001b[35m4.0985\u001b[0m  6.3666\n",
      "     47        4.0353       0.9424        \u001b[35m4.0982\u001b[0m  6.3626\n",
      "     48        \u001b[36m4.0345\u001b[0m       0.9430        \u001b[35m4.0977\u001b[0m  6.3674\n",
      "     49        4.0348       0.9411        4.0984  6.4057\n",
      "     50        \u001b[36m4.0341\u001b[0m       \u001b[32m0.9447\u001b[0m        \u001b[35m4.0967\u001b[0m  6.3601\n",
      "     51        \u001b[36m4.0341\u001b[0m       0.9421        4.0969  6.3593\n",
      "     52        4.0343       0.9430        4.0974  6.3809\n",
      "     53        4.0341       \u001b[32m0.9454\u001b[0m        \u001b[35m4.0960\u001b[0m  6.3778\n",
      "     54        4.0341       0.9434        4.0961  5.7559\n",
      "     55        \u001b[36m4.0334\u001b[0m       0.9427        4.0965  6.2620\n",
      "     56        4.0335       0.9430        4.0965  6.3812\n",
      "     57        \u001b[36m4.0333\u001b[0m       0.9417        4.0968  6.4097\n",
      "     58        \u001b[36m4.0331\u001b[0m       0.9411        4.0970  6.3710\n",
      "     59        \u001b[36m4.0330\u001b[0m       0.9424        \u001b[35m4.0958\u001b[0m  6.3687\n",
      "     60        4.0332       0.9407        4.0962  6.4016\n",
      "     61        4.0330       0.9411        4.0966  6.4241\n",
      "     62        \u001b[36m4.0329\u001b[0m       0.9430        \u001b[35m4.0955\u001b[0m  6.3834\n",
      "     63        4.0331       0.9427        4.0957  6.4149\n",
      "     64        \u001b[36m4.0327\u001b[0m       0.9440        \u001b[35m4.0948\u001b[0m  6.4023\n",
      "     65        4.0327       0.9437        4.0954  6.4038\n",
      "     66        \u001b[36m4.0326\u001b[0m       0.9437        \u001b[35m4.0946\u001b[0m  6.3288\n",
      "     67        \u001b[36m4.0325\u001b[0m       0.9440        4.0948  6.4098\n",
      "     68        \u001b[36m4.0325\u001b[0m       0.9447        \u001b[35m4.0945\u001b[0m  6.3746\n",
      "     69        4.0325       0.9424        4.0953  6.4198\n",
      "     70        4.0325       0.9411        4.0948  6.4252\n",
      "     71        \u001b[36m4.0322\u001b[0m       0.9421        \u001b[35m4.0944\u001b[0m  6.4532\n",
      "     72        \u001b[36m4.0320\u001b[0m       0.9434        \u001b[35m4.0941\u001b[0m  6.3896\n",
      "     73        4.0322       0.9421        4.0942  6.4018\n",
      "     74        \u001b[36m4.0319\u001b[0m       0.9427        \u001b[35m4.0939\u001b[0m  6.3962\n",
      "     75        4.0322       0.9427        4.0947  6.4550\n",
      "     76        4.0320       0.9440        \u001b[35m4.0933\u001b[0m  6.3801\n",
      "     77        4.0322       0.9440        \u001b[35m4.0930\u001b[0m  6.3945\n",
      "     78        \u001b[36m4.0319\u001b[0m       0.9434        4.0933  6.4072\n",
      "     79        4.0319       0.9447        4.0933  6.3823\n",
      "     80        4.0320       0.9427        4.0934  6.4034\n",
      "     81        \u001b[36m4.0316\u001b[0m       0.9424        4.0937  6.3710\n",
      "     82        4.0318       0.9421        4.0940  6.4306\n",
      "     83        4.0318       0.9444        \u001b[35m4.0929\u001b[0m  6.4311\n",
      "     84        4.0318       0.9427        4.0932  6.4286\n",
      "     85        4.0318       0.9411        4.0941  6.4253\n",
      "     86        \u001b[36m4.0316\u001b[0m       0.9430        4.0930  6.4407\n",
      "     87        4.0316       0.9440        \u001b[35m4.0926\u001b[0m  6.4779\n",
      "     88        4.0317       0.9440        4.0937  6.4099\n",
      "     89        4.0317       0.9450        4.0931  6.4804\n",
      "     90        \u001b[36m4.0316\u001b[0m       0.9437        4.0935  6.4805\n",
      "     91        \u001b[36m4.0315\u001b[0m       0.9447        \u001b[35m4.0925\u001b[0m  6.4396\n",
      "     92        \u001b[36m4.0313\u001b[0m       0.9447        4.0932  6.4296\n",
      "     93        4.0314       0.9430        4.0931  6.3747\n",
      "     94        4.0315       0.9417        4.0932  6.4525\n",
      "     95        4.0316       0.9454        \u001b[35m4.0918\u001b[0m  6.4238\n",
      "     96        \u001b[36m4.0313\u001b[0m       0.9430        4.0925  6.4123\n",
      "     97        4.0313       0.9421        4.0934  6.4800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     98        4.0313       0.9424        4.0942  6.4377\n",
      "     99        4.0315       0.9454        4.0926  6.4622\n",
      "    100        4.0313       0.9417        4.0944  6.4508\n",
      "    101        4.0313       0.9407        4.0935  6.4371\n",
      "    102        \u001b[36m4.0312\u001b[0m       0.9434        4.0934  6.3857\n",
      "    103        \u001b[36m4.0312\u001b[0m       0.9447        4.0931  6.4095\n",
      "    104        4.0312       0.9404        4.0944  6.4063\n",
      "    105        \u001b[36m4.0311\u001b[0m       0.9417        4.0934  6.6744\n",
      "    106        4.0311       0.9414        4.0933  6.4796\n",
      "    107        \u001b[36m4.0311\u001b[0m       0.9421        4.0931  6.4586\n",
      "    108        4.0312       0.9427        4.0921  6.4424\n",
      "    109        4.0311       0.9421        4.0923  6.4655\n",
      "    110        \u001b[36m4.0309\u001b[0m       0.9434        4.0928  6.4930\n",
      "    111        4.0311       0.9401        4.0935  6.4812\n",
      "    112        4.0311       0.9427        4.0924  6.4479\n",
      "    113        4.0310       0.9430        4.0920  6.4530\n",
      "    114        4.0310       0.9424        4.0930  6.4413\n",
      "    115        4.0310       0.9430        4.0920  6.4510\n",
      "    116        4.0311       0.9444        \u001b[35m4.0917\u001b[0m  6.4425\n",
      "    117        4.0309       0.9414        4.0922  6.4590\n",
      "    118        \u001b[36m4.0308\u001b[0m       0.9430        \u001b[35m4.0917\u001b[0m  6.4357\n",
      "    119        \u001b[36m4.0308\u001b[0m       0.9424        \u001b[35m4.0916\u001b[0m  6.4779\n",
      "    120        4.0308       0.9437        \u001b[35m4.0913\u001b[0m  6.4414\n",
      "    121        4.0309       0.9454        \u001b[35m4.0910\u001b[0m  6.4508\n",
      "    122        4.0308       0.9427        4.0917  6.4875\n",
      "    123        4.0308       0.9417        4.0921  6.4725\n",
      "    124        4.0308       0.9430        4.0919  6.4213\n",
      "    125        4.0309       0.9434        4.0918  6.5006\n",
      "    126        4.0308       0.9427        4.0924  6.4357\n",
      "    127        4.0310       0.9444        4.0917  6.4332\n",
      "    128        4.0308       0.9430        4.0920  6.4520\n",
      "    129        4.0309       0.9430        4.0919  6.4608\n",
      "    130        \u001b[36m4.0307\u001b[0m       0.9414        4.0925  6.4635\n",
      "    131        4.0310       0.9411        4.0922  6.5506\n",
      "    132        \u001b[36m4.0307\u001b[0m       0.9417        4.0922  6.4646\n",
      "    133        4.0309       0.9401        4.0930  6.5319\n",
      "    134        \u001b[36m4.0306\u001b[0m       0.9407        4.0930  6.5865\n",
      "    135        \u001b[36m4.0305\u001b[0m       0.9421        4.0927  6.4647\n",
      "    136        4.0306       0.9401        4.0930  6.5098\n",
      "    137        4.0306       0.9381        4.0939  6.2958\n",
      "    138        4.0306       0.9411        4.0930  6.4979\n",
      "    139        4.0307       0.9411        4.0923  6.4803\n",
      "    140        4.0306       0.9407        4.0921  6.4944\n",
      "    141        4.0307       0.9404        4.0927  6.5599\n",
      "    142        4.0307       0.9387        4.0941  6.4762\n",
      "    143        4.0306       0.9401        4.0936  6.4878\n",
      "    144        4.0307       0.9404        4.0930  6.4674\n",
      "    145        4.0307       0.9411        4.0922  6.4394\n",
      "    146        4.0307       0.9401        4.0933  6.5211\n",
      "    147        4.0307       0.9404        4.0927  6.5090\n",
      "    148        4.0307       0.9404        4.0932  6.5028\n",
      "    149        4.0306       0.9391        4.0929  6.4715\n",
      "    150        4.0306       0.9397        4.0926  6.4832\n",
      "    151        4.0306       0.9401        4.0931  6.4797\n",
      "    152        4.0306       0.9391        4.0930  6.4632\n",
      "    153        4.0306       0.9391        4.0933  6.4420\n",
      "    154        \u001b[36m4.0305\u001b[0m       0.9364        4.0944  6.4418\n",
      "    155        4.0306       0.9384        4.0933  6.5020\n",
      "    156        4.0305       0.9374        4.0937  6.4702\n",
      "    157        4.0306       0.9384        4.0934  6.4310\n",
      "    158        4.0306       0.9394        4.0924  6.4560\n",
      "    159        \u001b[36m4.0305\u001b[0m       0.9411        4.0922  6.5139\n",
      "    160        4.0305       0.9414        4.0918  6.4486\n",
      "    161        4.0305       0.9424        4.0917  6.4398\n",
      "    162        4.0305       0.9427        4.0919  6.4477\n",
      "    163        4.0307       0.9394        4.0933  6.4166\n",
      "    164        4.0306       0.9387        4.0937  6.4718\n",
      "    165        4.0306       0.9387        4.0931  6.4665\n",
      "    166        4.0306       0.9384        4.0933  6.4420\n",
      "    167        4.0305       0.9394        4.0931  6.5180\n",
      "    168        4.0306       0.9421        4.0915  6.4718\n",
      "    169        4.0305       0.9414        4.0919  6.5034\n",
      "Stopping since valid_loss has not improved in the last 50 epochs.\n",
      "training accuracy\n",
      "{5: 0.9870860927152317, 10: 0.9866887417218543, 20: 0.9874834437086093, 50: 0.9872185430463576}\n",
      "Val accuracy\n",
      "{5: 0.9066666666666666, 10: 0.909, 20: 0.9066666666666666, 50: 0.904}\n",
      "pred time\n",
      "{5: 0.3598189353942871, 10: 0.38475608825683594, 20: 0.3568098545074463, 50: 0.37584996223449707}\n",
      "OOS Val Accuracy\n",
      "{5: 0.3, 10: 0.2, 20: 0.2, 50: 0.13}\n",
      "OOS pred time\n",
      "{5: 0.010627985000610352, 10: 0.01389002799987793, 20: 0.010986089706420898, 50: 0.010825872421264648}\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "hidden_dim = 800 #hidden layer size\n",
    "dropout = 0.75\n",
    "patience_list = [5, 10, 20, 50]\n",
    "for patience in patience_list:    #looping for patience\n",
    "    print(hidden_dim)\n",
    "    class CLINCModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                input_dim=vocab_dim,\n",
    "                hidden_dim=hidden_dim, #setting hidden layer size\n",
    "                output_dim=output_dim,\n",
    "                dropout=dropout\n",
    "        ):\n",
    "            super(CLINCModule, self).__init__()\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "            self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = F.relu(self.hidden(X))\n",
    "            X = self.dropout(X)\n",
    "            X = F.softmax(self.output(X), dim=-1)\n",
    "            return X\n",
    "   \n",
    "    net = NeuralNetClassifier(\n",
    "    module=CLINCModule,\n",
    "    lr=lr,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    max_epochs=1000,\n",
    "    optimizer=torch.optim.Adam, \n",
    "    callbacks=[EarlyStopping(patience=patience)], #setting patience \n",
    "    )\n",
    "    \n",
    "    net.fit(train_x, train_y)\n",
    "    tlabels = net.predict(train_x)\n",
    "    tacc[patience] = accuracy_score(tlabels, train_y)\n",
    "    print('training accuracy')\n",
    "    print(tacc)\n",
    "    time0 = time.time()\n",
    "    labels = net.predict(val_x)\n",
    "    vacc[patience] = accuracy_score(labels, val_y)\n",
    "    time1 = time.time()\n",
    "    vtime[patience] = time1-time0\n",
    "    print('Val accuracy')\n",
    "    print(vacc)\n",
    "    print('pred time')\n",
    "    print(vtime)\n",
    "    time2 = time.time()\n",
    "    olabels = net.predict(val_oos_x)\n",
    "    oacc[patience] = accuracy_score(olabels, val_oos_y)\n",
    "    time3 = time.time()\n",
    "    otime[patience]=time3-time2\n",
    "    print('OOS Val Accuracy')\n",
    "    print(oacc)\n",
    "    print('OOS pred time')\n",
    "    print(otime)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best value for patience of 10 Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No early stopping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0158\u001b[0m       \u001b[32m0.5123\u001b[0m        \u001b[35m5.0102\u001b[0m  6.3291\n",
      "      2        \u001b[36m4.9124\u001b[0m       0.4752        \u001b[35m4.7288\u001b[0m  6.2838\n",
      "      3        \u001b[36m4.5918\u001b[0m       \u001b[32m0.6871\u001b[0m        \u001b[35m4.4679\u001b[0m  6.2390\n",
      "      4        \u001b[36m4.4122\u001b[0m       \u001b[32m0.7709\u001b[0m        \u001b[35m4.3588\u001b[0m  6.2377\n",
      "      5        \u001b[36m4.3182\u001b[0m       \u001b[32m0.8123\u001b[0m        \u001b[35m4.2924\u001b[0m  6.2310\n",
      "      6        \u001b[36m4.2627\u001b[0m       \u001b[32m0.8258\u001b[0m        \u001b[35m4.2583\u001b[0m  6.2400\n",
      "      7        \u001b[36m4.2282\u001b[0m       \u001b[32m0.8474\u001b[0m        \u001b[35m4.2322\u001b[0m  6.2204\n",
      "      8        \u001b[36m4.2028\u001b[0m       \u001b[32m0.8579\u001b[0m        \u001b[35m4.2155\u001b[0m  6.1701\n",
      "      9        \u001b[36m4.1816\u001b[0m       \u001b[32m0.8705\u001b[0m        \u001b[35m4.2000\u001b[0m  6.1621\n",
      "     10        \u001b[36m4.1614\u001b[0m       \u001b[32m0.8950\u001b[0m        \u001b[35m4.1813\u001b[0m  6.1194\n",
      "     11        \u001b[36m4.1372\u001b[0m       \u001b[32m0.9076\u001b[0m        \u001b[35m4.1617\u001b[0m  6.1333\n",
      "     12        \u001b[36m4.1199\u001b[0m       \u001b[32m0.9132\u001b[0m        \u001b[35m4.1513\u001b[0m  6.1468\n",
      "     13        \u001b[36m4.1096\u001b[0m       \u001b[32m0.9159\u001b[0m        \u001b[35m4.1455\u001b[0m  6.1595\n",
      "     14        \u001b[36m4.1006\u001b[0m       \u001b[32m0.9172\u001b[0m        \u001b[35m4.1386\u001b[0m  6.2133\n",
      "     15        \u001b[36m4.0922\u001b[0m       \u001b[32m0.9219\u001b[0m        \u001b[35m4.1350\u001b[0m  6.1740\n",
      "     16        \u001b[36m4.0857\u001b[0m       \u001b[32m0.9321\u001b[0m        \u001b[35m4.1284\u001b[0m  6.1740\n",
      "     17        \u001b[36m4.0763\u001b[0m       \u001b[32m0.9331\u001b[0m        \u001b[35m4.1255\u001b[0m  6.2482\n",
      "     18        \u001b[36m4.0723\u001b[0m       0.9318        \u001b[35m4.1223\u001b[0m  6.1989\n",
      "     19        \u001b[36m4.0676\u001b[0m       0.9331        \u001b[35m4.1201\u001b[0m  6.2283\n",
      "     20        \u001b[36m4.0624\u001b[0m       \u001b[32m0.9354\u001b[0m        \u001b[35m4.1179\u001b[0m  6.2026\n",
      "     21        \u001b[36m4.0587\u001b[0m       \u001b[32m0.9391\u001b[0m        \u001b[35m4.1140\u001b[0m  6.2253\n",
      "     22        \u001b[36m4.0549\u001b[0m       \u001b[32m0.9397\u001b[0m        \u001b[35m4.1125\u001b[0m  6.3206\n",
      "     23        \u001b[36m4.0510\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m4.1097\u001b[0m  6.2483\n",
      "     24        \u001b[36m4.0487\u001b[0m       0.9421        \u001b[35m4.1079\u001b[0m  6.2346\n",
      "     25        \u001b[36m4.0474\u001b[0m       0.9407        \u001b[35m4.1069\u001b[0m  6.2940\n",
      "     26        \u001b[36m4.0453\u001b[0m       0.9424        \u001b[35m4.1060\u001b[0m  6.2514\n",
      "     27        \u001b[36m4.0446\u001b[0m       \u001b[32m0.9437\u001b[0m        \u001b[35m4.1045\u001b[0m  6.3243\n",
      "     28        \u001b[36m4.0440\u001b[0m       0.9434        \u001b[35m4.1036\u001b[0m  6.3227\n",
      "     29        \u001b[36m4.0426\u001b[0m       0.9394        \u001b[35m4.1033\u001b[0m  6.3121\n",
      "     30        \u001b[36m4.0415\u001b[0m       0.9427        \u001b[35m4.1019\u001b[0m  6.2884\n",
      "     31        \u001b[36m4.0411\u001b[0m       \u001b[32m0.9450\u001b[0m        \u001b[35m4.1013\u001b[0m  6.2610\n",
      "     32        \u001b[36m4.0400\u001b[0m       0.9440        4.1015  6.2881\n",
      "     33        \u001b[36m4.0392\u001b[0m       \u001b[32m0.9454\u001b[0m        \u001b[35m4.1003\u001b[0m  6.2949\n",
      "     34        \u001b[36m4.0391\u001b[0m       0.9444        \u001b[35m4.1002\u001b[0m  6.2828\n",
      "     35        \u001b[36m4.0386\u001b[0m       0.9444        4.1004  6.2720\n",
      "     36        \u001b[36m4.0379\u001b[0m       0.9427        \u001b[35m4.1001\u001b[0m  6.3430\n",
      "     37        4.0381       0.9437        \u001b[35m4.0999\u001b[0m  6.3191\n",
      "     38        \u001b[36m4.0375\u001b[0m       0.9444        \u001b[35m4.0989\u001b[0m  6.2955\n",
      "     39        \u001b[36m4.0369\u001b[0m       0.9424        \u001b[35m4.0980\u001b[0m  6.3012\n",
      "     40        \u001b[36m4.0365\u001b[0m       0.9430        \u001b[35m4.0978\u001b[0m  6.2826\n",
      "     41        \u001b[36m4.0362\u001b[0m       0.9427        4.0983  6.2985\n",
      "     42        \u001b[36m4.0358\u001b[0m       0.9434        4.0987  6.2938\n",
      "     43        \u001b[36m4.0357\u001b[0m       \u001b[32m0.9460\u001b[0m        \u001b[35m4.0976\u001b[0m  6.2918\n",
      "     44        \u001b[36m4.0353\u001b[0m       0.9450        \u001b[35m4.0971\u001b[0m  6.2694\n",
      "     45        \u001b[36m4.0349\u001b[0m       0.9437        \u001b[35m4.0964\u001b[0m  6.2954\n",
      "     46        \u001b[36m4.0345\u001b[0m       0.9447        4.0969  6.3092\n",
      "     47        4.0345       0.9447        4.0964  6.2958\n",
      "     48        4.0347       0.9460        \u001b[35m4.0960\u001b[0m  6.3183\n",
      "     49        \u001b[36m4.0344\u001b[0m       0.9447        4.0961  6.3207\n",
      "     50        \u001b[36m4.0343\u001b[0m       0.9444        \u001b[35m4.0956\u001b[0m  6.2882\n",
      "     51        \u001b[36m4.0337\u001b[0m       0.9457        \u001b[35m4.0950\u001b[0m  6.2948\n",
      "     52        4.0339       0.9454        4.0953  6.3332\n",
      "     53        \u001b[36m4.0335\u001b[0m       0.9450        4.0953  6.3140\n",
      "     54        4.0337       0.9447        4.0952  6.3590\n",
      "     55        \u001b[36m4.0334\u001b[0m       0.9430        4.0957  6.3726\n",
      "     56        \u001b[36m4.0328\u001b[0m       0.9427        4.0955  6.3174\n",
      "     57        4.0332       0.9457        \u001b[35m4.0941\u001b[0m  6.2990\n",
      "     58        \u001b[36m4.0326\u001b[0m       0.9437        4.0950  6.3156\n",
      "     59        4.0330       0.9424        4.0948  6.3181\n",
      "     60        4.0328       0.9427        4.0949  6.3087\n",
      "     61        4.0328       0.9457        4.0946  6.3037\n",
      "     62        4.0326       0.9454        4.0945  6.2929\n",
      "     63        \u001b[36m4.0325\u001b[0m       \u001b[32m0.9464\u001b[0m        \u001b[35m4.0937\u001b[0m  6.3336\n",
      "     64        4.0327       0.9444        \u001b[35m4.0932\u001b[0m  6.3213\n",
      "     65        \u001b[36m4.0325\u001b[0m       0.9440        \u001b[35m4.0927\u001b[0m  6.3180\n",
      "     66        \u001b[36m4.0321\u001b[0m       0.9427        4.0934  6.3390\n",
      "     67        4.0324       0.9434        \u001b[35m4.0926\u001b[0m  6.3498\n",
      "     68        \u001b[36m4.0320\u001b[0m       0.9457        4.0928  6.3062\n",
      "     69        4.0321       0.9447        \u001b[35m4.0923\u001b[0m  6.3431\n",
      "     70        4.0321       0.9440        4.0926  6.3299\n",
      "     71        4.0322       0.9417        4.0930  6.3068\n",
      "     72        4.0322       0.9424        4.0934  6.3253\n",
      "     73        4.0322       0.9440        4.0933  6.3484\n",
      "     74        \u001b[36m4.0317\u001b[0m       0.9440        4.0934  6.3788\n",
      "     75        4.0319       0.9424        4.0929  6.3225\n",
      "     76        4.0318       0.9421        4.0931  6.3335\n",
      "     77        \u001b[36m4.0315\u001b[0m       0.9424        4.0932  6.3193\n",
      "     78        \u001b[36m4.0314\u001b[0m       0.9434        4.0927  6.3222\n",
      "     79        4.0317       0.9447        4.0925  6.3627\n",
      "     80        4.0317       0.9434        4.0926  6.3185\n",
      "     81        4.0315       0.9430        \u001b[35m4.0921\u001b[0m  6.3470\n",
      "     82        \u001b[36m4.0312\u001b[0m       0.9414        4.0925  6.3532\n",
      "     83        4.0315       0.9434        4.0927  6.3254\n",
      "     84        4.0316       0.9417        4.0922  6.3461\n",
      "     85        4.0314       0.9444        4.0924  6.3367\n",
      "     86        4.0314       0.9421        4.0928  6.3203\n",
      "     87        \u001b[36m4.0311\u001b[0m       0.9434        4.0925  6.3047\n",
      "     88        4.0312       0.9407        4.0940  6.2072\n",
      "     89        \u001b[36m4.0309\u001b[0m       0.9407        4.0930  6.3147\n",
      "     90        4.0311       0.9411        4.0924  6.3540\n",
      "     91        4.0310       0.9427        \u001b[35m4.0917\u001b[0m  6.3267\n",
      "     92        4.0311       0.9437        \u001b[35m4.0916\u001b[0m  6.4288\n",
      "     93        4.0312       \u001b[32m0.9467\u001b[0m        \u001b[35m4.0909\u001b[0m  6.3569\n",
      "     94        4.0312       0.9440        4.0918  6.3469\n",
      "     95        4.0310       0.9450        4.0912  6.3289\n",
      "     96        4.0310       0.9427        4.0918  6.3584\n",
      "     97        4.0311       0.9434        4.0915  6.5058\n",
      "     98        4.0311       0.9424        4.0916  6.4483\n",
      "     99        4.0312       0.9447        \u001b[35m4.0908\u001b[0m  6.4699\n",
      "    100        4.0311       0.9417        4.0925  6.4207\n",
      "    101        \u001b[36m4.0309\u001b[0m       0.9414        4.0925  6.4056\n",
      "    102        4.0309       0.9430        4.0919  6.5025\n",
      "    103        4.0310       0.9424        4.0921  6.4226\n",
      "    104        \u001b[36m4.0308\u001b[0m       0.9424        4.0925  6.4181\n",
      "    105        4.0308       0.9434        4.0917  6.4064\n",
      "    106        \u001b[36m4.0308\u001b[0m       0.9424        4.0919  6.4630\n",
      "    107        4.0308       0.9434        4.0916  6.4459\n",
      "    108        4.0308       0.9417        4.0914  6.4102\n",
      "    109        4.0309       0.9421        4.0914  6.5033\n",
      "    110        4.0309       0.9437        4.0913  6.3875\n",
      "    111        4.0308       0.9437        4.0913  6.4661\n",
      "    112        4.0309       0.9430        4.0920  6.4615\n",
      "    113        \u001b[36m4.0306\u001b[0m       0.9427        4.0917  6.4332\n",
      "    114        4.0309       0.9427        4.0913  6.3869\n",
      "    115        4.0307       0.9430        4.0912  6.3797\n",
      "    116        4.0307       0.9421        4.0918  6.4757\n",
      "    117        4.0307       0.9411        4.0917  6.4221\n",
      "    118        4.0308       0.9404        4.0922  6.4036\n",
      "    119        4.0308       0.9427        4.0915  6.4290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    120        4.0307       0.9427        4.0917  6.3932\n",
      "    121        4.0307       0.9424        4.0915  6.4292\n",
      "    122        \u001b[36m4.0305\u001b[0m       0.9417        4.0921  6.4065\n",
      "    123        \u001b[36m4.0305\u001b[0m       0.9430        4.0922  6.4458\n",
      "    124        4.0306       0.9437        4.0916  6.3946\n",
      "    125        4.0305       0.9424        4.0917  6.4726\n",
      "    126        4.0305       0.9404        4.0925  6.3902\n",
      "    127        \u001b[36m4.0305\u001b[0m       0.9424        4.0917  6.4056\n",
      "    128        4.0306       0.9411        4.0923  6.3937\n",
      "    129        4.0306       0.9434        4.0919  6.5274\n",
      "    130        4.0305       0.9430        4.0917  6.4062\n",
      "    131        \u001b[36m4.0305\u001b[0m       0.9401        4.0918  6.3949\n",
      "    132        \u001b[36m4.0304\u001b[0m       0.9424        4.0911  6.4151\n",
      "    133        \u001b[36m4.0304\u001b[0m       0.9421        4.0914  6.4482\n",
      "    134        4.0304       0.9437        4.0910  6.4010\n",
      "    135        4.0305       0.9427        4.0915  6.4399\n",
      "    136        4.0306       0.9411        4.0915  6.4705\n",
      "    137        4.0305       0.9427        4.0914  6.4177\n",
      "    138        4.0305       0.9424        4.0912  6.4142\n",
      "    139        4.0305       0.9414        4.0917  6.4093\n",
      "    140        4.0304       0.9414        4.0926  6.4196\n",
      "    141        4.0304       0.9440        4.0914  6.4029\n",
      "    142        4.0305       0.9440        4.0911  6.3532\n",
      "    143        \u001b[36m4.0303\u001b[0m       0.9421        4.0916  6.4384\n",
      "    144        4.0305       0.9430        4.0917  6.4291\n",
      "    145        4.0305       0.9414        4.0924  6.4123\n",
      "    146        4.0304       0.9447        \u001b[35m4.0907\u001b[0m  6.4429\n",
      "    147        \u001b[36m4.0303\u001b[0m       0.9427        4.0909  6.4175\n",
      "    148        4.0304       0.9417        4.0912  6.4836\n",
      "    149        4.0303       0.9434        \u001b[35m4.0906\u001b[0m  6.4676\n",
      "    150        4.0304       0.9424        4.0913  6.4188\n",
      "    151        4.0305       0.9424        4.0911  6.4114\n",
      "    152        4.0305       0.9427        4.0911  6.4306\n",
      "    153        4.0304       0.9414        4.0916  6.4092\n",
      "    154        \u001b[36m4.0303\u001b[0m       0.9414        4.0914  6.4253\n",
      "    155        \u001b[36m4.0303\u001b[0m       0.9414        4.0913  6.4170\n",
      "    156        4.0303       0.9404        4.0914  6.4924\n",
      "    157        4.0305       0.9444        \u001b[35m4.0901\u001b[0m  6.4345\n",
      "    158        4.0305       0.9447        4.0911  6.4334\n",
      "    159        4.0304       0.9424        4.0915  6.4486\n",
      "    160        4.0304       0.9414        4.0919  6.4266\n",
      "    161        4.0303       0.9424        4.0917  6.4008\n",
      "    162        4.0304       0.9424        4.0918  6.5062\n",
      "    163        4.0304       0.9427        4.0908  6.4627\n",
      "    164        4.0304       0.9411        4.0917  6.4111\n",
      "    165        4.0303       0.9404        4.0918  6.4296\n",
      "    166        \u001b[36m4.0303\u001b[0m       0.9417        4.0909  6.5464\n",
      "    167        4.0304       0.9414        4.0918  6.4386\n",
      "    168        4.0305       0.9394        4.0922  6.4431\n",
      "    169        4.0305       0.9414        4.0913  6.4789\n",
      "    170        4.0303       0.9427        4.0905  6.4244\n",
      "    171        4.0304       0.9414        4.0913  6.4322\n",
      "    172        4.0303       0.9414        4.0904  6.4092\n",
      "    173        4.0303       0.9417        4.0910  6.4452\n",
      "    174        4.0303       0.9411        4.0911  6.4103\n",
      "    175        \u001b[36m4.0303\u001b[0m       0.9404        4.0918  6.4253\n",
      "    176        4.0303       0.9411        4.0916  6.4957\n",
      "    177        4.0304       0.9427        4.0916  6.4370\n",
      "    178        4.0303       0.9424        4.0910  6.4325\n",
      "    179        \u001b[36m4.0303\u001b[0m       0.9427        4.0913  6.5198\n",
      "    180        4.0303       0.9427        4.0914  6.4141\n",
      "    181        4.0303       0.9401        4.0924  6.4551\n",
      "    182        4.0304       0.9394        4.0929  6.4996\n",
      "    183        4.0303       0.9407        4.0924  6.4423\n",
      "    184        4.0303       0.9397        4.0926  6.4758\n",
      "    185        4.0304       0.9404        4.0929  6.5291\n",
      "    186        4.0304       0.9384        4.0920  6.4459\n",
      "    187        \u001b[36m4.0302\u001b[0m       0.9387        4.0922  6.4545\n",
      "    188        4.0303       0.9404        4.0922  6.4341\n",
      "    189        4.0303       0.9417        4.0918  6.4397\n",
      "    190        4.0303       0.9394        4.0923  6.4494\n",
      "    191        4.0302       0.9397        4.0924  6.4314\n",
      "    192        4.0302       0.9411        4.0915  6.4830\n",
      "    193        \u001b[36m4.0302\u001b[0m       0.9411        4.0921  6.4462\n",
      "    194        4.0304       0.9414        4.0921  6.4792\n",
      "    195        4.0302       0.9404        4.0921  6.4931\n",
      "    196        4.0302       0.9407        4.0916  6.4152\n",
      "    197        4.0302       0.9401        4.0908  6.4413\n",
      "    198        4.0302       0.9384        4.0915  6.4824\n",
      "    199        4.0303       0.9377        4.0926  6.4504\n",
      "    200        4.0303       0.9384        4.0922  6.4416\n",
      "    201        \u001b[36m4.0302\u001b[0m       0.9391        4.0921  6.5189\n",
      "    202        4.0302       0.9407        4.0914  6.4083\n",
      "    203        4.0302       0.9394        4.0920  6.5189\n",
      "    204        4.0302       0.9401        4.0922  6.4805\n",
      "    205        4.0302       0.9397        4.0921  6.4577\n",
      "    206        4.0302       0.9407        4.0914  6.4409\n",
      "    207        4.0302       0.9377        4.0927  6.4547\n",
      "    208        4.0303       0.9401        4.0922  6.5110\n",
      "    209        \u001b[36m4.0302\u001b[0m       0.9401        4.0919  6.4607\n",
      "    210        4.0302       0.9407        4.0923  6.4337\n",
      "    211        \u001b[36m4.0302\u001b[0m       0.9401        4.0923  6.4588\n",
      "    212        \u001b[36m4.0301\u001b[0m       0.9407        4.0921  6.4684\n",
      "    213        4.0303       0.9397        4.0925  6.4261\n",
      "    214        4.0302       0.9404        4.0918  6.4978\n",
      "    215        4.0302       0.9404        4.0918  6.4487\n",
      "    216        4.0302       0.9421        4.0917  6.4109\n",
      "    217        \u001b[36m4.0301\u001b[0m       0.9414        4.0916  6.5005\n",
      "    218        4.0303       0.9414        4.0916  6.4350\n",
      "    219        4.0301       0.9401        4.0916  6.4413\n",
      "    220        4.0302       0.9411        4.0919  6.4678\n",
      "    221        4.0303       0.9407        4.0910  6.5092\n",
      "    222        4.0302       0.9414        4.0905  6.4516\n",
      "    223        4.0301       0.9414        4.0911  6.4897\n",
      "    224        4.0302       0.9397        4.0920  6.5664\n",
      "    225        4.0302       0.9401        4.0925  6.4841\n",
      "    226        4.0302       0.9424        4.0918  6.5390\n",
      "    227        4.0302       0.9391        4.0916  6.5210\n",
      "    228        4.0301       0.9397        4.0916  6.4647\n",
      "    229        4.0302       0.9414        4.0919  6.4820\n",
      "    230        4.0302       0.9414        4.0920  6.4933\n",
      "    231        4.0302       0.9401        4.0920  6.4328\n",
      "    232        \u001b[36m4.0301\u001b[0m       0.9391        4.0923  6.4418\n",
      "    233        4.0301       0.9394        4.0923  6.4973\n",
      "    234        4.0302       0.9391        4.0922  6.4225\n",
      "    235        \u001b[36m4.0301\u001b[0m       0.9414        4.0913  6.4578\n",
      "    236        4.0302       0.9411        4.0918  6.4140\n",
      "    237        4.0302       0.9391        4.0925  6.4666\n",
      "    238        4.0301       0.9401        4.0925  6.4376\n",
      "    239        4.0301       0.9411        4.0920  6.5804\n",
      "    240        4.0301       0.9404        4.0921  6.4643\n",
      "    241        4.0302       0.9397        4.0917  6.4648\n",
      "    242        \u001b[36m4.0301\u001b[0m       0.9401        4.0917  6.5074\n",
      "    243        4.0301       0.9391        4.0915  6.4362\n",
      "    244        4.0302       0.9411        4.0909  6.4495\n",
      "    245        4.0302       0.9407        4.0918  6.4712\n",
      "    246        4.0301       0.9421        4.0914  6.5035\n",
      "    247        4.0302       0.9407        4.0916  6.4260\n",
      "    248        4.0303       0.9407        4.0916  6.4490\n",
      "    249        4.0302       0.9404        4.0913  6.4175\n",
      "    250        4.0301       0.9404        4.0919  6.4526\n",
      "    251        4.0301       0.9421        4.0913  6.4273\n",
      "    252        4.0302       0.9391        4.0920  6.4945\n",
      "    253        4.0301       0.9387        4.0918  6.4477\n",
      "    254        4.0301       0.9387        4.0918  6.4684\n",
      "    255        4.0301       0.9384        4.0921  6.4843\n",
      "    256        \u001b[36m4.0301\u001b[0m       0.9384        4.0921  6.4549\n",
      "    257        4.0301       0.9391        4.0920  6.4756\n",
      "    258        4.0301       0.9387        4.0921  6.5274\n",
      "    259        4.0301       0.9391        4.0924  6.4518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    260        4.0301       0.9384        4.0924  6.4510\n",
      "    261        4.0302       0.9387        4.0916  6.4632\n",
      "    262        4.0301       0.9397        4.0914  6.4550\n",
      "    263        4.0301       0.9407        4.0916  6.5228\n",
      "    264        4.0302       0.9397        4.0923  6.4714\n",
      "    265        4.0301       0.9404        4.0922  6.4615\n",
      "    266        \u001b[36m4.0301\u001b[0m       0.9391        4.0930  6.4507\n",
      "    267        \u001b[36m4.0300\u001b[0m       0.9404        4.0922  6.4881\n",
      "    268        4.0301       0.9394        4.0923  6.4511\n",
      "    269        4.0301       0.9394        4.0925  6.4433\n",
      "    270        4.0301       0.9387        4.0933  6.4383\n",
      "    271        4.0301       0.9377        4.0940  6.5294\n",
      "    272        \u001b[36m4.0300\u001b[0m       0.9377        4.0937  6.5002\n",
      "    273        \u001b[36m4.0300\u001b[0m       0.9384        4.0930  6.4760\n",
      "    274        4.0300       0.9361        4.0937  6.5042\n",
      "    275        4.0301       0.9368        4.0935  6.4472\n",
      "    276        4.0300       0.9374        4.0935  6.5546\n",
      "    277        4.0301       0.9397        4.0928  6.5285\n",
      "    278        4.0300       0.9387        4.0923  6.4706\n",
      "    279        4.0300       0.9374        4.0926  6.4600\n",
      "    280        4.0301       0.9371        4.0927  6.5125\n",
      "    281        \u001b[36m4.0300\u001b[0m       0.9387        4.0926  6.4548\n",
      "    282        \u001b[36m4.0300\u001b[0m       0.9381        4.0931  6.4564\n",
      "    283        4.0300       0.9384        4.0925  6.4930\n",
      "    284        4.0301       0.9384        4.0923  6.4834\n",
      "    285        4.0300       0.9394        4.0918  6.4652\n",
      "    286        4.0300       0.9394        4.0920  6.5113\n",
      "    287        4.0300       0.9397        4.0919  6.4880\n",
      "    288        4.0300       0.9397        4.0919  6.4451\n",
      "    289        \u001b[36m4.0300\u001b[0m       0.9404        4.0917  6.4818\n",
      "    290        4.0300       0.9407        4.0916  6.4916\n",
      "    291        4.0300       0.9397        4.0923  6.4435\n",
      "    292        4.0300       0.9371        4.0924  6.5545\n",
      "    293        4.0300       0.9381        4.0928  6.4350\n",
      "    294        4.0301       0.9384        4.0925  6.5144\n",
      "    295        4.0300       0.9384        4.0924  6.4436\n",
      "    296        \u001b[36m4.0299\u001b[0m       0.9394        4.0925  6.4470\n",
      "    297        4.0300       0.9401        4.0920  6.4612\n",
      "    298        4.0300       0.9377        4.0923  6.4930\n",
      "    299        4.0300       0.9371        4.0927  6.4952\n",
      "    300        4.0300       0.9381        4.0925  6.4771\n",
      "    301        \u001b[36m4.0299\u001b[0m       0.9384        4.0923  6.4901\n",
      "    302        4.0299       0.9391        4.0912  6.4611\n",
      "    303        4.0299       0.9394        4.0918  6.4719\n",
      "    304        4.0299       0.9391        4.0918  6.4845\n",
      "    305        4.0300       0.9397        4.0917  6.4882\n",
      "    306        4.0300       0.9394        4.0920  6.4605\n",
      "    307        4.0300       0.9397        4.0923  6.4584\n",
      "    308        4.0300       0.9397        4.0923  6.4924\n",
      "    309        4.0300       0.9401        4.0918  6.4553\n",
      "    310        4.0300       0.9401        4.0917  6.4655\n",
      "    311        4.0299       0.9404        4.0914  6.5222\n",
      "    312        4.0300       0.9401        4.0913  6.5655\n",
      "    313        4.0300       0.9404        4.0912  6.5175\n",
      "    314        4.0300       0.9424        4.0907  6.5075\n",
      "    315        4.0300       0.9411        4.0909  6.4682\n",
      "    316        \u001b[36m4.0299\u001b[0m       0.9411        4.0908  6.4902\n",
      "    317        4.0299       0.9394        4.0911  6.5998\n",
      "    318        \u001b[36m4.0299\u001b[0m       0.9401        4.0908  6.4684\n",
      "    319        4.0299       0.9407        4.0909  6.4498\n",
      "    320        4.0299       0.9407        4.0906  6.5197\n",
      "    321        \u001b[36m4.0299\u001b[0m       0.9414        4.0905  6.4827\n",
      "    322        4.0299       0.9391        4.0905  6.4788\n",
      "    323        4.0299       0.9401        \u001b[35m4.0900\u001b[0m  6.5289\n",
      "    324        4.0299       0.9401        4.0907  6.4198\n",
      "    325        4.0299       0.9407        4.0907  6.4178\n",
      "    326        \u001b[36m4.0298\u001b[0m       0.9404        4.0907  6.5514\n",
      "    327        4.0299       0.9407        4.0903  6.4887\n",
      "    328        4.0298       0.9397        4.0904  6.5005\n",
      "    329        4.0298       0.9397        4.0907  6.5337\n",
      "    330        4.0299       0.9404        4.0902  6.5640\n",
      "    331        4.0299       0.9411        \u001b[35m4.0900\u001b[0m  6.4676\n",
      "    332        4.0298       0.9417        \u001b[35m4.0898\u001b[0m  6.5317\n",
      "    333        4.0298       0.9421        \u001b[35m4.0894\u001b[0m  6.4658\n",
      "    334        4.0299       0.9404        4.0902  6.4552\n",
      "    335        4.0299       0.9401        4.0908  6.5578\n",
      "    336        4.0299       0.9394        4.0912  6.5175\n",
      "    337        4.0299       0.9401        4.0911  6.4745\n",
      "    338        4.0298       0.9391        4.0912  6.5221\n",
      "    339        4.0298       0.9384        4.0919  6.5141\n",
      "    340        4.0299       0.9377        4.0920  6.4834\n",
      "    341        4.0299       0.9381        4.0919  6.5392\n",
      "    342        4.0299       0.9387        4.0921  6.5037\n",
      "    343        4.0298       0.9384        4.0919  6.4577\n",
      "    344        4.0299       0.9374        4.0921  6.5457\n",
      "    345        4.0299       0.9394        4.0915  6.4849\n",
      "    346        4.0299       0.9391        4.0918  6.4738\n",
      "    347        4.0298       0.9404        4.0919  6.5402\n",
      "    348        4.0299       0.9397        4.0918  6.5618\n",
      "    349        4.0299       0.9414        4.0908  6.4576\n",
      "    350        4.0299       0.9404        4.0911  6.5014\n",
      "    351        4.0299       0.9407        4.0913  6.4862\n",
      "    352        \u001b[36m4.0298\u001b[0m       0.9407        4.0913  6.4794\n",
      "    353        4.0298       0.9407        4.0912  6.5651\n",
      "    354        4.0298       0.9394        4.0914  6.4953\n",
      "    355        4.0299       0.9394        4.0912  6.4746\n",
      "    356        \u001b[36m4.0298\u001b[0m       0.9397        4.0914  6.5611\n",
      "    357        4.0298       0.9404        4.0911  6.4794\n",
      "    358        4.0299       0.9397        4.0912  6.4960\n",
      "    359        4.0299       0.9397        4.0913  6.5519\n",
      "    360        4.0299       0.9397        4.0911  6.4966\n",
      "    361        4.0299       0.9387        4.0914  6.5239\n",
      "    362        4.0299       0.9411        4.0913  6.6261\n",
      "    363        4.0298       0.9401        4.0917  6.5204\n",
      "    364        4.0299       0.9401        4.0910  6.4843\n",
      "    365        4.0298       0.9391        4.0912  6.5683\n",
      "    366        4.0299       0.9397        4.0915  6.5869\n",
      "    367        4.0299       0.9391        4.0920  6.5260\n",
      "    368        4.0299       0.9384        4.0917  6.5397\n",
      "    369        4.0299       0.9384        4.0923  6.5199\n",
      "    370        \u001b[36m4.0298\u001b[0m       0.9391        4.0925  6.5026\n",
      "    371        4.0299       0.9387        4.0927  6.5673\n",
      "    372        4.0299       0.9394        4.0930  6.5076\n",
      "    373        4.0298       0.9387        4.0926  6.5194\n",
      "    374        4.0299       0.9391        4.0927  6.5066\n",
      "    375        4.0299       0.9381        4.0925  6.5095\n",
      "    376        4.0298       0.9394        4.0920  6.4796\n",
      "    377        4.0299       0.9401        4.0921  6.4811\n",
      "    378        4.0298       0.9397        4.0924  6.5173\n",
      "    379        4.0298       0.9394        4.0925  6.5367\n",
      "    380        \u001b[36m4.0298\u001b[0m       0.9394        4.0927  6.5235\n",
      "    381        4.0299       0.9387        4.0926  6.4971\n",
      "    382        4.0299       0.9391        4.0929  6.5522\n",
      "    383        4.0298       0.9384        4.0931  6.6190\n",
      "    384        4.0298       0.9374        4.0930  6.7096\n",
      "    385        4.0298       0.9381        4.0927  6.7834\n",
      "    386        4.0299       0.9387        4.0925  6.6117\n",
      "    387        4.0298       0.9404        4.0920  6.7301\n",
      "    388        4.0298       0.9401        4.0913  6.7386\n",
      "    389        4.0299       0.9397        4.0915  6.6942\n",
      "    390        4.0298       0.9394        4.0915  6.7915\n",
      "    391        4.0298       0.9401        4.0912  6.6404\n",
      "    392        4.0298       0.9387        4.0918  6.6782\n",
      "    393        4.0298       0.9384        4.0925  6.8612\n",
      "    394        4.0298       0.9394        4.0921  6.6512\n",
      "    395        4.0298       0.9397        4.0918  6.7448\n",
      "    396        4.0299       0.9377        4.0928  6.7188\n",
      "    397        4.0298       0.9371        4.0932  6.6971\n",
      "    398        4.0299       0.9381        4.0923  6.7330\n",
      "    399        4.0299       0.9374        4.0926  6.6684\n",
      "    400        4.0299       0.9377        4.0925  6.6512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    401        4.0298       0.9384        4.0917  6.8595\n",
      "    402        4.0299       0.9387        4.0922  6.6630\n",
      "    403        4.0298       0.9391        4.0918  6.7649\n",
      "    404        4.0298       0.9381        4.0918  6.6705\n",
      "    405        4.0298       0.9387        4.0921  6.6471\n",
      "    406        4.0299       0.9391        4.0917  6.8459\n",
      "    407        4.0298       0.9384        4.0920  6.6308\n",
      "    408        4.0299       0.9381        4.0923  6.7126\n",
      "    409        4.0298       0.9391        4.0919  6.7349\n",
      "    410        4.0298       0.9377        4.0920  6.6377\n",
      "    411        4.0298       0.9374        4.0922  6.7885\n",
      "    412        4.0299       0.9377        4.0923  6.6540\n",
      "    413        4.0299       0.9381        4.0922  6.6350\n",
      "    414        4.0298       0.9387        4.0915  6.8223\n",
      "    415        4.0298       0.9381        4.0915  6.6780\n",
      "    416        4.0298       0.9384        4.0913  6.7458\n",
      "    417        4.0298       0.9391        4.0909  6.6639\n",
      "    418        4.0298       0.9401        4.0908  6.6688\n",
      "    419        \u001b[36m4.0298\u001b[0m       0.9404        4.0904  6.8421\n",
      "    420        \u001b[36m4.0298\u001b[0m       0.9397        4.0907  6.6320\n",
      "    421        4.0298       0.9397        4.0911  6.7190\n",
      "    422        4.0298       0.9387        4.0912  6.7578\n",
      "    423        4.0299       0.9394        4.0911  6.6685\n",
      "    424        4.0298       0.9404        4.0913  6.8282\n",
      "    425        4.0298       0.9394        4.0917  6.6691\n",
      "    426        \u001b[36m4.0298\u001b[0m       0.9394        4.0918  6.6527\n",
      "    427        4.0298       0.9381        4.0923  6.8494\n",
      "    428        4.0298       0.9384        4.0922  6.6593\n",
      "    429        4.0299       0.9384        4.0921  6.7586\n",
      "    430        4.0298       0.9381        4.0923  6.6970\n",
      "    431        \u001b[36m4.0298\u001b[0m       0.9387        4.0917  6.6626\n",
      "    432        4.0299       0.9387        4.0921  6.8205\n",
      "    433        4.0299       0.9391        4.0922  6.6457\n",
      "    434        \u001b[36m4.0298\u001b[0m       0.9364        4.0928  6.7181\n",
      "    435        4.0298       0.9351        4.0937  6.7697\n",
      "    436        4.0299       0.9377        4.0921  6.7415\n",
      "    437        4.0299       0.9361        4.0920  6.8487\n",
      "    438        4.0298       0.9397        4.0912  6.6758\n",
      "    439        4.0299       0.9387        4.0916  6.7110\n",
      "    440        4.0298       0.9377        4.0914  6.7956\n",
      "    441        \u001b[36m4.0298\u001b[0m       0.9391        4.0910  6.6597\n",
      "    442        4.0299       0.9381        4.0913  6.8082\n",
      "    443        4.0298       0.9384        4.0909  6.6900\n",
      "    444        4.0298       0.9381        4.0911  6.6655\n",
      "    445        4.0299       0.9387        4.0917  6.8760\n",
      "    446        4.0299       0.9384        4.0918  6.6625\n",
      "    447        4.0298       0.9368        4.0920  6.8249\n",
      "    448        \u001b[36m4.0298\u001b[0m       0.9371        4.0922  6.7382\n",
      "    449        4.0298       0.9361        4.0923  6.9506\n",
      "    450        4.0298       0.9364        4.0926  6.9425\n",
      "    451        4.0298       0.9361        4.0926  6.8838\n",
      "    452        \u001b[36m4.0298\u001b[0m       0.9374        4.0922  6.7804\n",
      "    453        4.0298       0.9374        4.0929  6.7626\n",
      "    454        4.0298       0.9377        4.0923  6.7652\n",
      "    455        4.0298       0.9371        4.0921  6.7650\n",
      "    456        4.0298       0.9391        4.0915  6.6812\n",
      "    457        4.0298       0.9371        4.0922  6.8350\n",
      "    458        4.0298       0.9381        4.0920  6.7066\n",
      "    459        4.0298       0.9377        4.0917  6.7364\n",
      "    460        4.0298       0.9381        4.0916  6.8166\n",
      "    461        4.0298       0.9387        4.0918  6.6725\n",
      "    462        4.0298       0.9391        4.0919  6.8564\n",
      "    463        4.0298       0.9401        4.0916  6.6849\n",
      "    464        4.0298       0.9394        4.0919  6.6926\n",
      "    465        4.0298       0.9394        4.0921  6.8543\n",
      "    466        4.0298       0.9404        4.0916  6.6916\n",
      "    467        \u001b[36m4.0298\u001b[0m       0.9387        4.0918  6.7396\n",
      "    468        4.0298       0.9391        4.0918  6.7319\n",
      "    469        4.0298       0.9381        4.0921  6.6056\n",
      "    470        4.0298       0.9371        4.0922  6.7293\n",
      "    471        4.0298       0.9381        4.0921  6.5798\n",
      "    472        4.0298       0.9387        4.0911  6.5912\n",
      "    473        4.0298       0.9371        4.0922  6.6086\n",
      "    474        4.0298       0.9381        4.0922  6.5756\n",
      "    475        4.0298       0.9394        4.0919  6.6497\n",
      "    476        4.0298       0.9391        4.0919  6.5918\n",
      "    477        4.0298       0.9397        4.0919  6.5657\n",
      "    478        4.0298       0.9394        4.0916  6.6351\n",
      "    479        4.0298       0.9401        4.0916  6.6119\n",
      "    480        4.0298       0.9391        4.0919  6.5858\n",
      "    481        4.0298       0.9381        4.0921  6.6615\n",
      "    482        4.0298       0.9384        4.0920  6.5750\n",
      "    483        4.0298       0.9384        4.0921  6.6040\n",
      "    484        4.0298       0.9381        4.0923  6.6359\n",
      "    485        4.0298       0.9377        4.0922  6.5966\n",
      "    486        4.0298       0.9384        4.0917  6.6251\n",
      "    487        4.0298       0.9407        4.0909  6.5938\n",
      "    488        4.0298       0.9401        4.0911  6.6815\n",
      "    489        \u001b[36m4.0298\u001b[0m       0.9407        4.0909  6.6565\n",
      "    490        4.0298       0.9401        4.0916  6.6041\n",
      "    491        4.0298       0.9384        4.0919  6.5907\n",
      "    492        4.0298       0.9387        4.0922  6.6451\n",
      "    493        4.0298       0.9394        4.0912  6.6206\n",
      "    494        4.0298       0.9397        4.0922  6.6283\n",
      "    495        4.0298       0.9381        4.0923  6.6163\n",
      "    496        4.0298       0.9381        4.0922  6.5999\n",
      "    497        4.0298       0.9384        4.0924  6.6856\n",
      "    498        4.0298       0.9391        4.0923  6.6211\n",
      "    499        4.0298       0.9387        4.0924  6.6060\n",
      "    500        4.0298       0.9377        4.0927  6.6901\n",
      "    501        4.0298       0.9387        4.0926  6.6106\n",
      "    502        4.0298       0.9391        4.0920  6.6485\n",
      "    503        4.0298       0.9374        4.0919  6.6617\n",
      "    504        4.0298       0.9381        4.0923  6.6513\n",
      "    505        4.0298       0.9381        4.0923  6.6270\n",
      "    506        4.0298       0.9381        4.0925  6.6280\n",
      "    507        4.0298       0.9377        4.0921  6.6292\n",
      "    508        4.0298       0.9377        4.0923  6.6412\n",
      "    509        \u001b[36m4.0298\u001b[0m       0.9377        4.0922  6.5951\n",
      "    510        4.0298       0.9384        4.0916  6.6672\n",
      "    511        4.0298       0.9381        4.0917  6.6396\n",
      "    512        4.0298       0.9387        4.0913  6.6173\n",
      "    513        4.0298       0.9381        4.0921  6.6777\n",
      "    514        4.0298       0.9368        4.0923  6.6247\n",
      "    515        4.0298       0.9368        4.0922  6.6422\n",
      "    516        4.0298       0.9374        4.0922  6.6765\n",
      "    517        4.0298       0.9374        4.0921  6.6377\n",
      "    518        4.0298       0.9368        4.0926  6.6724\n",
      "    519        4.0298       0.9374        4.0920  6.6538\n",
      "    520        4.0298       0.9394        4.0917  6.6359\n",
      "    521        4.0298       0.9401        4.0911  6.6772\n",
      "    522        4.0298       0.9397        4.0912  6.6203\n",
      "    523        4.0298       0.9401        4.0906  6.7193\n",
      "    524        4.0298       0.9424        4.0897  6.6666\n",
      "    525        4.0298       0.9414        4.0898  6.6469\n",
      "    526        4.0298       0.9424        4.0897  6.6718\n",
      "    527        4.0298       0.9411        4.0900  6.6657\n",
      "    528        4.0298       0.9411        4.0913  6.6620\n",
      "    529        4.0298       0.9397        4.0915  6.7064\n",
      "    530        4.0298       0.9397        4.0916  6.6283\n",
      "    531        4.0298       0.9394        4.0916  6.6159\n",
      "    532        4.0298       0.9394        4.0923  6.6549\n",
      "    533        4.0298       0.9387        4.0920  6.6397\n",
      "    534        4.0298       0.9384        4.0922  6.6913\n",
      "    535        4.0298       0.9407        4.0915  6.6562\n",
      "    536        4.0298       0.9401        4.0915  6.7395\n",
      "    537        4.0298       0.9404        4.0915  6.6520\n",
      "    538        4.0298       0.9404        4.0916  6.6630\n",
      "    539        4.0298       0.9401        4.0917  6.6736\n",
      "    540        4.0298       0.9394        4.0913  6.7187\n",
      "    541        \u001b[36m4.0298\u001b[0m       0.9394        4.0916  6.6518\n",
      "    542        4.0298       0.9394        4.0921  6.7178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    543        4.0298       0.9391        4.0922  6.6652\n",
      "    544        4.0298       0.9387        4.0920  6.6838\n",
      "    545        4.0298       0.9397        4.0916  6.6728\n",
      "    546        4.0298       0.9391        4.0916  6.5831\n",
      "    547        4.0298       0.9397        4.0915  6.9081\n",
      "    548        4.0298       0.9394        4.0919  6.6190\n",
      "    549        4.0298       0.9387        4.0922  6.7840\n",
      "    550        4.0298       0.9397        4.0916  10.2805\n",
      "    551        4.0298       0.9397        4.0917  286.7433\n",
      "    552        4.0298       0.9401        4.0908  7.8314\n",
      "    553        4.0298       0.9391        4.0913  7.2209\n",
      "    554        4.0298       0.9401        4.0912  7.0530\n",
      "    555        4.0298       0.9391        4.0912  7.1388\n",
      "    556        4.0298       0.9387        4.0914  6.8863\n",
      "    557        4.0298       0.9387        4.0917  6.7048\n",
      "    558        4.0298       0.9381        4.0920  6.7783\n",
      "    559        4.0298       0.9404        4.0919  6.6144\n",
      "    560        4.0298       0.9401        4.0920  6.5997\n",
      "    561        4.0298       0.9404        4.0920  6.6178\n",
      "    562        4.0298       0.9387        4.0923  6.6093\n",
      "    563        4.0298       0.9391        4.0920  6.5920\n",
      "    564        4.0298       0.9404        4.0915  6.6176\n",
      "    565        4.0298       0.9397        4.0916  6.6061\n",
      "    566        4.0298       0.9394        4.0916  6.6310\n",
      "    567        4.0298       0.9391        4.0914  6.6094\n",
      "    568        4.0298       0.9391        4.0915  6.5868\n",
      "    569        4.0298       0.9407        4.0910  6.6786\n",
      "    570        4.0298       0.9411        4.0907  6.6357\n",
      "    571        4.0298       0.9407        4.0910  6.6147\n",
      "    572        \u001b[36m4.0298\u001b[0m       0.9401        4.0911  6.6462\n",
      "    573        4.0298       0.9414        4.0904  6.6570\n",
      "    574        4.0298       0.9391        4.0913  6.6490\n",
      "    575        4.0298       0.9387        4.0914  6.6066\n",
      "    576        \u001b[36m4.0298\u001b[0m       0.9394        4.0914  6.6160\n",
      "    577        4.0298       0.9404        4.0913  6.6089\n",
      "    578        4.0298       0.9404        4.0910  6.6180\n",
      "    579        4.0298       0.9394        4.0913  6.6368\n",
      "    580        4.0298       0.9387        4.0917  6.6118\n",
      "    581        4.0298       0.9374        4.0925  6.6163\n",
      "    582        4.0298       0.9384        4.0923  6.6019\n",
      "    583        4.0298       0.9384        4.0921  6.6136\n",
      "    584        4.0298       0.9381        4.0922  6.6108\n",
      "    585        4.0298       0.9377        4.0922  6.6372\n",
      "    586        4.0298       0.9371        4.0925  6.6118\n",
      "    587        4.0298       0.9368        4.0926  6.6504\n",
      "    588        4.0298       0.9354        4.0924  6.6726\n",
      "    589        4.0298       0.9364        4.0928  6.6294\n",
      "    590        4.0298       0.9371        4.0927  6.6863\n",
      "    591        4.0298       0.9374        4.0928  6.7585\n",
      "    592        4.0298       0.9381        4.0918  6.6956\n",
      "    593        4.0298       0.9384        4.0918  6.6282\n",
      "    594        4.0298       0.9374        4.0918  6.6266\n",
      "    595        4.0298       0.9368        4.0920  6.6320\n",
      "    596        4.0298       0.9361        4.0924  6.6436\n",
      "    597        4.0298       0.9358        4.0925  6.6468\n",
      "    598        4.0298       0.9368        4.0923  6.6101\n",
      "    599        4.0298       0.9368        4.0923  6.6287\n",
      "    600        4.0298       0.9368        4.0924  6.6420\n",
      "    601        4.0298       0.9377        4.0922  6.6750\n",
      "    602        4.0298       0.9374        4.0925  6.6550\n",
      "    603        4.0298       0.9368        4.0925  6.6328\n",
      "    604        4.0298       0.9368        4.0924  6.7197\n",
      "    605        4.0298       0.9381        4.0916  6.6650\n",
      "    606        4.0298       0.9387        4.0921  6.6699\n",
      "    607        4.0298       0.9391        4.0915  6.6266\n",
      "    608        4.0298       0.9397        4.0915  6.7235\n",
      "    609        4.0298       0.9407        4.0913  6.6557\n",
      "    610        4.0298       0.9407        4.0911  6.6504\n",
      "    611        4.0298       0.9404        4.0916  6.6282\n",
      "    612        4.0298       0.9394        4.0922  6.6569\n",
      "    613        4.0298       0.9394        4.0922  6.6461\n",
      "    614        4.0298       0.9387        4.0924  6.6638\n",
      "    615        4.0298       0.9387        4.0923  6.7003\n",
      "    616        4.0298       0.9391        4.0927  6.6302\n",
      "    617        4.0298       0.9377        4.0930  6.6404\n",
      "    618        4.0298       0.9384        4.0928  6.6458\n",
      "    619        4.0298       0.9387        4.0926  6.6458\n",
      "    620        4.0298       0.9387        4.0920  6.6601\n",
      "    621        4.0298       0.9387        4.0919  6.5374\n",
      "    622        4.0298       0.9397        4.0918  6.6385\n",
      "    623        4.0298       0.9394        4.0921  6.6552\n",
      "    624        4.0298       0.9387        4.0919  6.6615\n",
      "    625        4.0298       0.9394        4.0921  6.7235\n",
      "    626        4.0298       0.9387        4.0920  6.6574\n",
      "    627        4.0298       0.9377        4.0922  6.6618\n",
      "    628        4.0298       0.9377        4.0924  6.6190\n",
      "    629        4.0298       0.9381        4.0921  6.6091\n",
      "    630        4.0298       0.9384        4.0919  6.6449\n",
      "    631        4.0298       0.9397        4.0917  6.6831\n",
      "    632        4.0298       0.9384        4.0919  6.6620\n",
      "    633        4.0298       0.9374        4.0919  6.6503\n",
      "    634        4.0298       0.9394        4.0913  6.6255\n",
      "    635        4.0298       0.9381        4.0912  6.6434\n",
      "    636        4.0298       0.9371        4.0920  6.8563\n",
      "    637        4.0298       0.9381        4.0921  6.5713\n",
      "    638        4.0298       0.9391        4.0918  6.6571\n",
      "    639        4.0298       0.9387        4.0908  18.4866\n",
      "    640        4.0298       0.9401        4.0909  13.0368\n",
      "    641        4.0298       0.9397        4.0910  21.5476\n",
      "    642        4.0298       0.9387        4.0917  295.7866\n",
      "    643        4.0298       0.9384        4.0916  10.5434\n",
      "    644        4.0298       0.9397        4.0911  21.2324\n",
      "    645        4.0298       0.9397        4.0917  297.3429\n",
      "    646        4.0298       0.9404        4.0915  6.6020\n",
      "    647        4.0298       0.9397        4.0915  21.3552\n",
      "    648        4.0298       0.9414        4.0906  299.7529\n",
      "    649        4.0298       0.9404        4.0907  6.3787\n",
      "    650        4.0298       0.9394        4.0910  19.4429\n",
      "    651        4.0298       0.9397        4.0909  304.8582\n",
      "    652        4.0298       0.9401        4.0909  6.4274\n",
      "    653        4.0298       0.9387        4.0914  14.5117\n",
      "    654        4.0298       0.9387        4.0912  21.5398\n",
      "    655        4.0298       0.9391        4.0913  293.1640\n",
      "    656        \u001b[36m4.0298\u001b[0m       0.9391        4.0914  10.2635\n",
      "    657        4.0298       0.9394        4.0917  21.4639\n",
      "    658        4.0298       0.9401        4.0913  297.3460\n",
      "    659        4.0298       0.9387        4.0919  6.3752\n",
      "    660        4.0298       0.9381        4.0920  21.6261\n",
      "    661        4.0298       0.9374        4.0922  302.4336\n",
      "    662        4.0298       0.9374        4.0922  6.3817\n",
      "    663        4.0298       0.9381        4.0924  16.4534\n",
      "    664        4.0298       0.9374        4.0924  21.5642\n",
      "    665        4.0298       0.9374        4.0923  290.2145\n",
      "    666        4.0298       0.9371        4.0924  13.4731\n",
      "    667        4.0298       0.9377        4.0918  21.6239\n",
      "    668        4.0298       0.9381        4.0918  158.4472\n",
      "    669        4.0298       0.9374        4.0920  9.8623\n",
      "    670        4.0298       0.9377        4.0920  21.7006\n",
      "    671        4.0298       0.9374        4.0917  13.6394\n",
      "    672        4.0298       0.9377        4.0916  6.5420\n",
      "    673        4.0298       0.9377        4.0915  6.7532\n",
      "    674        \u001b[36m4.0298\u001b[0m       0.9377        4.0919  7.5944\n",
      "    675        4.0298       0.9374        4.0922  6.9635\n",
      "    676        4.0298       0.9384        4.0915  6.5674\n",
      "    677        4.0298       0.9391        4.0913  6.3535\n",
      "    678        4.0298       0.9394        4.0912  32.7435\n",
      "    679        4.0298       0.9394        4.0914  6.5090\n",
      "    680        4.0298       0.9381        4.0913  20.3483\n",
      "    681        4.0298       0.9387        4.0914  303.8718\n",
      "    682        4.0298       0.9384        4.0910  6.3200\n",
      "    683        4.0298       0.9377        4.0912  16.0827\n",
      "    684        4.0298       0.9381        4.0916  21.9544\n",
      "    685        4.0298       0.9384        4.0917  291.1510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    686        4.0298       0.9368        4.0922  12.8274\n",
      "    687        4.0298       0.9371        4.0924  22.0418\n",
      "    688        4.0298       0.9361        4.0926  293.2432\n",
      "    689        4.0298       0.9361        4.0924  11.0351\n",
      "    690        4.0298       0.9368        4.0926  22.1673\n",
      "    691        4.0298       0.9371        4.0925  296.3504\n",
      "    692        4.0298       0.9377        4.0926  7.8375\n",
      "    693        4.0298       0.9371        4.0922  22.1364\n",
      "    694        4.0298       0.9374        4.0919  298.4188\n",
      "    695        4.0298       0.9374        4.0918  6.4436\n",
      "    696        4.0298       0.9377        4.0918  21.6877\n",
      "    697        4.0298       0.9368        4.0921  302.1354\n",
      "    698        4.0298       0.9377        4.0915  6.4095\n",
      "    699        4.0298       0.9384        4.0918  18.2301\n",
      "    700        4.0298       0.9377        4.0916  22.3095\n",
      "    701        4.0298       0.9374        4.0915  6.4356\n",
      "    702        4.0298       0.9377        4.0914  14.3832\n",
      "    703        4.0298       0.9368        4.0918  22.2479\n",
      "    704        4.0298       0.9374        4.0919  292.7896\n",
      "    705        4.0298       0.9377        4.0917  11.3994\n",
      "    706        4.0298       0.9377        4.0920  22.2445\n",
      "    707        4.0298       0.9374        4.0919  295.6023\n",
      "    708        4.0298       0.9387        4.0918  8.6502\n",
      "    709        4.0298       0.9387        4.0916  22.4770\n",
      "    710        4.0298       0.9381        4.0919  298.9711\n",
      "    711        4.0298       0.9377        4.0919  6.4586\n",
      "    712        4.0298       0.9381        4.0917  21.5283\n",
      "    713        4.0298       0.9377        4.0918  302.3235\n",
      "    714        4.0298       0.9371        4.0918  6.4950\n",
      "    715        4.0298       0.9361        4.0920  18.3732\n",
      "    716        4.0298       0.9374        4.0917  305.6607\n",
      "    717        4.0298       0.9371        4.0919  6.4713\n",
      "    718        4.0298       0.9371        4.0919  15.4652\n",
      "    719        \u001b[36m4.0298\u001b[0m       0.9371        4.0917  22.4655\n",
      "    720        4.0298       0.9381        4.0915  291.5686\n",
      "    721        4.0298       0.9401        4.0908  13.3636\n",
      "    722        4.0298       0.9401        4.0912  22.4718\n",
      "    723        4.0298       0.9391        4.0915  293.6341\n",
      "    724        4.0298       0.9401        4.0913  11.0539\n",
      "    725        4.0298       0.9397        4.0912  22.5322\n",
      "    726        4.0298       0.9387        4.0914  295.8950\n",
      "    727        4.0298       0.9391        4.0917  8.6836\n",
      "    728        4.0298       0.9374        4.0916  22.6221\n",
      "    729        4.0298       0.9374        4.0917  298.9026\n",
      "    730        4.0298       0.9404        4.0914  6.4537\n",
      "    731        4.0298       0.9397        4.0910  22.0278\n",
      "    732        4.0298       0.9394        4.0907  301.9849\n",
      "    733        4.0298       0.9401        4.0912  6.4772\n",
      "    734        4.0298       0.9387        4.0912  19.1751\n",
      "    735        4.0298       0.9401        4.0905  304.7911\n",
      "    736        4.0298       0.9364        4.0919  6.5127\n",
      "    737        4.0298       0.9368        4.0920  16.3613\n",
      "    738        4.0298       0.9364        4.0928  22.6437\n",
      "    739        4.0298       0.9364        4.0934  290.4698\n",
      "    740        4.0298       0.9377        4.0929  14.1568\n",
      "    741        4.0298       0.9377        4.0928  22.5643\n",
      "    742        4.0298       0.9371        4.0930  291.4770\n",
      "    743        4.0298       0.9374        4.0928  12.6685\n",
      "    744        4.0298       0.9368        4.0929  22.5199\n",
      "    745        4.0298       0.9374        4.0930  294.4482\n",
      "    746        4.0298       0.9377        4.0927  9.9226\n",
      "    747        4.0298       0.9368        4.0926  22.6570\n",
      "    748        4.0298       0.9374        4.0926  297.5721\n",
      "    749        4.0298       0.9374        4.0926  7.0511\n",
      "    750        4.0298       0.9381        4.0926  22.5668\n",
      "    751        4.0298       0.9368        4.0929  299.0724\n",
      "    752        4.0298       0.9368        4.0927  6.5032\n",
      "    753        4.0298       0.9374        4.0925  22.1083\n",
      "    754        4.0298       0.9374        4.0920  301.8971\n",
      "    755        4.0298       0.9377        4.0923  6.5692\n",
      "    756        4.0298       0.9371        4.0924  19.5305\n",
      "    757        4.0298       0.9377        4.0921  304.5062\n",
      "    758        4.0298       0.9374        4.0921  6.5110\n",
      "    759        4.0298       0.9371        4.0921  17.0571\n",
      "    760        4.0298       0.9371        4.0921  305.7528\n",
      "    761        4.0298       0.9361        4.0923  6.5080\n",
      "    762        4.0298       0.9371        4.0918  15.8735\n",
      "    763        4.0298       0.9374        4.0916  22.6354\n",
      "    764        4.0298       0.9394        4.0907  290.8624\n",
      "    765        4.0298       0.9397        4.0904  13.8850\n",
      "    766        4.0298       0.9381        4.0906  22.6538\n",
      "    767        4.0298       0.9381        4.0910  292.9024\n",
      "    768        4.0298       0.9384        4.0908  11.8749\n",
      "    769        4.0298       0.9387        4.0908  22.8701\n",
      "    770        4.0298       0.9391        4.0909  293.8969\n",
      "    771        4.0298       0.9384        4.0911  10.8465\n",
      "    772        4.0298       0.9391        4.0912  22.6866\n",
      "    773        4.0298       0.9391        4.0913  295.2264\n",
      "    774        4.0298       0.9391        4.0914  9.6421\n",
      "    775        4.0298       0.9394        4.0911  22.7541\n",
      "    776        4.0298       0.9411        4.0908  297.8358\n",
      "    777        4.0298       0.9411        4.0904  6.9321\n",
      "    778        4.0298       0.9401        4.0911  22.6898\n",
      "    779        4.0298       0.9401        4.0906  299.6562\n",
      "    780        4.0298       0.9397        4.0910  6.5088\n",
      "    781        4.0298       0.9394        4.0913  21.9362\n",
      "    782        4.0298       0.9401        4.0909  301.4125\n",
      "    783        4.0298       0.9397        4.0904  6.5400\n",
      "    784        4.0298       0.9411        4.0906  20.4270\n",
      "    785        4.0298       0.9411        4.0909  304.3459\n",
      "    786        4.0298       0.9397        4.0911  6.5472\n",
      "    787        4.0298       0.9397        4.0914  17.4727\n",
      "    788        4.0298       0.9391        4.0911  305.6267\n",
      "    789        4.0298       0.9397        4.0908  6.5070\n",
      "    790        4.0298       0.9394        4.0912  16.1036\n",
      "    791        4.0298       0.9384        4.0914  22.7524\n",
      "    792        4.0298       0.9394        4.0912  6.6025\n",
      "    793        4.0298       0.9394        4.0917  15.6755\n",
      "    794        4.0298       0.9384        4.0919  22.7244\n",
      "    795        4.0298       0.9384        4.0918  291.7400\n",
      "    796        4.0298       0.9391        4.0916  13.5735\n",
      "    797        4.0298       0.9381        4.0922  22.7528\n",
      "    798        4.0298       0.9374        4.0923  293.1287\n",
      "    799        4.0298       0.9377        4.0921  11.9029\n",
      "    800        4.0298       0.9374        4.0920  22.8106\n",
      "    801        4.0298       0.9384        4.0920  294.4809\n",
      "    802        4.0298       0.9387        4.0920  10.6113\n",
      "    803        4.0298       0.9377        4.0919  22.8462\n",
      "    804        4.0298       0.9387        4.0912  296.5666\n",
      "    805        4.0298       0.9401        4.0913  8.4292\n",
      "    806        4.0298       0.9401        4.0911  22.9074\n",
      "    807        4.0298       0.9394        4.0908  298.0517\n",
      "    808        4.0298       0.9394        4.0906  6.6759\n",
      "    809        4.0298       0.9397        4.0905  22.8447\n",
      "    810        4.0298       0.9384        4.0906  298.6704\n",
      "    811        4.0298       0.9384        4.0911  6.5551\n",
      "    812        4.0298       0.9387        4.0913  22.8183\n",
      "    813        4.0298       0.9381        4.0914  301.0954\n",
      "    814        4.0298       0.9394        4.0914  6.5484\n",
      "    815        4.0298       0.9397        4.0913  21.0699\n",
      "    816        4.0298       0.9391        4.0914  302.0178\n",
      "    817        4.0298       0.9387        4.0917  6.4836\n",
      "    818        4.0298       0.9384        4.0915  19.8198\n",
      "    819        4.0298       0.9381        4.0913  304.2146\n",
      "    820        4.0298       0.9381        4.0916  6.5867\n",
      "    821        4.0298       0.9377        4.0918  17.9629\n",
      "    822        4.0298       0.9387        4.0912  22.8525\n",
      "    823        \u001b[36m4.0298\u001b[0m       0.9387        4.0912  6.5838\n",
      "    824        \u001b[36m4.0298\u001b[0m       0.9397        4.0910  15.9035\n",
      "    825        4.0298       0.9394        4.0907  22.8970\n",
      "    826        4.0298       0.9397        4.0907  6.5652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    827        4.0298       0.9397        4.0907  15.3676\n",
      "    828        4.0298       0.9397        4.0907  22.9042\n",
      "    829        4.0298       0.9397        4.0906  290.2831\n",
      "    830        4.0298       0.9401        4.0908  15.3119\n",
      "    831        4.0298       0.9397        4.0905  22.9366\n",
      "    832        4.0298       0.9397        4.0905  291.9086\n",
      "    833        4.0298       0.9394        4.0904  13.4076\n",
      "    834        4.0298       0.9394        4.0903  22.9931\n",
      "    835        4.0298       0.9404        4.0899  293.0152\n",
      "    836        4.0298       0.9401        4.0904  12.2199\n",
      "    837        4.0298       0.9391        4.0905  22.9903\n",
      "    838        4.0298       0.9394        4.0906  293.9956\n",
      "    839        4.0298       0.9381        4.0906  11.1796\n",
      "    840        4.0298       0.9387        4.0910  22.8685\n",
      "    841        4.0298       0.9381        4.0911  296.1385\n",
      "    842        4.0298       0.9397        4.0911  9.1696\n",
      "    843        4.0298       0.9394        4.0909  22.9860\n",
      "    844        4.0298       0.9384        4.0910  297.2119\n",
      "    845        4.0298       0.9394        4.0905  8.2235\n",
      "    846        4.0298       0.9397        4.0906  22.9278\n",
      "    847        4.0298       0.9394        4.0904  297.3015\n",
      "    848        4.0298       0.9394        4.0904  8.0040\n",
      "    849        4.0298       0.9401        4.0906  22.9460\n",
      "    850        4.0298       0.9387        4.0912  299.1137\n",
      "    851        4.0298       0.9387        4.0911  6.5680\n",
      "    852        4.0298       0.9371        4.0917  23.3562\n",
      "    853        4.0298       0.9371        4.0914  300.5060\n",
      "    854        4.0298       0.9381        4.0910  6.6078\n",
      "    855        4.0298       0.9394        4.0908  21.9194\n",
      "    856        4.0298       0.9377        4.0914  301.3853\n",
      "    857        4.0298       0.9374        4.0915  6.5654\n",
      "    858        4.0298       0.9384        4.0914  20.8865\n",
      "    859        4.0298       0.9384        4.0917  303.8772\n",
      "    860        4.0298       0.9377        4.0916  6.5658\n",
      "    861        4.0298       0.9377        4.0915  18.4855\n",
      "    862        4.0298       0.9377        4.0914  23.9107\n",
      "    863        4.0298       0.9377        4.0913  6.6232\n",
      "    864        4.0298       0.9387        4.0907  17.0349\n",
      "    865        4.0298       0.9384        4.0909  22.9290\n",
      "    866        4.0298       0.9397        4.0904  6.6042\n",
      "    867        4.0298       0.9391        4.0906  15.8637\n",
      "    868        4.0298       0.9391        4.0911  22.9682\n",
      "    869        4.0298       0.9384        4.0915  290.4402\n",
      "    870        4.0298       0.9381        4.0913  15.1777\n",
      "    871        4.0298       0.9377        4.0916  22.9278\n",
      "    872        4.0298       0.9377        4.0916  291.9727\n",
      "    873        4.0298       0.9368        4.0918  13.3446\n",
      "    874        4.0298       0.9368        4.0916  22.9695\n",
      "    875        4.0298       0.9374        4.0915  293.0023\n",
      "    876        4.0298       0.9387        4.0911  11.6075\n",
      "    877        4.0298       0.9387        4.0914  23.0026\n",
      "    878        4.0298       0.9374        4.0918  294.6043\n",
      "    879        4.0298       0.9371        4.0918  11.4258\n",
      "    880        4.0298       0.9377        4.0917  23.0299\n",
      "    881        4.0298       0.9374        4.0920  295.6638\n",
      "    882        4.0298       0.9374        4.0920  9.8511\n",
      "    883        4.0298       0.9368        4.0922  22.9863\n",
      "    884        4.0298       0.9364        4.0923  296.5953\n",
      "    885        4.0298       0.9364        4.0925  9.0330\n",
      "    886        4.0298       0.9377        4.0924  23.0763\n",
      "    887        4.0298       0.9374        4.0920  296.5577\n",
      "    888        4.0298       0.9374        4.0920  9.2511\n",
      "    889        4.0298       0.9364        4.0920  23.0343\n",
      "    890        4.0298       0.9377        4.0914  297.8102\n",
      "    891        4.0298       0.9377        4.0912  8.0406\n",
      "    892        4.0298       0.9371        4.0916  23.0465\n",
      "    893        4.0298       0.9364        4.0919  298.2928\n",
      "    894        4.0298       0.9368        4.0925  7.1091\n",
      "    895        4.0298       0.9368        4.0922  23.1190\n",
      "    896        4.0298       0.9371        4.0922  298.3948\n",
      "    897        4.0298       0.9384        4.0915  7.1972\n",
      "    898        4.0298       0.9387        4.0915  23.0480\n",
      "    899        4.0298       0.9377        4.0919  299.2541\n",
      "    900        4.0298       0.9381        4.0918  6.5867\n",
      "    901        4.0298       0.9377        4.0914  23.0446\n",
      "    902        4.0298       0.9377        4.0918  300.1429\n",
      "    903        4.0298       0.9377        4.0910  6.6209\n",
      "    904        4.0298       0.9381        4.0912  22.6958\n",
      "    905        4.0298       0.9384        4.0910  301.4336\n",
      "    906        4.0298       0.9387        4.0912  6.6479\n",
      "    907        4.0298       0.9387        4.0910  21.6009\n",
      "    908        4.0298       0.9387        4.0912  302.5863\n",
      "    909        4.0298       0.9381        4.0913  6.6545\n",
      "    910        4.0298       0.9384        4.0909  20.5186\n",
      "    911        4.0298       0.9394        4.0909  303.5912\n",
      "    912        4.0298       0.9377        4.0911  6.6823\n",
      "    913        4.0298       0.9381        4.0916  19.5175\n",
      "    914        4.0298       0.9381        4.0918  304.6452\n",
      "    915        4.0298       0.9381        4.0916  6.6578\n",
      "    916        4.0298       0.9374        4.0916  18.5409\n",
      "    917        4.0298       0.9374        4.0914  305.6461\n",
      "    918        4.0298       0.9381        4.0914  6.7074\n",
      "    919        4.0298       0.9377        4.0910  19.3338\n",
      "    920        4.0298       0.9377        4.0911  305.3880\n",
      "    921        4.0298       0.9377        4.0910  6.6211\n",
      "    922        4.0298       0.9391        4.0909  18.1335\n",
      "    923        4.0298       0.9391        4.0909  305.4134\n",
      "    924        4.0298       0.9384        4.0908  6.6350\n",
      "    925        4.0298       0.9407        4.0902  17.9826\n",
      "    926        4.0298       0.9407        4.0903  306.1930\n",
      "    927        4.0298       0.9411        4.0902  6.6538\n",
      "    928        4.0298       0.9401        4.0904  17.3224\n",
      "    929        4.0298       0.9404        4.0900  306.8503\n",
      "    930        4.0298       0.9411        4.0900  6.6410\n",
      "    931        4.0298       0.9421        4.0895  17.1545\n",
      "    932        4.0298       0.9417        4.0898  311.3360\n",
      "    933        4.0298       0.9417        4.0898  6.6913\n",
      "    934        4.0298       0.9411        4.0900  17.4644\n",
      "    935        4.0298       0.9417        4.0897  23.3201\n",
      "    936        4.0298       0.9414        4.0898  6.6570\n",
      "    937        4.0298       0.9401        4.0904  16.5109\n",
      "    938        4.0298       0.9404        4.0903  23.2981\n",
      "    939        4.0298       0.9411        4.0903  6.7443\n",
      "    940        4.0298       0.9401        4.0910  17.1959\n",
      "    941        4.0298       0.9381        4.0913  23.3018\n",
      "    942        4.0298       0.9384        4.0912  6.8020\n",
      "    943        4.0298       0.9387        4.0916  17.2305\n",
      "    944        4.0298       0.9384        4.0914  23.3873\n",
      "    945        4.0298       0.9384        4.0913  6.7969\n",
      "    946        \u001b[36m4.0298\u001b[0m       0.9387        4.0910  18.0204\n",
      "    947        4.0298       0.9394        4.0906  66.2311\n",
      "    948        4.0298       0.9391        4.0910  6.6788\n",
      "    949        4.0298       0.9391        4.0913  17.4672\n",
      "    950        4.0298       0.9387        4.0912  16.2881\n",
      "    951        4.0298       0.9387        4.0910  6.7636\n",
      "    952        4.0298       0.9384        4.0911  32.3476\n",
      "    953        4.0298       0.9387        4.0912  16.4279\n",
      "    954        4.0298       0.9391        4.0907  23.3879\n",
      "    955        4.0298       0.9394        4.0904  6.7781\n",
      "    956        4.0298       0.9394        4.0900  9.1316\n",
      "    957        4.0298       0.9391        4.0903  6.9559\n",
      "    958        4.0298       0.9391        4.0902  6.8033\n",
      "    959        4.0298       0.9394        4.0909  6.6816\n",
      "    960        4.0298       0.9394        4.0912  7.1973\n",
      "    961        4.0298       0.9384        4.0911  7.6304\n",
      "    962        4.0298       0.9387        4.0911  25.5570\n",
      "    963        4.0298       0.9387        4.0908  14.0969\n",
      "    964        4.0298       0.9384        4.0906  23.5155\n",
      "    965        4.0298       0.9384        4.0905  292.0427\n",
      "    966        4.0298       0.9391        4.0908  14.0615\n",
      "    967        \u001b[36m4.0298\u001b[0m       0.9391        4.0904  23.4569\n",
      "    968        4.0298       0.9394        4.0905  93.5483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    969        4.0298       0.9394        4.0906  7.9113\n",
      "    970        4.0298       0.9387        4.0910  7.2865\n",
      "    971        4.0298       0.9384        4.0908  7.0860\n",
      "    972        4.0298       0.9377        4.0908  6.9257\n",
      "    973        4.0298       0.9391        4.0906  6.8468\n",
      "    974        4.0298       0.9404        4.0902  6.8487\n",
      "    975        4.0298       0.9404        4.0903  6.9166\n",
      "    976        4.0298       0.9407        4.0902  6.8827\n",
      "    977        4.0298       0.9417        4.0900  6.9436\n",
      "    978        4.0298       0.9401        4.0901  6.9277\n",
      "    979        4.0298       0.9401        4.0900  6.8692\n",
      "    980        4.0298       0.9397        4.0905  7.0795\n",
      "    981        4.0298       0.9397        4.0906  6.9153\n",
      "    982        4.0298       0.9391        4.0907  7.0382\n",
      "    983        4.0298       0.9391        4.0908  7.0542\n",
      "    984        4.0298       0.9401        4.0907  6.9938\n",
      "    985        4.0298       0.9394        4.0907  7.0106\n",
      "    986        4.0298       0.9401        4.0902  6.9701\n",
      "    987        4.0298       0.9401        4.0902  6.9651\n",
      "    988        4.0298       0.9401        4.0904  6.9539\n",
      "    989        4.0298       0.9397        4.0905  6.9193\n",
      "    990        4.0298       0.9397        4.0905  6.9595\n",
      "    991        4.0298       0.9411        4.0902  6.9000\n",
      "    992        4.0298       0.9407        4.0901  6.9903\n",
      "    993        4.0298       0.9394        4.0905  7.0617\n",
      "    994        4.0298       0.9387        4.0913  6.9368\n",
      "    995        4.0298       0.9391        4.0912  6.9417\n",
      "    996        4.0298       0.9377        4.0912  6.9876\n",
      "    997        4.0298       0.9377        4.0915  6.9780\n",
      "    998        4.0298       0.9377        4.0915  6.9623\n",
      "    999        4.0298       0.9381        4.0915  7.0506\n",
      "   1000        4.0298       0.9384        4.0912  6.9581\n",
      "training accuracy\n",
      "{50: 0.9867549668874173}\n",
      "Val accuracy\n",
      "{50: 0.9006666666666666}\n",
      "pred time\n",
      "{50: 0.35434603691101074}\n",
      "OOS Val Accuracy\n",
      "{50: 0.08}\n",
      "OOS pred time\n",
      "{50: 0.010483264923095703}\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "hidden_dim = 800 \n",
    "dropout = 0.75\n",
    "\n",
    "print(hidden_dim)\n",
    "class CLINCModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim=vocab_dim,\n",
    "            hidden_dim=hidden_dim, #setting hidden layer size\n",
    "            output_dim=output_dim,\n",
    "            dropout=dropout\n",
    "    ):\n",
    "        super(CLINCModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = F.relu(self.hidden(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "module=CLINCModule,\n",
    "lr=lr,\n",
    "criterion=torch.nn.CrossEntropyLoss,\n",
    "max_epochs=1000,\n",
    "optimizer=torch.optim.Adam, #Early Stopping removed\n",
    ")\n",
    "\n",
    "net.fit(train_x, train_y)\n",
    "tlabels = net.predict(train_x)\n",
    "tacc[patience] = accuracy_score(tlabels, train_y)\n",
    "print('training accuracy')\n",
    "print(tacc)\n",
    "time0 = time.time()\n",
    "labels = net.predict(val_x)\n",
    "vacc[patience] = accuracy_score(labels, val_y)\n",
    "time1 = time.time()\n",
    "vtime[patience] = time1-time0\n",
    "print('Val accuracy')\n",
    "print(vacc)\n",
    "print('pred time')\n",
    "print(vtime)\n",
    "time2 = time.time()\n",
    "olabels = net.predict(val_oos_x)\n",
    "oacc[patience] = accuracy_score(olabels, val_oos_y)\n",
    "time3 = time.time()\n",
    "otime[patience]=time3-time2\n",
    "print('OOS Val Accuracy')\n",
    "print(oacc)\n",
    "print('OOS pred time')\n",
    "print(otime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is worse. Retraining model using optimal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0158\u001b[0m       \u001b[32m0.5401\u001b[0m        \u001b[35m5.0104\u001b[0m  6.2687\n",
      "      2        \u001b[36m4.9119\u001b[0m       0.4685        \u001b[35m4.7284\u001b[0m  6.2613\n",
      "      3        \u001b[36m4.5989\u001b[0m       \u001b[32m0.6712\u001b[0m        \u001b[35m4.4784\u001b[0m  6.2625\n",
      "      4        \u001b[36m4.4203\u001b[0m       \u001b[32m0.7672\u001b[0m        \u001b[35m4.3602\u001b[0m  6.2490\n",
      "      5        \u001b[36m4.3205\u001b[0m       \u001b[32m0.8142\u001b[0m        \u001b[35m4.2892\u001b[0m  6.2845\n",
      "      6        \u001b[36m4.2618\u001b[0m       \u001b[32m0.8348\u001b[0m        \u001b[35m4.2541\u001b[0m  6.2805\n",
      "      7        \u001b[36m4.2274\u001b[0m       \u001b[32m0.8454\u001b[0m        \u001b[35m4.2330\u001b[0m  6.3284\n",
      "      8        \u001b[36m4.2029\u001b[0m       \u001b[32m0.8573\u001b[0m        \u001b[35m4.2160\u001b[0m  6.2509\n",
      "      9        \u001b[36m4.1778\u001b[0m       \u001b[32m0.8801\u001b[0m        \u001b[35m4.1933\u001b[0m  6.2657\n",
      "     10        \u001b[36m4.1532\u001b[0m       \u001b[32m0.9020\u001b[0m        \u001b[35m4.1732\u001b[0m  6.1212\n",
      "     11        \u001b[36m4.1310\u001b[0m       \u001b[32m0.9106\u001b[0m        \u001b[35m4.1584\u001b[0m  6.2055\n",
      "     12        \u001b[36m4.1183\u001b[0m       \u001b[32m0.9136\u001b[0m        \u001b[35m4.1505\u001b[0m  6.2318\n",
      "     13        \u001b[36m4.1070\u001b[0m       \u001b[32m0.9166\u001b[0m        \u001b[35m4.1435\u001b[0m  6.2497\n",
      "     14        \u001b[36m4.0961\u001b[0m       \u001b[32m0.9265\u001b[0m        \u001b[35m4.1348\u001b[0m  6.2474\n",
      "     15        \u001b[36m4.0888\u001b[0m       0.9255        \u001b[35m4.1310\u001b[0m  6.3155\n",
      "     16        \u001b[36m4.0808\u001b[0m       \u001b[32m0.9305\u001b[0m        \u001b[35m4.1266\u001b[0m  6.2787\n",
      "     17        \u001b[36m4.0758\u001b[0m       \u001b[32m0.9321\u001b[0m        \u001b[35m4.1240\u001b[0m  6.3158\n",
      "     18        \u001b[36m4.0699\u001b[0m       \u001b[32m0.9341\u001b[0m        \u001b[35m4.1219\u001b[0m  6.3194\n",
      "     19        \u001b[36m4.0656\u001b[0m       0.9318        \u001b[35m4.1200\u001b[0m  6.3029\n",
      "     20        \u001b[36m4.0614\u001b[0m       \u001b[32m0.9344\u001b[0m        \u001b[35m4.1169\u001b[0m  6.2961\n",
      "     21        \u001b[36m4.0563\u001b[0m       \u001b[32m0.9361\u001b[0m        \u001b[35m4.1140\u001b[0m  6.3312\n",
      "     22        \u001b[36m4.0523\u001b[0m       \u001b[32m0.9377\u001b[0m        \u001b[35m4.1115\u001b[0m  6.2926\n",
      "     23        \u001b[36m4.0503\u001b[0m       \u001b[32m0.9394\u001b[0m        \u001b[35m4.1095\u001b[0m  6.2311\n",
      "     24        \u001b[36m4.0484\u001b[0m       \u001b[32m0.9404\u001b[0m        \u001b[35m4.1081\u001b[0m  6.2255\n",
      "     25        \u001b[36m4.0463\u001b[0m       0.9394        \u001b[35m4.1074\u001b[0m  6.3347\n",
      "     26        \u001b[36m4.0450\u001b[0m       \u001b[32m0.9417\u001b[0m        \u001b[35m4.1054\u001b[0m  6.3346\n",
      "     27        \u001b[36m4.0433\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m4.1049\u001b[0m  6.3512\n",
      "     28        \u001b[36m4.0429\u001b[0m       \u001b[32m0.9427\u001b[0m        \u001b[35m4.1043\u001b[0m  6.3779\n",
      "     29        \u001b[36m4.0422\u001b[0m       \u001b[32m0.9437\u001b[0m        \u001b[35m4.1032\u001b[0m  6.3355\n",
      "     30        \u001b[36m4.0412\u001b[0m       0.9421        \u001b[35m4.1028\u001b[0m  6.3355\n",
      "     31        \u001b[36m4.0404\u001b[0m       0.9414        4.1032  6.3320\n",
      "     32        \u001b[36m4.0395\u001b[0m       0.9437        \u001b[35m4.1022\u001b[0m  6.3784\n",
      "     33        4.0396       0.9424        \u001b[35m4.1017\u001b[0m  6.3905\n",
      "     34        \u001b[36m4.0394\u001b[0m       \u001b[32m0.9444\u001b[0m        \u001b[35m4.1012\u001b[0m  6.3821\n",
      "     35        \u001b[36m4.0385\u001b[0m       0.9434        \u001b[35m4.1007\u001b[0m  6.3506\n",
      "     36        \u001b[36m4.0380\u001b[0m       0.9440        \u001b[35m4.0997\u001b[0m  6.3735\n",
      "     37        \u001b[36m4.0377\u001b[0m       \u001b[32m0.9447\u001b[0m        \u001b[35m4.0992\u001b[0m  6.3832\n",
      "     38        \u001b[36m4.0373\u001b[0m       0.9424        4.1000  6.4061\n",
      "     39        \u001b[36m4.0365\u001b[0m       0.9440        \u001b[35m4.0987\u001b[0m  6.4063\n",
      "     40        \u001b[36m4.0362\u001b[0m       \u001b[32m0.9450\u001b[0m        4.0987  6.3768\n",
      "     41        \u001b[36m4.0358\u001b[0m       0.9437        4.0989  6.3853\n",
      "     42        \u001b[36m4.0356\u001b[0m       0.9437        \u001b[35m4.0983\u001b[0m  6.4193\n",
      "     43        \u001b[36m4.0353\u001b[0m       0.9434        \u001b[35m4.0982\u001b[0m  6.3686\n",
      "     44        4.0357       0.9440        \u001b[35m4.0973\u001b[0m  6.3752\n",
      "     45        \u001b[36m4.0351\u001b[0m       0.9440        \u001b[35m4.0962\u001b[0m  6.3632\n",
      "     46        \u001b[36m4.0349\u001b[0m       0.9434        4.0968  6.4723\n",
      "     47        \u001b[36m4.0345\u001b[0m       0.9434        4.0969  6.3534\n",
      "     48        \u001b[36m4.0344\u001b[0m       0.9434        4.0964  6.4199\n",
      "     49        \u001b[36m4.0344\u001b[0m       0.9434        \u001b[35m4.0960\u001b[0m  6.4065\n",
      "     50        \u001b[36m4.0339\u001b[0m       0.9450        4.0961  6.5796\n",
      "     51        \u001b[36m4.0336\u001b[0m       \u001b[32m0.9460\u001b[0m        \u001b[35m4.0954\u001b[0m  6.2746\n",
      "     52        4.0341       0.9440        4.0962  6.3003\n",
      "     53        4.0338       0.9430        4.0962  36.5541\n",
      "     54        4.0336       0.9434        4.0955  6.3480\n",
      "     55        4.0336       0.9457        \u001b[35m4.0948\u001b[0m  10.7416\n",
      "     56        \u001b[36m4.0331\u001b[0m       0.9437        \u001b[35m4.0943\u001b[0m  6.5063\n",
      "     57        \u001b[36m4.0330\u001b[0m       0.9447        4.0948  6.8230\n",
      "     58        4.0331       0.9447        4.0947  6.5014\n",
      "     59        4.0331       0.9437        \u001b[35m4.0939\u001b[0m  6.3877\n",
      "     60        \u001b[36m4.0328\u001b[0m       0.9434        4.0939  6.3702\n",
      "     61        4.0328       0.9440        4.0939  6.3653\n",
      "     62        4.0330       0.9454        4.0940  6.3232\n",
      "     63        \u001b[36m4.0326\u001b[0m       0.9437        4.0941  6.3926\n",
      "     64        \u001b[36m4.0325\u001b[0m       0.9437        \u001b[35m4.0939\u001b[0m  6.4544\n",
      "     65        \u001b[36m4.0322\u001b[0m       0.9437        \u001b[35m4.0937\u001b[0m  6.3231\n",
      "     66        4.0323       0.9440        4.0941  6.3814\n",
      "     67        4.0323       0.9424        4.0939  6.4362\n",
      "     68        \u001b[36m4.0321\u001b[0m       0.9430        4.0940  6.5502\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training accuracy\n",
      "{50: 0.9872185430463576}\n",
      "Val accuracy\n",
      "{50: 0.907}\n",
      "pred time\n",
      "{50: 0.37975001335144043}\n",
      "OOS Val Accuracy\n",
      "{50: 0.2}\n",
      "OOS pred time\n",
      "{50: 0.011267662048339844}\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001 # best learning rate\n",
    "tacc={}\n",
    "vacc = {}\n",
    "vtime = {}\n",
    "oacc = {}\n",
    "otime = {}\n",
    "hidden_dim = 800 #hidden layer size\n",
    "dropout = 0.75 #best dropout rate\n",
    "\n",
    "print(hidden_dim)\n",
    "class CLINCModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim=vocab_dim,\n",
    "            hidden_dim=hidden_dim, \n",
    "            output_dim=output_dim,\n",
    "            dropout=dropout\n",
    "    ):\n",
    "        super(CLINCModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim) #one hidden layer only\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = F.relu(self.hidden(X)) #best activation function for hidden layer\n",
    "        X = self.dropout(X)\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "module=CLINCModule,\n",
    "lr=lr,\n",
    "criterion=torch.nn.CrossEntropyLoss,\n",
    "max_epochs=1000,\n",
    "optimizer=torch.optim.Adam, #best optimizer.\n",
    "callbacks=[EarlyStopping(patience=10)], #best patience\n",
    ")\n",
    "\n",
    "net.fit(train_x, train_y)\n",
    "tlabels = net.predict(train_x)\n",
    "tacc[patience] = accuracy_score(tlabels, train_y)\n",
    "print('training accuracy')\n",
    "print(tacc)\n",
    "time0 = time.time()\n",
    "labels = net.predict(val_x)\n",
    "vacc[patience] = accuracy_score(labels, val_y)\n",
    "time1 = time.time()\n",
    "vtime[patience] = time1-time0\n",
    "print('Val accuracy')\n",
    "print(vacc)\n",
    "print('pred time')\n",
    "print(vtime)\n",
    "time2 = time.time()\n",
    "olabels = net.predict(val_oos_x)\n",
    "oacc[patience] = accuracy_score(olabels, val_oos_y)\n",
    "time3 = time.time()\n",
    "otime[patience]=time3-time2\n",
    "print('OOS Val Accuracy')\n",
    "print(oacc)\n",
    "print('OOS pred time')\n",
    "print(otime)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting best model\n",
    "import pickle\n",
    "with open('okmlp.pkl', 'wb') as f:\n",
    "    pickle.dump(net, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing for best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0158\u001b[0m       \u001b[32m0.5652\u001b[0m        \u001b[35m5.0103\u001b[0m  7.3780\n",
      "      2        \u001b[36m4.9108\u001b[0m       0.4795        \u001b[35m4.7254\u001b[0m  6.3650\n",
      "      3        \u001b[36m4.5992\u001b[0m       \u001b[32m0.6844\u001b[0m        \u001b[35m4.4755\u001b[0m  6.2726\n",
      "      4        \u001b[36m4.4187\u001b[0m       \u001b[32m0.7679\u001b[0m        \u001b[35m4.3620\u001b[0m  6.3744\n",
      "      5        \u001b[36m4.3210\u001b[0m       \u001b[32m0.8043\u001b[0m        \u001b[35m4.2964\u001b[0m  6.6267\n",
      "      6        \u001b[36m4.2667\u001b[0m       \u001b[32m0.8325\u001b[0m        \u001b[35m4.2560\u001b[0m  6.4749\n",
      "      7        \u001b[36m4.2296\u001b[0m       \u001b[32m0.8497\u001b[0m        \u001b[35m4.2316\u001b[0m  6.4373\n",
      "      8        \u001b[36m4.1983\u001b[0m       \u001b[32m0.8626\u001b[0m        \u001b[35m4.2106\u001b[0m  6.5754\n",
      "      9        \u001b[36m4.1758\u001b[0m       \u001b[32m0.8838\u001b[0m        \u001b[35m4.1920\u001b[0m  6.5171\n",
      "     10        \u001b[36m4.1522\u001b[0m       \u001b[32m0.8983\u001b[0m        \u001b[35m4.1736\u001b[0m  6.4708\n",
      "     11        \u001b[36m4.1334\u001b[0m       \u001b[32m0.9063\u001b[0m        \u001b[35m4.1614\u001b[0m  6.4083\n",
      "     12        \u001b[36m4.1167\u001b[0m       \u001b[32m0.9123\u001b[0m        \u001b[35m4.1510\u001b[0m  6.3205\n",
      "     13        \u001b[36m4.1069\u001b[0m       \u001b[32m0.9129\u001b[0m        \u001b[35m4.1462\u001b[0m  6.3431\n",
      "     14        \u001b[36m4.1000\u001b[0m       \u001b[32m0.9156\u001b[0m        \u001b[35m4.1417\u001b[0m  6.3934\n",
      "     15        \u001b[36m4.0949\u001b[0m       \u001b[32m0.9192\u001b[0m        \u001b[35m4.1380\u001b[0m  6.6151\n",
      "     16        \u001b[36m4.0872\u001b[0m       \u001b[32m0.9242\u001b[0m        \u001b[35m4.1320\u001b[0m  6.6096\n",
      "     17        \u001b[36m4.0816\u001b[0m       \u001b[32m0.9248\u001b[0m        \u001b[35m4.1304\u001b[0m  6.4559\n",
      "     18        \u001b[36m4.0752\u001b[0m       0.9232        \u001b[35m4.1280\u001b[0m  6.5776\n",
      "     19        \u001b[36m4.0684\u001b[0m       \u001b[32m0.9338\u001b[0m        \u001b[35m4.1224\u001b[0m  6.6613\n",
      "     20        \u001b[36m4.0630\u001b[0m       \u001b[32m0.9358\u001b[0m        \u001b[35m4.1194\u001b[0m  6.6056\n",
      "     21        \u001b[36m4.0577\u001b[0m       \u001b[32m0.9384\u001b[0m        \u001b[35m4.1153\u001b[0m  6.5959\n",
      "     22        \u001b[36m4.0544\u001b[0m       0.9384        \u001b[35m4.1130\u001b[0m  6.6127\n",
      "     23        \u001b[36m4.0518\u001b[0m       \u001b[32m0.9404\u001b[0m        \u001b[35m4.1108\u001b[0m  6.6218\n",
      "     24        \u001b[36m4.0484\u001b[0m       \u001b[32m0.9411\u001b[0m        \u001b[35m4.1089\u001b[0m  6.6362\n",
      "     25        \u001b[36m4.0474\u001b[0m       0.9397        \u001b[35m4.1074\u001b[0m  6.5840\n",
      "     26        \u001b[36m4.0457\u001b[0m       \u001b[32m0.9417\u001b[0m        \u001b[35m4.1062\u001b[0m  6.6712\n",
      "     27        \u001b[36m4.0440\u001b[0m       0.9407        4.1063  6.5705\n",
      "     28        \u001b[36m4.0436\u001b[0m       \u001b[32m0.9421\u001b[0m        \u001b[35m4.1053\u001b[0m  6.7617\n",
      "     29        \u001b[36m4.0420\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m4.1043\u001b[0m  6.6729\n",
      "     30        \u001b[36m4.0410\u001b[0m       0.9401        4.1044  6.5715\n",
      "     31        \u001b[36m4.0408\u001b[0m       0.9421        \u001b[35m4.1034\u001b[0m  6.5173\n",
      "     32        \u001b[36m4.0400\u001b[0m       0.9424        \u001b[35m4.1023\u001b[0m  6.6072\n",
      "     33        \u001b[36m4.0392\u001b[0m       0.9411        \u001b[35m4.1022\u001b[0m  6.8117\n",
      "     34        \u001b[36m4.0391\u001b[0m       \u001b[32m0.9440\u001b[0m        \u001b[35m4.1011\u001b[0m  6.5246\n",
      "     35        \u001b[36m4.0385\u001b[0m       0.9421        \u001b[35m4.1008\u001b[0m  6.5179\n",
      "     36        \u001b[36m4.0376\u001b[0m       0.9434        \u001b[35m4.0997\u001b[0m  6.5783\n",
      "     37        \u001b[36m4.0375\u001b[0m       0.9427        \u001b[35m4.0995\u001b[0m  6.5168\n",
      "     38        4.0376       0.9430        \u001b[35m4.0992\u001b[0m  6.7997\n",
      "     39        \u001b[36m4.0370\u001b[0m       \u001b[32m0.9444\u001b[0m        \u001b[35m4.0985\u001b[0m  6.6754\n",
      "     40        \u001b[36m4.0363\u001b[0m       0.9434        4.0988  6.3800\n",
      "     41        \u001b[36m4.0356\u001b[0m       0.9427        4.0986  6.5241\n",
      "     42        4.0364       0.9427        4.0985  6.6244\n",
      "     43        \u001b[36m4.0353\u001b[0m       \u001b[32m0.9450\u001b[0m        \u001b[35m4.0971\u001b[0m  6.4910\n",
      "     44        \u001b[36m4.0353\u001b[0m       0.9447        \u001b[35m4.0971\u001b[0m  6.6612\n",
      "     45        \u001b[36m4.0350\u001b[0m       \u001b[32m0.9454\u001b[0m        \u001b[35m4.0964\u001b[0m  6.6624\n",
      "     46        4.0350       0.9444        \u001b[35m4.0964\u001b[0m  6.6079\n",
      "     47        \u001b[36m4.0347\u001b[0m       \u001b[32m0.9457\u001b[0m        \u001b[35m4.0960\u001b[0m  6.5881\n",
      "     48        \u001b[36m4.0345\u001b[0m       0.9447        4.0968  6.5672\n",
      "     49        \u001b[36m4.0343\u001b[0m       0.9417        4.0973  6.5351\n",
      "     50        4.0345       0.9440        4.0966  6.8191\n",
      "     51        \u001b[36m4.0338\u001b[0m       0.9411        4.0961  6.6679\n",
      "     52        \u001b[36m4.0337\u001b[0m       0.9427        \u001b[35m4.0957\u001b[0m  6.7431\n",
      "     53        4.0341       0.9450        \u001b[35m4.0952\u001b[0m  6.5949\n",
      "     54        \u001b[36m4.0336\u001b[0m       \u001b[32m0.9464\u001b[0m        \u001b[35m4.0947\u001b[0m  6.6611\n",
      "     55        4.0338       0.9427        4.0957  6.5703\n",
      "     56        \u001b[36m4.0335\u001b[0m       0.9457        4.0948  6.5873\n",
      "     57        \u001b[36m4.0335\u001b[0m       0.9444        4.0950  6.5712\n",
      "     58        \u001b[36m4.0332\u001b[0m       0.9427        4.0951  6.5499\n",
      "     59        \u001b[36m4.0332\u001b[0m       0.9440        \u001b[35m4.0944\u001b[0m  6.5306\n",
      "     60        \u001b[36m4.0329\u001b[0m       0.9434        \u001b[35m4.0941\u001b[0m  6.6320\n",
      "     61        \u001b[36m4.0327\u001b[0m       0.9450        \u001b[35m4.0939\u001b[0m  6.5918\n",
      "     62        4.0327       0.9444        \u001b[35m4.0938\u001b[0m  6.5513\n",
      "     63        \u001b[36m4.0326\u001b[0m       0.9447        \u001b[35m4.0934\u001b[0m  6.8247\n",
      "     64        4.0328       0.9440        4.0935  7.0945\n",
      "     65        \u001b[36m4.0323\u001b[0m       0.9440        4.0936  6.9377\n",
      "     66        4.0325       0.9460        4.0935  7.0976\n",
      "     67        4.0324       0.9434        4.0934  6.8563\n",
      "     68        4.0326       0.9450        \u001b[35m4.0931\u001b[0m  7.3395\n",
      "     69        4.0323       0.9440        4.0934  7.2417\n",
      "     70        \u001b[36m4.0322\u001b[0m       0.9444        4.0936  7.0701\n",
      "     71        \u001b[36m4.0321\u001b[0m       0.9414        4.0940  7.0130\n",
      "     72        \u001b[36m4.0319\u001b[0m       0.9447        \u001b[35m4.0928\u001b[0m  6.8471\n",
      "     73        4.0324       0.9437        4.0929  7.0414\n",
      "     74        \u001b[36m4.0316\u001b[0m       0.9437        4.0929  6.7322\n",
      "     75        4.0319       0.9427        4.0929  6.3843\n",
      "     76        4.0318       0.9434        4.0929  6.4033\n",
      "     77        4.0318       0.9434        \u001b[35m4.0927\u001b[0m  6.6976\n",
      "     78        \u001b[36m4.0314\u001b[0m       0.9430        4.0935  6.1948\n",
      "     79        4.0316       0.9440        4.0927  6.4118\n",
      "     80        4.0319       0.9430        4.0932  6.4593\n",
      "     81        4.0316       0.9437        4.0927  6.5620\n",
      "     82        4.0315       0.9464        \u001b[35m4.0923\u001b[0m  6.7093\n",
      "     83        4.0316       0.9464        \u001b[35m4.0917\u001b[0m  6.5320\n",
      "     84        4.0314       0.9450        4.0923  6.6209\n",
      "     85        4.0317       0.9454        4.0921  6.4171\n",
      "     86        4.0315       0.9457        \u001b[35m4.0910\u001b[0m  6.4097\n",
      "     87        \u001b[36m4.0313\u001b[0m       0.9450        4.0917  6.4008\n",
      "     88        4.0315       0.9460        4.0913  6.3601\n",
      "     89        \u001b[36m4.0312\u001b[0m       0.9454        4.0917  6.4099\n",
      "     90        \u001b[36m4.0311\u001b[0m       0.9460        4.0913  6.4545\n",
      "     91        4.0312       0.9450        4.0911  6.5361\n",
      "     92        4.0312       0.9447        4.0918  6.4953\n",
      "     93        4.0312       0.9457        4.0917  6.4083\n",
      "     94        4.0312       \u001b[32m0.9470\u001b[0m        4.0911  6.3966\n",
      "     95        4.0314       0.9450        4.0916  6.4872\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0158\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m5.0103\u001b[0m  6.2935\n",
      "      2        \u001b[36m4.9131\u001b[0m       0.4818        \u001b[35m4.7290\u001b[0m  6.3161\n",
      "      3        \u001b[36m4.5958\u001b[0m       \u001b[32m0.6854\u001b[0m        \u001b[35m4.4725\u001b[0m  6.3207\n",
      "      4        \u001b[36m4.4132\u001b[0m       \u001b[32m0.7728\u001b[0m        \u001b[35m4.3536\u001b[0m  6.3773\n",
      "      5        \u001b[36m4.3178\u001b[0m       \u001b[32m0.8113\u001b[0m        \u001b[35m4.2923\u001b[0m  6.7509\n",
      "      6        \u001b[36m4.2637\u001b[0m       \u001b[32m0.8295\u001b[0m        \u001b[35m4.2564\u001b[0m  6.3980\n",
      "      7        \u001b[36m4.2267\u001b[0m       \u001b[32m0.8457\u001b[0m        \u001b[35m4.2315\u001b[0m  6.5243\n",
      "      8        \u001b[36m4.2023\u001b[0m       \u001b[32m0.8613\u001b[0m        \u001b[35m4.2137\u001b[0m  6.4166\n",
      "      9        \u001b[36m4.1786\u001b[0m       \u001b[32m0.8831\u001b[0m        \u001b[35m4.1939\u001b[0m  6.3197\n",
      "     10        \u001b[36m4.1510\u001b[0m       \u001b[32m0.9026\u001b[0m        \u001b[35m4.1712\u001b[0m  6.4056\n",
      "     11        \u001b[36m4.1297\u001b[0m       \u001b[32m0.9073\u001b[0m        \u001b[35m4.1594\u001b[0m  6.2978\n",
      "     12        \u001b[36m4.1171\u001b[0m       \u001b[32m0.9106\u001b[0m        \u001b[35m4.1513\u001b[0m  6.2815\n",
      "     13        \u001b[36m4.1069\u001b[0m       \u001b[32m0.9146\u001b[0m        \u001b[35m4.1452\u001b[0m  6.3123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     14        \u001b[36m4.0999\u001b[0m       \u001b[32m0.9156\u001b[0m        \u001b[35m4.1411\u001b[0m  6.2991\n",
      "     15        \u001b[36m4.0943\u001b[0m       \u001b[32m0.9166\u001b[0m        \u001b[35m4.1380\u001b[0m  6.3786\n",
      "     16        \u001b[36m4.0865\u001b[0m       \u001b[32m0.9255\u001b[0m        \u001b[35m4.1306\u001b[0m  6.6013\n",
      "     17        \u001b[36m4.0777\u001b[0m       \u001b[32m0.9291\u001b[0m        \u001b[35m4.1266\u001b[0m  6.6279\n",
      "     18        \u001b[36m4.0717\u001b[0m       \u001b[32m0.9321\u001b[0m        \u001b[35m4.1234\u001b[0m  6.4790\n",
      "     19        \u001b[36m4.0659\u001b[0m       \u001b[32m0.9348\u001b[0m        \u001b[35m4.1206\u001b[0m  6.4075\n",
      "     20        \u001b[36m4.0618\u001b[0m       \u001b[32m0.9354\u001b[0m        \u001b[35m4.1172\u001b[0m  6.3652\n",
      "     21        \u001b[36m4.0571\u001b[0m       \u001b[32m0.9394\u001b[0m        \u001b[35m4.1144\u001b[0m  6.4991\n",
      "     22        \u001b[36m4.0532\u001b[0m       \u001b[32m0.9397\u001b[0m        \u001b[35m4.1117\u001b[0m  6.5207\n",
      "     23        \u001b[36m4.0513\u001b[0m       \u001b[32m0.9427\u001b[0m        \u001b[35m4.1093\u001b[0m  6.3909\n",
      "     24        \u001b[36m4.0488\u001b[0m       0.9417        \u001b[35m4.1077\u001b[0m  6.3628\n",
      "     25        \u001b[36m4.0477\u001b[0m       0.9427        \u001b[35m4.1068\u001b[0m  6.3544\n",
      "     26        \u001b[36m4.0454\u001b[0m       0.9407        \u001b[35m4.1058\u001b[0m  6.4454\n",
      "     27        \u001b[36m4.0444\u001b[0m       \u001b[32m0.9437\u001b[0m        \u001b[35m4.1045\u001b[0m  6.4014\n",
      "     28        \u001b[36m4.0429\u001b[0m       0.9427        \u001b[35m4.1041\u001b[0m  6.3866\n",
      "     29        \u001b[36m4.0423\u001b[0m       0.9434        \u001b[35m4.1031\u001b[0m  6.5668\n",
      "     30        \u001b[36m4.0411\u001b[0m       0.9437        \u001b[35m4.1027\u001b[0m  6.3973\n",
      "     31        \u001b[36m4.0401\u001b[0m       0.9430        \u001b[35m4.1022\u001b[0m  6.4261\n",
      "     32        4.0405       0.9437        \u001b[35m4.1020\u001b[0m  6.3931\n",
      "     33        \u001b[36m4.0395\u001b[0m       0.9430        \u001b[35m4.1006\u001b[0m  6.4643\n",
      "     34        \u001b[36m4.0392\u001b[0m       \u001b[32m0.9444\u001b[0m        \u001b[35m4.1000\u001b[0m  6.4359\n",
      "     35        \u001b[36m4.0384\u001b[0m       0.9440        \u001b[35m4.0997\u001b[0m  6.5104\n",
      "     36        \u001b[36m4.0380\u001b[0m       0.9421        4.1006  6.5221\n",
      "     37        \u001b[36m4.0378\u001b[0m       0.9430        \u001b[35m4.0995\u001b[0m  6.4055\n",
      "     38        \u001b[36m4.0372\u001b[0m       0.9440        \u001b[35m4.0994\u001b[0m  6.5627\n",
      "     39        \u001b[36m4.0364\u001b[0m       \u001b[32m0.9457\u001b[0m        \u001b[35m4.0985\u001b[0m  6.5328\n",
      "     40        \u001b[36m4.0363\u001b[0m       \u001b[32m0.9467\u001b[0m        \u001b[35m4.0976\u001b[0m  6.5859\n",
      "     41        \u001b[36m4.0360\u001b[0m       0.9464        \u001b[35m4.0971\u001b[0m  6.6600\n",
      "     42        4.0365       0.9464        4.0971  6.5791\n",
      "     43        \u001b[36m4.0353\u001b[0m       \u001b[32m0.9474\u001b[0m        \u001b[35m4.0969\u001b[0m  6.5801\n",
      "     44        \u001b[36m4.0346\u001b[0m       0.9474        4.0970  6.4931\n",
      "     45        4.0351       0.9460        \u001b[35m4.0962\u001b[0m  6.4659\n",
      "     46        4.0351       0.9454        4.0964  6.7131\n",
      "     47        \u001b[36m4.0344\u001b[0m       0.9470        \u001b[35m4.0958\u001b[0m  6.6571\n",
      "     48        4.0346       0.9467        \u001b[35m4.0954\u001b[0m  6.5670\n",
      "     49        4.0344       0.9467        4.0958  6.3196\n",
      "     50        \u001b[36m4.0340\u001b[0m       0.9460        \u001b[35m4.0945\u001b[0m  6.4831\n",
      "     51        4.0341       0.9457        4.0952  6.4416\n",
      "     52        \u001b[36m4.0339\u001b[0m       0.9470        \u001b[35m4.0942\u001b[0m  6.4792\n",
      "     53        \u001b[36m4.0336\u001b[0m       0.9467        4.0943  6.7118\n",
      "     54        \u001b[36m4.0336\u001b[0m       0.9460        4.0944  6.5849\n",
      "     55        4.0337       0.9467        4.0945  6.5862\n",
      "     56        \u001b[36m4.0333\u001b[0m       0.9457        \u001b[35m4.0942\u001b[0m  6.6073\n",
      "     57        4.0333       0.9437        4.0943  6.7752\n",
      "     58        \u001b[36m4.0331\u001b[0m       0.9464        \u001b[35m4.0932\u001b[0m  6.5969\n",
      "     59        \u001b[36m4.0330\u001b[0m       0.9450        \u001b[35m4.0930\u001b[0m  6.5928\n",
      "     60        4.0331       0.9467        4.0933  6.5894\n",
      "     61        \u001b[36m4.0327\u001b[0m       0.9467        4.0934  6.7363\n",
      "     62        4.0328       0.9467        4.0934  6.6782\n",
      "     63        4.0327       \u001b[32m0.9487\u001b[0m        \u001b[35m4.0929\u001b[0m  6.5501\n",
      "     64        4.0329       0.9470        \u001b[35m4.0929\u001b[0m  6.7439\n",
      "     65        \u001b[36m4.0325\u001b[0m       0.9470        \u001b[35m4.0925\u001b[0m  6.6517\n",
      "     66        \u001b[36m4.0322\u001b[0m       0.9470        4.0926  6.6536\n",
      "     67        4.0324       0.9437        4.0934  6.6038\n",
      "     68        \u001b[36m4.0322\u001b[0m       0.9447        \u001b[35m4.0925\u001b[0m  6.5775\n",
      "     69        4.0324       0.9457        4.0927  6.6971\n",
      "     70        \u001b[36m4.0322\u001b[0m       0.9464        \u001b[35m4.0925\u001b[0m  6.6713\n",
      "     71        \u001b[36m4.0318\u001b[0m       0.9467        \u001b[35m4.0921\u001b[0m  6.6088\n",
      "     72        4.0321       0.9467        \u001b[35m4.0921\u001b[0m  6.6240\n",
      "     73        4.0319       0.9457        4.0921  6.6259\n",
      "     74        4.0318       0.9447        4.0927  6.5100\n",
      "     75        4.0321       0.9457        \u001b[35m4.0918\u001b[0m  6.4882\n",
      "     76        4.0319       0.9454        4.0920  6.5501\n",
      "     77        \u001b[36m4.0317\u001b[0m       0.9450        \u001b[35m4.0917\u001b[0m  6.7334\n",
      "     78        4.0320       0.9427        4.0925  6.7096\n",
      "     79        4.0318       0.9440        4.0923  6.6331\n",
      "     80        4.0318       0.9437        4.0921  6.6210\n",
      "     81        \u001b[36m4.0314\u001b[0m       0.9444        4.0923  6.5671\n",
      "     82        4.0318       0.9454        4.0922  6.5825\n",
      "     83        4.0317       0.9447        4.0920  6.6033\n",
      "     84        4.0318       0.9480        \u001b[35m4.0911\u001b[0m  6.5205\n",
      "     85        4.0316       0.9460        \u001b[35m4.0911\u001b[0m  6.6841\n",
      "     86        \u001b[36m4.0314\u001b[0m       0.9474        \u001b[35m4.0909\u001b[0m  6.7566\n",
      "     87        4.0315       0.9454        4.0911  6.6409\n",
      "     88        4.0315       0.9447        4.0914  6.6076\n",
      "     89        4.0314       0.9447        4.0914  6.5638\n",
      "     90        4.0314       0.9450        4.0912  6.5096\n",
      "     91        4.0315       0.9460        \u001b[35m4.0907\u001b[0m  6.6078\n",
      "     92        4.0314       0.9447        4.0912  6.6314\n",
      "     93        \u001b[36m4.0313\u001b[0m       0.9464        \u001b[35m4.0906\u001b[0m  6.6334\n",
      "     94        \u001b[36m4.0312\u001b[0m       0.9470        \u001b[35m4.0903\u001b[0m  6.6184\n",
      "     95        4.0314       0.9464        4.0913  6.6821\n",
      "     96        \u001b[36m4.0312\u001b[0m       0.9460        4.0911  6.6701\n",
      "     97        4.0312       0.9470        4.0906  6.6519\n",
      "     98        4.0312       0.9447        4.0912  6.6596\n",
      "     99        \u001b[36m4.0311\u001b[0m       0.9470        4.0910  6.6209\n",
      "    100        4.0312       0.9454        4.0909  6.7089\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0158\u001b[0m       \u001b[32m0.4924\u001b[0m        \u001b[35m5.0102\u001b[0m  6.5300\n",
      "      2        \u001b[36m4.9122\u001b[0m       0.4738        \u001b[35m4.7293\u001b[0m  6.5801\n",
      "      3        \u001b[36m4.6000\u001b[0m       \u001b[32m0.6689\u001b[0m        \u001b[35m4.4809\u001b[0m  6.5551\n",
      "      4        \u001b[36m4.4239\u001b[0m       \u001b[32m0.7560\u001b[0m        \u001b[35m4.3693\u001b[0m  6.5848\n",
      "      5        \u001b[36m4.3254\u001b[0m       \u001b[32m0.8228\u001b[0m        \u001b[35m4.2909\u001b[0m  6.5949\n",
      "      6        \u001b[36m4.2590\u001b[0m       \u001b[32m0.8414\u001b[0m        \u001b[35m4.2507\u001b[0m  6.6234\n",
      "      7        \u001b[36m4.2231\u001b[0m       \u001b[32m0.8553\u001b[0m        \u001b[35m4.2267\u001b[0m  6.6582\n",
      "      8        \u001b[36m4.1978\u001b[0m       \u001b[32m0.8662\u001b[0m        \u001b[35m4.2111\u001b[0m  6.5353\n",
      "      9        \u001b[36m4.1763\u001b[0m       \u001b[32m0.8745\u001b[0m        \u001b[35m4.1941\u001b[0m  6.3671\n",
      "     10        \u001b[36m4.1570\u001b[0m       \u001b[32m0.8947\u001b[0m        \u001b[35m4.1768\u001b[0m  6.2050\n",
      "     11        \u001b[36m4.1347\u001b[0m       \u001b[32m0.9083\u001b[0m        \u001b[35m4.1583\u001b[0m  6.2582\n",
      "     12        \u001b[36m4.1155\u001b[0m       \u001b[32m0.9169\u001b[0m        \u001b[35m4.1475\u001b[0m  6.3184\n",
      "     13        \u001b[36m4.1051\u001b[0m       \u001b[32m0.9228\u001b[0m        \u001b[35m4.1391\u001b[0m  6.3023\n",
      "     14        \u001b[36m4.0940\u001b[0m       \u001b[32m0.9245\u001b[0m        \u001b[35m4.1343\u001b[0m  6.3172\n",
      "     15        \u001b[36m4.0863\u001b[0m       \u001b[32m0.9275\u001b[0m        \u001b[35m4.1299\u001b[0m  6.2672\n",
      "     16        \u001b[36m4.0810\u001b[0m       \u001b[32m0.9334\u001b[0m        \u001b[35m4.1260\u001b[0m  6.3074\n",
      "     17        \u001b[36m4.0754\u001b[0m       0.9311        \u001b[35m4.1235\u001b[0m  6.3897\n",
      "     18        \u001b[36m4.0700\u001b[0m       0.9325        \u001b[35m4.1214\u001b[0m  6.3586\n",
      "     19        \u001b[36m4.0652\u001b[0m       \u001b[32m0.9361\u001b[0m        \u001b[35m4.1177\u001b[0m  6.4741\n",
      "     20        \u001b[36m4.0599\u001b[0m       \u001b[32m0.9371\u001b[0m        \u001b[35m4.1155\u001b[0m  6.4795\n",
      "     21        \u001b[36m4.0555\u001b[0m       \u001b[32m0.9374\u001b[0m        \u001b[35m4.1134\u001b[0m  6.5791\n",
      "     22        \u001b[36m4.0528\u001b[0m       \u001b[32m0.9394\u001b[0m        \u001b[35m4.1112\u001b[0m  6.5077\n",
      "     23        \u001b[36m4.0510\u001b[0m       \u001b[32m0.9411\u001b[0m        \u001b[35m4.1092\u001b[0m  6.6616\n",
      "     24        \u001b[36m4.0479\u001b[0m       \u001b[32m0.9417\u001b[0m        \u001b[35m4.1077\u001b[0m  6.4565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     25        \u001b[36m4.0466\u001b[0m       0.9407        \u001b[35m4.1066\u001b[0m  6.6347\n",
      "     26        \u001b[36m4.0455\u001b[0m       0.9417        \u001b[35m4.1054\u001b[0m  6.7291\n",
      "     27        \u001b[36m4.0439\u001b[0m       0.9417        \u001b[35m4.1048\u001b[0m  6.6612\n",
      "     28        \u001b[36m4.0428\u001b[0m       \u001b[32m0.9430\u001b[0m        \u001b[35m4.1045\u001b[0m  6.5828\n",
      "     29        \u001b[36m4.0421\u001b[0m       \u001b[32m0.9447\u001b[0m        \u001b[35m4.1029\u001b[0m  6.5609\n",
      "     30        \u001b[36m4.0412\u001b[0m       0.9440        \u001b[35m4.1025\u001b[0m  6.4501\n",
      "     31        \u001b[36m4.0402\u001b[0m       0.9427        \u001b[35m4.1017\u001b[0m  6.7104\n",
      "     32        \u001b[36m4.0399\u001b[0m       0.9421        4.1022  6.7797\n",
      "     33        \u001b[36m4.0387\u001b[0m       0.9447        \u001b[35m4.1008\u001b[0m  6.9062\n",
      "     34        \u001b[36m4.0386\u001b[0m       0.9447        \u001b[35m4.1006\u001b[0m  6.5777\n",
      "     35        \u001b[36m4.0383\u001b[0m       \u001b[32m0.9467\u001b[0m        \u001b[35m4.0993\u001b[0m  6.5613\n",
      "     36        \u001b[36m4.0375\u001b[0m       0.9447        4.0995  6.5703\n",
      "     37        \u001b[36m4.0370\u001b[0m       0.9444        4.0996  6.5061\n",
      "     38        4.0372       0.9427        \u001b[35m4.0991\u001b[0m  6.4243\n",
      "     39        \u001b[36m4.0366\u001b[0m       0.9447        \u001b[35m4.0983\u001b[0m  6.5010\n",
      "     40        \u001b[36m4.0365\u001b[0m       0.9440        \u001b[35m4.0979\u001b[0m  6.5814\n",
      "     41        4.0369       0.9447        \u001b[35m4.0975\u001b[0m  6.5255\n",
      "     42        \u001b[36m4.0360\u001b[0m       0.9421        4.0980  6.5630\n",
      "     43        \u001b[36m4.0352\u001b[0m       0.9440        \u001b[35m4.0971\u001b[0m  6.4335\n",
      "     44        \u001b[36m4.0351\u001b[0m       0.9427        \u001b[35m4.0970\u001b[0m  6.4730\n",
      "     45        \u001b[36m4.0350\u001b[0m       0.9430        \u001b[35m4.0966\u001b[0m  6.5193\n",
      "     46        \u001b[36m4.0349\u001b[0m       0.9430        4.0973  6.5994\n",
      "     47        \u001b[36m4.0347\u001b[0m       0.9427        \u001b[35m4.0963\u001b[0m  6.6136\n",
      "     48        \u001b[36m4.0345\u001b[0m       0.9440        \u001b[35m4.0959\u001b[0m  6.5091\n",
      "     49        \u001b[36m4.0338\u001b[0m       0.9437        4.0961  6.6049\n",
      "     50        4.0340       0.9437        \u001b[35m4.0946\u001b[0m  6.5471\n",
      "     51        \u001b[36m4.0338\u001b[0m       0.9454        \u001b[35m4.0939\u001b[0m  6.7679\n",
      "     52        4.0341       0.9437        4.0952  6.7308\n",
      "     53        \u001b[36m4.0335\u001b[0m       0.9440        4.0946  6.7921\n",
      "     54        4.0336       0.9454        4.0944  6.5559\n",
      "     55        4.0338       0.9460        4.0946  6.4155\n",
      "     56        \u001b[36m4.0331\u001b[0m       0.9440        4.0943  6.3977\n",
      "     57        \u001b[36m4.0331\u001b[0m       0.9464        \u001b[35m4.0935\u001b[0m  6.4314\n",
      "     58        \u001b[36m4.0328\u001b[0m       0.9457        4.0936  6.4255\n",
      "     59        \u001b[36m4.0327\u001b[0m       0.9467        \u001b[35m4.0930\u001b[0m  6.6979\n",
      "     60        4.0330       0.9464        4.0935  6.5526\n",
      "     61        4.0329       0.9454        4.0935  6.5938\n",
      "     62        4.0327       0.9427        4.0943  6.4993\n",
      "     63        \u001b[36m4.0323\u001b[0m       0.9437        4.0937  6.4995\n",
      "     64        4.0325       0.9414        4.0944  6.5812\n",
      "     65        4.0327       0.9447        4.0934  6.4703\n",
      "     66        4.0324       0.9440        4.0939  6.5949\n",
      "     67        \u001b[36m4.0323\u001b[0m       0.9434        4.0936  6.5838\n",
      "     68        \u001b[36m4.0320\u001b[0m       0.9457        \u001b[35m4.0924\u001b[0m  6.4525\n",
      "     69        \u001b[36m4.0319\u001b[0m       0.9437        4.0935  6.4106\n",
      "     70        4.0320       0.9454        4.0930  6.4218\n",
      "     71        4.0321       0.9457        4.0930  6.5252\n",
      "     72        4.0323       \u001b[32m0.9474\u001b[0m        \u001b[35m4.0923\u001b[0m  6.6021\n",
      "     73        \u001b[36m4.0318\u001b[0m       0.9434        \u001b[35m4.0922\u001b[0m  6.6607\n",
      "     74        4.0320       0.9447        4.0923  6.6777\n",
      "     75        \u001b[36m4.0317\u001b[0m       0.9444        4.0930  6.6288\n",
      "     76        4.0319       0.9437        4.0931  6.5975\n",
      "     77        4.0317       0.9437        4.0927  6.6179\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0158\u001b[0m       \u001b[32m0.4954\u001b[0m        \u001b[35m5.0102\u001b[0m  6.3506\n",
      "      2        \u001b[36m4.9117\u001b[0m       0.4626        \u001b[35m4.7292\u001b[0m  6.3749\n",
      "      3        \u001b[36m4.5988\u001b[0m       \u001b[32m0.6775\u001b[0m        \u001b[35m4.4777\u001b[0m  6.6456\n",
      "      4        \u001b[36m4.4185\u001b[0m       \u001b[32m0.7679\u001b[0m        \u001b[35m4.3625\u001b[0m  6.6044\n",
      "      5        \u001b[36m4.3180\u001b[0m       \u001b[32m0.8179\u001b[0m        \u001b[35m4.2886\u001b[0m  6.5286\n",
      "      6        \u001b[36m4.2568\u001b[0m       \u001b[32m0.8397\u001b[0m        \u001b[35m4.2496\u001b[0m  6.6038\n",
      "      7        \u001b[36m4.2239\u001b[0m       \u001b[32m0.8490\u001b[0m        \u001b[35m4.2311\u001b[0m  6.7015\n",
      "      8        \u001b[36m4.1989\u001b[0m       \u001b[32m0.8675\u001b[0m        \u001b[35m4.2116\u001b[0m  6.3926\n",
      "      9        \u001b[36m4.1773\u001b[0m       \u001b[32m0.8791\u001b[0m        \u001b[35m4.1957\u001b[0m  6.2663\n",
      "     10        \u001b[36m4.1556\u001b[0m       \u001b[32m0.8970\u001b[0m        \u001b[35m4.1758\u001b[0m  6.2501\n",
      "     11        \u001b[36m4.1348\u001b[0m       \u001b[32m0.9017\u001b[0m        \u001b[35m4.1636\u001b[0m  6.2722\n",
      "     12        \u001b[36m4.1217\u001b[0m       \u001b[32m0.9172\u001b[0m        \u001b[35m4.1504\u001b[0m  6.2983\n",
      "     13        \u001b[36m4.1026\u001b[0m       \u001b[32m0.9235\u001b[0m        \u001b[35m4.1392\u001b[0m  6.3079\n",
      "     14        \u001b[36m4.0935\u001b[0m       \u001b[32m0.9278\u001b[0m        \u001b[35m4.1336\u001b[0m  6.3521\n",
      "     15        \u001b[36m4.0863\u001b[0m       0.9265        \u001b[35m4.1302\u001b[0m  6.3350\n",
      "     16        \u001b[36m4.0808\u001b[0m       \u001b[32m0.9285\u001b[0m        \u001b[35m4.1275\u001b[0m  6.4150\n",
      "     17        \u001b[36m4.0747\u001b[0m       \u001b[32m0.9325\u001b[0m        \u001b[35m4.1243\u001b[0m  6.3509\n",
      "     18        \u001b[36m4.0696\u001b[0m       0.9321        \u001b[35m4.1218\u001b[0m  6.3393\n",
      "     19        \u001b[36m4.0648\u001b[0m       \u001b[32m0.9364\u001b[0m        \u001b[35m4.1195\u001b[0m  6.3610\n",
      "     20        \u001b[36m4.0601\u001b[0m       0.9348        \u001b[35m4.1165\u001b[0m  6.4502\n",
      "     21        \u001b[36m4.0553\u001b[0m       \u001b[32m0.9401\u001b[0m        \u001b[35m4.1137\u001b[0m  6.5980\n",
      "     22        \u001b[36m4.0527\u001b[0m       0.9381        \u001b[35m4.1114\u001b[0m  6.4819\n",
      "     23        \u001b[36m4.0503\u001b[0m       0.9401        \u001b[35m4.1103\u001b[0m  6.3831\n",
      "     24        \u001b[36m4.0479\u001b[0m       0.9387        \u001b[35m4.1092\u001b[0m  6.4238\n",
      "     25        \u001b[36m4.0464\u001b[0m       \u001b[32m0.9430\u001b[0m        \u001b[35m4.1070\u001b[0m  6.4202\n",
      "     26        \u001b[36m4.0453\u001b[0m       0.9430        \u001b[35m4.1058\u001b[0m  6.4929\n",
      "     27        \u001b[36m4.0441\u001b[0m       \u001b[32m0.9434\u001b[0m        \u001b[35m4.1048\u001b[0m  6.4147\n",
      "     28        \u001b[36m4.0429\u001b[0m       0.9421        \u001b[35m4.1043\u001b[0m  6.4952\n",
      "     29        \u001b[36m4.0416\u001b[0m       0.9424        \u001b[35m4.1037\u001b[0m  6.5058\n",
      "     30        4.0419       0.9430        \u001b[35m4.1026\u001b[0m  6.4750\n",
      "     31        \u001b[36m4.0404\u001b[0m       0.9427        4.1027  6.4413\n",
      "     32        \u001b[36m4.0396\u001b[0m       0.9434        \u001b[35m4.1017\u001b[0m  6.4329\n",
      "     33        \u001b[36m4.0393\u001b[0m       0.9434        \u001b[35m4.1008\u001b[0m  6.4413\n",
      "     34        \u001b[36m4.0385\u001b[0m       \u001b[32m0.9440\u001b[0m        4.1008  6.4224\n",
      "     35        \u001b[36m4.0381\u001b[0m       0.9437        \u001b[35m4.1005\u001b[0m  6.4456\n",
      "     36        \u001b[36m4.0378\u001b[0m       \u001b[32m0.9450\u001b[0m        \u001b[35m4.1000\u001b[0m  6.4412\n",
      "     37        \u001b[36m4.0369\u001b[0m       0.9447        \u001b[35m4.0994\u001b[0m  6.4417\n",
      "     38        4.0370       0.9430        \u001b[35m4.0989\u001b[0m  6.4390\n",
      "     39        \u001b[36m4.0358\u001b[0m       0.9434        4.0991  6.4512\n",
      "     40        4.0359       0.9447        \u001b[35m4.0981\u001b[0m  6.4612\n",
      "     41        \u001b[36m4.0357\u001b[0m       \u001b[32m0.9457\u001b[0m        \u001b[35m4.0977\u001b[0m  6.4346\n",
      "     42        \u001b[36m4.0354\u001b[0m       0.9454        \u001b[35m4.0970\u001b[0m  6.4239\n",
      "     43        \u001b[36m4.0350\u001b[0m       \u001b[32m0.9460\u001b[0m        \u001b[35m4.0965\u001b[0m  6.4447\n",
      "     44        4.0355       0.9450        4.0966  6.4477\n",
      "     45        4.0350       \u001b[32m0.9464\u001b[0m        \u001b[35m4.0963\u001b[0m  6.4858\n",
      "     46        \u001b[36m4.0350\u001b[0m       \u001b[32m0.9470\u001b[0m        \u001b[35m4.0956\u001b[0m  6.4302\n",
      "     47        \u001b[36m4.0344\u001b[0m       \u001b[32m0.9480\u001b[0m        \u001b[35m4.0947\u001b[0m  6.4533\n",
      "     48        \u001b[36m4.0343\u001b[0m       0.9464        4.0948  6.4215\n",
      "     49        \u001b[36m4.0340\u001b[0m       0.9450        4.0957  6.4511\n",
      "     50        \u001b[36m4.0338\u001b[0m       0.9460        4.0960  6.4512\n",
      "     51        4.0339       0.9447        4.0954  6.7274\n",
      "     52        \u001b[36m4.0330\u001b[0m       0.9450        4.0952  6.4647\n",
      "     53        4.0330       0.9444        4.0957  6.5295\n",
      "     54        4.0336       0.9444        4.0958  6.5163\n",
      "     55        4.0333       0.9457        4.0950  6.5093\n",
      "     56        4.0331       0.9474        4.0948  6.7418\n",
      "     57        \u001b[36m4.0329\u001b[0m       0.9447        \u001b[35m4.0940\u001b[0m  6.6626\n",
      "     58        \u001b[36m4.0327\u001b[0m       0.9444        4.0942  6.4578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     59        4.0328       0.9457        4.0943  6.4243\n",
      "     60        4.0328       0.9454        \u001b[35m4.0938\u001b[0m  6.6775\n",
      "     61        \u001b[36m4.0326\u001b[0m       0.9460        4.0941  6.5448\n",
      "     62        \u001b[36m4.0325\u001b[0m       0.9470        \u001b[35m4.0938\u001b[0m  6.3740\n",
      "     63        4.0327       0.9460        \u001b[35m4.0935\u001b[0m  6.6394\n",
      "     64        \u001b[36m4.0322\u001b[0m       0.9467        \u001b[35m4.0923\u001b[0m  6.6024\n",
      "     65        4.0323       0.9450        4.0930  6.6287\n",
      "     66        4.0323       0.9464        4.0927  6.6050\n",
      "     67        4.0324       0.9450        4.0928  6.6565\n",
      "     68        \u001b[36m4.0320\u001b[0m       0.9457        4.0926  6.6289\n",
      "     69        4.0321       0.9467        4.0927  6.5386\n",
      "     70        4.0320       0.9450        4.0929  6.6314\n",
      "     71        \u001b[36m4.0319\u001b[0m       0.9480        \u001b[35m4.0923\u001b[0m  6.6163\n",
      "     72        4.0323       0.9467        4.0929  6.5793\n",
      "     73        \u001b[36m4.0319\u001b[0m       0.9444        4.0930  6.5792\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0158\u001b[0m       \u001b[32m0.5202\u001b[0m        \u001b[35m5.0104\u001b[0m  6.3930\n",
      "      2        \u001b[36m4.9122\u001b[0m       0.4679        \u001b[35m4.7284\u001b[0m  6.4195\n",
      "      3        \u001b[36m4.5983\u001b[0m       \u001b[32m0.6715\u001b[0m        \u001b[35m4.4785\u001b[0m  6.4168\n",
      "      4        \u001b[36m4.4182\u001b[0m       \u001b[32m0.7775\u001b[0m        \u001b[35m4.3555\u001b[0m  6.5104\n",
      "      5        \u001b[36m4.3133\u001b[0m       \u001b[32m0.8185\u001b[0m        \u001b[35m4.2854\u001b[0m  6.3748\n",
      "      6        \u001b[36m4.2580\u001b[0m       \u001b[32m0.8354\u001b[0m        \u001b[35m4.2522\u001b[0m  6.3821\n",
      "      7        \u001b[36m4.2244\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m4.2299\u001b[0m  6.4319\n",
      "      8        \u001b[36m4.1992\u001b[0m       \u001b[32m0.8642\u001b[0m        \u001b[35m4.2124\u001b[0m  6.3625\n",
      "      9        \u001b[36m4.1746\u001b[0m       \u001b[32m0.8834\u001b[0m        \u001b[35m4.1932\u001b[0m  6.2104\n",
      "     10        \u001b[36m4.1505\u001b[0m       \u001b[32m0.9040\u001b[0m        \u001b[35m4.1704\u001b[0m  6.1969\n",
      "     11        \u001b[36m4.1298\u001b[0m       \u001b[32m0.9076\u001b[0m        \u001b[35m4.1591\u001b[0m  6.5450\n",
      "     12        \u001b[36m4.1180\u001b[0m       \u001b[32m0.9123\u001b[0m        \u001b[35m4.1520\u001b[0m  6.5779\n",
      "     13        \u001b[36m4.1080\u001b[0m       \u001b[32m0.9169\u001b[0m        \u001b[35m4.1452\u001b[0m  6.5267\n",
      "     14        \u001b[36m4.0980\u001b[0m       \u001b[32m0.9172\u001b[0m        \u001b[35m4.1407\u001b[0m  6.5177\n",
      "     15        \u001b[36m4.0920\u001b[0m       \u001b[32m0.9199\u001b[0m        \u001b[35m4.1370\u001b[0m  6.3003\n",
      "     16        \u001b[36m4.0873\u001b[0m       \u001b[32m0.9242\u001b[0m        \u001b[35m4.1322\u001b[0m  6.3562\n",
      "     17        \u001b[36m4.0774\u001b[0m       \u001b[32m0.9334\u001b[0m        \u001b[35m4.1264\u001b[0m  6.2148\n",
      "     18        \u001b[36m4.0714\u001b[0m       0.9318        \u001b[35m4.1227\u001b[0m  6.6047\n",
      "     19        \u001b[36m4.0657\u001b[0m       \u001b[32m0.9344\u001b[0m        \u001b[35m4.1202\u001b[0m  6.4434\n",
      "     20        \u001b[36m4.0614\u001b[0m       \u001b[32m0.9377\u001b[0m        \u001b[35m4.1178\u001b[0m  6.7180\n",
      "     21        \u001b[36m4.0568\u001b[0m       \u001b[32m0.9381\u001b[0m        \u001b[35m4.1148\u001b[0m  6.5375\n",
      "     22        \u001b[36m4.0522\u001b[0m       \u001b[32m0.9414\u001b[0m        \u001b[35m4.1113\u001b[0m  6.4927\n",
      "     23        \u001b[36m4.0505\u001b[0m       0.9414        \u001b[35m4.1102\u001b[0m  6.3907\n",
      "     24        \u001b[36m4.0481\u001b[0m       0.9397        \u001b[35m4.1083\u001b[0m  6.4464\n",
      "     25        \u001b[36m4.0470\u001b[0m       \u001b[32m0.9430\u001b[0m        \u001b[35m4.1067\u001b[0m  6.4597\n",
      "     26        \u001b[36m4.0453\u001b[0m       \u001b[32m0.9434\u001b[0m        \u001b[35m4.1052\u001b[0m  6.4387\n",
      "     27        \u001b[36m4.0438\u001b[0m       0.9427        \u001b[35m4.1049\u001b[0m  6.4233\n",
      "     28        \u001b[36m4.0423\u001b[0m       0.9430        \u001b[35m4.1045\u001b[0m  6.3867\n",
      "     29        4.0424       \u001b[32m0.9444\u001b[0m        \u001b[35m4.1037\u001b[0m  6.4139\n",
      "     30        \u001b[36m4.0416\u001b[0m       0.9430        \u001b[35m4.1034\u001b[0m  6.4438\n",
      "     31        \u001b[36m4.0399\u001b[0m       0.9430        \u001b[35m4.1029\u001b[0m  6.4492\n",
      "     32        \u001b[36m4.0398\u001b[0m       0.9437        \u001b[35m4.1023\u001b[0m  6.3456\n",
      "     33        \u001b[36m4.0392\u001b[0m       0.9440        \u001b[35m4.1010\u001b[0m  6.3807\n",
      "     34        \u001b[36m4.0386\u001b[0m       0.9440        \u001b[35m4.1010\u001b[0m  6.3757\n",
      "     35        \u001b[36m4.0381\u001b[0m       \u001b[32m0.9447\u001b[0m        \u001b[35m4.1001\u001b[0m  6.3796\n",
      "     36        \u001b[36m4.0373\u001b[0m       0.9427        4.1008  6.3833\n",
      "     37        \u001b[36m4.0373\u001b[0m       \u001b[32m0.9454\u001b[0m        \u001b[35m4.0999\u001b[0m  6.4590\n",
      "     38        \u001b[36m4.0370\u001b[0m       0.9440        \u001b[35m4.0992\u001b[0m  6.3901\n",
      "     39        \u001b[36m4.0363\u001b[0m       0.9447        4.0993  6.6015\n",
      "     40        4.0364       0.9434        \u001b[35m4.0992\u001b[0m  6.6120\n",
      "     41        \u001b[36m4.0359\u001b[0m       0.9447        \u001b[35m4.0978\u001b[0m  6.5415\n",
      "     42        \u001b[36m4.0355\u001b[0m       0.9454        \u001b[35m4.0976\u001b[0m  6.3897\n",
      "     43        4.0357       0.9437        4.0983  6.4932\n",
      "     44        \u001b[36m4.0349\u001b[0m       0.9447        \u001b[35m4.0975\u001b[0m  6.4824\n",
      "     45        4.0352       0.9430        \u001b[35m4.0975\u001b[0m  6.4394\n",
      "     46        4.0350       0.9444        \u001b[35m4.0970\u001b[0m  6.3755\n",
      "     47        \u001b[36m4.0348\u001b[0m       0.9450        \u001b[35m4.0969\u001b[0m  6.3751\n",
      "     48        \u001b[36m4.0347\u001b[0m       0.9444        \u001b[35m4.0965\u001b[0m  6.4012\n",
      "     49        \u001b[36m4.0344\u001b[0m       0.9447        4.0967  6.4009\n",
      "     50        \u001b[36m4.0343\u001b[0m       0.9434        4.0969  6.3933\n",
      "     51        \u001b[36m4.0336\u001b[0m       0.9450        \u001b[35m4.0962\u001b[0m  6.4950\n",
      "     52        4.0341       \u001b[32m0.9467\u001b[0m        \u001b[35m4.0958\u001b[0m  6.6688\n",
      "     53        4.0338       0.9454        \u001b[35m4.0951\u001b[0m  6.7264\n",
      "     54        \u001b[36m4.0336\u001b[0m       0.9464        4.0954  6.4986\n",
      "     55        \u001b[36m4.0333\u001b[0m       0.9464        \u001b[35m4.0946\u001b[0m  6.6239\n",
      "     56        \u001b[36m4.0331\u001b[0m       \u001b[32m0.9470\u001b[0m        4.0947  6.6062\n",
      "     57        4.0331       0.9454        \u001b[35m4.0943\u001b[0m  6.8857\n",
      "     58        4.0333       0.9450        4.0944  6.6565\n",
      "     59        \u001b[36m4.0331\u001b[0m       0.9464        \u001b[35m4.0937\u001b[0m  6.6759\n",
      "     60        \u001b[36m4.0328\u001b[0m       0.9450        4.0941  6.6412\n",
      "     61        4.0329       0.9447        4.0938  6.5595\n",
      "     62        \u001b[36m4.0327\u001b[0m       0.9447        4.0938  6.7832\n",
      "     63        \u001b[36m4.0325\u001b[0m       0.9460        \u001b[35m4.0931\u001b[0m  6.6165\n",
      "     64        4.0327       0.9454        4.0937  6.4267\n",
      "     65        \u001b[36m4.0324\u001b[0m       0.9437        4.0942  6.4223\n",
      "     66        4.0325       0.9464        \u001b[35m4.0929\u001b[0m  6.4716\n",
      "     67        4.0324       0.9450        4.0935  6.4899\n",
      "     68        \u001b[36m4.0321\u001b[0m       0.9457        4.0930  6.5707\n",
      "     69        4.0322       0.9440        4.0931  6.4945\n",
      "     70        \u001b[36m4.0320\u001b[0m       0.9447        \u001b[35m4.0928\u001b[0m  6.6321\n",
      "     71        \u001b[36m4.0319\u001b[0m       0.9434        4.0929  6.7966\n",
      "     72        \u001b[36m4.0317\u001b[0m       0.9447        4.0929  6.7357\n",
      "     73        \u001b[36m4.0317\u001b[0m       0.9460        \u001b[35m4.0925\u001b[0m  6.5416\n",
      "     74        4.0319       0.9444        4.0928  6.5202\n",
      "     75        4.0317       0.9440        4.0930  6.4797\n",
      "     76        \u001b[36m4.0315\u001b[0m       0.9447        4.0928  6.5647\n",
      "     77        4.0317       0.9434        4.0933  6.4977\n",
      "     78        4.0316       0.9440        \u001b[35m4.0921\u001b[0m  6.4882\n",
      "     79        \u001b[36m4.0312\u001b[0m       0.9450        \u001b[35m4.0913\u001b[0m  6.4106\n",
      "     80        4.0316       0.9444        4.0918  6.3458\n",
      "     81        4.0314       0.9427        4.0925  6.3991\n",
      "     82        4.0315       0.9457        4.0923  6.4106\n",
      "     83        4.0314       0.9454        4.0921  6.4072\n",
      "     84        4.0313       0.9450        4.0921  6.4091\n",
      "     85        4.0314       0.9464        \u001b[35m4.0909\u001b[0m  6.4288\n",
      "     86        \u001b[36m4.0311\u001b[0m       0.9464        4.0916  6.5373\n",
      "     87        4.0312       0.9440        4.0920  6.4903\n",
      "     88        4.0312       0.9437        4.0913  6.5319\n",
      "     89        4.0313       0.9464        \u001b[35m4.0907\u001b[0m  6.5532\n",
      "     90        4.0312       0.9437        4.0916  6.6276\n",
      "     91        4.0313       0.9427        4.0917  6.6647\n",
      "     92        4.0312       0.9421        4.0922  6.4103\n",
      "     93        4.0313       0.9450        4.0914  6.4498\n",
      "     94        \u001b[36m4.0310\u001b[0m       0.9440        4.0917  6.7060\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0158\u001b[0m       \u001b[32m0.5325\u001b[0m        \u001b[35m5.0106\u001b[0m  6.5968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m4.9137\u001b[0m       0.4828        \u001b[35m4.7283\u001b[0m  6.6732\n",
      "      3        \u001b[36m4.6009\u001b[0m       \u001b[32m0.6864\u001b[0m        \u001b[35m4.4767\u001b[0m  6.6676\n",
      "      4        \u001b[36m4.4176\u001b[0m       \u001b[32m0.7685\u001b[0m        \u001b[35m4.3615\u001b[0m  6.3482\n",
      "      5        \u001b[36m4.3219\u001b[0m       \u001b[32m0.8172\u001b[0m        \u001b[35m4.2922\u001b[0m  6.3929\n",
      "      6        \u001b[36m4.2599\u001b[0m       \u001b[32m0.8407\u001b[0m        \u001b[35m4.2485\u001b[0m  6.3426\n",
      "      7        \u001b[36m4.2198\u001b[0m       \u001b[32m0.8546\u001b[0m        \u001b[35m4.2256\u001b[0m  6.2989\n",
      "      8        \u001b[36m4.1964\u001b[0m       \u001b[32m0.8652\u001b[0m        \u001b[35m4.2086\u001b[0m  6.3067\n",
      "      9        \u001b[36m4.1725\u001b[0m       \u001b[32m0.8864\u001b[0m        \u001b[35m4.1915\u001b[0m  6.2652\n",
      "     10        \u001b[36m4.1518\u001b[0m       \u001b[32m0.8983\u001b[0m        \u001b[35m4.1724\u001b[0m  6.3402\n",
      "     11        \u001b[36m4.1307\u001b[0m       \u001b[32m0.9066\u001b[0m        \u001b[35m4.1590\u001b[0m  6.2250\n",
      "     12        \u001b[36m4.1188\u001b[0m       \u001b[32m0.9116\u001b[0m        \u001b[35m4.1507\u001b[0m  6.3543\n",
      "     13        \u001b[36m4.1072\u001b[0m       \u001b[32m0.9136\u001b[0m        \u001b[35m4.1453\u001b[0m  6.3472\n",
      "     14        \u001b[36m4.1005\u001b[0m       0.9136        \u001b[35m4.1417\u001b[0m  6.2645\n",
      "     15        \u001b[36m4.0914\u001b[0m       \u001b[32m0.9209\u001b[0m        \u001b[35m4.1352\u001b[0m  6.3650\n",
      "     16        \u001b[36m4.0822\u001b[0m       \u001b[32m0.9288\u001b[0m        \u001b[35m4.1287\u001b[0m  6.3448\n",
      "     17        \u001b[36m4.0762\u001b[0m       \u001b[32m0.9321\u001b[0m        \u001b[35m4.1259\u001b[0m  6.2964\n",
      "     18        \u001b[36m4.0713\u001b[0m       0.9308        \u001b[35m4.1229\u001b[0m  6.3558\n",
      "     19        \u001b[36m4.0661\u001b[0m       \u001b[32m0.9341\u001b[0m        \u001b[35m4.1205\u001b[0m  6.4190\n",
      "     20        \u001b[36m4.0620\u001b[0m       \u001b[32m0.9364\u001b[0m        \u001b[35m4.1167\u001b[0m  6.4483\n",
      "     21        \u001b[36m4.0569\u001b[0m       \u001b[32m0.9384\u001b[0m        \u001b[35m4.1139\u001b[0m  6.3420\n",
      "     22        \u001b[36m4.0533\u001b[0m       \u001b[32m0.9397\u001b[0m        \u001b[35m4.1113\u001b[0m  6.3876\n",
      "     23        \u001b[36m4.0509\u001b[0m       \u001b[32m0.9421\u001b[0m        \u001b[35m4.1089\u001b[0m  6.4366\n",
      "     24        \u001b[36m4.0491\u001b[0m       0.9407        \u001b[35m4.1084\u001b[0m  6.3262\n",
      "     25        \u001b[36m4.0466\u001b[0m       0.9414        \u001b[35m4.1065\u001b[0m  6.3899\n",
      "     26        \u001b[36m4.0458\u001b[0m       0.9421        \u001b[35m4.1059\u001b[0m  6.3723\n",
      "     27        \u001b[36m4.0447\u001b[0m       \u001b[32m0.9437\u001b[0m        \u001b[35m4.1049\u001b[0m  6.5077\n",
      "     28        \u001b[36m4.0437\u001b[0m       0.9424        \u001b[35m4.1038\u001b[0m  6.7269\n",
      "     29        \u001b[36m4.0417\u001b[0m       \u001b[32m0.9447\u001b[0m        \u001b[35m4.1027\u001b[0m  6.4853\n",
      "     30        \u001b[36m4.0414\u001b[0m       0.9437        4.1030  6.4545\n",
      "     31        \u001b[36m4.0409\u001b[0m       0.9434        \u001b[35m4.1023\u001b[0m  6.2840\n",
      "     32        \u001b[36m4.0394\u001b[0m       \u001b[32m0.9454\u001b[0m        \u001b[35m4.1013\u001b[0m  6.7000\n",
      "     33        \u001b[36m4.0393\u001b[0m       0.9444        \u001b[35m4.1007\u001b[0m  6.5697\n",
      "     34        \u001b[36m4.0386\u001b[0m       0.9450        \u001b[35m4.1005\u001b[0m  6.6875\n",
      "     35        \u001b[36m4.0383\u001b[0m       0.9450        \u001b[35m4.0993\u001b[0m  6.7626\n",
      "     36        \u001b[36m4.0380\u001b[0m       0.9437        4.0997  6.7066\n",
      "     37        \u001b[36m4.0379\u001b[0m       0.9434        \u001b[35m4.0991\u001b[0m  6.6558\n",
      "     38        \u001b[36m4.0374\u001b[0m       0.9454        \u001b[35m4.0987\u001b[0m  6.6625\n",
      "     39        \u001b[36m4.0366\u001b[0m       0.9450        \u001b[35m4.0984\u001b[0m  6.5941\n",
      "     40        \u001b[36m4.0360\u001b[0m       0.9450        4.0984  6.5354\n",
      "     41        4.0364       0.9440        \u001b[35m4.0983\u001b[0m  6.4574\n",
      "     42        \u001b[36m4.0358\u001b[0m       \u001b[32m0.9467\u001b[0m        \u001b[35m4.0972\u001b[0m  6.5119\n",
      "     43        \u001b[36m4.0352\u001b[0m       0.9450        \u001b[35m4.0971\u001b[0m  6.6157\n",
      "     44        4.0354       0.9444        \u001b[35m4.0967\u001b[0m  6.5415\n",
      "     45        \u001b[36m4.0351\u001b[0m       \u001b[32m0.9483\u001b[0m        \u001b[35m4.0961\u001b[0m  6.7693\n",
      "     46        \u001b[36m4.0348\u001b[0m       0.9450        4.0972  6.7240\n",
      "     47        \u001b[36m4.0345\u001b[0m       0.9457        \u001b[35m4.0959\u001b[0m  6.5591\n",
      "     48        4.0345       0.9460        4.0959  6.5533\n",
      "     49        \u001b[36m4.0340\u001b[0m       0.9464        \u001b[35m4.0955\u001b[0m  6.5345\n",
      "     50        \u001b[36m4.0338\u001b[0m       0.9454        4.0957  6.6203\n",
      "     51        4.0339       0.9447        \u001b[35m4.0953\u001b[0m  6.6009\n",
      "     52        \u001b[36m4.0337\u001b[0m       0.9454        \u001b[35m4.0951\u001b[0m  6.6861\n",
      "     53        \u001b[36m4.0336\u001b[0m       0.9454        4.0951  7.1779\n",
      "     54        4.0338       0.9480        \u001b[35m4.0946\u001b[0m  6.9037\n",
      "     55        \u001b[36m4.0335\u001b[0m       0.9474        4.0946  6.6007\n",
      "     56        4.0337       0.9464        4.0949  6.5863\n",
      "     57        \u001b[36m4.0332\u001b[0m       0.9464        \u001b[35m4.0942\u001b[0m  6.5969\n",
      "     58        \u001b[36m4.0330\u001b[0m       0.9460        \u001b[35m4.0939\u001b[0m  6.7586\n",
      "     59        \u001b[36m4.0328\u001b[0m       0.9437        4.0947  6.6830\n",
      "     60        4.0329       0.9447        4.0943  6.5264\n",
      "     61        \u001b[36m4.0325\u001b[0m       0.9454        4.0940  6.5141\n",
      "     62        4.0328       0.9447        4.0943  6.6249\n",
      "     63        4.0328       0.9454        \u001b[35m4.0938\u001b[0m  6.8541\n",
      "     64        4.0326       0.9444        4.0941  6.7694\n",
      "     65        \u001b[36m4.0322\u001b[0m       0.9444        \u001b[35m4.0936\u001b[0m  6.6543\n",
      "     66        4.0325       0.9437        \u001b[35m4.0933\u001b[0m  6.8775\n",
      "     67        4.0322       0.9454        \u001b[35m4.0928\u001b[0m  6.5508\n",
      "     68        4.0323       0.9447        4.0930  6.6120\n",
      "     69        \u001b[36m4.0320\u001b[0m       0.9447        4.0931  6.5912\n",
      "     70        4.0320       0.9437        4.0932  6.5862\n",
      "     71        \u001b[36m4.0319\u001b[0m       0.9430        4.0936  6.6669\n",
      "     72        4.0321       0.9437        4.0930  6.6144\n",
      "     73        \u001b[36m4.0319\u001b[0m       0.9460        \u001b[35m4.0927\u001b[0m  6.4712\n",
      "     74        4.0320       0.9434        \u001b[35m4.0924\u001b[0m  6.5689\n",
      "     75        4.0319       0.9450        \u001b[35m4.0923\u001b[0m  6.5160\n",
      "     76        \u001b[36m4.0316\u001b[0m       0.9440        \u001b[35m4.0920\u001b[0m  6.3719\n",
      "     77        4.0318       0.9421        4.0930  6.6624\n",
      "     78        4.0318       0.9417        4.0930  6.5493\n",
      "     79        4.0318       0.9444        \u001b[35m4.0914\u001b[0m  6.4585\n",
      "     80        4.0319       0.9440        4.0923  6.5761\n",
      "     81        4.0318       0.9440        4.0920  6.5870\n",
      "     82        4.0318       0.9434        4.0920  6.6759\n",
      "     83        4.0316       0.9464        4.0918  6.5859\n",
      "     84        \u001b[36m4.0314\u001b[0m       0.9447        \u001b[35m4.0912\u001b[0m  6.6509\n",
      "     85        4.0316       0.9440        4.0916  6.5812\n",
      "     86        4.0314       0.9437        4.0925  6.5273\n",
      "     87        4.0314       0.9430        4.0933  6.5763\n",
      "     88        4.0315       0.9444        4.0925  6.7305\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0158\u001b[0m       \u001b[32m0.5470\u001b[0m        \u001b[35m5.0104\u001b[0m  6.5063\n",
      "      2        \u001b[36m4.9137\u001b[0m       0.4831        \u001b[35m4.7321\u001b[0m  6.5849\n",
      "      3        \u001b[36m4.5992\u001b[0m       \u001b[32m0.6699\u001b[0m        \u001b[35m4.4763\u001b[0m  6.5802\n",
      "      4        \u001b[36m4.4221\u001b[0m       \u001b[32m0.7632\u001b[0m        \u001b[35m4.3679\u001b[0m  6.5452\n",
      "      5        \u001b[36m4.3252\u001b[0m       \u001b[32m0.8086\u001b[0m        \u001b[35m4.2981\u001b[0m  6.5202\n",
      "      6        \u001b[36m4.2672\u001b[0m       \u001b[32m0.8291\u001b[0m        \u001b[35m4.2593\u001b[0m  6.6051\n",
      "      7        \u001b[36m4.2278\u001b[0m       \u001b[32m0.8599\u001b[0m        \u001b[35m4.2265\u001b[0m  6.1817\n",
      "      8        \u001b[36m4.1963\u001b[0m       \u001b[32m0.8666\u001b[0m        \u001b[35m4.2068\u001b[0m  6.2211\n",
      "      9        \u001b[36m4.1714\u001b[0m       \u001b[32m0.8785\u001b[0m        \u001b[35m4.1930\u001b[0m  6.1565\n",
      "     10        \u001b[36m4.1527\u001b[0m       \u001b[32m0.8997\u001b[0m        \u001b[35m4.1742\u001b[0m  6.1947\n",
      "     11        \u001b[36m4.1294\u001b[0m       \u001b[32m0.9126\u001b[0m        \u001b[35m4.1553\u001b[0m  6.2360\n",
      "     12        \u001b[36m4.1123\u001b[0m       \u001b[32m0.9166\u001b[0m        \u001b[35m4.1460\u001b[0m  6.2902\n",
      "     13        \u001b[36m4.1014\u001b[0m       \u001b[32m0.9169\u001b[0m        \u001b[35m4.1409\u001b[0m  6.5842\n",
      "     14        \u001b[36m4.0952\u001b[0m       \u001b[32m0.9182\u001b[0m        \u001b[35m4.1372\u001b[0m  6.4001\n",
      "     15        \u001b[36m4.0895\u001b[0m       \u001b[32m0.9212\u001b[0m        \u001b[35m4.1340\u001b[0m  6.3066\n",
      "     16        \u001b[36m4.0836\u001b[0m       \u001b[32m0.9275\u001b[0m        \u001b[35m4.1284\u001b[0m  6.4321\n",
      "     17        \u001b[36m4.0760\u001b[0m       \u001b[32m0.9325\u001b[0m        \u001b[35m4.1255\u001b[0m  6.3617\n",
      "     18        \u001b[36m4.0703\u001b[0m       \u001b[32m0.9341\u001b[0m        \u001b[35m4.1228\u001b[0m  6.5342\n",
      "     19        \u001b[36m4.0643\u001b[0m       \u001b[32m0.9358\u001b[0m        \u001b[35m4.1186\u001b[0m  6.5631\n",
      "     20        \u001b[36m4.0597\u001b[0m       \u001b[32m0.9384\u001b[0m        \u001b[35m4.1162\u001b[0m  6.4731\n",
      "     21        \u001b[36m4.0558\u001b[0m       0.9381        \u001b[35m4.1140\u001b[0m  6.5399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     22        \u001b[36m4.0518\u001b[0m       \u001b[32m0.9411\u001b[0m        \u001b[35m4.1113\u001b[0m  6.6125\n",
      "     23        \u001b[36m4.0503\u001b[0m       \u001b[32m0.9427\u001b[0m        \u001b[35m4.1098\u001b[0m  6.4819\n",
      "     24        \u001b[36m4.0491\u001b[0m       0.9404        \u001b[35m4.1082\u001b[0m  6.4985\n",
      "     25        \u001b[36m4.0471\u001b[0m       0.9427        \u001b[35m4.1070\u001b[0m  6.4314\n",
      "     26        \u001b[36m4.0452\u001b[0m       0.9414        \u001b[35m4.1059\u001b[0m  6.3382\n",
      "     27        \u001b[36m4.0439\u001b[0m       \u001b[32m0.9434\u001b[0m        \u001b[35m4.1047\u001b[0m  6.4079\n",
      "     28        \u001b[36m4.0425\u001b[0m       0.9430        \u001b[35m4.1040\u001b[0m  6.5185\n",
      "     29        4.0427       0.9421        \u001b[35m4.1038\u001b[0m  6.4130\n",
      "     30        \u001b[36m4.0407\u001b[0m       \u001b[32m0.9437\u001b[0m        \u001b[35m4.1031\u001b[0m  6.5538\n",
      "     31        \u001b[36m4.0404\u001b[0m       0.9424        \u001b[35m4.1027\u001b[0m  6.4830\n",
      "     32        \u001b[36m4.0398\u001b[0m       0.9424        \u001b[35m4.1027\u001b[0m  6.5192\n",
      "     33        \u001b[36m4.0391\u001b[0m       0.9430        \u001b[35m4.1018\u001b[0m  6.6374\n",
      "     34        \u001b[36m4.0387\u001b[0m       0.9407        4.1023  6.5581\n",
      "     35        \u001b[36m4.0378\u001b[0m       \u001b[32m0.9450\u001b[0m        \u001b[35m4.1005\u001b[0m  6.4688\n",
      "     36        4.0378       0.9447        \u001b[35m4.1004\u001b[0m  6.4646\n",
      "     37        \u001b[36m4.0370\u001b[0m       0.9447        \u001b[35m4.0995\u001b[0m  6.4748\n",
      "     38        \u001b[36m4.0367\u001b[0m       \u001b[32m0.9464\u001b[0m        \u001b[35m4.0989\u001b[0m  6.6906\n",
      "     39        \u001b[36m4.0363\u001b[0m       0.9437        4.0990  6.4246\n",
      "     40        \u001b[36m4.0363\u001b[0m       0.9457        \u001b[35m4.0982\u001b[0m  6.4834\n",
      "     41        4.0363       0.9454        \u001b[35m4.0980\u001b[0m  6.5385\n",
      "     42        \u001b[36m4.0352\u001b[0m       0.9427        \u001b[35m4.0978\u001b[0m  6.5352\n",
      "     43        4.0356       0.9450        \u001b[35m4.0974\u001b[0m  6.3804\n",
      "     44        \u001b[36m4.0348\u001b[0m       0.9447        \u001b[35m4.0968\u001b[0m  6.4651\n",
      "     45        4.0348       0.9460        4.0971  6.5907\n",
      "     46        \u001b[36m4.0347\u001b[0m       \u001b[32m0.9467\u001b[0m        \u001b[35m4.0964\u001b[0m  6.5196\n",
      "     47        \u001b[36m4.0345\u001b[0m       0.9454        \u001b[35m4.0963\u001b[0m  6.8894\n",
      "     48        \u001b[36m4.0341\u001b[0m       0.9447        4.0964  6.5355\n",
      "     49        \u001b[36m4.0340\u001b[0m       0.9450        \u001b[35m4.0959\u001b[0m  6.4294\n",
      "     50        \u001b[36m4.0338\u001b[0m       0.9450        \u001b[35m4.0953\u001b[0m  6.5692\n",
      "     51        \u001b[36m4.0338\u001b[0m       0.9444        4.0955  6.5363\n",
      "     52        4.0339       0.9434        4.0965  6.5055\n",
      "     53        \u001b[36m4.0336\u001b[0m       0.9447        4.0960  6.5995\n",
      "     54        \u001b[36m4.0333\u001b[0m       0.9454        \u001b[35m4.0949\u001b[0m  6.5372\n",
      "     55        \u001b[36m4.0329\u001b[0m       0.9447        4.0951  6.5349\n",
      "     56        4.0332       0.9454        4.0951  6.5848\n",
      "     57        4.0332       0.9454        4.0952  6.6338\n",
      "     58        4.0331       0.9450        \u001b[35m4.0949\u001b[0m  6.6030\n",
      "     59        \u001b[36m4.0328\u001b[0m       0.9450        \u001b[35m4.0940\u001b[0m  6.4305\n",
      "     60        4.0328       0.9440        4.0941  6.4120\n",
      "     61        \u001b[36m4.0326\u001b[0m       0.9447        4.0943  6.5913\n",
      "     62        4.0327       0.9447        4.0947  6.5119\n",
      "     63        4.0327       0.9457        4.0946  6.5060\n",
      "     64        \u001b[36m4.0323\u001b[0m       0.9440        4.0951  6.4782\n",
      "     65        \u001b[36m4.0323\u001b[0m       0.9444        4.0942  6.4286\n",
      "     66        \u001b[36m4.0322\u001b[0m       0.9454        \u001b[35m4.0938\u001b[0m  6.4573\n",
      "     67        4.0325       0.9450        4.0944  6.6184\n",
      "     68        4.0324       0.9434        4.0949  6.5817\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0158\u001b[0m       \u001b[32m0.5308\u001b[0m        \u001b[35m5.0104\u001b[0m  6.3199\n",
      "      2        \u001b[36m4.9142\u001b[0m       0.4781        \u001b[35m4.7306\u001b[0m  6.3134\n",
      "      3        \u001b[36m4.6001\u001b[0m       \u001b[32m0.6762\u001b[0m        \u001b[35m4.4771\u001b[0m  6.4152\n",
      "      4        \u001b[36m4.4224\u001b[0m       \u001b[32m0.7712\u001b[0m        \u001b[35m4.3641\u001b[0m  6.4480\n",
      "      5        \u001b[36m4.3227\u001b[0m       \u001b[32m0.8099\u001b[0m        \u001b[35m4.2928\u001b[0m  6.7083\n",
      "      6        \u001b[36m4.2625\u001b[0m       \u001b[32m0.8394\u001b[0m        \u001b[35m4.2517\u001b[0m  6.3883\n",
      "      7        \u001b[36m4.2212\u001b[0m       \u001b[32m0.8613\u001b[0m        \u001b[35m4.2236\u001b[0m  6.6051\n",
      "      8        \u001b[36m4.1894\u001b[0m       \u001b[32m0.8778\u001b[0m        \u001b[35m4.2020\u001b[0m  6.5343\n",
      "      9        \u001b[36m4.1657\u001b[0m       \u001b[32m0.8904\u001b[0m        \u001b[35m4.1843\u001b[0m  6.5637\n",
      "     10        \u001b[36m4.1428\u001b[0m       \u001b[32m0.9076\u001b[0m        \u001b[35m4.1648\u001b[0m  6.2801\n",
      "     11        \u001b[36m4.1232\u001b[0m       \u001b[32m0.9149\u001b[0m        \u001b[35m4.1526\u001b[0m  6.2255\n",
      "     12        \u001b[36m4.1124\u001b[0m       \u001b[32m0.9166\u001b[0m        \u001b[35m4.1459\u001b[0m  6.3678\n",
      "     13        \u001b[36m4.1029\u001b[0m       \u001b[32m0.9189\u001b[0m        \u001b[35m4.1403\u001b[0m  6.4824\n",
      "     14        \u001b[36m4.0943\u001b[0m       \u001b[32m0.9212\u001b[0m        \u001b[35m4.1361\u001b[0m  6.3105\n",
      "     15        \u001b[36m4.0896\u001b[0m       \u001b[32m0.9215\u001b[0m        \u001b[35m4.1330\u001b[0m  6.3703\n",
      "     16        \u001b[36m4.0842\u001b[0m       \u001b[32m0.9235\u001b[0m        \u001b[35m4.1320\u001b[0m  6.5282\n",
      "     17        \u001b[36m4.0794\u001b[0m       \u001b[32m0.9291\u001b[0m        \u001b[35m4.1264\u001b[0m  6.5586\n",
      "     18        \u001b[36m4.0728\u001b[0m       \u001b[32m0.9295\u001b[0m        \u001b[35m4.1241\u001b[0m  6.5270\n",
      "     19        \u001b[36m4.0675\u001b[0m       \u001b[32m0.9308\u001b[0m        \u001b[35m4.1223\u001b[0m  6.9066\n",
      "     20        \u001b[36m4.0628\u001b[0m       \u001b[32m0.9328\u001b[0m        \u001b[35m4.1190\u001b[0m  6.5698\n",
      "     21        \u001b[36m4.0583\u001b[0m       \u001b[32m0.9344\u001b[0m        \u001b[35m4.1155\u001b[0m  6.9041\n",
      "     22        \u001b[36m4.0544\u001b[0m       \u001b[32m0.9391\u001b[0m        \u001b[35m4.1132\u001b[0m  6.5295\n",
      "     23        \u001b[36m4.0510\u001b[0m       0.9391        \u001b[35m4.1110\u001b[0m  6.4789\n",
      "     24        \u001b[36m4.0490\u001b[0m       \u001b[32m0.9414\u001b[0m        \u001b[35m4.1086\u001b[0m  6.4234\n",
      "     25        \u001b[36m4.0466\u001b[0m       0.9401        \u001b[35m4.1082\u001b[0m  6.4272\n",
      "     26        \u001b[36m4.0451\u001b[0m       0.9401        \u001b[35m4.1066\u001b[0m  6.3414\n",
      "     27        \u001b[36m4.0442\u001b[0m       0.9401        \u001b[35m4.1057\u001b[0m  6.3751\n",
      "     28        \u001b[36m4.0429\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m4.1045\u001b[0m  6.3964\n",
      "     29        \u001b[36m4.0423\u001b[0m       \u001b[32m0.9447\u001b[0m        \u001b[35m4.1034\u001b[0m  6.4355\n",
      "     30        \u001b[36m4.0406\u001b[0m       \u001b[32m0.9450\u001b[0m        \u001b[35m4.1024\u001b[0m  6.5710\n",
      "     31        4.0407       0.9440        4.1029  6.3364\n",
      "     32        \u001b[36m4.0402\u001b[0m       0.9437        \u001b[35m4.1016\u001b[0m  6.4441\n",
      "     33        \u001b[36m4.0390\u001b[0m       \u001b[32m0.9460\u001b[0m        \u001b[35m4.1010\u001b[0m  6.4421\n",
      "     34        \u001b[36m4.0384\u001b[0m       0.9437        4.1012  6.4802\n",
      "     35        \u001b[36m4.0380\u001b[0m       0.9440        \u001b[35m4.1008\u001b[0m  6.5599\n",
      "     36        4.0380       0.9434        \u001b[35m4.0996\u001b[0m  6.5972\n",
      "     37        \u001b[36m4.0371\u001b[0m       0.9447        \u001b[35m4.0992\u001b[0m  6.3627\n",
      "     38        \u001b[36m4.0366\u001b[0m       0.9440        \u001b[35m4.0989\u001b[0m  6.4018\n",
      "     39        \u001b[36m4.0363\u001b[0m       0.9434        \u001b[35m4.0986\u001b[0m  6.4826\n",
      "     40        \u001b[36m4.0362\u001b[0m       0.9450        \u001b[35m4.0983\u001b[0m  6.7007\n",
      "     41        \u001b[36m4.0361\u001b[0m       0.9444        \u001b[35m4.0976\u001b[0m  6.9551\n",
      "     42        \u001b[36m4.0355\u001b[0m       0.9447        \u001b[35m4.0975\u001b[0m  6.8676\n",
      "     43        \u001b[36m4.0352\u001b[0m       0.9454        \u001b[35m4.0971\u001b[0m  6.8018\n",
      "     44        4.0356       0.9447        \u001b[35m4.0970\u001b[0m  6.4098\n",
      "     45        \u001b[36m4.0351\u001b[0m       0.9457        \u001b[35m4.0962\u001b[0m  6.5310\n",
      "     46        \u001b[36m4.0344\u001b[0m       0.9454        4.0965  6.4720\n",
      "     47        4.0345       0.9447        \u001b[35m4.0961\u001b[0m  6.4964\n",
      "     48        \u001b[36m4.0343\u001b[0m       0.9450        4.0961  6.4726\n",
      "     49        \u001b[36m4.0340\u001b[0m       0.9444        \u001b[35m4.0957\u001b[0m  6.5125\n",
      "     50        4.0341       0.9447        \u001b[35m4.0952\u001b[0m  6.3635\n",
      "     51        \u001b[36m4.0338\u001b[0m       0.9450        4.0953  6.6265\n",
      "     52        \u001b[36m4.0338\u001b[0m       0.9454        \u001b[35m4.0949\u001b[0m  6.4556\n",
      "     53        \u001b[36m4.0337\u001b[0m       0.9427        \u001b[35m4.0947\u001b[0m  6.6206\n",
      "     54        \u001b[36m4.0334\u001b[0m       0.9444        4.0959  6.5725\n",
      "     55        \u001b[36m4.0334\u001b[0m       \u001b[32m0.9474\u001b[0m        \u001b[35m4.0940\u001b[0m  6.6305\n",
      "     56        \u001b[36m4.0333\u001b[0m       0.9437        4.0946  6.4667\n",
      "     57        \u001b[36m4.0330\u001b[0m       0.9464        \u001b[35m4.0936\u001b[0m  6.4091\n",
      "     58        4.0331       0.9454        4.0938  6.4138\n",
      "     59        \u001b[36m4.0329\u001b[0m       0.9460        4.0941  6.4217\n",
      "     60        \u001b[36m4.0326\u001b[0m       0.9454        4.0945  6.4311\n",
      "     61        \u001b[36m4.0324\u001b[0m       0.9457        4.0939  6.5835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     62        4.0327       0.9440        4.0945  6.4249\n",
      "     63        \u001b[36m4.0323\u001b[0m       0.9450        4.0936  6.4443\n",
      "     64        \u001b[36m4.0323\u001b[0m       0.9460        \u001b[35m4.0930\u001b[0m  6.4440\n",
      "     65        \u001b[36m4.0321\u001b[0m       0.9457        4.0934  6.5259\n",
      "     66        4.0324       0.9450        \u001b[35m4.0929\u001b[0m  6.5915\n",
      "     67        4.0322       0.9444        4.0934  6.5167\n",
      "     68        4.0322       0.9437        4.0942  6.5535\n",
      "     69        \u001b[36m4.0321\u001b[0m       0.9444        4.0929  6.6276\n",
      "     70        \u001b[36m4.0320\u001b[0m       0.9450        4.0930  6.4476\n",
      "     71        \u001b[36m4.0319\u001b[0m       0.9440        \u001b[35m4.0928\u001b[0m  6.4105\n",
      "     72        4.0321       0.9447        \u001b[35m4.0923\u001b[0m  6.4377\n",
      "     73        4.0319       0.9447        4.0938  6.4220\n",
      "     74        \u001b[36m4.0318\u001b[0m       0.9447        4.0929  6.4105\n",
      "     75        4.0319       0.9457        \u001b[35m4.0920\u001b[0m  6.4444\n",
      "     76        \u001b[36m4.0317\u001b[0m       0.9454        4.0922  6.4296\n",
      "     77        \u001b[36m4.0314\u001b[0m       0.9444        4.0925  6.4248\n",
      "     78        4.0315       0.9437        4.0920  6.4273\n",
      "     79        4.0316       0.9454        \u001b[35m4.0915\u001b[0m  6.4386\n",
      "     80        4.0316       0.9450        4.0921  6.4266\n",
      "     81        \u001b[36m4.0313\u001b[0m       0.9444        4.0923  6.5017\n",
      "     82        \u001b[36m4.0313\u001b[0m       0.9440        4.0922  6.4892\n",
      "     83        4.0316       0.9434        \u001b[35m4.0914\u001b[0m  6.4274\n",
      "     84        \u001b[36m4.0311\u001b[0m       0.9444        \u001b[35m4.0912\u001b[0m  6.4315\n",
      "     85        4.0314       0.9454        \u001b[35m4.0911\u001b[0m  6.4200\n",
      "     86        4.0314       0.9450        4.0913  6.4307\n",
      "     87        4.0313       0.9474        \u001b[35m4.0910\u001b[0m  6.4250\n",
      "     88        \u001b[36m4.0310\u001b[0m       0.9447        4.0915  6.4207\n",
      "     89        4.0311       0.9447        4.0915  6.4670\n",
      "     90        4.0311       0.9457        4.0915  6.4733\n",
      "     91        4.0310       0.9444        4.0916  6.4918\n",
      "     92        4.0310       0.9430        4.0924  6.4376\n",
      "     93        \u001b[36m4.0310\u001b[0m       0.9417        4.0926  6.4509\n",
      "     94        4.0311       0.9450        4.0915  6.4728\n",
      "     95        \u001b[36m4.0309\u001b[0m       0.9457        4.0916  6.4190\n",
      "     96        4.0310       0.9467        \u001b[35m4.0908\u001b[0m  6.4304\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0158\u001b[0m       \u001b[32m0.5573\u001b[0m        \u001b[35m5.0104\u001b[0m  6.3266\n",
      "      2        \u001b[36m4.9119\u001b[0m       0.4719        \u001b[35m4.7265\u001b[0m  6.3322\n",
      "      3        \u001b[36m4.5994\u001b[0m       \u001b[32m0.6705\u001b[0m        \u001b[35m4.4804\u001b[0m  6.3240\n",
      "      4        \u001b[36m4.4192\u001b[0m       \u001b[32m0.7705\u001b[0m        \u001b[35m4.3585\u001b[0m  6.2979\n",
      "      5        \u001b[36m4.3172\u001b[0m       \u001b[32m0.8152\u001b[0m        \u001b[35m4.2905\u001b[0m  6.2018\n",
      "      6        \u001b[36m4.2587\u001b[0m       \u001b[32m0.8404\u001b[0m        \u001b[35m4.2499\u001b[0m  6.2695\n",
      "      7        \u001b[36m4.2231\u001b[0m       \u001b[32m0.8493\u001b[0m        \u001b[35m4.2287\u001b[0m  6.3397\n",
      "      8        \u001b[36m4.1967\u001b[0m       \u001b[32m0.8629\u001b[0m        \u001b[35m4.2115\u001b[0m  6.2481\n",
      "      9        \u001b[36m4.1725\u001b[0m       \u001b[32m0.8901\u001b[0m        \u001b[35m4.1893\u001b[0m  6.2114\n",
      "     10        \u001b[36m4.1478\u001b[0m       \u001b[32m0.9043\u001b[0m        \u001b[35m4.1690\u001b[0m  6.2126\n",
      "     11        \u001b[36m4.1283\u001b[0m       \u001b[32m0.9063\u001b[0m        \u001b[35m4.1582\u001b[0m  6.2297\n",
      "     12        \u001b[36m4.1161\u001b[0m       \u001b[32m0.9099\u001b[0m        \u001b[35m4.1512\u001b[0m  6.2388\n",
      "     13        \u001b[36m4.1052\u001b[0m       \u001b[32m0.9149\u001b[0m        \u001b[35m4.1450\u001b[0m  6.1211\n",
      "     14        \u001b[36m4.0984\u001b[0m       \u001b[32m0.9182\u001b[0m        \u001b[35m4.1407\u001b[0m  6.2625\n",
      "     15        \u001b[36m4.0913\u001b[0m       \u001b[32m0.9232\u001b[0m        \u001b[35m4.1356\u001b[0m  6.2851\n",
      "     16        \u001b[36m4.0836\u001b[0m       \u001b[32m0.9245\u001b[0m        \u001b[35m4.1309\u001b[0m  6.2841\n",
      "     17        \u001b[36m4.0790\u001b[0m       \u001b[32m0.9281\u001b[0m        \u001b[35m4.1282\u001b[0m  6.2869\n",
      "     18        \u001b[36m4.0736\u001b[0m       \u001b[32m0.9288\u001b[0m        \u001b[35m4.1271\u001b[0m  6.3130\n",
      "     19        \u001b[36m4.0694\u001b[0m       0.9275        \u001b[35m4.1246\u001b[0m  6.3503\n",
      "     20        \u001b[36m4.0657\u001b[0m       \u001b[32m0.9328\u001b[0m        \u001b[35m4.1209\u001b[0m  6.7100\n",
      "     21        \u001b[36m4.0611\u001b[0m       0.9321        \u001b[35m4.1191\u001b[0m  6.5341\n",
      "     22        \u001b[36m4.0576\u001b[0m       0.9315        \u001b[35m4.1171\u001b[0m  6.6752\n",
      "     23        \u001b[36m4.0561\u001b[0m       \u001b[32m0.9354\u001b[0m        \u001b[35m4.1140\u001b[0m  6.7638\n",
      "     24        \u001b[36m4.0514\u001b[0m       \u001b[32m0.9411\u001b[0m        \u001b[35m4.1097\u001b[0m  6.3942\n",
      "     25        \u001b[36m4.0484\u001b[0m       0.9401        \u001b[35m4.1084\u001b[0m  6.3912\n",
      "     26        \u001b[36m4.0463\u001b[0m       \u001b[32m0.9440\u001b[0m        \u001b[35m4.1056\u001b[0m  6.4241\n",
      "     27        \u001b[36m4.0445\u001b[0m       0.9437        \u001b[35m4.1055\u001b[0m  6.4669\n",
      "     28        \u001b[36m4.0445\u001b[0m       0.9430        \u001b[35m4.1044\u001b[0m  6.4660\n",
      "     29        \u001b[36m4.0427\u001b[0m       0.9421        \u001b[35m4.1036\u001b[0m  6.6036\n",
      "     30        \u001b[36m4.0415\u001b[0m       \u001b[32m0.9444\u001b[0m        \u001b[35m4.1027\u001b[0m  6.5139\n",
      "     31        \u001b[36m4.0408\u001b[0m       0.9440        \u001b[35m4.1025\u001b[0m  6.5298\n",
      "     32        \u001b[36m4.0401\u001b[0m       0.9444        \u001b[35m4.1017\u001b[0m  6.5702\n",
      "     33        \u001b[36m4.0392\u001b[0m       0.9430        \u001b[35m4.1012\u001b[0m  6.5741\n",
      "     34        \u001b[36m4.0390\u001b[0m       \u001b[32m0.9450\u001b[0m        \u001b[35m4.1004\u001b[0m  6.8064\n",
      "     35        \u001b[36m4.0387\u001b[0m       \u001b[32m0.9454\u001b[0m        \u001b[35m4.0999\u001b[0m  6.5104\n",
      "     36        \u001b[36m4.0383\u001b[0m       0.9440        4.1001  6.6769\n",
      "     37        \u001b[36m4.0378\u001b[0m       0.9440        \u001b[35m4.0995\u001b[0m  6.5350\n",
      "     38        \u001b[36m4.0372\u001b[0m       \u001b[32m0.9457\u001b[0m        \u001b[35m4.0993\u001b[0m  6.5642\n",
      "     39        4.0375       0.9447        \u001b[35m4.0985\u001b[0m  6.6514\n",
      "     40        \u001b[36m4.0366\u001b[0m       0.9454        \u001b[35m4.0979\u001b[0m  6.4364\n",
      "     41        \u001b[36m4.0363\u001b[0m       \u001b[32m0.9464\u001b[0m        \u001b[35m4.0972\u001b[0m  6.5717\n",
      "     42        \u001b[36m4.0362\u001b[0m       0.9444        4.0978  6.5985\n",
      "     43        \u001b[36m4.0359\u001b[0m       0.9450        4.0972  6.4803\n",
      "     44        \u001b[36m4.0356\u001b[0m       \u001b[32m0.9474\u001b[0m        \u001b[35m4.0967\u001b[0m  6.3869\n",
      "     45        \u001b[36m4.0350\u001b[0m       0.9440        4.0975  6.3937\n",
      "     46        4.0352       0.9454        4.0968  6.3886\n",
      "     47        \u001b[36m4.0349\u001b[0m       0.9467        \u001b[35m4.0963\u001b[0m  6.4025\n",
      "     48        \u001b[36m4.0345\u001b[0m       0.9454        4.0966  6.4016\n",
      "     49        4.0345       0.9447        4.0963  6.3815\n",
      "     50        \u001b[36m4.0343\u001b[0m       0.9464        \u001b[35m4.0955\u001b[0m  6.4157\n",
      "     51        \u001b[36m4.0341\u001b[0m       0.9464        4.0957  6.3803\n",
      "     52        \u001b[36m4.0338\u001b[0m       0.9440        \u001b[35m4.0955\u001b[0m  6.4023\n",
      "     53        \u001b[36m4.0337\u001b[0m       0.9450        \u001b[35m4.0947\u001b[0m  6.3968\n",
      "     54        \u001b[36m4.0333\u001b[0m       0.9454        4.0949  6.4536\n",
      "     55        4.0336       0.9457        4.0947  6.3935\n",
      "     56        4.0333       0.9457        \u001b[35m4.0946\u001b[0m  6.3825\n",
      "     57        4.0336       0.9457        \u001b[35m4.0942\u001b[0m  6.4258\n",
      "     58        \u001b[36m4.0331\u001b[0m       0.9444        4.0947  6.3943\n",
      "     59        \u001b[36m4.0330\u001b[0m       0.9450        \u001b[35m4.0938\u001b[0m  6.3978\n",
      "     60        4.0332       0.9440        4.0949  6.4500\n",
      "     61        \u001b[36m4.0329\u001b[0m       0.9467        4.0938  6.5972\n",
      "     62        \u001b[36m4.0327\u001b[0m       0.9464        \u001b[35m4.0934\u001b[0m  6.5759\n",
      "     63        \u001b[36m4.0326\u001b[0m       0.9437        4.0941  6.5651\n",
      "     64        \u001b[36m4.0326\u001b[0m       0.9454        \u001b[35m4.0931\u001b[0m  6.6167\n",
      "     65        \u001b[36m4.0324\u001b[0m       0.9460        \u001b[35m4.0924\u001b[0m  6.5723\n",
      "     66        4.0324       0.9450        4.0924  6.6814\n",
      "     67        4.0324       0.9440        4.0933  6.4500\n",
      "     68        \u001b[36m4.0323\u001b[0m       0.9450        4.0930  6.4537\n",
      "     69        \u001b[36m4.0323\u001b[0m       0.9444        4.0926  6.4058\n",
      "     70        \u001b[36m4.0323\u001b[0m       0.9467        \u001b[35m4.0922\u001b[0m  6.6488\n",
      "     71        \u001b[36m4.0321\u001b[0m       0.9460        \u001b[35m4.0919\u001b[0m  6.6843\n",
      "     72        \u001b[36m4.0319\u001b[0m       0.9470        4.0922  6.4998\n",
      "     73        4.0320       0.9464        \u001b[35m4.0917\u001b[0m  6.7125\n",
      "     74        \u001b[36m4.0318\u001b[0m       \u001b[32m0.9477\u001b[0m        \u001b[35m4.0909\u001b[0m  6.4051\n",
      "     75        \u001b[36m4.0316\u001b[0m       0.9470        4.0914  6.6020\n",
      "     76        4.0318       0.9454        4.0917  6.6052\n",
      "     77        4.0318       0.9454        4.0922  6.5758\n",
      "     78        \u001b[36m4.0316\u001b[0m       0.9437        4.0927  6.5812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     79        4.0317       0.9454        4.0921  6.6292\n",
      "     80        \u001b[36m4.0315\u001b[0m       0.9434        4.0922  6.6057\n",
      "     81        \u001b[36m4.0315\u001b[0m       0.9450        4.0920  6.4910\n",
      "     82        4.0317       0.9447        4.0927  6.5474\n",
      "     83        4.0315       0.9454        4.0910  6.5867\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.0158\u001b[0m       \u001b[32m0.4874\u001b[0m        \u001b[35m5.0102\u001b[0m  6.5338\n",
      "      2        \u001b[36m4.9122\u001b[0m       0.4864        \u001b[35m4.7246\u001b[0m  6.6421\n",
      "      3        \u001b[36m4.5979\u001b[0m       \u001b[32m0.6659\u001b[0m        \u001b[35m4.4811\u001b[0m  6.6101\n",
      "      4        \u001b[36m4.4219\u001b[0m       \u001b[32m0.7603\u001b[0m        \u001b[35m4.3626\u001b[0m  6.7448\n",
      "      5        \u001b[36m4.3218\u001b[0m       \u001b[32m0.8142\u001b[0m        \u001b[35m4.2924\u001b[0m  6.5438\n",
      "      6        \u001b[36m4.2583\u001b[0m       \u001b[32m0.8447\u001b[0m        \u001b[35m4.2485\u001b[0m  6.7564\n",
      "      7        \u001b[36m4.2203\u001b[0m       \u001b[32m0.8593\u001b[0m        \u001b[35m4.2238\u001b[0m  6.4868\n",
      "      8        \u001b[36m4.1941\u001b[0m       \u001b[32m0.8692\u001b[0m        \u001b[35m4.2078\u001b[0m  6.2943\n",
      "      9        \u001b[36m4.1748\u001b[0m       \u001b[32m0.8808\u001b[0m        \u001b[35m4.1929\u001b[0m  6.2932\n",
      "     10        \u001b[36m4.1560\u001b[0m       \u001b[32m0.9023\u001b[0m        \u001b[35m4.1744\u001b[0m  6.2194\n",
      "     11        \u001b[36m4.1329\u001b[0m       \u001b[32m0.9076\u001b[0m        \u001b[35m4.1592\u001b[0m  6.3433\n",
      "     12        \u001b[36m4.1188\u001b[0m       \u001b[32m0.9126\u001b[0m        \u001b[35m4.1497\u001b[0m  6.2713\n",
      "     13        \u001b[36m4.1035\u001b[0m       \u001b[32m0.9199\u001b[0m        \u001b[35m4.1405\u001b[0m  6.6620\n",
      "     14        \u001b[36m4.0947\u001b[0m       \u001b[32m0.9235\u001b[0m        \u001b[35m4.1351\u001b[0m  6.4264\n",
      "     15        \u001b[36m4.0865\u001b[0m       \u001b[32m0.9262\u001b[0m        \u001b[35m4.1313\u001b[0m  6.5015\n",
      "     16        \u001b[36m4.0822\u001b[0m       \u001b[32m0.9301\u001b[0m        \u001b[35m4.1286\u001b[0m  6.5310\n",
      "     17        \u001b[36m4.0754\u001b[0m       \u001b[32m0.9325\u001b[0m        \u001b[35m4.1235\u001b[0m  6.5600\n",
      "     18        \u001b[36m4.0700\u001b[0m       0.9325        \u001b[35m4.1220\u001b[0m  6.6981\n",
      "     19        \u001b[36m4.0652\u001b[0m       \u001b[32m0.9354\u001b[0m        \u001b[35m4.1195\u001b[0m  6.4323\n",
      "     20        \u001b[36m4.0621\u001b[0m       \u001b[32m0.9364\u001b[0m        \u001b[35m4.1171\u001b[0m  6.3588\n",
      "     21        \u001b[36m4.0570\u001b[0m       \u001b[32m0.9394\u001b[0m        \u001b[35m4.1136\u001b[0m  6.7008\n",
      "     22        \u001b[36m4.0528\u001b[0m       \u001b[32m0.9397\u001b[0m        \u001b[35m4.1114\u001b[0m  6.5594\n",
      "     23        \u001b[36m4.0510\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m4.1094\u001b[0m  6.4249\n",
      "     24        \u001b[36m4.0490\u001b[0m       0.9421        \u001b[35m4.1079\u001b[0m  6.5635\n",
      "     25        \u001b[36m4.0463\u001b[0m       \u001b[32m0.9434\u001b[0m        \u001b[35m4.1064\u001b[0m  6.5668\n",
      "     26        \u001b[36m4.0451\u001b[0m       \u001b[32m0.9447\u001b[0m        \u001b[35m4.1056\u001b[0m  6.3612\n",
      "     27        \u001b[36m4.0438\u001b[0m       \u001b[32m0.9454\u001b[0m        \u001b[35m4.1049\u001b[0m  6.3883\n",
      "     28        \u001b[36m4.0429\u001b[0m       \u001b[32m0.9467\u001b[0m        \u001b[35m4.1039\u001b[0m  6.6810\n",
      "     29        \u001b[36m4.0419\u001b[0m       0.9450        \u001b[35m4.1034\u001b[0m  6.4747\n",
      "     30        \u001b[36m4.0414\u001b[0m       0.9457        \u001b[35m4.1024\u001b[0m  6.5701\n",
      "     31        \u001b[36m4.0401\u001b[0m       0.9447        \u001b[35m4.1018\u001b[0m  6.3597\n",
      "     32        \u001b[36m4.0395\u001b[0m       0.9454        \u001b[35m4.1014\u001b[0m  6.3833\n",
      "     33        \u001b[36m4.0389\u001b[0m       0.9447        \u001b[35m4.1007\u001b[0m  6.5088\n",
      "     34        \u001b[36m4.0388\u001b[0m       0.9464        \u001b[35m4.1000\u001b[0m  6.2867\n",
      "     35        \u001b[36m4.0380\u001b[0m       \u001b[32m0.9483\u001b[0m        \u001b[35m4.0992\u001b[0m  6.7157\n",
      "     36        4.0382       0.9474        \u001b[35m4.0989\u001b[0m  6.5551\n",
      "     37        \u001b[36m4.0370\u001b[0m       0.9474        \u001b[35m4.0987\u001b[0m  6.5933\n",
      "     38        4.0375       0.9483        \u001b[35m4.0987\u001b[0m  6.8630\n",
      "     39        \u001b[36m4.0367\u001b[0m       0.9454        4.0987  6.6200\n",
      "     40        \u001b[36m4.0362\u001b[0m       0.9454        \u001b[35m4.0980\u001b[0m  6.4190\n",
      "     41        \u001b[36m4.0360\u001b[0m       0.9460        \u001b[35m4.0970\u001b[0m  6.8450\n",
      "     42        4.0360       0.9470        \u001b[35m4.0967\u001b[0m  6.7065\n",
      "     43        4.0360       0.9460        \u001b[35m4.0962\u001b[0m  6.7330\n",
      "     44        \u001b[36m4.0351\u001b[0m       0.9467        4.0964  6.6901\n",
      "     45        \u001b[36m4.0351\u001b[0m       0.9467        4.0963  6.4339\n",
      "     46        \u001b[36m4.0351\u001b[0m       0.9467        \u001b[35m4.0961\u001b[0m  6.4338\n",
      "     47        \u001b[36m4.0341\u001b[0m       0.9467        \u001b[35m4.0960\u001b[0m  6.4882\n",
      "     48        4.0345       0.9480        \u001b[35m4.0952\u001b[0m  7.0930\n",
      "     49        4.0344       0.9470        4.0953  6.8222\n",
      "     50        \u001b[36m4.0338\u001b[0m       0.9470        4.0953  6.5790\n",
      "     51        4.0339       0.9444        4.0958  6.4078\n",
      "     52        \u001b[36m4.0334\u001b[0m       0.9464        \u001b[35m4.0951\u001b[0m  6.5417\n",
      "     53        4.0334       0.9460        \u001b[35m4.0949\u001b[0m  6.6237\n",
      "     54        4.0337       0.9474        \u001b[35m4.0941\u001b[0m  6.5183\n",
      "     55        \u001b[36m4.0333\u001b[0m       0.9477        \u001b[35m4.0940\u001b[0m  6.7039\n",
      "     56        4.0335       0.9464        4.0950  6.6528\n",
      "     57        \u001b[36m4.0332\u001b[0m       0.9454        4.0944  6.7165\n",
      "     58        \u001b[36m4.0329\u001b[0m       0.9474        4.0941  6.7830\n",
      "     59        \u001b[36m4.0327\u001b[0m       0.9460        \u001b[35m4.0934\u001b[0m  6.5252\n",
      "     60        4.0330       0.9470        4.0936  6.4282\n",
      "     61        4.0328       0.9470        4.0937  6.6051\n",
      "     62        \u001b[36m4.0326\u001b[0m       0.9457        \u001b[35m4.0930\u001b[0m  6.5596\n",
      "     63        4.0327       0.9477        \u001b[35m4.0926\u001b[0m  6.4107\n",
      "     64        \u001b[36m4.0326\u001b[0m       0.9477        4.0932  6.4803\n",
      "     65        \u001b[36m4.0324\u001b[0m       0.9457        4.0930  6.5345\n",
      "     66        \u001b[36m4.0323\u001b[0m       0.9464        \u001b[35m4.0926\u001b[0m  6.7876\n",
      "     67        4.0324       0.9454        \u001b[35m4.0924\u001b[0m  6.7106\n",
      "     68        4.0325       0.9457        4.0926  6.8604\n",
      "     69        \u001b[36m4.0322\u001b[0m       0.9474        4.0925  6.4768\n",
      "     70        4.0323       0.9464        4.0926  6.4412\n",
      "     71        \u001b[36m4.0320\u001b[0m       0.9470        \u001b[35m4.0923\u001b[0m  6.4585\n",
      "     72        4.0321       0.9480        \u001b[35m4.0919\u001b[0m  6.4705\n",
      "     73        \u001b[36m4.0319\u001b[0m       0.9467        4.0920  6.4757\n",
      "     74        4.0323       0.9470        4.0922  6.4328\n",
      "     75        \u001b[36m4.0316\u001b[0m       0.9450        \u001b[35m4.0916\u001b[0m  6.5156\n",
      "     76        4.0319       0.9450        \u001b[35m4.0916\u001b[0m  6.7227\n",
      "     77        4.0319       0.9450        4.0921  6.7202\n",
      "     78        4.0318       0.9437        4.0928  6.8014\n",
      "     79        4.0317       0.9440        4.0926  6.9611\n",
      "     80        \u001b[36m4.0316\u001b[0m       0.9454        4.0920  6.5950\n",
      "     81        \u001b[36m4.0315\u001b[0m       0.9457        4.0916  6.5070\n",
      "     82        \u001b[36m4.0314\u001b[0m       0.9470        \u001b[35m4.0910\u001b[0m  6.4507\n",
      "     83        \u001b[36m4.0314\u001b[0m       0.9450        4.0917  6.4176\n",
      "     84        \u001b[36m4.0313\u001b[0m       0.9447        4.0921  6.4789\n",
      "     85        4.0314       0.9450        4.0911  6.4217\n",
      "     86        4.0316       0.9470        4.0911  6.4399\n",
      "     87        4.0313       0.9450        4.0915  6.4301\n",
      "     88        4.0315       0.9444        4.0913  6.4119\n",
      "     89        4.0314       0.9460        \u001b[35m4.0909\u001b[0m  6.4108\n",
      "     90        4.0314       0.9440        4.0912  6.4231\n",
      "     91        \u001b[36m4.0311\u001b[0m       0.9460        \u001b[35m4.0908\u001b[0m  6.4368\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "training time(average of 10 iterations)\n",
      "573.6046422004699\n",
      "validation prediction time (average of 100 iterations)\n",
      "0.36831582069396973\n",
      "OOS prediction time (average of 100 iterations)\n",
      "{50: 0.010187678337097168}\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "hidden_dim = 800 #hidden layer size\n",
    "dropout = 0.75\n",
    "\n",
    "print(hidden_dim)\n",
    "class CLINCModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim=vocab_dim,\n",
    "            hidden_dim=hidden_dim, #setting hidden layer size\n",
    "            output_dim=output_dim,\n",
    "            dropout=dropout\n",
    "    ):\n",
    "        super(CLINCModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = F.relu(self.hidden(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "module=CLINCModule,\n",
    "lr=lr,\n",
    "criterion=torch.nn.CrossEntropyLoss,\n",
    "max_epochs=1000,\n",
    "optimizer=torch.optim.Adam, #Adam again - momentum has been removed accordingly.\n",
    "callbacks=[EarlyStopping(patience=10)],\n",
    ")\n",
    "timet0 = time.time()\n",
    "for i in range(10): #taking average over 10 full optimizations\n",
    "    net.fit(train_x, train_y)\n",
    "timet1 = time.time()\n",
    "t_time = (timet1-timet0)/10\n",
    "print('training time(average of 10 iterations)')\n",
    "print(t_time)\n",
    "\n",
    "time0 = time.time()\n",
    "for i in range(100): #taking average over 100 predictions\n",
    "    labels = net.predict(val_x)\n",
    "time1 = time.time()\n",
    "vtime = (time1-time0)/100\n",
    "print('validation prediction time (average of 100 iterations)')\n",
    "print(vtime)\n",
    "\n",
    "\n",
    "time2 = time.time()\n",
    "for i in range(100): #taking average over 100 predictions\n",
    "    olabels = net.predict(val_oos_x)\n",
    "time3 = time.time()\n",
    "otime[patience]=(time3-time2)/100\n",
    "print('OOS prediction time (average of 100 iterations)')\n",
    "print(otime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
